[
{"title": "Помещаем строки в параметры шаблонов", "article_text": "Современный C++ принес нам кучу возможностей, которых раньше в языке остро не хватало. Чтобы хоть как-то получить подобный эффект на протяжении долгого времени изобретались потрясающие костыли, в основном состоящие из очень больших портянок шаблонов и макросов (зачастую еще и автогенеренных). Но и сейчас время от времени возникает потребность в возможностях, которых все еще нет в языке. И мы начинаем снова изобретать сложные конструкции из шаблонов и макросов, генерировать их и достигать нужного нам поведения. Это как раз такая история.\r\nЗа последние пол-года мне дважды понадобились значения, которые можно было бы использовать в параметрах шаблона. При этом хотелось иметь человеко-читаемые имена для этих значений и исключить необходимость в объявлении этих имен заранее. Конкретные задачи, которые я решал — отдельный вопрос, возможно позже я еще напишу про них отдельные посты, где-нибудь в хабе «ненормальное программирование». Сейчас же я расскажу о подходе, которым я решал эту задачу.\r\nИтак, когда речь идет о параметрах шаблонов, мы можем использовать либо тип, либо static const значение. Для большинства задач этого более-чем достаточно. Хотим использовать в параметрах человеко-читаемые идентификаторы — объявляем структуру, перечисление или константу и используем их. Проблемы начинаются тогда, когда мы не можем заранее определить этот идентификатор и хотим сделать это на месте.\r\nМожно было бы задекларировать структуру или класс прямо в параметре шаблона. Это даже будет работать, если шаблон не будет делать с этим параметром чего-либо, что требует полного описания структуры. К тому же, мы не можем контролировать пространство имен, в котором декларируется такая структура. И полностью одинаковые на вид подстановки шаблонов будут превращаться в совершенно разный код, если эти строчки находятся в соседних классах или пространствах имен.\r\nНужно использовать литералы, а из всех литералов в C++ читаемыми можно назвать только символьный литерал и строковой литерал. Но символьный литерал ограничен четырьмя символами (при использовании char32_t), а строковой литерал является массивом символов и его значение нельзя передать в параметры шаблона.\r\nПолучается какой-то замкнутый круг. Нужно либо объявлять что-то заранее, либо использовать неудобные идентификаторы. Попробуем добиться от языка того, к чему он не приспособлен. Что если имплементировать макрос, который сделает из строкового литерала что-то пригодное для использования в аргументах шаблона?\r\nДля начала сделаем основу для строки. В C++11 появились variadic template arguments. \r\nОбъявляем структуру, которая в аргументах содержит символы строки:\r\nЭто работает. Мы даже можем сразу использовать такие строки примерно вот так:\r\nОтлично. Было бы не плохо уметь доставать значение этой строки в рантайме. Пусть будет дополнительная шаблонная структура, которая будет извлекать аргументы из такой строки и делать из них константу:\r\nЭто тоже работает. Так как строки у нас не содержат '\\0' на конце, нужно достаточно аккуратно оперировать с этой константой (лучше, на мой взгляд, сразу создавать string_view используя в аргументах конструктора константу и sizeof от нее). Можно было бы просто добавить '\\0' в конце массива, но для моих задач это не нужно.\r\nЛадно, что еще можно делать с такими строками? Например конкатенировать:\r\nВ принципе, можно сделать боле-менее любую операцию (я не пробовал, так как мне не нужно, но примерно представляю, как можно сделать поиск подстроки или даже замену подстроки).\r\nТеперь у нас остался главный вопрос, как в compile-time извлечь символы из строкового литерала и положить их в аргументы шаблона.\r\nНачнем со способа положить символы в аргументы шаблона по одному:\r\nЯ использую отдельную специализацию для символа '\\0', чтобы не добавлять его в используемую строку. К тому же, это несколько упрощает другие части макроса.\r\nХорошая новость — строковой литерал может быть параметром constexpr функции. Напишем функцию, которая вернет символ по индексу в строке либо '\\0', если длина строки меньше, чем индекс (вот тут пригодится специализация PushBackCharacter для символа '\\0').\r\nВ принципе, мы уже можем писать нечто вроде этого:\r\nПомещаем такую портянку, да подлиньше (мы же умеем писать скрипты для генерации кода) внутрь нашего макроса, и все!\r\nЕсть нюанс. Если количество символов в строке окажется больше, чем уровней вложенности в макросе, строчка просто обрежется и мы этого даже не заметим. Непорядок.\r\nСделаем еще одну структуру, которая никак не преобразовывает поступившую в нее строку, но делает static_assert, что ее длина не превышает константу:\r\nНу и макрос будет выглядеть примерно вот так:\r\nРеализацию, которая получилась у меня, можно .\r\nМне было бы очень интересно услышать о возможных применениях этого механизма, отличных от тех, что придумал я.", "url": "https://habr.com/ru/post/438146/"},
{"title": "Рисуем мультяшный взрыв за 180 строчек голого C++", "article_text": "Неделю назад я  из моего ; сегодня опять возвращаемся к трассировке лучей, но на сей раз пойдём самую чуточку дальше отрисовки тривиальных сфер. Фотореалистичность мне не нужна, для мультяшных целей , как мне кажется, сойдёт.\r\nКак всегда, в нашем распоряжении только голый компилятор, никаких сторонних библитек использовать нельзя. Я не хочу заморачиваться с оконными менеджерами, обработкой мыши/клавиатуры и тому подобным. Результатом работы нашей программы будет простая картинка, сохранённая на диск. Я совершенно не гонюсь за скоростью/оптимизацией, моя цель — показать основные принципы.\r\nИтого, как в таких условиях нарисовать вот такую картинку за 180 строчек кода?\r\nДавайте я даже анимированную гифку вставлю (шесть метров):\r\nА теперь разобьём всю задачу на несколько этапов:\r\nДа, именно так. Самым первым делом нужно прочитать , которая рассказывает об основах трассировки лучей. Она совсем короткая, в принципе, всякие отражения-преломления можно не читать, но хотя бы до рассеянного освещения дочитать всё же рекомендую. Код достаточно простой, народ его даже на микроконтроллерах запускает:\r\nДавайте нарисуем одну сферу, не заморачиваясь ни материалами, ни освещением. Для простоты эта сфера будет жить в центре координат. Примерно вот такую картинку я хочу получить:\r\nКод смотреть , но давайте я приведу основной прямо в тексте статьи:\r\nКласс векторов живёт в файле geometry.h, описывать я его здесь не буду: во-первых, там всё тривиально, простое манипулирование двух и трёхмерными векторами (сложение, вычитание, присваивание, умножение на скаляр, скалярное произвдение), а во-вторых,  его уже  в рамках курса лекций по компьютерной графике.\r\nКартинку я сохраняю в ; это самый простой способ сохранения изображений, хотя и не всегда самый удобный для дальнейшего просматривания.\r\nИтак, в функции main() у меня два цикла: второй цикл просто сохраняет картинку на диск, а первый цикл — проходит по всем пикселям картинки, испускает луч из камеры через этот пиксель, и смотрит, не пересекается ли этот луч с нашей сферой.  если в прошлой статье мы аналитически считали пересечение луча и сферы, то сейчас я его считаю численно. Идея простая: сфера имеет уравнение вида x^2 + y^2 + z^2 — r^2 = 0; но вообще функция f(x,y,z) = x^2 + y^2 + z^2 — r^2 определена во всём пространстве. Внутри сферы функция f(x,y,z) будет иметь отрицательные значения, а снаружи сферы положительные. То есть, функция f(x,y,z) задаёт для точки (x,y,z) расстояние (со знаком!) до нашей сферы. Поэтому мы просто будем скользить вдоль луча до тех пор, пока либо нам не надоест, либо функция f(x,y,z) станет отрицательной. Функция sphere_trace() именно это и делает. \r\nДавайте закодим простейшее диффузуное освещение, вот такую картинку я хочу получить на выходе:\r\nКак и в прошлой статье, для простоты чтения я сделал один этап = один коммит. Изменения можно . \r\nДля диффузного освещения нам мало посчитать точку пересечения луча с поверхностью, нам нужно знать вектор нормали к поверхности в этой точке. Я этот нормальный вектор получил простыми  по нашей функции расстояния до поверхности:\r\nВ принципе, конечно, поскольку мы рисуем сферу, то нормаль можно получить гораздо проще, но я сделал так с заделом на будущее.\r\nА давайте нарисум какой-нибудь паттерн на нашей сфере, например, вот такой:\r\nДля этого в предыдущем коде я изменил \r\nКак я это сделал? Разумеется, у меня нет никаких текстур. Я просто взял функцию g(x,y,z) = sin(x) * sin(y) * sin(z); она опять же определена во всём пространстве. Когда мой луч пересекает сферу в какой-то точке, то значение функции g(x,y,z) в этой точке мне задаёт цвет пикселя.\r\nКстати, обратите внимание на концентрические круги по сфере — это артефакты моего численного подсчёта пересечения.\r\nДля чего я захотел нарисовать этот паттерн? А он мне поможет нарисовать вот такого ёжика:\r\nТам, где мой паттерн давал чёрный цвет, я хочу продавить ямку на нашей сфере, а где он был белым, там наоборот, вытянуть горбик.\r\nЧтобы это сделать, достаточно  в нашем коде:\r\nТо есть, я изменил расчёт расстояния до нашей поверхности, определив его как x^2+y^2+z^2 — r^2 — sin(x)*sin(y)*sin(z). По факту, мы определили .\r\nА почему это я оцениваю произведение синусов только для точек, лежащих на поверхности нашей сферы? Давайте переопределим нашу неявную функцию вот так:\r\nРазница с предыдущим кодом совсем маленькая, лучше . Вот что получится в итоге:\r\nТаким образом мы можем определять несвязные компоненты в нашем объекте!\r\nПредыдущая картинка уже начинает отдалённо напоминать взрыв, но произведение синусов имеет слишком регулярный паттерн. Нам бы какую-нибудь боолее «рваную», более «случайную» функцию… На помощь нам придёт . Вот что-нибудь такое нам бы подошло гораздо лучше произведения синусов:\r\nКак генерировать подобный шум — немного оффтоп, но вот основная идея: нужно сгенерировать случайных картинок с разными разрешениями, сгладить их, чтобы получить примерно такой набор:\r\nА потом просто их просуммировать:\r\nПодробнее прочитать можно  и .\r\nДавайте , генерирующего этот шум, и получим такую картинку:\r\nОбратите внимание, что в коде рендеринга я не изменил вообще ничего, изменилась только функция, которая «мнёт» нашу сферу.\r\nЕдинственное, что я , это вместо равномерного белого цвета я наложил цвет, который линейно зависит от величины приложенного шума:\r\nЭто простой линейный градиент между пятью ключевыми цветами. Ну а вот картинка!\r\nЭта техника трассировки лучей называется ray marching. Домашнее задание простое: скрестить предыдущий рейтрейсер с блэкджеком и отражениями с нашим взрывом, да так, чтобы взрыв ещё и освещал всё вокруг! Кстати, этому взрыву сильно не хватает полупрозрачности.", "url": "https://habr.com/ru/post/437714/"},
{"title": "Реализация горячей перезагрузки С++ кода в Linux и macOS: копаем глубже", "article_text": "*Ссылка на библиотеку и демо видео в конце статьи. Для понимания того, что происходит, и кто все эти люди, рекомендую прочитать .В прошлой статье мы ознакомились с подходом, позволяющим осуществлять \"горячую\" перезагрузку c++ кода. \"Код\" в данном случае — это функции, данные и их согласованная работа друг с другом. С функциями особых проблем нет, перенаправляем поток выполнения из старой функции в новую, и все работает. Проблема возникает с данными (статическими и глобальными переменными), а именно со стратегией их синхронизации в старом и новом коде. В первой реализации эта стратегия была очень топорной: просто копируем значения всех статических переменных из старого кода в новый, чтобы новый код, ссылаясь на новые переменные, работал со значениями из старого кода. Конечно это некорректно, и сегодня мы попытаемся исправить этот изъян, попутно решив ряд небольших, но интересных задач.В статье опущены детали, касающиеся механической работы, например чтение символов и релокаций из elf и mach-o файлов. Упор делается на тонких моментах, с которыми я столкнулся в процессе реализации, и которые могут быть полезны кому-то, кто, как и я недавно, ищет ответы.Давайте представим, что у нас есть класс (примеры синтетические, прошу не искать в них смысла, важен только код):Ничего особенного, кроме статической переменной. Теперь представим, что мы хотим изменить метод  на такой:Что произойдет после перезагрузки кода? В библиотеку с новым кодом, кроме методов класса , попадет и статическая переменная . Ничего страшного не случится, если мы просто скопируем значение этой переменной из старого кода в новый, и продолжим пользоваться новой переменной, забыв о старой, ведь все методы, которые используют эту переменную напрямую, находятся в библиотеке с новым кодом.C++ очень гибок и богат. И пусть элегантность решения некоторых задач на c++ граничит с дурно пахнущим кодом, я люблю этот язык. Например, представьте, что в вашем проекте не используется rtti. В то же время вам нужно иметь реализацию класса  со сколь-нибудь типобезопасным интерфейсом:Не будем вдаваться в детали реализации этого класса. Нам важно лишь то, что для реализации нам нужен какой-то механизм для однозначного отображения типа (compile-time сущность) в значение переменной, например  (runtime сущность), то есть \"пронумеровать\" типы. При использовании rtti нам доступны такие вещи, как  и, что больше нам подходит, . Но у нас нет rtti. В этом случае достаточно распространенным хаком (или элегантным решением?) является такая функция:Тогда реализация класса  будет выглядеть как-то так:Для каждого типа функция будет инстанцироваться ровно 1 раз, соответственно в каждой версии функции будет своя статическая переменная, очевидно со своим уникальным адресом. Что же произойдет, когда мы перезагрузим код, использующий эту функцию? Вызовы старой версии функции будут перенаправляться в новую. В новой будет лежать своя статическая переменная, уже проинициализированная (мы скопировали значение и guard variable). Но нас не интересует значение, мы используем только адрес. И адрес у новой переменной будет другой. Таким образом данные стали несогласованными: в уже созданных экземплярах класса  будет храниться адрес старой статической переменной, а метод  будет сравнивать его с адресом новой, и \"эта  уже не будет прежней \" ©.Чтобы решить эту проблему, нужно что-то более умное, чем простое копирование. Потратив пару вечеров на гугление, чтение документации, исходников и системных api, в голове выстроился следующий план:В этом случае не останется ссылок на новые данные, все приложение продолжит работать со старыми версиями переменных с точностью до адреса. Это должно сработать. Это не может не сработать.Когда компилятор генерирует машинный код, он в каждое место, в котором происходит либо вызов функции, либо загрузка адреса переменной, вставляет несколько байт, достаточных для записи в это место реального адреса переменной или функции, а также генерирует релокацию. Он не может сразу записать реальный адрес, поскольку на этом этапе ему этот адрес неизвестен. Функции и переменные после линковки могут оказаться в разных секциях, в разных местах секций, в конце концов секции могут быть загружены по разным адресам во время выполнения. Релокация содержит информацию:В разных ОС релокации представлены по-разному, но в итоге они все работают по одному принципу. Например, в elf (Linux) релокации расположены в специальных секциях  (в 32-битной версии это ), которые ссылаются на секцию с адресом, который нужно исправить (например,  — секция, в которой находятся релокации, применяемые к секции ), а каждая запись хранит информацию о символе, адрес которого нужно вставить в место релокации. В mach-o (macOS) все немного наоборот, здесь нет отдельной секции для релокаций, вместо этого каждая секция содержит указатель на таблицу релокаций, которые должны быть применены к этой секции, и в каждой записи этой таблицы есть ссылка на релоцируемый символ.\r\nНапример, для такого кода (с опцией ):компилятор создаст такую секцию с релокациями на Linux:и такую таблицу релокаций на macOS:А вот так выглядит функция  (в Linux):и так после линковки объектника в динамическую библиотеку:В ней 4 места, в которых зарезервировано по 4 байта для адреса реальных переменных.На разных системах набор возможных релокаций свой. В Linux на x86-64 целых . На macOS на x86-64 их . Все типы релокаций условно можно поделить на 2 группы:Во вторую группу попадают релокации экспортируемых функций и переменных. Когда динамическая библиотека загружается в память процесса, для всех динамических релокаций (сюда попадают в том числе релокации глобальных переменных) линковщик ищет определение символов во всех уже загруженных библиотеках, в том числе в самой программе, и адрес первого подходящего символа используется для релокации. Таким образом с этими релокациями ничего делать не нужно, линковщик сам найдет переменную из нашего приложения, поскольку оно попадется ему раньше в списке загруженных библиотек и программ, и подставит ее адрес в новый код, проигнорировав новую версию этой переменной.Есть тонкий момент, связанный с macOS и его динамическим линковщиком. В macOS реализован так называемый механизм двухуровнего пространства имен (two-level namespace). Если грубо, то при загрузке динамической библиотеки линковщик в первую очередь будет искать символы в этой библиотеке, и если не найдет, пойдет искать в других. Это сделано в целях производительности, чтобы релокации разрешались быстро, что, в общем-то, логично. Но это ломает наш флоу касательно глобальных переменных. К счастью, в ld на macOS есть специальный флаг — , и если собрать библиотеку с этим флагом, то алгоритм поиска символов будет идентичен таковому в Linux.В первую же группу попадают релокации статических переменных — именно то, что нам нужно. Единственная проблема в том, что эти релокации отсутствуют в собранной библиотеке, поскольку они уже разрешены линковщиком. Поэтому читать их будем из объектных файлов, из которых была собрана библиотека.\r\nНа возможные типы релокаций также накладывает ограничение то, является ли собранный код position-dependent или нет. Поскольку мы собираем наш код в режиме PIC (position-independent code), то и релокации используются только относительные. Итого интересующие нас релокации — это:Тонкий момент, связанный с секцией . В Linux также есть аналогичная секция . В  могут попасть глобальные переменные. Но, пока я тестировал и компилировал кучу фрагментов кода, на Linux релокации символов из  секции всегда были динамическими, как у обычных глобальных переменных. В то же время в macOS такие символы иногда релоцировались во время линковки, если функция и символ находятся в одном файле. Поэтому на macOS имеет смысл учитывать и эту секцию при чтении символов и релокаций.Отлично, теперь у нас есть набор всех нужных нам релокаций, что же с ними делать? Логика тут простая. Когда линковщик линкует библиотеку, он по адресу релокации записывает адрес символа, вычисленный по . Для наших релокаций на обеих платформах эта формула содержит адрес символа в качестве слагаемого. Таким образом вычисленный адрес, уже записанный в тело функций, имеет вид:В то же время мы знаем адреса обеих версий переменных — старых, уже живущих в приложении, и новых. Нам осталось изменить его по формуле:и записать его по адресу релокации. После этого все функции в новом коде будут использовать уже существующие версии переменных, а новые переменные просто будут лежать и ничего не делать. То, что надо! Но есть один тонкий момент.Когда система загружает динамическую библиотеку в память процесса, она вольна разместить ее в любое место виртуального адресного пространства. У меня на Ubuntu 18.04 приложение загружается по адресу , а наши динамические библиотеки — сразу после  по адресам в районе . Расстояние между адресами загрузки программы и библиотеки сильно больше числа, которое бы влезло в знаковый 32-битный integer. А в link-time релокациях резервируется только 4 байта для адресов целевых символов.Покурив документацию к компиляторам и линковщикам, я решил попробовать опцию . Она заставляет компилятор генерировать код без каких-либо предположений о расстоянии между символами, тем самым все адреса подразумеваются 64-битными. Но эта опция не дружит с PIC, как будто  нельзя использовать вместе с , по крайней мере на macOS. Я так и не понял, в чем проблема, возможно на macOS нет подходящих релокаций для такой ситуации.В библиотеке под windows эта проблема решается так. Руками выделяется кусок виртуальной памяти недалеко от места загрузки приложения, достаточный, чтобы разместить нужные секции библиотеки. Затем в него руками грузятся секции, выставляются нужные права страницам памяти с соответствующими секциями, руками разруливаются все релокации, и производится патчинг всего остального. Я ленив. Мне очень не хотелось делать всю эту работу с load-time релокациями, особенно на Linux. Да и зачем делать то, что уже умеет делать динамический линковщик? Ведь люди, которые его писали, знают гораздо больше, чем я.К счастью, в документации нашлись нужные опции, позволяющие указать, куда следует загрузить нашу динамическую библиотеку:Эти опции нужно передавать линковщику в момент линковки динамической библиотеки. Тут есть 2 сложности.\r\nПервая связана с GNU ld. Для того, чтобы эти опции сработали, нужно, чтобы:То есть если линковщик выставил выравнивание в , то эту библиотеку не получится загрузить по адресу , даже с учетом того, что адрес выровнен по размеру страницы. Если одно из этих условий не выполнится, библиотека загрузится \"как обычно\". У меня в системе GNU ld 2.30, и, в отличие от LLVM lld, он по умолчанию выставляет выравнивание сегмента  в , что сильно выбивается из общей картины. Чтобы обойти это, нужно кроме опции  указать . Я потратил день, пока не понял, почему библиотека не грузится туда, куда надо.Вторая сложность — адрес загрузки должен быть известен на этапе линковки библиотеки. Это не очень сложно организовать. В Linux достаточно распарсить псевдо-файл , найти ближайший к программе незанятый кусок, в который влезет библиотека, и адрес начала этого куска использовать при линковке. Размер будущей библиотеки можно примерно прикинуть, посмотрев на размеры объектных файлов, либо распарсив их и посчитав размеры всех секций. В конце концов нам нужно не точное число, а примерный размер с запасом.В macOS нет , вместо этого предлагается воспользоваться утилитой . Вывод команды  содержит ту же информацию, что и . Но тут возникает другая сложность. Если в приложении породить дочерний процесс, который выполнит эту команду, и в качестве  будет указан идентификатор текущего процесса, то программа намертво повиснет. Насколько я понял,  останавливает процесс, чтобы прочитать его маппинги памяти, и, видимо, если это вызывающий процесс, то что-то идет не так. На этот случай нужно указывать дополнительный флаг , чтобы  создал пустой дочерний процесс от нашего процесса, снял с него маппинг и убил его, тем самым не прерывая программу.В общем-то это все, что нам нужно знать.С этими модификациями итоговый алгоритм перезагрузки кода выглядит так:В шаг 8 попадают только guard variables статических переменных, поэтому их смело можно копировать (тем самым сохраняя \"инициализированность\" самих статических переменных).Поскольку это исключительно инструмент для разработки, не предназначенный ни для какого продакшна, самое страшное, что может случиться, если очередная библиотека с новым кодом не влезет в память, либо случайно загрузится по другому адресу, это перезапуск отлаживаемого приложения. При прогонке тестов в память по очереди грузится 31 библиотека с обновленным кодом.Для полноты картины в реализации не хватает еще 3 увесистых кусков:Но уже текущая реализация лично мне начала приносить пользу, ее достаточно для использования на моей основной работе. Нужно немного привыкнуть, но полет нормальный.\r\nЕсли я доберусь до этих трех пунктов и найду в их реализации достаточное количество интересного, обязательно поделюсь.Поскольку реализация позволяет добавлять новые единицы трансляции налету, я решил записать небольшое видео, в котором я с нуля пишу неприлично простую игру про космический корабль, бороздящий просторы вселенной и расстреливающий квадратные астероиды. Писать старался не в стиле \"все в одном файле\", а по возможности раскладывая все по полочкам, тем самым порождая множество небольших файлов (поэтому вышло так много писанины). Конечно, для рисования, инпутов, окна и прочего используется фреймворк, но код самой игры писался с нуля.\r\nОсновная фишка — я только 3 раза запускал приложение: в самом начале, когда в нем была только пустая сцена, и 2 раза после падения по моей неосторожности. Вся игра инкрементально подливалась в процессе написания кода. Реального времени — около 40 минут. В общем, милости прошу.Как всегда, буду рад любой критике, спасибо!", "url": "https://habr.com/ru/post/437312/"},
{"title": "О создании бюджетных стереоизображений на пальцах (стереограмма, анаглиф, стереоскоп)", "article_text": "Пришли очередные выходные, надо написать пару десятков строк кода и нарисовать картинку, да лучше не одну. Итак, на прошлых и позапрошлых выходных я показал, как  и даже  Это многих удивляет, но комьпютерная графика — очень простая вещь, пары сотен строк голого C++ вполне хватает на создание интересных картинок.\r\nТема сегдоняшнего разговора — бинокулярное зрение, причём сегодня даже до ста строк кода не дотянем. Умея рендерить трёхмерные сцены, было бы глупо пройти мимо стерепар, сегодня будем рисовать примерно вот такое:\r\nБезумие разработчиков  не даёт мне покоя. Для тех, кто не застал, эта игра позволяла делать 3Д рендер и в анаглиф, и в стереограммы  Мозг это взрывало просто конкретно.\r\nИтак, приступим. Для начала, благодаря чему вообще наш зрительный аппарат позволяет воспринимать глубину? Есть такое умное слово «параллакс». Если на пальцах, то давайте сфокусируем взгляд на экране. Всё, что находится в плоскости экрана, для нашего мозга существует в единичном экземпляре. А вот если вдруг муха пролетит перед экраном, то (если мы не меняем взгляда!) наш мозг её зарегистрирует в двух экземплярах. А заодно и паук на стене за экраном тоже раздваивается, причём направление раздвоения зависит от того, находится объект перед точкой фокуса или позади:\r\nНаш мозг — это очень эффективная машина для анализа слегка отличающихся изображений. Он использует  для получения информации о глубине из двумерных изображений сетчатки для . Ну да бог с ними, со словами, давайте лучше картинки рисовать!\r\nДавайте преставим, что наш экран — это окно в виртуальный мир :)\r\nНаша задача — нарисовать две картинки с тем, что будет видно через это «окно». Картинок будет две, по одной на каждый глаз, на схеме выше я их показал красно-синим «бутербродом». Давайте пока не будем заморачиваться, как именно мы скормим эти картинки зрительному аппарату, нам нужно просто сохранить два файла. Конкретно меня интересует, как эти изображения можно получить при помощи .\r\nНу, положим, направление взляда не меняется, это вектор (0,0,-1). Допустим, положение камеры мы можем сдвинуть на межглазное расстояние, что же ещё? Есть одна маленькая тонкость: конус взгляда через наше «окно» несимметричен. А наш рейтрейсер умеет рендерить только симметричный конус взгляда:\r\nЧто же делать? Читить :)\r\nНа самом деле, мы можем отрендерить картинки шире, нежели нам нужно, и просто обрезать лишнее:\r\nС общим механизмом рендеринга должно быть понятно, теперь самое время задаться вопросом доставки изображения до нашего мозга. Один из самых простых вариантов это красно-синие очки:\r\nМы просто сделаем два пре-рендера не цветными, а чёрно-белыми, левую картинку запишем в красный канал, а правую — в синий. Получится вот такая картинка:\r\nКрасное стекло отрежет один канал, а синее стекло отрежет другой, таким образом, глаза получат каждый свою картинку, и мы можем посмотреть на мир в 3D. Вот тут , которые показывают и установки камеры для обоих глаз, и сборку каналов.\r\nАнаглифные рендеры — один из самых древних способов просмотра (компьютерных!) стереокартинок. У них много недостатков, например, плохая цветопередача (кстати, попробуйте в зелёный канал финальной картинки записать зелёный канал правого глаза). Одна польза — такие очки легко сделать из подручных материалов.\r\nС массовым распространением смартфонов мы вспомнили, что такое стереоскопы (которые, на секундочку, были изобретены в 19м веке)! Несколько лет назад  использовать две копеечные линзы (к сожалению, на коленке не делаются), немного картона (валяется повсюду) и смартфон (лежит в кармане) для получения вполне сносных очков виртуальной реальности:\r\nНа алиэкспрессе их завались, сто рублей штука. По сравнению с анаглифом делать вообще ничего не надо, просто взять две картинки и составить их бок-о-бок, . \r\nСтрого говоря, в зависимости от линзы, может понадобиться , но я вообще не заморачивался, и на моих очках и так выглядит отлично. Но если очень нужно применить бочкообразное пред-искажение, которое компенсирует искажения от линзы, то вот вот так оно выглядит для моего смартфона и для моих очков:\r\nА что же делать, если вообще не хочется использовать дополнительных приборов? Тогда вариант один — окосеть. Вообще говоря, предыдущей картинки вполне хватает для просмотра стерео, достаточно использовать трюк для просмотра стереограмм. Принципов просмотра стереограмм два: либо сдвигать глаза, либо раздвигать. Вот я нарисовал схему, на которой показываю, как можно смотреть на предыдущую картинку. Предыдущая картинка двойная, два красных штриха на схеме показывают два изображения на левой сетчатке, два синих — на правой.\r\nЕсли мы сфокусируем взгляд на экране, то из четырёх изображений у нас получится два. Если скосим глаза к носу, то вполне возможно показать мозгу «три» картинки. И наоборот, если раздвинуть глаза, то тоже можно получить «три» картинки. Наложение центральных картинок и даст мозгу стереоэффект.\r\nРазным людям эти приёмы даются по-разному, я, например, совсем не умею глаза сдвигать, зато с лёгкостью развожу. Важно то, что стереограмма построенная для одного способа, должна этим же способом и просматриваться, иначе получается инвертированная карта глубин (см. отрицательный и положительный параллакс). Проблема такого способа просмотра стерео в том, что очень сложно  сдвинуть глаза относительно нормального состояния, поэтому приходится довольствоваться маленькими картинками. А что делать, если хочется больших? Давайте полностью пожертвуем цветом, и захотим получить только восприятие глубины. Забегая вперёд, вот картинка, которую мы получим в конце этой части:\r\nЭта стереогрмма создана для «разведения» глаз (wall-eyed stereogram). Тем, кто предпочитает обратный способ просматривания, . Если вы не привыкли к стереограммам, попробуйте разные условия: картинка на полный экран, маленькая картинка, яркий свет, темнота. Задача развести глаза так, чтобы две соседние вретикальные полоски совпали. Проще всего фокусироваться на левой верхней части картинки, т.к. она плоская. Мне, например, мешает окружение хабра, я открываю картинку на полный экран. Не забудьте с неё убрать мышку!\r\nНе довольствуйтесь неполноценным 3D-эффектом. Если вы только смутно осознаёте округлые формы посреди случайных точек наряду с некоторыми слабыми 3D-эффектами, это, конечно, неполная иллюзия! Если смотреть правильно, шарики должны явно выйти из плоскости экрана на зрителя, эффект должен быть стабильным и сохраняться благодаря постоянному и детальному изучению каждой части изображения, как переднего плана, так и фона. У стереопсиса есть гистерезис: как только удаётся получить стабильное изображение, оно становится тем яснее, чем дольше вы смотрите. Чем дальше экран от глаз, тем больше эффект глубины. \r\nЭта стереограмма нарисована по методу, предложенному четверть века назад Thimbleby и др. в их статье «».\r\nОтправной точкой для отрисовки стереограмм является карта глубины (мы же забыли про цвет). , который рендерит вот такую картинку:\r\nГлубины в нашем рендере обрезаны ближней и дальней плоскостями, то есть, самая дальняя точка в моей карте имеет глубину 0, самая ближняя 1.\r\nПусть у нас глаза находятся на расстоянии d от экрана. Поместим (воображаемую) дальнюю плоскость (z=0) на том же расстоянии позади экрана. Выберем постоянную μ, которая определит положение ближней плоскости (z=0): она будет на расстоянии μd от дальней. Я в своём коде выбрал μ=1/3. Итого, весь наш мир живёт на расстоянии от d-μd до d за экраном. Пусть у нас определено расстояние e между глазами (в пикселях, в моём коде я выбрал 400 пикселей).\r\nЕсли мы смотрим на точку нашего объекта, отмеченную на схеме красным, то два пикселя, отмеченных зелёным, должны иметь одинаковый цвет в стереограмме. Как найти расстояние между этими пикселями? Очень просто. Если текущая проецируемая точка имеет глубину z, то отношение параллакса к расстоянию между глазами равно отношениям соответствующих глубин: p/e = (d-dμz)/(2d-dμz). Кстати, обратите внимание, что d сокращается и более нигде не участвует! То есть, p/e = (1-μz)/(2-μz), а это означает, что параллакс равняется p=e*(1-μz)/(2-μz) пикселей.\r\nТо есть, основной принцип построения стереограммы: мы проходим по всей карте глубины, для каждого значения глубины мы определяем, какие пиксели должны иметь одинаковый цвет, и записываем это в нашу систему ограничений. После чего стартуем с произвольной картинки, и стараемся выполнить все ранее наложенные ограничения.\r\nВ этом этапе мы подготовим картинку, на которую позже наложим ограничения параллакса. , он рисует вот такую картинку:\r\nОбратите внимание, что в целом цвета просто случайные, за исключением того, что я в красном канале положил rand()*sin, чтобы обеспечить периодические волны. Эти волны сделаны с расстоянием в 200 пикселей, это (при выбранных μ=1/3 и e=400) максимальное значение параллакса в нашем мире, оно же дальняя плоскость. Эти волны необязательны, но они облегчат нужную фокусировку зрения.\r\nСобственно, полный код, относящийся к стереограмме, выглядит вот так:\r\nЕсли что, то . Функция int parallax(const float z) даёт расстояние между пикселями одинакового цвета для текущего значения глубины. Мы рендерим стереограмму построчно, так как строчки независимы между собой (у нас нет вертикального параллакса). Поэтому основной цикл просто пробегает все строчки; для каждой из них мы начинаем с полного неограниченного набора пикселей, на который затем будем накладывать попарные ограничения равенства, и в итоге у нас окажется некое количество кластеров (несвязных) пикселей одного цвета. Например, пиксель с индеком left и пиксель с индексом right должны в итоге оказаться одинаковыми.\r\nКак хранить этот набор ограничений? Самый простой ответ — . Её я описывать не буду, это и так только три строчки кода, можно прочитать в википедии. Основная мысль в том, что для каждого кластера у нас окажется некий «ответственный» за него, он же коренной, пиксель, его мы оставим того цвета, какого он был в исходной картинке, а все остальные пиксели кластера перекрасим:\r\nНу, собственно, и всё. Двадцать строчек кода — и наша стереограмма готова, ломайте глаза и головы, рисуйте картинки! Кстати, просто случайные цвета в стереограмме — это вообще роскошь, в принципе, если постараться, то можно сделать и частичную передачу цвета нашей картинки.\r\nДругие системы просмотра стерео, например, , я вынес за рамки обсуждения, так как они выходят из бюджета ста рублей. Если что упустил, дополняйте и поправляйте!", "url": "https://habr.com/ru/post/438646/"},
{"title": "Форматирование исходного кода в Linux средствами ClangFormat: проблемы и решение", "article_text": "\r\nСогласитесь, приятно и полезно, когда в проекте исходный код выглядит красиво и единообразно. Это облегчает его понимание и поддержку. Покажем и расскажем, как реализовать форматирование исходного кода при помощи ,  и .\r\n \r\n \r\nВ результате получился следующий sh-скрипт, запускаемый как  — хук для git: \r\nЧто делает скрипт: — изменения в коде, которые подадут на вход \r\n \r\n  — команда для форматирования diff, полученного через стандартный ввод. — применение к коду патча, выданного предыдущей командой. — изменения форматера для индекса. форматирует исходный код в индексе (после ). К сожалению, нет такого хука, который срабатывал бы перед добавлением файлов в индекс. Поэтому форматирование разделено на две части: форматируется то, что в индексе и отдельно то, что не добавлено в индекс. — форматирование кода не в индексе (запускается, только когда что-то было отформатировано в индексе). Форматирует вообще все текущие изменения в проекте (под контролем версий), а не только из предыдущего шага. Это спорное, на первый взгляд, решение. Но оно оказалось удобным, т.к. рано или поздно другие изменения надо форматировать тоже. Можно заменить  опцией , которая заставит  менять файлы самостоятельно.\r\n \r\n \r\n  (который здесь ) выдаёт diff только тех файлов, что были добавлены в индекс. А  обращается к полным версиям файлов за пределами него. Поэтому, если изменить какой-то файл, сделать , а потом изменить тот же файл, то  будет генерировать патч для форматирования кода (в индексе) на основе отличающегося файла. Таким образом, файл после  и до коммита лучше не редактировать. \r\nВот пример такой ошибки:\r\n \r\n Скрипт должен сообщить , т.е.  не нашёл контекст патча, выданного . Если вы не поняли, в чём тут проблема, просто не меняйте файлы после  их и до . Если надо поменять, можете сделать коммит (без push) и потом  с новыми изменениями.\r\n \r\n \r\n \r\n \r\n Если хотите посмотреть, какие изменения сделает скрипт на ваших текущих правках (не в индексе), используйте  Также можно проверить, как будет работать скрипт на последних коммитах, например, на тридцати: . Данная команда должна была форматировать предыдущие коммиты, но по факту меняет только их id. Поэтому стоит проводить такие эксперименты в отдельной копии проекта! После она станет непригодной для работы.\r\n Субъективно, от такого решения гораздо больше пользы чем вреда. Но надо тестировать поведение  разных версий на коде вашего проекта, с конфигом для вашего стиля кода. \r\nК сожалению, такой же git-hook для Windows мы не делали. Предлагайте в комментариях, как это сделать там. А если нужна статья для быстрого старта с , советуем посмотреть .", "url": "https://habr.com/ru/post/433832/"},
{"title": "Как я Keras на C++ запускал", "article_text": "Не так давно передо мной встала производственная задача – запустить обученную модель нейронной сети  на нативном  коде. Как ни странно, решение оказалось вообще не тривиальным. В результате чего появилась собственная библиотека, дающая такую возможность. О том, как же это – нейросети на чистых крестах и будет сегодняшняя небольшая статья.Тем, кому не терпится – вот  репозитарий на github, с подробным описанием использования. Ну а всех остальных прошу под кат… В процессе работы мне понадобилась запустить обученную модель на  приложении . Но вот незадача: на сегодняшний день нет практически никакой возможности запустить модель Keras на C++.Вариант с вызовом  из  не представлялся мне хорошим. Еще одним вариантом было конвертация модели Keras в модель  и потом  и вызов API TF уже из C++ кода.Сей процесс метаморфозов хорошо описан в . Но с этим также возникают трудности. , TensorFlow собирается через . А сам безель штука капризная и отказался собираться под . , сам  довольно  штуковина, а мне хотелось чего-то более легкого и производительного. Могу лишь сказать, что на просторах github был найден , с нужным мне функционалом. Но, он не поддерживал актуальные версии  и . А попытки переделать его, не увенчались успехом: . Было принято писать свою реализацию…Включив рок потяжелее, закинувшись бутылкой  энергетика, я сел за код. Во многом в реализации этой библиотеки мне помог код TensorFlow, попытки реабилитации найденного на  кода, некоторые знания об алгоритмах и структурах данных  и хорошая музыка в ушах. Так или иначе библиотека была написана за одну ночь.Первая чать библиотеки – это  модуль для сохранения обученной модели в собственный  формат.Ничего сложного в этой операции нет. Мы просто читаем модель  и записываем побитово в файл: сначала , потом , потом  в формате .Теперь перейдем к самому вкусному – C++ реализации.Пользователю доступны 2 сущности  и .  –  На данный момент поддерживается максимальная размерность в  измерения.  каждого измерения хранится в поле  а  каждого элемента тензора – в . Из доступных методов можно выделить  и . Остальные операции вы можете посмотреть в исходном коде. После того как математика для тензоров была написана я приступил к реализации моделей. –  Для пользователя доступны 2 функции  и .Вот полный пример кода.На этом я думаю все. Приятного использования, а я пойду к любимому C# и Python писать нейросети дальше.Мне понравилось писать эту библиотеку. Когда пишешь все сам с нуля – больше понимаешь, а как оно работает… В планах добавить поддержку других архитектур и GPU…", "url": "https://habr.com/ru/post/438398/"},
{"title": "Настройка VSCODE под разработку для ARM на примере отладочной платы stm32f429i-disco", "article_text": "Всем привет!Сегодня рассмотрим настройку удобной и красивой среды разработки для программиста микроконтроллеров с помощью набора полностью бесплатных инструментов разработки.  Если готовы, то поехалиДля запуска vscode вызвать в терминале команду .\r\nЗаходим в раздел .\r\nИщем и устанавливаем следующие плагины:Открываем папку с проектом через меню .\r\nЗаходим в раздел . Вверху в выпадающей строке видим текст . Нажимаем на шестерёнку рядом с ней, выпадает меню с предложением создать конфигурацию для дебага, выбираем . В каталоге проекта создаётся скрытая папка , в которой создаётся файл с конфигурациями дебага . Если этот файл не открылся сам, открываем его руками: переходим в раздел  и в дереве выбираем этот файл. Настраиваем конфигурацию для openocd:Последние три свойства: расположение elf-файла, расположение svd-файла, путь к конфигу для openocd, — настраиваем под себя. Сохраняем файл  и снова идём в раздел , там убеждаемся, что в выпадающем меню появилась наша конфигурация. Далее возвращаемся в раздел  и в каталог  добавляем новый файл с именем , открываем его, пишем там следующее:Далее добавляем в  ещё один файл , открываем его и пишем там следующее:По нажатию  можно запускать отладку (не забудьте перед этим собрать проект, чтобы elf-файл был на нужном месте).", "url": "https://habr.com/ru/post/437760/"},
{"title": "«Современные» обедающие философы на C++ посредством акторов и CSP", "article_text": "Некоторое время назад ссылка на статью  распространилась по ресурсам вроде Reddit и HackerNews. Статья интересная, она показывает несколько решений этой известной задачи, реализованных на современном C++ с использованием task-based подхода. Если кто-то это статью еще не читал, то имеет смысл потратить время и прочесть ее.Однако, не могу сказать, что представленные в статье решения мне показались простыми и понятными. Вероятно это как раз из-за использования тасков. Слишком уж их много создается и диспетчируется посредством разнообразных диспетчеров/сериализаторов. Так что не всегда понятно, где, когда и какие задачи выполняются.При этом task-based подход не является единственным возможным для решения подобных задач. Почему бы не посмотреть, как задача \"обедающих философов\" решается посредством моделей Акторов и CSP?Посему попробовал посмотреть и реализовал несколько решений этой задачи как с использованием Акторов, так и с использованием CSP. Код этих решений можно найти . А под катом пояснения и объяснения, так что кому интересно, милости прошу под кат.У меня не было цели в точности повторить решения, показанные в той самой статье , тем более, что мне в них принципиально не нравится одна важная штука: по сути, в тех решениях \"философ\" ничего сам не делает. Он только говорит \"хочу есть\", а дальше либо ему кто-то магическим образом предоставляет вилки, либо говорит \"сейчас не получится\".Понятно, почему автор прибег к такому поведению: оно позволяет использовать одну и ту же реализацию \"философа\" совместно с разными реализациями \"протоколов\". Однако, мне лично кажется, что более интересно когда именно \"философ\" пытается взять сперва одну вилку, затем другую. И когда \"философ\" вынужден обрабатывать неудачные попытки захвата вилки.Именно такие реализации задачи \"обедающих философов\" я и попробовал сделать. При этом в некоторых решениях использовались те же самые подходы, что и в упомянутой статье (например, реализуемые протоколами ForkLevelPhilosopherProtocol и WaiterFair).Свои решения я строил на базе , что вряд ли удивит тех, кто читал мои статьи раньше. Если же кто-то про SObjectizer еще не слышал, то в двух словах: это один из немногих живых и развивающихся OpenSource \"акторных фреймворков\" для С++ (из прочих можно упомянуть так же  и ). Надеюсь, что приведенные примеры с моими комментариями будут достаточно понятными даже для незнакомых с SObjectizer-ом. Если нет, то я с удовольствием отвечу на вопросы в комментариях.Обсуждение реализованных решений начнем с тех, которые сделаны на базе Акторов. Сперва рассмотрим реализацию решения Эдсгера Дейкстры, затем перейдем к нескольким другим решениям и посмотрим, как отличается поведение каждого из решений.Эдсгер Дейкстра, мало того, что сформулировал саму задачу \"обедающих филофосов\" (формулировку оной с использованием \"вилок\" и \"спагетти\" озвучил Тони Хоар), так еще и предложил очень простое и красивое решение. А именно: философы должны захватывать вилки только в порядке увеличения номеров вилок и если философ сумел взять первую вилку, то он уже не отпускает ее пока не получит и вторую вилку.Например, если философу нужно пользоваться вилками с номерами 5 и 6, то философ должен сперва взять вилку номер 5. Только после этого он может взять вилку номер 6. Т.о., если вилки с меньшими номерами лежат слева от философов, то философ должен сперва взять левую вилку и лишь затем он может взять правую вилку.Последний философ в списке, которому приходится иметь дело с вилками за номерами (N-1) и 0, поступает наоборот: он сперва берет правую вилку с номером 0, а затем левую вилку с номером (N-1).Для реализации этого подхода потребуется два типа акторов: один для вилок, второй для философов. Если философ захотел поесть, то он отсылает соответствующему актору-вилке сообщение на захват вилки, а актор-вилка отвечает ответным сообщением.Код реализации этого подхода можно увидеть .Прежде чем говорить об акторах, нужно посмотреть на сообщения, которыми акторы будут обмениваться:Когда актор-философ хочет взять вилку, он отсылает актору-вилке сообщение , а актор-вилка отвечает сообщением . Когда актор-философ заканчивает есть и хочет положить вилки обратно на стол, он отсылает акторам-вилкам сообщения .В сообщении  поле  обозначает почтовый ящик (он же mbox) актора-философа. В этот почтовый ящик должно быть отправлено ответное сообщение . Второе поле из  в данном примере не используется, оно нам потребуется, когда мы дойдем до реализаций waiter_with_queue и waiter_with_timestamps.Теперь мы можем посмотреть на то, что из себя представляет актор-вилка. Вот его код:Каждый актор в SObjectizer-е должен быть производен от базового класса . Что мы и видим здесь для типа .В классе  переопределяется метод . Это специальный метод, он автоматически вызывается SObjectizer-ом при регистрации нового агента. В методе  производится \"настройка\" агента для работы в SObjectizer-е: меняется стартовое состояние, производится подписка на нужные сообщения.Каждый актор в SObjectizer-е представляет из себя конечный автомат с состояниями (даже если актор использует всего одно дефолтное состояние). Вот у актора  есть два состояния:  и . Когда актор в состоянии , вилка может быть \"захвачена\" философом. И после захвата \"вилки\" актор  должен перейти в состояние . Внутри класса  состояния представляются экземплярами  и  специального типа .Состояния позволяют обрабатывать входящие сообщения по-разному. Например, в состоянии  агент реагирует только на  и реакция эта очень простая: меняется состояние актора и отсылается ответное :Тогда как все остальные сообщения, включая  в состоянии  попросту игнорируются.В состоянии же  актор обрабатывает два сообщения, и даже сообщение  он обрабатывает иначе:Здесь наиболее интересен обработчик для : если очередь ждущих философов пуста, то мы можем вернуться в , а вот если не пуста, то первому из них нужно отослать . гораздо более объемен, поэтому я не буду приводить его здесь полностью. Мы обсудим лишь наиболее значимые фрагменты.У актора-философа немного больше состояний:Актор начинает свою работу в состоянии , потом переключается в , затем в , затем в . Из  актор может вернуться в  или же может перейти в , если философ съел все, что должен был.Диаграмму состояний для актора-философа можно представить следующим образом:Логика же поведения актора описана в реализации его метода :Пожалуй, единственный момент, на котором следует остановится особо — это подход к имитации процессов \"размышления\" и \"еды\". В коде актора нет  или какого-то другого способа блокирования текущей рабочей нити. Вместо этого используются отложенные сообщения. Например, когда актор входит в состояние  он отсылает самому себе отложенное сообщение . Это сообщение отдается таймеру SObjectizer-а и таймер доставляет сообщение актору когда приходит время.Использование отложенных сообщений позволяет запускать всех акторов на контексте одной единственной рабочей нити. Грубо говоря, одна нить читает из какой-то очереди сообщения и дергает обработчик очередного сообщения у соответствующего актора-получателя. Подробнее о рабочих контекстах для акторов речь пойдет ниже.Результаты работы этой реализации могут выглядеть следующим образом (небольшой фрагмент):Читать это следует следующим образом:Мы можем видеть, что Сократ может взять вилку слева только после того, как Сартр отдаст ее. После чего Сократ будет ждать, пока Платон освободит правую вилку. Только после этого Сократ сможет поесть.Если мы проанализируем результат работы решения Дейкстры, то увидим, что философы проводят много времени в ожидании захвата вилок. Что не есть хорошо, т.к. это время можно также потратить на раздумья. Не зря же бытует мнение, что если размышлять на голодный желудок, то можно получить гораздо более интересные и неожиданные результаты ;)Давайте посмотрим на простейшее решение, в котором философ возвращает первую захваченную вилку, если он не может захватить вторую (в упомянутой выше статье \"Modern dining philosophers\" это решение реализует ForkLevelPhilosopherProtocol).Исходный код этой реализации можно увидеть , а код соответствующего актора-философа . В данном решении используется практически такой же набор сообщений:Единственное отличие — это присутствие сигнала . Этот сигнал актор-вилка отсылает в ответ актору-философу если вилка уже захвачена другим философом.Актор-вилка в этом решении оказывается даже проще, чем в решении Дейкстры:Нам здесь даже не нужно хранить очередь ждущих философов.Актор-философ в этой реализации похож на оного из решения Дейкстры, но здесь актору-философу приходится обрабатывать еще и , поэтому диаграмма состояний выглядит следующим образом:Аналогично, вся логика актора-философа определяется в :В общем-то, это практически такой же код, как и в решении Дейкстры, разве что добавилась пара обработчиков для .Результаты работы выглядят уже по-другому:Здесь мы видим новый символ, который означает, что актор-философ находится в \"голодных раздумьях\".Даже на этом коротком фрагменте можно увидеть, что есть длительные моменты времени, на протяжении которых философ не может поесть. Это потому, что данное решение защищено от проблемы дедлоков, но не имеет защиты от голоданий.Показанное выше простейшее решение без арбитра не защищает от голоданий. Упомянутая выше статья \"Modern dining philosophers\" содержит решение проблемы голоданий в виде протокола WaiterFair. Суть в том, что появляется арбитр (официант), к которому обращаются философы когда хотят поесть. А у официанта есть очередь заявок от философов. И вилки достаются философу только если обе вилки сейчас свободны, а в очереди еще нет ни одного из соседей того философа, который обратился к официанту.Давайте посмотрим на то, как это же решение может выглядеть на акторах.Исходный код этой реализации можно найти .Проще всего было бы ввести новый набор сообщений, посредством которого философы могли бы общаться с официантом. Но я хотел сохранить не только уже существующий набор сообщений (т.е. , , , ). Я так же хотел, чтобы использовался тот же самый актор-философ, что и в предыдущем решении. Поэтому мне нужно было решить хитрую задачку: как сделать так, чтобы актор-философ общался с единственным актором-официантом, но при этом думал, что он взаимодействует напрямую с акторами-вилками (коих уже нет на самом-то деле).Эта задачка была решена с помощью нехитрого трюка: актор-официант создает набор mbox-ов, ссылки на которые отдаются акторам-философам как ссылки на mbox-ы акторов-вилок. При этом актор-официант подписывается на сообщения из всех этих mbox-ов (что в SObjectizer-е реализуется запросто, т.к. SObjectizer — это реализация не только/столько Модели Акторов, но еще и Pub/Sub поддерживается \"из коробки\").В коде это выглядит приблизительно вот так:Т.е. сперва создаем вектор mbox-ов для несуществующих \"вилок\", затем подписываемся на каждый из них. Да так подписываемся, чтобы знать к какой именно вилке относится запрос.Реальным обработчиком входящего запроса  является метод :Кстати говоря, именно здесь нам и потребовалось второе поле из сообщения .Итак, в  мы имеем исходный запрос и индекс вилки, к которой запрос относится. Следовательно, мы можем определить, просит ли философ левую вилку или правую. И, соответственно, мы можем обрабатывать их по-разному (и нам приходится обрабатывать их по-разному).Поскольку философ всегда сперва просит левую вилку, то все необходимые проверки нам нужно проделать именно в этот момент. И мы можем оказаться в одной из следующих ситуаций:Благодаря такой логике работы философ, получивший  для левой вилки, может спокойно послать запрос  для правой вилки. Этот запрос будет сразу же удовлетворен, т.к. вилка уже зарезервирована для данного философа.Если запустить получившееся решение, то можно увидеть что-то вроде:Можно обратить внимание на отсутствие символов . Это потому, что не может возникнуть неудачи или ожидания на запросе правой вилки.В некоторых случаях предыдущее решение waiter_with_queue может показывать результаты, похожие вот на этот:Можно увидеть наличие достаточно длинных периодов времени, когда философы не могут поесть даже не смотря на наличие свободных вилок. Например, левая и правая вилки для Канта свободны на протяжении длительного времени, но Кант не может их взять, т.к. в очереди ожидания уже стоят его соседи. Которые ждут своих соседей. Которые ждут своих соседей и т.д.Поэтому рассмотренная выше реализация waiter_with_queue защищает от голодания в том смысле, что рано или поздно философ поест. Это ему гарантировано. Но периоды голодания могут быть довольно долгими. И утилизация ресурсов может быть не оптимальной временами.Дабы решить эту проблему я реализовал еще одно решение, waiter_with_timestamp (его код можно найти ). Вместо очереди там используется приоритизация запросов от философов с учетом времени их голодания. Чем дольше философ голодает, тем приоритетнее его запрос.Рассматривать код этого решения мы не будем, т.к. по большому счету главное в нем — это тот же самый трюк с набором mbox-ов для несуществующих \"вилок\", который мы уже обсудили в разговоре про реализацию waiter_with_queue.Есть несколько деталей в реализациях на базе Акторов, на которые хотелось бы обратить внимание, т.к. эти детали демонстрируют интересные особенности SObjectizer-а.В рассмотренных реализациях все основные акторы (, , ) работали на контексте одной общей рабочей нити. Что вовсе не означает, что в SObjectizer-е все акторы работают только на одной единственной нити. В SObjectizer-е можно привязывать акторов к разным контекстам, что можно увидеть, например, в коде функции  в решении no_waiter_simple.В этой функции создаются дополнительные акторы типов  и . Они будут работать на отдельных рабочих контекстах. Для этого создается два экземпляра диспетчера типа  и акторы привязываются к этим экземплярам диспетчеров. Что означает, что данные акторы будут работать как : каждый будет владеть собственной рабочей нитью.SObjectizer предоставляет набор из нескольких разных диспетчеров, которые могут использоваться прямо \"из коробки\". При этом разработчик может создать в своем приложении столько экземпляров диспетчеров, сколько разработчику нужно.Но самое важное то, что в самом акторе ничего не нужно менять, чтобы заставить его работать на другом диспетчере. Скажем, мы легко можем запустить акторов  на одном пуле рабочих нитей, а акторов  на другом пуле.И при этом нам не потребовалось поменять ни строчки в классах  и .Если посмотреть в реализацию философов в упомянутой выше статье  можно легко увидеть код, относящийся к трассировке действий философа, например:В тоже время в показанных выше реализациях на базе SObjectizer подобного кода нет. Но трассировка, тем не менее, выполняется. За счет чего?Дело в том, что в SObjectizer-е есть специальная штука: слушатель состояний агента. Такой слушатель реализуется как наследник класса . Когда слушатель связывается с агентом, то SObjectizer автоматически уведомляет слушателя о каждом изменении состояния агента.Установку слушателя можно увидеть в конструкторе агентов  и :Здесь  — это и есть нужная мне реализация слушателя.Когда экземпляр  связан с агентом SObjectizer вызывает метод  при смене состояния агента. И уже внутри  инициируются действия для трассировки действий актора-философа.Теперь мы поговорим о реализациях, которые не используют акторов вообще. Посмотрим на те же самые решения (no_waiter_dijkstra, no_waiter_simple, waiter_with_timestamps) при реализации которых применяются  и SObjectizer-овские mchain-ы (которые, по сути, есть CSP-шные каналы). Причем, подчеркну особо, в CSP-шных решениях используется тот же самый набор сообщений (все те же , , , ).В CSP-подходе вместо \"процессов\" используются нити ОС. Поэтому каждая вилка, каждый философ и каждый официант реализуется отдельным объектом .Исходный код этого решения можно увидеть .Нить для вилки в решении Дейкстры работает очень просто: цикл чтения сообщений из входного канала + обработка сообщений типа  и . Что реализуется функцией  следующего вида:У функции  всего один аргумент: входной канал, который создается где-то в другом месте.Самое интересное в  — это \"цикл\" выборки сообщений из канала до тех пор, пока канал не будет закрыт. Этот цикл реализуется всего одним вызовом функции :В SObjectizer-е есть несколько версий функции  и здесь мы видим одну из них. Эта версия читает сообщения из канала пока канал не будет закрыт. Для каждого прочитанного сообщения ищется обработчик. Если обработчик найден, то он вызывается и сообщение обрабатывается. Если не найден, то сообщение просто выбрасывается.Обработчики сообщений задаются в виде лямбда-функций. Эти лямбды выглядят как близнецы братья соответствующих обработчиков в акторе  из решения на базе Акторов. Что, в принципе, не удивительно.Логика работы философа реализована в функции . У этой функции достаточно объемный код, поэтому мы будем разбираться с ним по частям.Давайте начнем с прототипа функции:Смысл и назначение некоторых из этих параметров придется пояснить.Поскольку мы не используем SObjectizer-овских агентов, то у нас нет возможности снимать след работы философа через слушателя состояний агента, как это делалось в варианте на Actor-ах. Поэтому в коде философа приходится делать вот такие вставки:И аргумент  как раз является ссылкой на объект, который занимается трассировкой работы философов.Аргумент  задает канал, в который должно быть записано сообщение  после того, как философ съест все, что ему положено. Этот канал затем будет использоваться для определения момента завершения работы всех философов.Аргументы  и  задают каналы для взаимодействия с вилками. Именно в эти каналы будут отсылаться сообщения  и . Но если это каналы, то почему используется тип  вместо ?Это хороший вопрос! Но ответ на него мы увидим ниже, при обсуждении другого решения. Пока же можно сказать, что mchain — это что-то вроде разновидности mbox-а, поэтому ссылки на mchain-ы можно передавать через объекты .Далее определяется ряд переменных, которые формируют состояние философа:Наверное наиболее важная переменная — это . Это персональный канал философа, через который философ будет получать ответные сообщения от вилок.Ну а теперь мы можем перейти к основной логике работы философа. Т.е. к циклу повторения таких операций как размышления, захват вилок и поглощение пищи.Можно отметить, что в отличии от решения на базе Акторов, для имитации длительных операций здесь используется  вместо отложенных сообщений.Попытка взять вилку выглядит практически так же, как и в случае с Акторами:Здесь используется все тот же тип . Но в нем есть поле типа , тогда как  имеет тип . Поэтому приходится преобразовывать ссылку на канал в ссылку на почтовый ящик через вызов .Далее можно увидеть вызов :Этот вызов возвращает управление только когда один экземпляр  будет извлечен и обработан. Ну или если канал будет закрыт. В общем, мы здесь ждем поступление нужного нам ответа от вилки.В общем-то это практически все, что можно было бы рассказать про . Хотя стоит заострить внимание на вложенном вызове  для одного и того же канала:Эта вложенность позволяет записать логику работы философа в простом и более-менее компактном виде.При обсуждении решений на базе Акторов мы не останавливались на разборе функций , поскольку там ничего особо интересного или важного не было. Но вот в случае с CSP-подходом на  имеет смысл остановиться. В том числе для того, чтобы в очередной раз убедиться в том, насколько непросто писать корректный многопоточный код (кстати говоря вне зависимости от языка программирования).В принципе, в основном код  должен быть более-менее понятен. Поэтому я разберу только некоторые моменты.Нам требуются рабочие нити для вилок. Этот фрагмент как раз отвечает за их создание:При этом нам нужно сохранять и каналы, созданные для вилок, и сами рабочие нити. Каналы потребуются ниже для передачи ссылок на них философам. А рабочие нити потребуются для того, чтобы затем вызвать  для них.После чего мы создаем рабочие нити для философов и так же собираем рабочие нити в контейнер, т.к. нам нужно будет затем вызывать :Далее мы должны дать философам некоторое время для выполнения симуляции. Дожидаемся момента завершения симуляции с помощью этого фрагмента:Этот вариант  возвращает управление только после получения  сообщений типа .Ну а после получения всех  остается выполнить очистку ресурсов.Делаем  для всех рабочих нитей философов:После чего нужно сделать  для всех нитей вилок. Но просто вызывать  нельзя, т.к. тогда мы тупо зависнем. Ведь рабочие нити вилок спят внутри вызовов  и никто их не разбудит. Поэтому нам нужно сперва закрыть все каналы для вилок и лишь затем вызывать :Вот теперь главные операции по очистке ресурсов можно считать законченными.Надеюсь, что код  сейчас полностью понятен и я могу попробовать объяснить, почему эта функция помечена как . Дело в том, что в ней exception-safety не обеспечивается от слова совсем. Поэтому самая лучшая реакция на возникновение исключения в такой тривиальной реализации — это принудительное завершение всего приложения.Но почему  не обеспечивает безопасность по отношению к исключениям?Давайте представим, что мы создаем рабочие нити для вилок и при создании очередной нити у нас выскакивает исключение. Дабы обеспечить хоть какую-нибудь exception-safety нам нужно принудительно завершить те нити, которые уже были запущены. И кто-то может подумать, что для этого достаточно переписать код запуска нитей для вилок следующим образом:К сожалению, это очевидное и неправильное решение. Т.к. оно окажется бесполезным если исключение возникнет уже после того, как мы создадим все нити для вилок. Поэтому лучше использовать что-то вроде вот такого:Ну или можно воспользоваться трюками, которые позволяют выполнять нужный нам код при выходе из скоупа (например, Boost-овским ScopeExit-ом, GSL-овским finally() и им подобным).Аналогичная проблема существует и с запуском нитей для философов. И решать ее нужно будет подобным образом.Однако, если поместить весь необходимый код по обеспечению exception-safety в , то код  окажется и объемнее, и сложнее в восприятии. Что не есть хорошо для функции, написанной исключительно в демонстрационных целях и не претендующей на продакшен-качество. Поэтому я решил забить на обеспечение exception-safety внутри  и пометил функцию как , что приведет к вызову  в случае возникновения исключения. ИМХО, для такого рода демонстрационных примеров это вполне себе разумный вариант.Тем не менее, проблема в том, что нужно иметь соответствующий опыт чтобы понять, какой код по очистке ресурсов будет работать, а какой нет. Неопытный программист может посчитать, что достаточно только вызвать , хотя на самом деле нужно еще предварительно закрыть каналы перед вызовом . И такую проблему в коде будет очень непросто выловить.Теперь мы можем рассмотреть, как в CSP-подходе будет выглядеть простое решение с возвратом вилок при неудачном захвате, но без арбитра.Исходный код этого решения можно найти .Нить для вилки реализуется функцией , которая выглядит следующим образом:Можно увидеть, что эта  проще, чем аналогичная в решении Дейкстры (ту же самую картину мы могли наблюдать, когда рассматривали решения на базе Акторов).Нить для философа реализуется функцией , которая оказывается несколько сложнее, чем ее аналог в решении Дейкстры.В общем-то код  очень похож на код  из решения Дейкстры. Но есть два важных отличия.Во-первых, это переменная . Она нужна для того, чтобы формировать правильный след работы философа, а так же для того, чтобы вычислять паузы при имитации \"раздумий\" философа.Во-вторых, это обработчики для сообщений . Мы их можем увидеть при вызове :Да, обработчики для  пусты, но это потому, что все необходимые действия либо уже были сделаны перед вызовом , либо будут сделаны после выхода из . Поэтому при получении  ничего не нужно делать. Но сами обработчики должны быть определены, т.к. их присутствие запрещает  выбрасывать экземпляры  без обработки. Благодаря присутствию таких обработчиков  возвращает управление когда в канал приходит сообщение .На базе CSP-подхода было сделано еще одно решение, которое я бы хотел здесь кратко осветить. Разбирая решения на базе Акторов речь шла о решениях с арбитром (официантом): мы рассматривали решение waiter_with_queue, в котором официант использует очередь заявок, а так же упоминалось решение waiter_with_timestamps. Оба эти решения использовали один и тот же трюк: официант создавал набор mbox-ов для несуществующих вилок, эти mbox-ы раздавались философам, но сообщения из mbox-ов обрабатывались официантом.Похожий трюк нужен и в CSP-подходе для того, чтобы я смог переиспользовать уже существующую реализацию  из решения no_waiter_simple. Но может ли официант создать набор mchain-ов которые будут использоваться философами и из которых официант будет читать сообщения, адресованные вилкам?К сожалению, нет.Создать набор mchain-ов не проблема. Проблема в том, чтобы читать сообщения сразу из нескольких mchain-ов.В SObjectizer-е есть функция , которая позволяет это делать, например, она позволяет написать так:Но для  нужно, чтобы список каналов и обработчиков сообщений из них был доступен в компайл-тайм. Тогда как в моих решениях задачи \"обедающих философов\" этот список становится известен только во время исполнения. Поэтому в CSP-подходе нельзя в чистом виде переиспользовать трюк из подхода на базе Акторов.Но мы можем его переосмыслить.Итак, суть в том, что в исходных сообщениях  и  нет поля для хранения индекса вилки. И поэтому нам нужно как-то эти индексы получить. Раз уж мы не можем запихнуть индексы внутрь  и , то давайте сделаем расширенные версии этих сообщений:Теперь нужно сделать так, чтобы официант читал именно расширенные версии сообщений вместо оригинальных. Значит нам нужно научиться перехватывать сообщения  и , преобразовывать их в  и , отсылать новые сообщения официанту.Для этого нам потребуется собственный mbox. Всего лишь :)Здесь использовался самый простой способ создания собственного mbox-а: в сопутствующем проекте  есть заготовка, которую можно переиспользовать и сохранить себе кучу времени. Без использования этой заготовки мне пришлось бы наследоваться напрямую от  и реализовывать ряд чистых виртуальных методов.Как бы то ни было, теперь есть класс . Так что мы теперь можем создать набор экземпляров этого класса, ссылки на которые и будут раздаваться философам. Философы будут отсылать сообщения в wrapping_mbox, а эти сообщения будут преобразовываться и переадресовываться в единственный mchain официанта. Поэтому функция , которая является главной функцией нити официанта, будет иметь вот такой простой вид:Конечно же, прикладная логика официанта реализована в другом месте и ее код не так прост и короток, но мы не будем туда погружаться. Интересующиеся могут посмотреть код решения waiter_with_timestamps .Вот сейчас мы можем ответить на вопрос: \"Почему каналы для вилок передаются в  как mbox-ы?\" Это потому, что для решения waiter_with_timestamps был реализован собственный mbox, а не mchain.Конечно же, можно было бы создать и собственный mchain. Но это потребовало бы несколько больше работы, т.к. в so_5_extra пока нет такой же заготовки для собственных mchain-ов (может быть со временем появится). Так что для экономии времени я просто остановился на mbox-ах вместо mchain-ов.Вот, пожалуй, и все, что хотелось рассказать про реализованные на базе Акторов и CSP решения. Свою задачу я видел не в том, чтобы сделать максимально эффективные решения. А в том, чтобы показать, как именно они могут выглядеть. Надеюсь, что кому-то это было интересно.Позволю себе отвлечь внимание тех, кто интересуется SObjectizer-ом. Все идет к тому, что в ближайшее время начнется работа над следующей \"большой\" версией SObjectizer — веткой 5.6, нарушающей совместимость с веткой 5.5. Желающие сказать свое веское слово по этому поводу, могут сделать это  (или ). Более-менее актуальный список того, что поменяется в SO-5.6 можно найти  (туда же можно добавить и свои пожелания).На этом у меня все, большое спасибо всем читателям за потраченное на данную статью время!PS. Слово \"современные\" в заголовке взято в кавычки потому, что в самих решениях нет ничего современного. Разве что за исключением использования кода на C++14.", "url": "https://habr.com/ru/post/437998/"},
{"title": "Конференция C++ Russia 2019", "article_text": "Всем привет! Представьте, что C++ Russia больше нет. Куда вы пойдёте вместо этого? Есть множество конференций, посвящённых более широким темам, но наша — одна из немногих, целиком и полностью сфокусированная на C++ и открыто заявляющая, что это будет реальный хардкор. Выбора немного. Хорошо, что мы никуда не исчезали! В следующий раз C++ Russia .Конференция состоится . Скорее всего, будет дополнительный третий день мастер-классов, которые не входят в основную программу.Темы докладов: многопоточность и параллельные вычисления, новые фичи языка и компиляторов, сборка и инфраструктура сложных проектов с большими кодовыми базами, производительность и низкоуровневая жесть, метапрограммирование, функциональное программирование и другие парадигмы, архитектура сложных проектов, и многое другое. В прошлый раз мы привозили Daveed Vandevoorde, а в этот раз к нам приедет его соавтор. Открывать конференцию будет Nicolai M. Josuttis. Про Николая лучше всего . Здесь стоит отметить, что он не только мастер C++ разработки, но ещё и автор нескольких популярных книг и давний участник Комитета Стандартизации в части библиотек. Сейчас программа находится на этапе формирования, идёт активная работа со спикерами, но про несколько докладов уже есть информация. Пройдемся по ним очень коротко: Антон Полухин – «Незаменимый С++». У Антона есть профиль на хабре () с кучей статей, он часто выступает и рассказывает про интересные штуки. Один из трёх человек в России, участвующих в Комитете Стандартизации (два других — Антон Бикинеев и Александр Фокин). Мне приятно думать, что именно благодаря нашим конференциям Россия появилась в Комитете — возможно, это тема для отдельного рассказа. Не знаю, нужно ли представлять Антона здесь, но всё-таки это сделаю. Антон — автор книги «Boost C++ Application Development Cookbook». Контрибьютор Boost, автор библиотеки Boost.TypeIndex, мейнтейнер Boost.Any, Boost.LexicalCast и тд. Точное содержание доклада уточняется, будем держать вас в курсе. Александр Гранин — «Монадические парсеры». Думаю, по названию уже всё ясно :-) Отличный доклад от функционального программиста, разбирающегося не только в C++, но и в Haskell. Интересно, что Александр обычно рассказывает не о конкретном единственно верном способе делать вещи, а о наборе идей из функционального программирования, которые по желанию можно использовать или не использовать в своём коде на C++. А ещё Александр — член Программного Комитета C++ Russia, так что мы попробуем сделать с ним отдельное интервью. Андрей Давыдов — «Метапрограммирование, щадящее компилятор» и «Концепты как средство реализовать старые классы по-новому». Это два доклада, каждый занимает полный слот. Андрей — разработчик в команде ReSharper C++ в JetBrains с прошлым в ГИС-ах и 3D-визуализации. Изначально это был один большой двухчасовой доклад, но после серии рефакторингов он разделился на две независимые части. Можно прийти только на одну из них и всё отлично понять. Если побывать на двух слотах подряд, это даст более системную картину происходящего. Андрей Карпов — «На что нужно обратить внимание при обзоре кода разрабатываемой библиотеки». Андрея () мы все на Хабре хорошо знаем за статьи про нахождение багов в открытых проектах. На этот раз у него будет полномасштабный доклад про то, что разработчик библиотеки должен обращать дополнительное внимание на мелкие детали и вопросы переносимости, которые заставляют его по-новому взглянуть на множество популярных функций, выбор типов данных, обработку ошибок, и так далее. Rainer Grimm — «Concurrency and Parallelism in C++17 and C++20/23». Райнер — разработчик с 20-летним стажем, написавший несколько книг про C++ для O'Reilly и Leanpub, а с какого-то момента — ещё и . Постоянные участники его хорошо знают, так как он читал доклады на всех C++ Russia. Проблематика этого доклада очевидна: начиная с 17 стандарта и выше работа с базовыми блоками многопоточных приложений серьёзно изменилась и продолжает меняться. Как именно обстоят дела с параллельным STL в C++17? Что можно сказать про executors, transactional memory и coroutines в C++23? В этом легко потеряться, и вот про это будет доклад. Единственная ловушка здесь в том, что у Райнера специфичный немецкий акцент, и к нему придётся привыкнуть. Arno Schödl — «Text Formatting For a Future Range-Based Standard Library». Арно — директор в Think-Cell, направляющий работу подразделений R&D, Quality Assurance и Customer Care. Тема звучит горячо, особенно на фоне недавней статьи с примером использования ренжей (). Если вы тоже вдруг возмущены (или наоборот) — у вас только что появился отличный шанс пообщаться с автором вживую и выяснить все наболевшие вопросы. Ivan Čukić — «Move-only C++ design». Иван — Ph.D.c. Computer Science в  в Сербии, исследует языки программирования и даже опубликовал книжку . Кроме того, он контрибьютил в KDE и Plasma. Это доклад про move-семантику C++ от человека, побывавшего на обеих сторонах баррикад: и как эксперт по дизайну языков, и как практик низкоуровневой разработки.  Viktor Kirilov — «The hitchhiker’s guide to faster builds». Это доклад о том, почему сборка и линковка занимает такое безумно большое время, и что с этим теперь делать. Будет полный разбор темы, начиная с тулинга и заканчивая модулями в C++. Виктор — разработчик с 6 годами в геймдеве на С++, известный рядом вещей вроде разработки подгрузки кода в рантайме языка Nim или библиотеки doctest (это такой single-header фреймворк для тестирования). Мастер-классы перед основной программой практикуются не первый год. В 2017 году их было два, в 2018-м — уже четыре. Прямо сейчас мы разбираемся, кто приедет в этом году. Как только этот вопрос прояснится, мы напишем об этом отдельно на Хабре.До конференции ещё есть пара месяцев, поэтому вы успеваете подать свой доклад. Программные комитеты читают совершенно все заявки и внимательно их рассматривают. Да, в списке спикеров много известных личностей, но попасть туда вполне возможно. Придётся, конечно, здорово поработать и над содержанием, и над подачей, но вам будут помогать люди, которые в этом хорошо разбираются. Есть вполне конкретные критерии принятия доклада, которым можно просто соответствовать. Есть конкретный процесс, который начинается приёмом заявки и заканчивается выступлением на конференции.Чтобы начать своё путешествие в качестве спикера, нужно , всё там внимательно прочитать и сделать как написано.Помните, в самом начале поста я спрашивал: что будет, если C++ Russia исчезнет? Этот вопрос был не просто так. Чтобы продолжать делать конференции и выйти на новый уровень, к организации всех мероприятий присоединяется компания . Кроме всего прочего, это означает появление нескольких дополнительных фишек, о которых пойдет речь далее. После каждого доклада спикер направляется в выделенную дискуссионную зону, где с ним можно пообщаться и задать свои вопросы, порисовать на маркерной доске, и так далее. Формально, это можно сделать в перерыве между докладами. Спикеры не обязаны, но обычно остаются куда дольше — например, на время всего следующего доклада. Иногда имеет смысл пропустить доклад из основной программы (если вы купили билет, у вас всё равно появятся записи) и потратить его на сфокусированное общение с важным экспертом.Это что-то вроде круглого стола или дискуссионной группы, в которой могут принять участие все желающие. Общение идёт на равных, нет деления «спикеров» и «слушателей». Но есть «модераторы дискуссии». Среди участников обычно собирается множество крутых специалистов, которые могут внести большой вклад в обсуждение. Если вдруг интересно,  расшифровывается как «birds of a feather», а его происхождение отсчитывается от . Выделенная зона на выставке, где можно обратиться к эксперту со своей проблемой и прямо на месте получить практические советы. Приносите свои ноутбуки и готовьте вопросы!Напитки, закуски и музыка. Общение в непринужденной обстановке с коллегами и любимым спикером за бокалом пенного или красного. Ненавязчивая музыка и бар для тех кто любит «погорячее». Тёплая ламповая атмосфера. Всё как вы любите.Приобрести билеты можно . В прошлом году мы уже делали специальную студенческую программу и онлайн-билеты. Обратите внимание, что сейчас эта система улучшилась — на сайте есть несколько видов билетов. Выбрав правильный тип, можно существенно сэкономить. Прямая трансляция и видеозаписи там тоже есть.Увидимся на конференции!", "url": "https://habr.com/ru/company/jugru/blog/436068/"},
{"title": "«Современный» C++: сеанс плача с причитаниями", "article_text": "Здесь будет длиннющая стена текста, с типа случайными мыслями. Основные идеи:Блогпост «» Эрика Ниблера, посвященный ренжам в C++20, недавно облетел всю твиттерную вселенную, сопровождаясь кучей не очень лестных комментариев (это ещё мягко сказано!) о состоянии современного C++.Даже я внёс свою лепту ():Давайте подробно разберём всё это под катом.Всё это немножко вышло из-под контроля (даже спустя неделю, в это дерево тредов продолжали прилетать комментарии!).Теперь, надо извиниться перед Эриком за то, что я начал с его статьи; мой плач Ярославны будет, в основном, об «общем состоянии C++». «Горстка озлобленных чуваков из геймдева» год назад наезжала на  примерно тем же способом, и то же происходило по поводу десятков остальных аспектов экосистемы C++.Но знаете, Твиттер — это не самое лучшее место для деликатных разговоров, и т.д и т.п. Придётся развернуть мысль прямо здесь и сейчас!Держите полный текст примера из  Эрика: Пост Эрика появился из его же , написанного пару лет назад, который в свою очередь являлся ответом на статью Бартоша Милевского «», в котором простая сишная функция для распечатки первых N пифагоровых троек выглядела так: Там же были перечислены проблемы с этим кодом:После чего ленивые вычисления со сборкой списков (list comprehensions) представляются как  решать этим проблемы. Конечно, это действительно  решить данные проблемы, ведь в языке C++ для этой задачи недостаточно встроенной функциональности, которая есть в каком-нибудь Haskell и других языках. C++20 получит  для этого встроенных ништяков, на что и намекает пост Эрика. Но до этого мы ещё доберёмся.Так, давай вернёмся к стилю решения задачи, основанному на простом C/C++ («простом» — в смысле, «подходит, пока не нужно модифицировать или переиспользовать», по версии Бартоша). Держите законченную программу, которая распечатывает первую сотню троек:Вот как её можно собрать: . Сборка занимает 0.064 секунды, на выходе имеем экзешник размером 8480 байтов, который отрабатывает 2 миллисекунды и потом печатает числа (всё это на моём железе: 2018 MacBookPro; Core i9 2.9GHz; компилятор — Xcode 10 clang).Стоять! Это был дефолтная, неопитмизированная («Debug») сборка; давайте теперь соберём с оптимизациями («Release»): . Это займёт 0.071 секнду на компиляцию и на выходе получится экзешник того же размера (8480 байт), который работает за 0 миллисекунд (то есть, ниже чувствительности таймера ).Как правильно заметил Бартош, алгоритм здесь нельзя переиспользовать, ведь он смешан с манипуляциями результатом вычислений. Вопрос «действительно ли это является проблемой» выходит за рамки этой статьи (). Давайте предположим, что это проблема, и нам действительно нужно что-то, что вернёт первые N троек, но никаких манипуляций над ними производить не станет.Что бы сделал я — простейшую и из простых вещей, создать нечто пригодное для вызова, что будет возвращать следующую тройку. Это может выглядеть так:Оно собирается и работает примерно за то же самое время. Отладочный экзешник вырастает на 168 байт, релизный остаётся того же размера.Я сделал структуру , для которой каждый следующий вызов  переходит к следующей валидной тройке; вызывающий код может делать с этим результатом всё, что душе угодно. Поэтому я просто зову его сто раз, и каждый раз распечатываю результат на экран.Несмотря на то, что реализация является функционально эквивалентной тому, что делал цикл из трёх вложенных for-ов в изначальном примере, в реальности , по крайней мере, для меня. Совершенно ясно,  он делает то, что он делает (несколько ветвлений и простые операции над целыми числами), но далеко не сразу понятно  он делает на высоком уровне.Если бы в C++ было чего-нибудь вроде концепции , стало бы возможно реализовать генератор троек, такой же лаконичный, как вложенные циклы в изначальном примере, но при этом не имеющий ни одну из перечисленных «проблем» (Джейсон Мейзель именно об этом говорит в статье «»); это могло быть нечто вроде (это предварительный синтаксис, потому что в стандарте C++ корутин нет):Может ли стиль записи в виде ренжей C++20 более ясно справиться с этой задачей? Давайте взглянем на пост Эрика, на основную часть кода:Каждый решает за себя. По мне так, подход с корутинами, описанный выше, куда как более читабельный. Тот способ, которым в C++ создаются лямбды, и то, как в стандарте C++ придумали записывать вещи особо умным способом («что такое ? это греческая буква, глядите какой я умный!») — обе этих вещи выглядят громоздко и нескладно. Множество return-ов кажется необычным, если читатель привык к императивному стилю программирования, но возможно, к этому можно и привыкнуть., вы осилите свести глаза особым образом и представить, что это приемлемый и приятный синтаксис.Тем не менее, я отказываюсь верить, что мы, простые смертные без докторской степени в C++, сможем написать утилиты, необходимые для работы вот такого кода:, что для кого-то это язык родной, но для меня всё это ощущается как если бы кто-то решил, что Perl излишне читабельный, а Brainfuck — излишне нечитабельный, поэтому давайте целиться между ними. Я программировал в основном на C++ все последние 20 лет. Может быть, я слишком тупой, чтобы во всём этом разобраться, отлично.И да, конечно, , ,  — все они являются «переиспользуемыми компонентами», которые можно перенести в библиотеку; эта тема, про которую я расскажу… да прямо сейчас.Существует как минимум два понимания производительности:Продолжим иллюстрировать это на примере примера с пифагоровыми тройками, но на самом деле, эти проблемы справедливы для множества других фичей C++, реализованных как часть библиотек, а не как часть синтаксиса.Финальная версия C++20 ещё не вышла, поэтому для быстрой проверки я взял текущее лучшее приближение ренжей, коим является  (написанное самим Эриком Ниблером), и собрал относительно него канонический пример с пифагоровыми тройками.Я использовал версию после 0.4.0 ( за 22 декабря 2018 года), и собрал с помощью команды . Оно , исполняемый файл получился размером 219 килобайт, а .И да, это сборка без оптимизаций. Оптимизированная сборка () компилируется за 3.02 секунды, экзешник выходит размером 13976 байтов, и выполняется за 1 миллисекунду. Скорость выполнения в рантайме хороша, размер экзешника чуть увеличился, а вот время компиляции всё так же осталось проблемой.Углубимся в подробности.Время компиляции этого реально наипростейшего примера заняло на 2.85 секунды дольше, чем версия с «простым C++».Если вы вдруг подумали, что «меньше 3 секунд» — слишком маленькое время, то совершенно нет. За три секунды современный CPU может произвести несметное число операций. Например, за какое время clang сможет скомпилировать настоящий полноценный движок базы данных () в отладочном режиме, включая все 220  строчек кода? За 0.9 секунд на моём ноутбуке. В какой такой вселенной стало нормальным, чтобы тривиальный пример на 5 строчек компилировался в три раза дольше целого движка баз данных?Время компиляции С++ было источником боли на всех нетривиальных по размеру кодовых базах, где я работал. Не верите мне? Хорошо, попробуйте собрать какую-нибудь из широкоизвестных кодовых баз (Chromium, Clang/LLVM, UE4, и так далее отлично подойдут для примера). Среди множества вещей, которые  хочется иметь в C++, вопрос времени компиляции, наверное, на самом первом месте списка, и был там всегда. Тем не менее, складывается ощущение, что сообщество C++ в массе своей притворяется, что это совсем даже и не проблема, и в каждой следующей версии языка они перекладывают в заголовочные файлы  разных вещей,  вещей появляется в шаблонном коде, который обязан быть в заголовочных файлах.В большинстве своём это связано с доисторической концепцией «просто скопипастим всё содержимое файла» модели , унаследованной из Си. Но в Си есть тенденция хранить в заголовках только объявления структур и прототипы функций, в C++ же обычно нужно свалить туда все шаблонные классы/функции. представляет из себя кусок кода размером 1.8 мегабайтов, и всё это в заголовочных файлах! Несмотря на то, что пример с сотней пифагоровых троек занимает 30 строчек, после обработки заголовков компилятору придётся скомпилировать 102 тысячи строк. В «простом C++» после всех преобразований получается 720 строк. — так и слышу, что вы это сейчас сказали. Справедливо. Давайте положим заголовки библиотеки ренжей в precompiled header (pch.h с текстом: , заинклудим получившийся pch.h, создадим PCH: , скомпилируем с помощью pch: ). Время компиляции станет 2.24 секунды. То есть, PCH может сэкономить нам около 0.7 секунды времени компиляции. С оставшимися 2.1 секундами они никак не помогут, и это куда дольше, чем подход с простым C++ :(В рантайме пример с ренжами оказался . Возможно, замедление в 2 или 3 раза ещё можно считать приемлемым. Всё, что в 10 раз медленней можно отнести в категорию непригодного к использованию. Больше, чем в сто раз медленней? Серьёзно?На реальных кодовых базах, решающих реальные проблемы, разница в два порядка означает, что программа просто не сможет обработать настоящий объем данных. Я работаю в индустрии видеогейминга; по чисто практическим причинам это означает, что отладочные сборки игрового движка или тулинга не смогут обрабатывать настоящие игровые уровни (производительность даже не приблизится к необходимому уровню интерактивности). Возможно, существует такая индустрия, в которой можно запустить программу на наборе данных, подождать результата, и если это займет от 10 до 100 раз больше времени в отладочном режиме, это будет «досадно». Неприятно, раздражающе тормозно. Но если делается нечто, , «досадно» превращается в «неприменимо». Вы буквально не сможете играть в игру, если она рендерит изображение со скоростью всего 2 кадра в секунду.Да, сборка с оптимизациями ( в clang) работает со скоростью «простого C++»… ну да, ну да, «zero cost abstractions», где-то слышали. Бесплатные абстракции до тех пор, пока вам неинтересно время компиляции и возможно использовать оптимизирующий компилятор.Но отладка оптимизированного кода — это ! Конечно, это возможно, и даже является очень полезным навыком. Подобно тому, как езда на одноколёсном велосипеде тоже возможна и учит наиважнейшему навыку балансирования. Кое-кто умеет получать от этого удовольствие, и даже вполне неплох в данном занятии. Но большинство людей никогда не выберут моноцикл в качестве основного средства передвижения, так же как большинство людей не отлаживают оптимизированный код, если есть хоть малейшая возможность этого избежать.Arseny Kapoulkine делал крутой стрим «» на YouTube, там он упёрся в проблему тормознутости отладочной сборки, и сделал её в 10 раз быстрее, выбросив некоторые куски STL (). Побочными эффектами стало ускорение компиляции () и упрощение отладки, поскольку реализация STL от Microsoft адски помешана на вложенных вызовах функций.Это не к тому, что «STL — плохо»; возможно написать такую реализацию STL, которая не будет тормозить десятикратно в неоптимизированной сборке (EASTL и libc++ так умеют), но по какой-то причине Microsoft STL  тормозит потому, что они излишне сильно заложились на принцип «инлайнинг всё починит».Как , мне всё равно, чья это проблема! Всё что мне известно изначально — «STL тормозит в отладочном режиме», и я бы предпочёл, чтобы кто-то это исправил уже. Ну или мне придётся искать альтернативы (например, не использовать STL, самостоятельно написать нужные лично мне вещи, или вообще отказаться от C++, как вам такое).Давайте коротко взглянем на очень схожую реализацию «лениво вычисляемых пифагоровых троек» на C#:По мне так, это кусок весьма и весьма читабелен. Сравните вот эту строчку на C#:с примером на C++:Мне ясно видно, что здесь чище написано. А вам? Если честно, то альтернатива на C# LINQ тоже выглядит перегруженной:Сколько собирается этот код на C#? Я использую Mac, поэтому запустив на компиляторе Mono (который тоже написан на C#) версии 5.16 команду  получилось скомпилировать второй пример за 0.20 секунд. Эквивалентный пример на «простом C#» уложился в 0.17 секунд.То есть, ленивые вычисления в стиле LINQ . Сравните с дополнительными 3 секундами для C++ — это !Да, в какой-то степени.Например, мы здесь в  любим шутить, что «за добавление в проект Boost можно оказаться уволенным по статье». Похоже, всё же не увольняют, потому что в прошлом году я обнаружил, что кто-то добавил , всё стало дико медленно собираться, и мне пришлось разбираться с тем, что простое добавление  инклудит за собой весь , со всеми  внутри.По большей части мы стараемся не использовать и большую часть STL. У нас есть собственные контейнеры, созданные по той же причине, что описаны во  — более однообразный способ доступа, работающий между различными платформами/компиляторами, более хорошая производительность в сборках без оптимизаций, лучшая интеграция с нашими собственными аллокаторами памяти и трекингом аллокаций. Есть и кое-какие другие контейнеры, чисто по причинам производительности ( в STL  не может быть быстрой, поскольку стандарт требует использования separate chaining; наша же хэш-таблица использует вместо этого открытую адресацию). Большая часть стандартной библиотеки нам и не нужна совсем.Тем не менее.Требуется время, чтобы убедить каждого нового сотрудника (особенно джуниоров, только что вышедших из университета) что нет, «современный» C++ не означает автоматически, что он лучше старого (). Или например, что «код на Си» не обязательно значит, что его сложно понимать и он весь завален багами (). Всего пару недель назад я жаловался всем и каждому, как я пытаюсь понять один конкретный кусок (нашего собственного) кода, и не могу, потому что этот код «слишком сложный» для меня. Другой (джуниор) подсел рядом и спросил, почему я выгляжу так, как будто готов ‎(ﾉಥ益ಥ）ﾉ﻿ ┻━┻, я сказал «ну, потому что пытаюсь понять этот код, но для меня он слишком сложный». Его мгновенная реакция была вроде: . И я такой: . (Код, о котором идёт речь, был чем-то вроде ). Он не работал ни над большими кодовыми базами, ни над C или C++, но  уже убедило его, что нечитаемым должен быть именно код на Си. Я виню университет; обычно студентам сразу же втирают, что «Си — это плохо», и потом никогда не объясняют — почему; это оставляет неизгладимый отпечаток на неокрепшей психике будущих программистов.Поэтому да, я определённо склонен игнорировать те части C++, которые мне не нравятся. Но обучать всех коллег вокруг весьма утомительно, поскольку слишком многие находятся под влиянием идей вроде «современное — значит хорошее», или «стандартная библиотека должна быть лучше, чем что угодно, что мы сможем написать сами».Понятия не имею. У них есть очень сложная задача, «как продолжать эволюцию языка, сохраняя почти стопроцентную обратную совместимость с решениями, сделанными на протяжении многих десятков лет». Наложите этот факт на то, что C++ пытается служить сразу нескольким хозяевам, учитывать множество способов использования и уровней опыта, и у вас появилась огромная проблема!Но до какой-то степени, есть ощущение, что большая часть комитета C++ и экосистемы сфокусирована на «сложности» в смысле доказательства собственной полезности. В интернетах ходит шутка о стадиях развития программиста на C/C++. Я помню, как был на средней стадии где-то лет 16 назад. Был очень поражён Boost, в том смысле что: «вау, , это так круто!». Не задаваясь вопросом,  это вообще делать.Точно так же, ну например, автомобили Formula 1 или гитары с тремя грифами. Поразительно? Конечно. Чудо инженерной мысли? Безусловно. Требует огромного скилла, чтобы управляться с ними? Да!  для 99% ситуаций, в которых вы когда либо находились? Точняк.Кристер Эриксон красиво сказал об этом :И да, люди, обеспокоенные состоянием C++ и стандартных библиотек, конечно, могут объединить усилия и попытаться улучшить их. Некоторые так и делают. Некоторые слишком заняты (или они так думают) чтобы тратить время на комитеты. Некоторые игнорируют куски стандартов и делают свои собственные параллельные библиотеки (вроде ). Некоторые пришли к выводу, что C++ уже не спасти, и пытаются сделать собственные языки () или перепрыгнуть на другую лодку (, ).Я знаю, насколько это неприятно, когда «куча озлобленных людей в интернете» пытается сказать, что вся твоя работа — лошадиного навоза не стоит. Я работаю, возможно, над , которым пользуются миллионы, и часть из них любит говорить, прямо или непрямо, насколько он отвратительный. Это тяжело; я и другие коллеги вложили в это столько раздумий и усилий, и вдруг кто-то проходит мимо и говорит, что мы тут все идиоты и наша работа — мусор. Печально!Скорей всего, что-то подобное испытывает каждый, кто работает над C++, STL или любой другой широко используемой технологией. Они годами работали над чем-то важным, и тут куча Разъярённых Жителей Нижнего Интернета пришла и расфигачила твою любимую работу.Слишком легко перейти в защитную позу, это наиболее естественная реакция. Обычно — не самая конструктивная.Если не обращать внимания на буквальных троллей, которые ноют по интернетам просто для удовольствия, большинство жалобщиков  проблемы или неприятности, стоящие за ними. Они могут плохо это формулировать, или преувеличивать, или жалобщик не подумал над множеством других точек зрения кроме своей собственной, но тем не менее, существует , лежащая за всеми этими проявлениями.Что я делаю, когда кто-то жалуется на вещь, над которой я работал? Нужно забыть о «себе» и «своей работе», и принять их точку зрения. С чем они пытаются разобраться, какие проблемы пытаются решить? Задача любого софта/библиотек/языков — помочь пользователям решить их проблемы. Это может быть или идеальный инструмент для решения этих проблем, или «ок, это может сработать», или совершенно ужасно плохое решение.Некоторые из ответов вида «весь фидбек будет проигнорирован, если он не оформлен в виде документа, представленного на собрании комитета C++», которые я видел в последнее время не кажутся мне продуктивным подходом. Точно так же, защита архитектуры библиотеки с помощью аргумента вида «это была популярная бибилиотека в Boost!» не учитывает той части мира C++, которая не считает, что Boost — это что-то хорошее.Индустрия видеогейминга, если смотреть глобально, тоже виновата. Игровые технологии традиционно создаются с помощью C или C++ просто потому, что вплоть до самого последнего времени остальные системные языки программирования просто не существовали (но теперь есть как минимум Rust, составляющий достойную конкуренцию). Учитывая ту зависимость от C++, в которую попала индустрия, она совершенно точно не проделала достаточной работы, чтобы её замечали, и не занимается достаточно улучшением языка, библиотек и экосистемы.Да, это тяжелая работа, и да — жаловаться в интернете куда проще. И кто бы ни начал работать над будущим C++, это самое будущее не в решении «непосредственных проблем» (вроде поставки игры или чего-то такого); они должны работать над чем-то куда более долговременным. Существуют компании, которые могут это позволить; любая компания, производящая большой игровой движок или большой издатель с централизованной технологической группой совершенно точно может этим заняться. Если это будет стоить того, но знаете, это как-то лицемерно, говорить «C++ — фигня полная, нам это не нужно», и при этом никогда не доносить разработчикам языка, что же вам нужно.Моё впечатление от всего этого в том, что большинство игровых технологий чувствуют себя достаточно хорошо с последними (C++11/14/17) нововведениями в сам язык C++ — например, полезными оказались лямбды,  очень крут, и так далее. Но есть тенденция игнорировать то, что добавилось в стандартные библиотеки, как по причине описанных выше проблем в архитектуре и реализациях STL (долгое время компиляции, плохая производительность в отладке), так и просто потому, что они эти дополнения недостаточно вкусные, или компании уже написали свои собственные контейнеры/строки/алгоритмы/… многие годы назад, и не понимают, зачем им менять то, что уже работает.", "url": "https://habr.com/ru/company/jugru/blog/438260/"},
{"title": "К чему готовиться в 2019 году: тренды в программировании", "article_text": "Перед вами перевод статьи пользователя под ником Constantin, опубликованной на ресурсе hackernoon.com. Под катом можно узнать, какие из языков программирования сегодня достойны того, чтобы их освоили.\r\nЯнварь — отличное время для того, чтобы проанализировать прошедший год и заглянуть в новый.\r\nПрограммисты пытаются предположить, каким он будет: прикидывают, какими навыками было бы неплохо овладеть, в каких проектах можно поучаствовать. Недавно на Indorse шла беседа об ожидаемых трендах. В этом обсуждении родились любопытные мысли, которыми хотелось бы поделиться.\r\nНиже представлены языки, ставшие трендовыми в ушедшем году, а также новые тренды, которые помогут вам оставаться на гребне волны в 2019-м. и  обладают большим количеством информации о наиболее используемых языках программирования.\r\nСхема от Stack Overflow, представленная ниже, демонстрирует самые популярные языки 2018 года. Как вы видите, JavaScript возглавляет список, и это неудивительно: он продолжает использоваться повсеместно как для фронтенд-, так и для бэкенд-разработок. Более того: JavaScript лидирует шестой год подряд.\r\nИсточник: \r\nJavaScript на высоте и по данным GitHub (см. схему ниже). Мы видим, в организациях любого масштаба и в любом регионе мира у JavaScript больше всего контрибьюторов — как в публичных, так и в частных репозиториях.\r\nИсточник: \r\nПо другим критериям превосходство также у JavaScript. В 2018 году этот язык стал первым не только по количеству контрибьюторов, но и по числу новых репозиториев на GitHub (см. схему ниже).\r\nТоп языков программирования по количеству созданных репозиториев с 2008 по 2018 гг. Источник: \r\nЭтот стремительный взлет произошел благодаря новым серверам JavaScript (например, Node.js, что был запущен в 2009 г.), которые позволяют программистам использовать один код как для клиента, так и для сервера.\r\nА что же с другими языками? Python и C++ поднялись в списке, C — немного опустился, а Ruby рухнул с 5 на 10 место. Другой прорыв в прошлом году совершил TypeScript: в списке он поднялся с 10 до 7 пункта.\r\nКак вышеописанные тренды повлияют на сферу программирования в 2019-м? Очевидно, что JavaScript останется преобладающим языком. Но есть и другие языки, которые развиваются гораздо быстрее.\r\nЕсли вы посмотрите на схему вверху, то увидите, что Python уже третий по популярности язык в мире. Но эту позицию он занял недавно: согласно данным от Stack Overflow, Python обошел PHP в 2017 году, а C# — в 2018-м (даты в выделенном авторском тексте не соответствуют данным на схеме ниже. — Прим. ред.). \r\nСледующая схема иллюстрирует стремительный взлет Python.\r\nИсточник: \r\nЕстественно, растущий интерес к искусственному интеллекту (ИИ) способствует развитию Python. И инженерам, судя по всему, нравится использовать этот язык для программирования. Согласно результатам последнего  членов IEEE, Python их фаворит. \r\nИсточник: \r\nПо результатам опроса IEEE Python и в 2017 году занял первое место — с небольшим отрывом от C. Похоже, ему удается вытеснить R во многих сферах (R — специализированный язык для работы со статистикой и большими данными, критически необходимый для ИИ и приложений для машинного обучения).\r\nВполне вероятно, что доступность библиотечных модулей Python для статистики и машинного обучения сделали его более привлекательным языком для машинного обучения, чем R. В целом с Python вы можете сделать гораздо больше, чем с R, который действительно создан лишь для работы со статистикой и большими данными. Например, вы можете использовать Python для создания игр, веб-сайтов, бизнес-приложений и др.\r\nТак что, если вы подумываете о работе с ИИ и машинным обучением или уже работаете, используя R, Python — это язык, который обязательно нужно освоить в новом году.\r\nСогласно последнему докладу , сейчас TypeScript на 7 месте по популярности, в 2017 году он был на 10 месте (см. вторую схему в начале статьи). Как вы видите на картинке ниже, на данный момент это третий по счету самый быстроразвивающийся язык из всех.\r\nСамые быстроразвивающиеся языки по мнению пользователей на 30 сентября 2018. Источник: \r\nTypeScript — это, в сущности, версия JavaScript с , созданная с учетом безопасности типов и функциональной совместимости. Сильная типизация означает, что вам никогда не придется определять типы для переменных, потому что они уже определены с помощью . \r\nИнтересно то, что вы можете кодировать с помощью TypeScript, а затем  (конвертировать) ваш код для JavaScript. Таким образом, TypeScript позволяет обойти наиболее раздражающие недостатки JavaScript. в 2018 году первый раз попал в  (см. выше рейтинг, опубликованный в журнале IEEE Spectrum). Кроме того, это пятый по счету самый быстроразвивающийся язык по данным IEEE, и седьмой по данным GitHub. Должно быть, он действительно особенный. Давайте узнаем почему. \r\nGo — это язык программирования с открытым исходным кодом, разработанный компанией Google. Похожий по синтаксису на язык C, он, как и Python, проще остальных языков в плане чтения и написания. Вероятно, в этом и кроется причина стремительного роста популярности. \r\n \r\nКроме того, Go — язык с сильной типизацией (как и TypeScript). Вы можете использовать его для всех видов фронтенд- и бэкенд-приложений, а также для создания сопутствующих приложений, которые разбивают работу на множество потоков в ходе ее выполнения. И, что здорово, вы можете написанный в Go код компилировать в JavaScript.\r\n \r\nВидимо, Google подумывает перевести свои продукты на работу с Go, что повысило бы популярность этого языка еще больше. Так что выбирайте для освоения Go, не прогадаете.\r\nТеперь вы знаете, на какие тренды в программировании обратить внимание в 2019 году. Все они — прекрасный выбор для тех, кто хочет освоить что-нибудь новое.\r\nPython будет хорошим вариантом, если вы планируете заниматься статистическим анализом или машинным обучением на больших данных. Можно остановиться на TypeScript, чтобы с большей легкостью писать коды для JavaScript. Если вы привыкли кодировать с помощью C, то Go упростит вам жизнь, позволяя при необходимости компилировать код в JavaScript.\r\nУдастся ли новым языкам, таким как Go и TypeScript, вытеснить JavaScript? Если это произойдет, то многие разработчики будут просто счастливы, но делать подобные прогнозы пока рано. Сейчас мы знаем точно только то, что с Python, TypeScript и Go в новом году мы будем встречаться чаще.", "url": "https://habr.com/ru/company/plarium/blog/436618/"},
{"title": "Цикл уроков по SDL 2.0: урок 4 — Обработка событий", "article_text": "\r\nВ этом уроке мы изучим основы получения пользовательского ввода, а для простоты примера будем воспринимать любое действие пользователя как попытку  завершить работу программы. Для получения информации о событиях SDL использует структуру SDL_Event и функции извлечения событий из очереди событий, такие как SDL_PollEvent. Код, написанный в рамках этого урока, основывается на результатах .\r\nНо для начала, давайте поменяем картинку по центру экрана, чтобы пользователю, впервые увидевшему вашу программу, было понятно, что она делает, и что требуется от него.\r\nМы добавим в программу , который заставит программу работать, пока пользователь не захочет выйти (и не сообщит об этом программе в доступной ей форме, само собой), вместо фиксированной задержки, как это было в предыдущих уроках. Вот приблизительная структура такого цикла:\r\nЧтобы правильно использовать систему событий SDL, нам понадобится хотя бы минимальное представление о её функционировании. Когда SDL получает событие от операционной системы, оно помещает его в конец очереди, после всех остальных событий, которые были получены ранее, но ещё не были извлечены оттуда программой. Если бы после запуска программы мы бы поочерёдно изменили размер окна, щёлкнули по нему мышью и нажали на какую-нибудь клавишу, то очередь событий выглядела бы так:\r\nПри вызове SDL_PollEvent мы получаем событие из начала очереди, самое старое из оставшихся. Получение событий из очереди при помощи SDL_PollEvent удаляет их оттуда, чтобы этого избежать, можно «подглядеть» событие, воспользовавшись функцией SDL_PeepEvents с установленным флагом SDL_PEEKEVENT. Подробнее об этой функции можно прочитать в документации, в рамках этой статьи она не потребуется (и вам, скорее всего, тоже) и потому рассматриваться не будет.\r\nВ главном цикле мы хотим получать все доступные события, пришедшие после отрисовки предыдущего кадра, и обрабатывать их. Чтобы это сделать, достаточно поместить SDL_PollEvent в условие цикла while, поскольку он возвращает 1, если она получила событие, и 0, если получать нечего. Раз уж всё, что делает программа — это завершает свою работу при определённых событиях, достаточно будет использовать булевскую переменную (bool quit), обозначающую, хотим мы закончить работу программы или нет, и установить её значение в истинное при получении этих событий.\r\nЭтот цикл следует разместить внутри главного цикла приложения.\r\nСобытие типа SDL_QUIT происходит, когда пользователь закрывает окно, SDL_KEYDOWN — когда нажата клавиша на клавиатуре (и приходит много-много раз, пока она удерживается, подобно тому, как повторяются буквы при удержании клавиши во время печати текста), а событие типа SDL_MOUSEBUTTONDOWN — при нажатии клавиши мыши. Это лишь некоторые из событий, которые может получить ваше приложение — а всего SDL может получить более 20 типов событий, покрыть которые эта статья, само собой, не в силах, поэтому о них стоит почитать в документации к \r\nС обработкой событий закончили, но в главном цикле не хватает ещё одной части — отображения сцены. Эту тему мы уже рассмотрели в предыдущих уроках, осталось лишь применить эти знания, и главный цикл примет следующий вид:\r\nЭта программа будет работать вечно. Ну, или, по крайней мере, до тех пор, пока пользователь  не попросит её остановиться. После запуска программы, нажатие на кнопку с крестиком, нажатие любой клавиши на клавиатуре или щелчок мыши внутри окна должен приводить к завершению её работы. А до того момента, она просто будет постоянно перерисовывать содержимое окна.\r\nВот и подошёл к концу очередной урок. Всем до встречи в уроке 5: Выборка из текстурного атласа попробуйте добавить движение изображения, например, при помощи стрелок.", "url": "https://habr.com/ru/post/437308/"},
{"title": "Цикл уроков по SDL 2.0: урок 3 — Библиотеки-расширения SDL", "article_text": "\r\nДо этого момента мы использовали только изображения в формате BMP, поскольку это единственный тип изображений, поддерживаемый основной библиотекой SDL 2, и это не очень-то удобно. К счастью, существует множество библиотек-расширений для SDL, добавляющих полезные возможности, например, SDL_image позволяет загружать многие типы изображений, SDL_ttf добавляет поддержку отрисовки текста с помощью шрифтов в формате TTF, SDL_net — низкоуровневую поддержку сети, а SDL_mixer — вывод многоканального аудио.\r\nВ этом уроке мы будем использовать только SDL_image, однако процесс установки для остальных расширений не отличается, и, в целом, почти совпадает с таковым для установки самой SDL2.\r\nТакже, чтобы использовать расширение, потребуется обновить список используемых заголовочных файлов и подключаемых библиотек, точно так же, как это было сделано для самого SDL2.\r\nПеред началом работы с расширением к использующим его файлам .c и .cpp необходимо подключить файл <SDL2/SDL_image.h>, или файл, соответствующий названию нужного расширения, после заголовочного файла самого SDL.\r\nПри первой загрузке изображения каждого типа SDL_image автоматически инициализирует необходимую для этого типа подсистему, однако, это вызовет небольшую задержку. Чтобы этого избежать, можно заранее проинициализировать необходимые подсистемы с помощью функции IMG_Init. IMG_Init возвращает битовую маску со списком всех успешно проинициализированных на данный момент подсистем, поэтому для проверки успешности вызова необходимо проверить, что биты для всех указанных для инициализации подсистем были установлены, например, применив маску к результату побитовым И. Для этого урока нам хватит только одной подсистемы PNG. Важно проводить эту операцию после SDL_Init.\r\nВ этом уроке мы рассмотрим, как загружать изображения с помощью SDL_image, как масштабировать текстуры при отрисовке и замостим фон плиткой более рациональным способом, нежели в предыдущем уроке — циклом, основывающемся на размерах окна и плиток. \r\nНо для начала зададим константу для размера плиток, прямо под константами для размеров окна.\r\nSDL_image позволяет загрузить несколько типов изображений, а так же сразу преобразовать их в SDL_Texture функцией IMG_LoadTexture. Эта функция заменяет почти весь код функции loadTexture из предыдущего урока, теперь достаточно просто вызвать IMG_LoadTexture, проверить, не возникло ли ошибок при загрузке, и выйти из функции. Поскольку определённая в SDL_image функция IMG_GetError — не более чем синоним для SDL_GetError, для вывода сообщений об ошибках мы можем использовать любую из них.\r\nЕсли при отрисовке текстуры на рендерер указать размер прямоугольника, отличный от размера самой текстуры, SDL2 отмасштабирует её соответствующим образом. Однако, если масштабирование не требуется, то каждый раз определять исходный размер текстуры может быть неудобно, поэтому мы реализуем две версии функции renderTexture, одна из которых будет отрисовывать текстуру с масштабированием, а вторая — без.\r\nПоскольку основная цель этого урока — загрузка изображений PNG, мы воспользуемся новым набором изображений. Также, мы продемонстрируем сохранение прозрачности PNG при отрисовке изображения переднего плана (с прозрачным фоном) поверх замощёного плиткой фона.\r\nМы будем использовать вот эти картиночки:\r\nПлитка для заполнения фона:\r\nИзображение переднего плана (как на нём и написано, с прозрачным фоном, а так же снова со смайликами, нарушающими правила Хабра):\r\nЗагружаем изображения:\r\nПоскольку плитки стали заметно меньше, нам понадобится поставить больше четырёх штук, чтобы заполнить всё окно, и указывать позицию для каждой вручную будет довольно сложно. К счастью, можно заставить компьютер определять эти позиции самостоятельно.\r\nМы можем узнать, сколько нужно плиток в ширину, поделив ширину окна на размер плитки, и аналогично для высоты.\r\nКак и прежде, изображение переднего плана помещается в середине окна.\r\nОсталось только отобразить результат на окне и подождать пару секунд, так же, как и во втором уроке.\r\nОсвобождение ресурсов аналогично таковому в уроке 2 (и уже встречалось выше, при обработке ошибки загрузки изображения), за исключением добавившегося вызова IMG_Quit.\r\nПосле успешной компиляции и запуска, если вы всё сделали правильно, окно будет выглядеть примерно так:\r\nВот и подошел к концу очередной урок. Всем до встречи в уроке 4: Обработка событий.", "url": "https://habr.com/ru/post/437252/"},
{"title": "Трехмерная визуализация в тренажерах подвижного состава на базе движка OpenSceneGraph", "article_text": "\r\nЧуть меньше года назад увидела свет , где мы рассказывали об учебно-лабораторном комплексе (УЛК) электропоезда ЭС1 «Ласточка», разработанном нашем университете. Тогда я обещал, что это будет не последняя публикация на данную тему, в частности грозился рассказать о проблемах создания трехмерной визуализации для подобного рода симуляторов и очертить основные подходы к их решению.\r\nПрошедший год порадовал нас очередным релизом — УЛК высокоскоростного электропоезда ЭВС2 «Сапсан», который состоялся ещё в августе прошлого года. Сам по себе учебно-лабораторный комплекс данного электропоезда заслуживает отдельного рассказа, но в контексте этой публикации речь пойдет о наболевшем — проблеме создания адекватной подсистемы трехмерной визуализации, к решению которой наша команда подступалась с разных сторон около двух лет. Релиз симулятора «Сапсана» знаменателен (среди прочего) и тем, что определил вектор развития наших разработок в этой области.\r\nХочу подчеркнуть ещё раз (что я делаю с завидной периодичностью) что учебно-лабораторные комплексы подвижного состава, разрабатываемые в нашем университете, не предназначены для подготовки локомотивных бригад. Как справедливо  предыдущей статьи, наши УЛК являются не тренажерами, а симуляторами, где основной упор делается на грамотную реализацию физики движения поезда и моделирование работы подсистем подвижного состава, обеспечивающих его движение и остановку. Не является исключением и симулятор «Сапсана», на котором решены следующие задачи:\r\nКроме того, учебно-лабораторный комплекс имеет в своем составе полноразмерный макет кабины электропоезда с основными органами управления и средствами отображения информации. В отличие от тренажера «Ласточки» эта кабина не изготавливалась нами самостоятельно, а была приобретена в 2015 году у одной известной в нашей стране конторы, занимающейся выпуском учебных тренажеров. Поэтому в процесс разработки симулятора сосредоточился на создании программного обеспечения.\r\nРазработка ПО подобного тренажера-симулятора вопрос очень широкий, и я постараюсь (в меру разумного) удовлетворить интерес читателей к этим вопросам в будущем (если таковой появится), но пока что, вернемся к основной теме статьи — трехмерной визуализации процесса движения поезда.\r\nВ комментариях к прошлой статье , который, признаюсь честно, изрядно меня позабавил. Да, действительно, во многих, до сих пор эксплуатируемых сегодня тренажерах до сих пор применяется такой подход: снимается видео на реальном участке железной дороги, а затем прокручивается на тренажере со скоростью, пропорциональной скорости движения. Так делали только потому, что в те далекие времена, когда подобные тренажеры создавались, качество трехмерной графики, оставляло желать лучшего, причем это касалось и суровых графических станций на коммерческих юниксах, а уж о ПК и речи не шло. Поэтому, даже производители компьютерных игр, например , не гнушались использовать такой подход. \r\nНа сегодняшний день это не имеет смысла, потому что:\r\nПоэтому все современные тренажеры и симуляторы создаются с применением интерактивной 3D-графики, благо сегодня нет никаких препятствий ни с программной, ни с аппаратной точки зрения.\r\nЕсли с аппаратной точки зрения всё предельно ясно — монитор установленный вместо лобового стекла подключается к ПК с нормальной видеокартой (даже не самой топовой), то с программной точки зрения встает вопрос выбора технологии реализации задачи. \r\nМогу ошибаться, но заранее предчувствую комментарии, в которых будет задаваться вполне закономерный вопрос, почему при анализе существующих технологий наш выбор не остановился на таких мастодонтах как Unity или Unreal Engine 4? Я отвечу на этот вопрос, более того, я обосную свой ответ. \r\nКратко — ни Unity ни Unreal Engine не удовлетворяют требованиям решаемой задачи. Более подробный ответ предусматривает, прежде всего перечисления тех требований, о которых идет речь. ТЗ, составленной нами на подсистему трехмерной визуализации, включает в себя (в порядке убывания значимости) следующие положения:\r\nЧто же не так с Unity и UE? Что тот, что другой движки способны импортировать ресурсы совершенно разных форматов. Однако при сборке проекта происходит их необратимое преобразование во внутренний бинарный формат, делающее невозможным добавление и изменение ресурсов без повторной сборки проекта. Технологии типа prefabs и asset bundles, доступные в Unity не решают задачу, так как редактор движка — не лучшее место для создания железнодорожных локаций, из-за чего возникает потребность расширения редактора, что приводит к необходимости писать «движок внутри движка». Кроме того, создание префабов и бандлов невозможно без применения редактора Unity, а это, как показала практика, не слишком удобно, особенно для чистых моделлеров и левел-дизайнеров. Что же касается UE, и на этом и на других ресурсах за два года мной было задано достаточно вопросов, о том как отделить процесс сборки проекта от процесса добавления/изменения используемых им ресурсов, и адекватного ответа я не получил ни в документации, ни от «матерых» геймдевелоперов. Буду очень рад (без сарказма) если меня аргументировано натыкают носом во что-то, что было мной упущено.\r\nЧто касается второго требования, то и Unity и UE вроде как обеспечивают возможность создания динамически загружаемых локаций, но остается нераскрытым вопрос, каким образом подобные локации можно создавать независимо от редактора и без пересборки проекта? Выход один — писать «движок внутри движка», который будет загружать «сырую» (в любом из наперед заданном формате экспорта из 3D-редакторов) геометрию и текстуры, применять к ним все необходимые эффекты и позиционировать в пространстве опираясь на данные, описанные в стороннем, независимом от движка формате, который нужно ещё разработать и научить движок его интерпретировать.\r\nВ связи с вышеперечисленным возникает вопрос — если для решения поставленной задачи необходимо писать мощную программную прослойку над игровым движком, большая часть функциональности которого в рассматриваемой задаче просто не нужна, то зачем нужен игровой движок? \r\nМожет быть достаточно графического движка? Этот вопрос я задавал предыдущей команде, бравшейся за обсуждаемую проблему опираясь на Unity (и закономерно слившейся чуть позже). В ответ получил встречный вопрос: «А что предлагаете вы?», ответив на который в духе приведенного выше текста получил саркастическую улыбку оппонента.\r\nЕсли обойтись без сарказма, то представленная задача является типичной задачей визуализации — здесь требуется только фреймворк для работы с графикой, так как и физика, и аудиоподсистема, опирающаяся на физику реализованы на серверной стороне. Я и моя команды пришли к пониманию этого факта двигаясь по инерции предыдущих разработчиков сначала в сторону Unity, через UE и попытки прикрутить графическую подсистему от оного из открытых железнодорожных симуляторов (OpenBVE, что кстати получилось, но стало временным костылем) является на сегодняшний день самым развитым (из открытых и бесплатных) графическим движком, ориентированным на C++ разработку. Он достаточно широко применяется за рубежом именно для технической трехмерной визуализации. Этот движок не обошли стороной и разного рода симулятора, наиболее известный из которых — . Некогда существовал и железнодорожный симулятор на базе этого движка — , от которого, впрочем, остались только унылые скриншоты по вышеприведенной ссылке и его дальнейшая судьба мне неизвестна. \r\nВ контексте решаемой задачи графический движок OSG обладает следующими положительными качествами:\r\nПотребовалось около полугода напряженного изучения возможностей OSG для того чтобы тщательно «прощупать почву» и найти подходы к решению поставленной задачи с помощью этого движка. То что родилось в итоге заслуживает отдельного разговора.\r\nВидеоподсистема тренажеров подвижного состава (ВТПС) является клиентским приложением, буднично именуемым video3d-client и выполняет следующие функции: \r\nНе то чтобы этот проект был opensource, однако с кодом полнофункциональной технологической демки вполне можно ознакомится . Проект состоит из следующих модулей:\r\nПри проектировании ВТПС встал вопрос выбора: разрабатывать формат маршрутов самостоятельно, либо воспользоваться существующим форматом маршрутов, а так же готовыми маршрутами отечественных железных дорог для существующего железнодорожного симулятора. На счастье подвернулось решение — закрытый проприетарный продукт , обладающий той особенностью, что он заточен под отечественный подвижной состав и специфику работы сети железных дорог. Несмотря на похвальбу авторов проекта, он имеет массу существенных недостатков, но при этом имеет простой и понятный формат маршрутов, находящихся в открытом доступе. На первом этапе было грех не воспользоваться имеющейся возможностью, при том что графическая часть симулятора основана на открытом движке DGLEngine. Беда в том, что данный движок хоть и развивается (текущее состояние проекта ), но его текущая вторая версия несовместима с версией 1.1, на которой основан ZDSimulator. Исходники версии 1.1 утеряны, ссылки ведущие к ним давно протухли.\r\nТщательный поиск в вебархиве позволил найти утерянное и спасти, разместив  на Gtihub. Этот движок использует свой, специфический формат 3D-моделей. Имея исходники движка нетрудно было написать соответствующий плагин для OSG. \r\nТаким образом задача создания ВТПС свелась к написанию программной части на движке OSG. В дальнейшем планируется разработка собственного формата маршрутов, так как текущий формат предусматривает движение только по главным путям и обладает рядом недостатков, не позволяющих воссоздать ряд сложных маршрутов.\r\nИерархия основных классов ВТПС представлена на следующей диаграмме\r\nИерархия классов загрузчика маршрутов выглядит так\r\nЗагрузчик любого другого формата маршрутов может быть написан как плагин, содержащий класс, наследующий от класса RouteLoader. При старте ВТПС ей передается путь к каталогу с маршрутом, определяется формат маршрута и динамически загружается соответствующий плагин, выполняющий далее остальную грязную работу.\r\nПринципиально важным нюансом явилась интеграция движка OSG и Qt. Таковая интеграция существует и именуется . Эта библиотека не использована в данном проекте по двум причинам:\r\nВозникло понимание того, что интеграция с Qt нужна в части использования концепции «сигналы-слоты», для обеспечения взаимодействия с сетевой подсистемой tcp-connection, использующей Qt и являющейся стандартом де-факто в наших разработках. Опираться на систему сообщений OSG и заново писать TCP-клиент (да ещё и кроссплатформенный) очень не хотелось. Нашлось элегантное решение, опирающееся на то, что если мы хотим, чтобы один объект послал сигнал, инициирующий срабатывание слота у другого объекта мы должны выполнить три условия:\r\nПри этом вовсе ни в коем случае не следует выполнять вызов QApplication::exec(), запускающий штатный цикл обработки сигналов, достаточно организовать цикл в котором просто обрабатывать сигналы вызовом QApplication::processEvents(). В OSG таковой цикл имеется (тот цикл, в котором выполняется рендеринг) и имеется возможность создать обработчик событий, в котором обрабатывается событие osgGA::GUIEventAdapter::FRAME, генерируемое движком при отрисовке очередного кадра. Таким образом вся интеграция свелась к коду\r\nпосле чего, классы унаследованные от QObject и его производных могут обмениваться сигналами до потери пульса.\r\nВсё вышеперечисленной позволило за два месяца создать первый рабочий прототип ВТПС. Чтобы продемонстрировать что вышло в итоге, предлагаю следующую нарезку из опытных поездок по реальным маршрутам. Заранее прошу прощения за качество съемки — не разжились толковой техникой\r\nГлавным выводом, по крайней мере для нашей команды стало то, что «серябрянной пули» не существует и в вопросах выбора технологии реализации проекта. Агрессивно продвигаемые на рынок игровые движки не всегда подходят для решения специфических задач, к каким относится визуализация результатов моделирования технических систем. А если и подходят, то не являются оптимальными с точки зрения усилий, потраченных на разработку и сопровождение проекта.\r\nОбидно, что весьма неплохой, а главное свободный, графический движок OSG по факту не имеет в нашей стране сообщества. Дабы исправить эту проблему я пишу  (там я собрал все ссылки на более менее адекватные источники информации, в том числе и на русском языке). Кроме того, в качестве документации, описывающей базовые принципы OSG могу предложить ещё и . Надеюсь что кому-то эта информация окажется полезной.\r\nЧто касается ВТПС, то работа в этом направлении продолжается. На очереди ещё масса важных задач, которые предстоит решить в ближайшем будущем.\r\nБлагодарю за внимание!", "url": "https://habr.com/ru/post/436276/"},
{"title": "Инициализация в С++ действительно безумна. Лучше начинать с Си", "article_text": "Недавно  , почему я   давать новичкам C++. Это  , потому что в C++ реальный бардак — хотя и красивый, но извращённый, трагический и удивительный бардак. Несмотря на нынешнее состояние сообщества, эта статья не направлена против  C++. Скорее она частично продолжает  Саймона Брэнда , а частично — это послание каждому студенту, который хочет начать своё образование, глядя в бездну.\r\nТипичные возражения студентов, когда им говорят об изучении C:\r\nКажется, многие студенты думают, что изучение C не имеет особого значения (от автора: это не так) и вместо этого нужно начинать с C++. Давайте рассмотрим только одну из причин, почему это абсурдное предложение: . В оригинальной статье Саймон Брэнд предположил, что читатель уже знаком со странностями инициализации в версиях до C++11. Мы же здесь посмотрим на некоторые из них и пойдём немного дальше.\r\nПозвольте для начала пояснить, что в этой статье моё личное мнение, а  официальная позиция университета Дрекселя, где я преподаю на кафедре электротехники и вычислительной техники. Мои лекции обычно входят в курс инженерной программы, а не информатики, то есть больше относятся к системному программированию и встраиваемым системам. умудрился пересказать всю эту статью в одной гифке. (Думаю, это оригинальная работа )\r\nЯ ничего не имею против C++, но там много всего, что вам не нужно на раннем этапе.\r\nВот и всё. Иди домой. Погуляй с собакой. Постирай бельё. Позвони маме и скажи, что ты её любишь. Попробуй новый рецепт. Здесь нечего читать, ребята. В самом деле, подумайте о том, насколько плохо инженеры (то есть я) умеют доносить свои мысли… \r\nВсё, я уговаривал как мог!\r\nИтак, ты ещё здесь? Настоящий солдат. Если бы я мог, я бы дал тебе медаль! И вкусное шоколадное молочко!\r\nСначала рассмотрим , потому что она похожа на C++ по соображениям совместимости. Это будет довольно быстро, потому что C такой скучный и простой (). Эту инициализацию назубок заучивает каждый новичок, потому что в C она работает иначе, чем во многих новых статически типизированных языках. Там либо инициализация по умолчанию для приемлемых значений, либо выдаётся ошибка компиляции.\r\nЛюбой нормальный программист на C знает, что это инициализирует  как неопределённое значение (для всех намерений и целей  не инициализирована). Обычно рекомендуется инициализировать переменные, когда они определены, например ;, и переменные всегда следует инициализировать перед использованием. Независимо от того, сколько раз  мягко напоминать студентам об этом, остаются те, кто считает, что переменная по умолчанию инициализируется в .\r\nОтлично, попробуем ещё один простой пример.\r\nОчевидно, это одно и то же? Мы понятия не имеем о значении  — она может быть любой.\r\nНет.\r\nПоскольку у переменной есть статическая продолжительность хранения, она инициализируется в беззнаковый ноль. Вы спросите, почему? Потому что так сказано в стандарте. Аналогичное поведение у типов указателей, которые я даже не собираюсь рассматривать в этой статье.\r\nОкей, посмотрим на структуры.\r\nТо же самое.  не инициализирована. Мы увидим предупреждение при компиляции.\r\nВ C можно инициализировать объект несколькими простыми способами. Например: 1) с помощью вспомогательной функции, 2) во время определения или 3) присвоить некое глобальное значение по умолчанию.\r\nЭто практически всё, что нужно знать об инициализации в C, и этого достаточно, чтобы вызвать множество хитрых ошибок во многих студенческих проектах. И уж точно проблемы появятся, если считать, что по умолчанию всё инициализируется в .\r\nЕсли вам не терпится узнать все  чудеса C++, сначала изучите способы инициализации переменных. Здесь такое же , как в C из предыдущего кода, но с некоторыми оговорками в  этого поведения. В тексте я буду выделять  специфический жаргон C++, чтобы подчеркнуть те моменты, где я не просто произвольно называю вещи, а указывают на огромное количество новых… … в C++ по сравнению с C. Начнём с простого:\r\nЗдесь у С и C++ почти одинаковое поведение. В C просто создаётся объект типа , значение которого может быть любым. В C++  , то есть для построения структуры используется . Поскольку  настолько тривиальна, у неё , который в этом случае ничего не делает. Неявно определенный конструктор по умолчанию «имеет точно такой же эффект», как:\r\nЧтобы проверить наличие неинициализированного значения, смотрим на предупреждение во время компиляции. На момент написания этой статьи  выдавал хорошие предупреждения, а  в этом случае ничего не выдавал (с установленным ). Обратите внимание, что включена оптимизация для просмотра дополнительных примеров.\r\nПо сути именно этого мы ожидаем от C. Так как же инициализировать ?\r\nНаверное, можно применить те же способы, что и в С? В конце концов, C++ является надмножеством С, верно? ()\r\nВот вам и родственники. Явные инициализаторы не поддерживаются в C++ до C++20. Это стандарт C++, который планируется к выходу в 2020 году. Да, в C++ функцию реализуют через 21 год после того, как она появилась C. Обратите внимание, что я добавил  для удаления поддержки нестандартных расширений gcc.\r\nЧто насчёт такого?\r\nНу хоть это работает. Мы также можем сделать  с тем же эффектом, что и нулевая инициализация . Это потому что  представляет собой . Что это такое? агрегированный тип (по сути) является либо простым массивом в стиле C, либо структурой, которая выглядит как простая структура C. Ни спецификаторов доступа, ни базовых классов, ни пользовательских конструкторов, ни виртуальных функций. Агрегированный тип получает агрегированную инициализацию. Что это значит?\r\nОтлично, что это значит? Если у объекта другой тип класса с пользовательским конструктором, будет вызван этот конструктор. Если объект является типом класса без пользовательского конструктора, как , он будет рекурсивно инициализирован определённым значением. Если у нас встроенный объект, как , то он .\r\nУрррррррааа! Наконец-то мы получили своего рода значение по умолчанию: ноль! Ух ты. ситуация выглядит иначе… вернёмся к этому позже.\r\nТрудно запомнить и запутано? Обратите внимание, что у каждой версии C++ свой набор правил. . Эти правила обычно действуют, поэтому обычно система работает так, будто вы инициализируете элементы как ноль. Но на практике лучше явно всё инициализировать. Я не придираюсь к агрегированной инициализации, но мне не нравится необходимость пробираться сквозь дебри стандарта, чтобы точно узнать, что происходит во время инициализации.\r\nЧто ж, инициализируем  методом C++ с  ()! Можем назначить элементу  в структуре  начальное значение в  конструкторе по умолчанию:\r\nЭто инициализирует  в . Более грязный способ — установить значение внутри тела конструктора:\r\nПоскольку тело конструктора может делать практически что угодно, лучше выделить инициализацию в список инициализаторов членов (технически часть тела конструктора).\r\nОкей, теперь конструктор по умолчанию гарантирует, что  установлен в 0, когда любая структура  инициализируется по умолчанию. Наконец, если мы хотим разрешить пользователям A задать начальное значение , можно для этого создать другой конструктор. Или смешать их вместе с аргументами по умолчанию:\r\nОтлично! Вот и всё. Миссия выполнена. Вы получили толчок и готовы продолжать приключения в мире C++, раздобыв полезное руководство по выживанию с инструкциями по инициализации переменных. Разворачиваемся и идём дальше!\r\nМы  бы остановиться. Но, если мы хотим использовать  возможности  C++, то должны углубиться дальше. На самом деле моя версия g++ (8.2.1), по умолчанию использует , что эквивалентно C++14 с некоторыми дополнительными расширениями GNU. Более того, эта версия g++ также полностью поддерживает C++17. «Разве это имеет значение?» — можете вы спросить. Парень, надевай свои рыболовные сапоги и следуй за мной в самую гущу.\r\nВо всех последних версиях, включая C++11, реализован этот новомодный способ инициализации объектов, который называется . Чувствуете, как холодок пробежал по спине? Это также называется . Есть несколько веских причин использовать этот синтаксис: см.  и . Одна забавная цитата из FAQ:\r\nСписок инициализации применяется с фигурными скобками (, это называется ) и выглядит следующим образом:\r\nЭй, эй, вы это заметили? Остался неинициализированным только . Очевидно, что список инициализации работает иначе, чем просто вызов конструктора. производит то же поведение, что и . В обоих случаях  инициализируется пустым списком braced-init-list. Кроме того,  больше не называется агрегатной инициализацией — теперь это  (). Мы уже говорили, что  создаёт объект с неопределённым значением и вызывает конструктор по умолчанию.\r\nВ строках 7/8 происходит следующее (помните, что это ):\r\nА если список не пуст? инициализируется в 0,  инициализируется пустым списком, а  — копия, построенная из . Вы ведь знаете, что такое конструктор копий, ? Тогда вы знаете также о конструкторах перемещения, ссылках rvalue, а также передаваемых ссылках, pr-значениях, x-значениях, gl-значе… ладно, неважно.\r\nК сожалению, в каждой версии с C++11 значение агрегата изменялось, хотя функционально до сих пор между агрегатами C++17 и C++20 нет никакой разницы. В зависимости от того, какая используется версия стандарта C++, что-то может быть или не быть агрегатом. Тренд в направлении либерализации. Например, публичные базовые классы в агрегатах разрешены начиная с C++17, что в свою очередь усложняет правила инициализации агрегатов. Всё замечательно!\r\nКак себя чувствуете? Немного водички? Сжимаются кулаки? Может, сделаем перерыв, выйдем на улицу?\r\nЧто произойдет, если  не является агрегатным типом?\r\nВкратце, что такое агрегат:\r\nТак что неагрегатный объект может быть таким:\r\nЗдесь у  есть предоставленный пользователем конструктор, поэтому инициализация списка работает иначе.\r\nВ строке 7 происходит следующее:\r\nКак насчет следующего: — это класс, а не структура, поэтому  будет приватным, и нам пришлось установить  в качестве дружественной функции. Что делает  не агрегатом. Это просто обычный тип класса. Это значит, что  останется неинициализированным, верно?\r\nЧёрт побери. И это тогда, когда мы вроде начали разбираться со всем этим. Оказывается,  инициализируется как 0, даже если не вызывает инициализацию агрегата:\r\nЧто если мы попробуем агрегатную инициализацию: не является агрегатом, поэтому происходит следующее:\r\nВ качестве бонуса озорной примерчик:\r\nЗдесь нет приватных переменных, как в предыдущем примере, но есть пользовательский конструктор, как в предпоследнем примере: таким образом, A не является агрегатом. Предоставленный пользователем конструктор исключает нулевую инициализацию, ?! Разберёмся по пунктам:\r\nОдин последний пример: инициализируется, а  нет. Что происходит в этом примере? Не знаю! Все базы  и члены здесь должны получить нулевую инициализацию. Я задал вопрос на , и  люди пришли к консенсусу, что здесь ошибка компилятора. Эти правила тонкие и сложные для . Для сравнения, статический анализатор clang (не обычный компилятор) вообще не предупреждает о неинициализированных значениях. Разбирайтесь сами.\r\n... хорошо, давайте нырнём ещё глубже!\r\nВ C++11 появилось нечто под названием . У него собственный тип: очевидно, . Вы можете создать его с помощью braced-init-list. И кстати, braced-init-list для списка инициализации не имеет типа. Не путайте initializer_list со списком инициализации и braced-init-list! Все они имеют отношение к спискам инициализаторов членов и инициализаторам членов по умолчанию, так как помогают инициализировать нестатические элементы данных, но при этом сильно отличаются. Они связаны, но разные! Несложно, правда?\r\nОкей. У  один шаблонный конструктор, который принимает . Каждый раз вызывается конструктор, предоставляемый пользователем, что ничего не делает, поэтому  остаётся неинициализированным. Тип  выводится в зависимости от элементов в списке, а новый конструктор создаётся в зависимости от типа. действует примерно как типичный контейнер STL, но только с тремя компонентными функциями: ,  и . Итераторы  и  вы можете нормально разыменовать, увеличивать и сравнивать. Это полезно, когда требуется инициализировать объект списками разной длины:\r\nУ  есть конструктор, который принимает , поэтому мы можем легко инициализировать векторы, как показано выше.\r\nОки–доки, последний пример:\r\nНа первый взгляд, это не слишком сложно. У нас два конструктора: один принимает , а другой с аргументами по умолчанию принимает . Прежде чем посмотреть на выдачу ниже, попробуйте сказать, каким будет значение для каждого .\r\nПодумали...? Посмотрим, что получится.\r\nС  всё должно быть легко. Это простая инициализация по умолчанию, которая выбирает конструктор по умолчанию, используя его аргументы по умолчанию.  использует список инициализации с пустым списком. Поскольку у  есть конструктор по умолчанию (с аргументами по умолчанию), происходит инициализация значения с простым обращением к этому конструктору. Если бы у  не было этого конструктора, то пошло бы обращение к конструктору в третьей строке с вызовом пустого списка.  использует скобки, а не список braced-init-list, поэтому разрешение перегрузки выбирает  с конструктором, принимающим . Далее,  использует список инициализации, для которого разрешение перегрузки склоняется в пользу конструктора, принимающего объект . Очевидно,  нельзя соотнести с каким-то , поэтому используется тот же конструктор, что и для .\r\nНадеюсь, вы поняли, что эта статья () полемическая и, надеюсь, немного информативная. Многие описанные здесь нюансы можно игнорировать, и язык будет предсказуемо реагировать, если вы не забудете инициализировать переменные перед использованием и инициализировать элементы данных во время построения. Для написания грамотного кода необязательно изучать все пограничные ситуации С++, вы всё равно по ходу работы разберётесь с подводными камнями и идиомами. , список инициализация — хорошая вещь. Если вы написали конструктор по умолчанию, он вызывается и должен всё инициализировать. В противном случае все инициализируется нулём, а затем независимо активируются дефолтные инициализаторы членов. Неинициализированное поведение тоже нужно оставить, потому что где-то, вероятно, есть код, который  на неинициализированные переменные.\r\nНадеюсь, мне удалось продемонстрировать, что C++ большой, трудный язык (по многим историческим причинам). Вся статья посвящена нюансам инициализации. . И мы даже не раскрыли тему целиком, а кратко описали лишь 5 типов инициализации. Саймон в  упоминает 18 типов инициализации.\r\nЯ бы не хотел обучать новичков программированию на примере C++. В этой статье не нашлось места концепциям системного программирования, рассуждениям о парадигмах программирования, методологиям решения задач или фундаментальным алгоритмам. Если вы заинтересованы в C++, то записывайтесь на курс конкретно по C++, но имейте в виду, что там будут изучать именно этот язык. Если вам интересует  или , то сначала узнайте о реализации  и коллизиях идентификаторов в C.\r\nC — отличный, чёткий, быстрый, хорошо поддерживаемый и широко используемый язык для решения проблем в различных областях. И у него точно нет 18 типов инициализации.\r\nКстати, я совершенно забыл, что . Вот что делает подсознание.\r\nОбсуждение этой статьи и критика на разных форумах: да, можно научиться разумным способам инициализации переменных и никогда не встретиться с . На этот счёт я специально написал в эпилоге, что список инициализации — хорошая вещь. Лично я редко пользуюсь шаблонами, но всё равно использую C++. Дело не в этом. Дело в том, что начинающий программист может полностью игнорировать STL и использовать стандартную библиотеку C, игнорировать ссылки, исключения и наследование. Так мы приближаемся к C с классами, за исключением того, что это не C, и вы всё ещё не понимаете указатели, выделение памяти, стек, кучу, виртуальную память. И теперь всякий раз, когда мне действительно нужен C, я должен переключиться на  язык, который мог выучить с самого начала. Если вы собираетесь использовать C++, используйте C++. Но если вы хотите использовать C++ без всех особенностей C++, то просто изучите C. И повторю из , я не против C++. Мы видим бородавки на теле любимых и всё равно любим их.", "url": "https://habr.com/ru/post/438492/"},
{"title": "Переход на Boost-1.65.1 и баги, которые всплыли", "article_text": "В прошлом году(уже почти целый год прошел) мы все–таки перешли на новую версию Boost-1.65.1, и под капотом вы найдете тройку багов boost-а, с которыми мы столкнулись. Еще важно упомянуть, что до этого у нас в ПО использовался boost -1.62.1, поскольку какие-то баги появились в boost ранее версии 1.65.1\r\nВ нашем проекте есть специальная команда интеграции, основной задачей которой является миграция всего софта на новую версию библиотек, Visual Studio, новые версии компонентов низкого уровня (базовые, от которых зависят большинство других компонентов) и т.п. Также команда интеграции ответственна за устранение всех проблем, которые при этом возникают, естественно при содействии мейнтейнеров компонентов, если это необходимо. Итак, баги, которые особенно запомнились мне.\r\nЭтот баг всплыл достаточно быстро. Тесты начали падать с “Access violation” при поиске полного пути к задаваемому имени файла. В функции делался вызов boost::filesystem::exist, и программа крашилась. Запустив еще несколько тестов, было замечено еще несколько аналогичных случаев, при этом во всех случаях вызов boost::filesystem::exist делался для глобальных переменных. Видимо, что-то поменялось во времени жизни переменных boost-та. Тикет для обнаруженного бага очень легко гуглится \r\nОказалось, что этот баг затесался в boost, начиная с версии 1.64. На самом деле проблема была в вызове make_permissions (используется в filesystem::exist). В 1.64 имплементация make_permissions была изменена, и теперь использовала глобальные переменные, а это значит, что когда делается попытка вызова filesystem::exist при инициализации глобальной переменной или объекта, глобальные переменные, используемые в make_permissions, могут быть еще не проинициализированы. Поэтому попытка доступа к несозданной переменной бросает исключение.\r\nВ тестах, использующих boost::python, была обнаружена странная вещь. При выполнении тривиального вызова eval() для литерала (например, «40+2») все норм. А если переменные определить, а потом использовать в выражениях, то получаем сообщение о том, что в вычислениях используются неопределенные переменные(ERROR: [name] not defined). Для решения этой проблемы я потратила уже больше времени. Я не смогла найти тикет этой проблемы в баг трекере boost-а, поэтому пришлось попросить помощи команды этого компонента. Информация о баге была оперативно найдена .\r\nТак случилось, что в имплементации eval объекты global и local не использовались. Пожелав в поиске фикса без перекомпиляции исходников либы, команда откланялась :) \r\nЭто самая нелюбимая моя часть. boost::python::numeric был удален и теперь как альтернатива появился boost::python::numpy. Но код, использовавший numeric, пришлось изрядно переделать, поскольку дело не только в переименовании неймспейсов, но и в имплементации объектов.\r\nПомимо этого, в хедере boost-та была дезинформация, которая ввела меня в заблуждение.\r\nСогласно комментарию в исходнике, вызов import_array() уже делается в numpy::initialize():\r\nНо на деле, как оказалось, import_array() необходим.\r\nК тому же, были проблемы с тестированием изменений, поскольку куски кода с numpy (ранее с boost::python::numeric) вообще не были покрыты тестами, а сам код использовался еще и в другом компоненте. Поэтому проблемы выявлялись только при тестировании соответствующего компонента. Команда интеграции не обязана писать тесты для компонент, и данная ситуация была упущением самой команды. Ух и наслушалась я от них о том, что сломала их код. Но после того, как команда поворчала, они наконец-то покрыли свой код тестами. Однако обидка осталась (при следующей миграции, команда не хотела давать права доступа к своему компоненту моему коллеге, упоминая, что в прошлый раз, мы сломали им код.  Но после трех дней переговоров они сдались).\r\nПосле проделанной работы могу отметить плюсы для себя, поскольку boost до этого использовала не очень часто(в основном std), поэтому из миграции можно подчеркнуть много нового. Забавно, но факт, после такого почему-то вы по дефолту становитесь для многих коллег “экспертом boost”, и, смиритесь, вам будут задавать вопросы по нему еще некоторое время. \r\nКстати последние годы многие компании начали активно избавляться от boost и заменять по возможности std библиотекой, либо чем-то еще в случае отсутствия каких-то возможностей в стандартной библиотеке. И мы тоже не остались в стороне. Процесс запущен, но не завершен, еще много работы.", "url": "https://habr.com/ru/post/436828/"},
{"title": "Преодоление порога 32 КБ для данных в ПЗУ микроконтроллеров AVR", "article_text": "Что может быть хуже костылей? Только неполно документированные костыли.Перед вами скриншот из последней официальной интегрированной среды разработки для 8-битных микроконтроллеров AVR, Atmel Studio 7, язык программирования Си. Как видно из столбца Value, переменная my_array содержит число 0x8089. Другими словами, массив my_array располагается в памяти, начиная с адреса 0x8089.В то же время столбец Type даёт нам несколько иную информацию: my_array является массивом из 4 элементов типа int16_t, расположенным в ПЗУ (это обозначается словом prog, в отличие от data для ОЗУ), начиная с адреса 0x18089. Стоп, но ведь 0x8089 != 0x18089. Какой же на самом деле адрес у массива?8-битные микроконтроллеры AVR производства ранее Atmel, а ныне Microchip, популярные, в частности, из-за того, что они лежат в основе Arduino, построены по гарвардской архитектуре, то есть код и данные расположены в разных адресных пространствах. Официальная документация содержит примеры кода на двух языках: ассемблере и Си. Ранее производитель предлагал бесплатную интегрированную среду разработки, поддерживающую только ассемблер. А как же те, кто хотел бы программировать на Си, а то и Си++? Существовали платные решения, например, IAR AVR и CodeVisionAVR. Лично я им никогда не пользовался, ведь, когда я начал программировать AVR в 2008-м году, уже был бесплатный WinAVR с возможностью интеграции с AVR Studio 4, а в нынешнюю Atmel Studio 7 он просто включён.Проект WinAVR основан на компиляторе GNU GCC, который разрабатывался для архитектуры фон Неймана, подразумевающей единое адресное пространство для кода и данных. При адаптации GCC к AVR был применён следующий костыль: под код (ПЗУ, flash) отводятся адреса с 0 по 0x007fffff, а под данные (ОЗУ, SRAM) — с 0x00800100 по 0x0080ffff. Были и всякие другие хитрости, например, адреса с 0x00800000 по 0x008000ff представляли регистры, к которым можно обращаться теми же опкодами, что и к ОЗУ. В принципе, если вы простой программист, наподобие начинающего ардуинщика, а не хакер, смешивающий в одной прошивке ассемблер и Си/Си++, вам не нужно всё это знать.Помимо собственно компилятора WinAVR включает различные библиотеки (часть стандартной библиотеки языка Си и специфичные для AVR модули) в виде проекта AVR Libc. Последняя версия, 2.0.0, выпущена почти три года назад, а документация доступна не только на сайте самого проекта, но и на сайте производителя микроконтроллеров. Есть и неофициальные русские переводы.Иногда в микроконтроллер нужно поместить не просто много, а очень много данных: столько, что они просто не помещаются в ОЗУ. Причём данные эти неизменяемые, известные на момент прошивки. Например, растровая картинка, мелодия или какая-нибудь таблица. В то же время код зачастую занимает лишь небольшую долю имеющегося ПЗУ. Так почему бы не использовать оставшееся место под данные? Легко! В документации avr-libc 2.0.0 этому посвящена целая глава 5 Data in Program Space. Если опустить часть про строки, то всё предельно просто. Рассмотрим пример. Для ОЗУ пишем так:А для ПЗУ так:Так просто, что эта технология неоднократно освещалась даже в рунете.Помните утверждение, что 640 КБ хватит каждому? Помните, как переходили от 16-битной архитектуры к 32-битной, а от 32-битной к 64-битной? Как Windows 98 нестабильно работала на более 512 МБ ОЗУ при том, что её разрабатывали для 2 ГБ? Случалось ли вам обновлять БИОС, чтобы материнская плата работала с жёсткими дисками более 8 ГБ? Помните джамперы на 80-ГБ жёстких дисках, урезающие их объём до 32 ГБ?Первая проблема настигла меня тогда, когда я попытался создать в ПЗУ массив размером не менее 32 КБ. Почему именно в ПЗУ, а не в ОЗУ? Потому что в настоящее время 8-битных AVR с ОЗУ более 32 КБ просто не существует. А с более 256 Б — существуют. Вероятно, именно поэтому создатели компилятора выбрали для указателей в ОЗУ (и заодно для типа int) размер 16 б (2 Б), о чём можно узнать из чтения абзаца Data types, расположенного в главе 11.14 What registers are used by the C compiler? документации AVR Libc. Ох, а ведь мы не собирались хакерствовать, а тут регистры… Но вернёмся к массиву. Оказалось, что нельзя создать объект размером более 32 767 Б (2^(16 — 1) — 1 Б). Я не знаю, зачем длину объекта понадобилось делать знаковой, но это факт: никакой объект, даже многомерный массив, не может иметь длину 32 768 Б или больше. Немного напоминает ограничение на адресное пространство 32-битных приложений (4 ГБ) в 64-битной ОС, не правда ли?Насколько я знаю, эта проблема не имеет решения. Если вы хотите поместить в ПЗУ объект длиной от 32 768 — дробите его на более мелкие объекты.Ещё раз обратимся к абзацу Data types: pointers are 16 bits. Применим это знание к главе 5 Data in Program Space. Нет, теорией тут не обойтись, нужна практика. Я написал тестовую программу, запустил отладчик (к сожалению, программный, а не аппаратный) и увидел, что функция  способна возвратить только те данные, чьи адреса укладываются в 16 бит (64 КБ; спасибо, что не 15). Потом происходит переполнение, старшая часть отбрасывается. Логично, учитывая, что указатели 16-битные. Но возникает два вопроса: почему об этом не написано в главе 5 (вопрос риторический, но именно он побудил меня написать эту статью) и как всё-таки преодолеть границу в 64 КБ ПЗУ, не переходя на ассемблер.К счастью, помимо главы 5 есть ещё 25.18 pgmspace.h File Reference, откуда мы узнаём, что семейство функций  — это лишь переобозначение для , принимающих 16-битные адреса, а есть ещё , и туда можно подать адрес длиной 32 бита. Эврика!Пишем код:Он компилируется, но не работает так, как нам бы этого хотелось (если array2d расположен после 32 КБ). Почему? Да потому, что операция  возвращает знаковое 16-битное число! Забавно, что семейство  принимает беззнаковые 16-битные адреса, то есть способно работать с 64 КБ данных, а операция  полезна лишь для 32 КБ.Идём дальше. Что у нас есть в pgmspace.h помимо ? Функция , имеющая аж полстраницы описания, и заменяющая операцию .Наверное, правильно так:Ошибка компиляции. Читаем описание: 'var' has to be resolved at linking time as an existing symbol, i.e, a simple type variable name, an array name (not an indexed element of the array, if the index is a constant the compiler does not complain but fails to get the address if optimization is enabled), a struct name or a struct field name, a function identifier, a linker defined identifier,...Ставим очередной костыль: переходим от индексов массивов к арифметике указателей:Вот теперь всё работает.Если вы пишете на Си/Си++ для 8-битных микроконтроллеров AVR, используя компилятор GCC, и храните данные в ПЗУ, то:", "url": "https://habr.com/ru/post/436904/"},
{"title": "Запускаем свой нейросетевой детектор на Raspberry Pi с помощью Neural Compute Stick и OpenVINO", "article_text": "С распространением и развитием нейронный сетей все чаще возникает потребность их использования на встроенных и маломощных устройствах, роботах и дронах. Устройство Neural Compute Stick в связке с фреймворком OpenVINO от компании Intel позволяет решить эту задачу, беря тяжелые вычисления нейросетей на себя. Благодаря этому можно без особых усилий запустить нейросетевой классификатор или детектор на маломощном устройстве вроде Raspberry Pi практически в реальном времени, при этом не сильно повышая энергопотребление. В данной публикации я расскажу, как использовать фреймворк OpenVINO (на C++) и Neural Compute Stick, чтобы запустить простую систему обнаружения лиц на Raspberry Pi.\r\nКак обычно, весь код доступен на .\r\nЛетом 2017 года компания Intel выпустила устройство  (NCS), предназначенное для запуска нейронных сетей на маломощных устройствах, и уже через пару месяцев его можно было приобрести и испытать, что я и сделал. NCS представляет собой небольшой вычислительный модуль с корпусом лазурного цвета (выполняющим также роль радиатора), подключаемый к основному устройству по USB. Внутри, помимо всего прочего, находится Intel Myriad , по сути являющийся 12-ядерным параллельным процессором, заточенным под операции, часто возникающие в нейросетях. NCS не пригодна для обучения нейросетей, но вот инференс в уже обученных нейросетях сравним по скорости с таковым на GPU. Все вычисления в NCS проводятся над 16-bit float числами, что позволяет повысить скорость. NCS для работы требуется всего 1 Ватт мощности, то есть при 5 В на USB разъеме потребляется ток до 200 мА — это даже меньше, чем у камеры для Raspberry Pi (250 мА).\r\nДля работы с первой NCS использовался  (NCSDK): в него включены инструменты для компиляции нейросетей в форматах  и  в формат NCS, инструменты для измерения их производительности, а также Python и С++ API для инференса. \r\nЗатем была выпущена новая версия фреймворка для работы с NCS: . В ней довольно сильно изменился API, и хотя некоторые изменения показались мне странными, были и полезные нововведения. В частности, было добавлено автоматическое преобразование из float 32 bit в float 16 bit в C++ (раньше для этого приходилось вставлять костыли в виде кода из Numpy). Также появились очереди изображений и результатов их обработки.\r\nВ мае 2018 Intel выпустила  (который ранее именовался Intel Computer Vision SDK). Этот фреймворк предназначен для эффективного запуска нейросетей на различных устройствах: процессорах и графических картах Intel, , а также Neural Compute Stick.\r\nВ ноябре 2018 увидела свет новая версия ускорителя: . Вычислительная мощность устройства была повышена: в описании на сайте обещают ускорение до 8x, однако новую версию устройства мне не довелось протестировать. Ускорение достигается за счет увеличения числа ядер с 12 до 16, а также добавления новых вычислительных устройств, оптимизированных под нейросети. Правда, про потребляемую мощность информации я не нашел.\r\nВторая версия NCS уже несовместима с NCSDK или NCSDK2: их полномочия перешли OpenVINO, который способен помимо обеих версий NCS работать с множеством других устройств. Сам OpenVINO обладает огромным функционалом и включает следующие компоненты:\r\nВ своих предыдущих статьях я рассказывал о том, как запустить детектор лиц YOLO на NCS , а также о том, как обучить свой SSD детектор лиц и запустить его на Raspberry Pi и NCS . В этих статьях я использовал NCSDK и NCSDK2. В данной статье я расскажу, как проделать нечто похожее, но уже с помощью OpenVINO, проведу небольшое сравнение как разных детекторов лиц, так и двух фреймворков для их запуска, и укажу на некоторые подводные камни. Я пишу на C++, так как верю, что таким способом можно добиться большей производительности, что будет важно в случае Raspberry Pi.\r\nНе самая сложная задача, хотя есть тонкости. OpenVINO на момент написания статьи поддерживает только Ubuntu 16.04 LTS, CentOS 7.4 и Windows 10. У меня стоит Ubuntu 18, и для установки в ней нужны . Также я хотел сравнить OpenVINO с NCSDK2, с установкой которого тоже есть проблемы: в частности, он подтягивает свои версии Caffe и TensorFlow и может слегка поломать настройки окружения. В итоге я решил пойти по простому пути и установить оба фреймворка в виртуальную машину с Ubuntu 16 (я использую ). \r\nСтоит заметить, что для успешного подключения NCS к виртуальной машине нужно установить гостевые дополнения VirtualBox и включить поддержку USB 3.0. Также я добавил универсальный фильтр USB устройств, в результате чего NCS подключалась без проблем (хотя веб-камеру все еще приходится подключать в настройках виртуальной машины). Для установки и компиляции OpenVINO нужно завести учетную запись Intel, выбрать вариант фреймворка (с поддержкой FPGA или без) и следовать . С NCSDK еще проще: он загружается  (не забудьте выбрать ветку ncsdk2 для новой версии фреймворка), после чего нужно сделать .\r\nЕдинственная проблема, с которой я столкнулся при запуске NCSDK2 в виртуальной машине, это ошибка следующего вида:\r\nОна возникает в конце корректного выполнения программы и (вроде) ни на что не влияет. Судя по всему, это  (на Raspberry такого не должно быть).\r\nУстановка на Raspberry Pi существенно отличается. Для начала убедитесь, что у вас стоит Raspbian Stretch: оба фреймворка официально работают только на этой ОС. NCSDK2 нужно , иначе он попытается установить Caffe и TensorFlow, что вряд ли понравится вашей Raspberry. В случае OpenVINO есть уже , которую нужно лишь распаковать и настроить переменные окружения. В этой версии есть только C++ и Python API, а также библиотека OpenCV, все остальные инструменты недоступны. Это значит, что для обоих фреймворков модели нужно конвертировать заранее на машине с Ubuntu. Моя  работает как на Raspberry, так и на десктопе, поэтому я просто добавил конвертированные файлы нейросетей в свой репозиторий на GitHub, чтобы их было проще синхронизировать с Raspberry. У меня Raspberry Pi 2 model B, но должно взлететь и с другими моделями.\r\nЕсть еще одна тонкость, касающаяся взаимодействия Raspberry Pi и Neural Compute Stick: если в случае ноутбука достаточно просто ткнуть NCS в ближайший USB 3.0 порт, то для Raspberry придется найти USB кабель, иначе NSC своим корпусом заблокирует оставшиеся три USB разъема. Также стоит помнить, что на Raspberry все USB версии 2.0, поэтому скорость инференса будет ниже из-за задержек коммуникации (подробное сравнение будет позже). А вот если вы захотите подсоединить к Raspberry две или больше NCS, скорее всего, придется найти USB-hub с дополнительными питанием.\r\nДовольно громоздко. Нужно сделать много разных действий, начиная с загрузки плагина и заканчивая самим инференсом — поэтому я написал класс-обертку для детектора. Полный код можно посмотреть на GitHub, а здесь я просто перечислю основные моменты. Начнем по порядку: \r\nОпределения всех нужных нам функций находятся в файле  в пространстве имен .\r\nСледующие переменные будут нужны постоянно.  и  нам нужны для того, чтобы адресовать вход и выход нейросети. Вообще говоря, у нейросети может быть много входов и выходов, но в наших детекторах их будет по одному. Переменная  — это сама сеть,  — указатель на последний запрос инференса,  — указатель на массив данных входа нейросети. Остальные переменные говорят сами за себя.\r\nТеперь загрузим необходимый плагин — нам нужен тот, что отвечает за NCS и NCS2, его можно получить по имени «MYRIAD». Напомню, что в контексте OpenVINO плагин — это просто динамическая библиотека, подключающаяся по явному запросу. Параметром функции  является список директорий, в которых следует искать плагины. Если вы настроили переменные среды по инструкции, пустой строки будет достаточно. Для справки, плагины находятся в \r\nТеперь создадим объект для загрузки нейросети, считаем ее описание и установим размер батча (число одновременно обрабатываемых изображений). Нейросеть в формате OpenVINO задается двумя файлами: .xml с описанием структуры и .bin с весами. Пока будем использовать готовые детекторы из OpenVINO, позже создадим свой. Здесь  — это имя файла без расширения. Также нужно иметь в виду, что NCS поддерживает размер батча только равный 1. \r\nДалее происходит следующее:\r\nТеперь самый важный момент: загружаем нейросеть в плагин (то есть, в NCS). Судя по всему, компиляция в нужный формат происходит налету. Если на этой функции программа падает, вероятно, нейросеть не подходит для данного устройства.\r\nИ напоследок — произведем пробный инференс и получим размеры входа (возможно, это можно сделать и более изящно). Сначала открываем запрос на инференс, затем от него получаем ссылку на входной блок данных, и уже у него запрашиваем размер.\r\nПопробуем загрузить картинку в NCS. Точно так же создаем запрос на инференс, от него получаем указатель на блок данных, и уже оттуда достаем указатель на сам массив. Далее просто копируем данные из нашей картинки (здесь она уже приведена к нужному размеру). Стоит заметить, что в  и  измерения хранятся в разном порядке (в OpenCV индекс канала меняется быстрее всех, в OpenVINO — медленнее всех), поэтому одним memcpy не обойтись. Затем начинаем асинхронный инференс. \r\nЗачем асинхронный? Это позволит оптимизировать распределение ресурсов. Пока NCS считает нейросеть, можно обрабатывать следующий кадр — это приведет к заметному ускорению на Raspberry Pi.\r\nЕсли вы хорошо знакомы с нейросетями, у вас мог возникнуть вопрос о том, в какой момент мы масштабируем значения входных пикселей нейросети (например, приводим к диапазону ). Дело в том, что в моделях OpenVINO это преобразование уже включено в описание нейросети, а при использовании своего детектора мы сделаем что-то похожее. А поскольку и конвертацию в float, и масштабирование входов производит OpenVINO, нам остается только изменить размер изображения.\r\nТеперь (после выполнения некоторой полезной работы) завершим запрос на инференс. Программа блокируется, пока не придут результаты выполнения. Получаем указатель на результат.\r\nТеперь самое время задуматься о том, в каком формате NCS возвращает результат работы детектора. Стоит заметить, что формат немного отличается от того, что был при использовании NCSDK. Вообще говоря, выход детектора четырехмерный и имеет размерность (1 x 1 x максимальное число детекций x 7), можно считать, что это массив размера ( x 7). \r\nПараметр  задается в описании нейросети, и его несложно изменить, например, в .prototxt описании сети в формате Caffe. Ранее мы получили его из объекта, представляющего детектор. Этот параметр связан со спецификой работы класса детекторов , к которому относятся все поддерживаемые NCS детекторы. SSD всегда рассматривает одинаковое (и очень большое) число ограничивающих рамок для каждого изображения, а после отсеивания детекций с низкой оценкой уверенности и удаления перекрывающихся рамок с помощью Non-maximum Suppression обычно оставляют 100-200 лучших. Именно за это и отвечает параметр.\r\nСемь значений в описании одной детекции представляют собой следующее: \r\nТеперь о том, как выглядит общая схема инференса в реальном времени. Сначала инициализируем нейросеть и камеру, заводим  для сырых кадров и еще один для кадров, приведенных к нужному размеру. Заполняем наши кадры нулями — это прибавит уверенности в том, что на холостом запуске нейросеть ничего не найдет. Затем запускаем цикл инференса:\r\nВ примерах InferenceEngine мне не понравились громоздкие CMake файлы, и я решил компактно переписать все в свой Makefile:\r\nЭта команда будет работать как на Ubuntu, так и на Raspbian, благодаря паре трюков. Пути для поиска заголовков и динамических библиотек я указал и для Raspberry, и для машины с Ubuntu. Из библиотек, помимо OpenCV, надо подключить также  и  — библиотеку для динамической линковки других библиотек, она нужна, чтобы сработала загрузка плагина. При этом сам  указывать не надо. Помимо прочего, для Raspberry я также подключаю библиотеку  для работы с камерой (это ). Также пришлось использовать стандарт C++11.\r\nОтдельно стоит отметить, что при компиляции на Raspberry нужен флаг  (это ). Если его не указать, программа скомпилируется, но будет падать с тихим сегфолтом. А еще можно добавить оптимизации с помощью , это прибавит скорости.\r\nNCS поддерживает из коробки только SSD детекторы в формате Caffe, хотя с помощью пары грязных трюков мне удавалось запустить на ней .  является популярной архитектурой среди легковесных нейросеток, а с помощью разных энкодеров (или backbone сетей) можно достаточно гибко варьировать соотношение скорости и качества. \r\nЯ буду экспериментировать с разными детекторами лиц: \r\nДля детекторов из OpenVINO нет весов ни в формате Caffe, ни в формате NCSDK, поэтому их я смогу запустить только в OpenVINO.\r\nУ меня есть два файла в формате Caffe: .prototxt с описанием сети и .caffemodel с весами. Мне нужно получить из них два файла в формате OpenVINO: .xml и .bin с описанием и весами соответственно. Для этого необходимо использовать скрипт mo.py из OpenVINO (он же Model Optimizer): задает директорию, в которой будут созданы новые файлы,  — имя для новых файлов без расширения,  — тип весов в нейросети (NCS поддерживает только FP16). Параметры  задают среднее и масштаб для предобработки изображений перед их запуском в нейросеть. Конкретное преобразование выглядит так:\r\nВ данном случае происходит приведение значений из диапазона  в диапазон . Вообще у этого скрипта очень много параметров, некоторые из которых специфичны для отдельных фреймворков, рекомендую посмотреть мануал к скрипту.\r\nВ дистрибутиве OpenVINO для Raspberry нет готовых моделей, но их достаточно просто скачать.\r\nЯ использовал три варианта сравнения: 1) NCS + Виртуальная машина с Ubuntu 16.04, процессор Core i7, разъем USB 3.0; 2) NCS + Та же машина, разъем USB 3.0 + кабель USB 2.0 (будут больше задержки на обмен с устройством); 3) NCS + Raspberry Pi 2 model B, Raspbian Stretch, разъем USB 2.0 + кабель USB 2.0.\r\nСвой детектор я запускал как с OpenVINO, так и с NCSDK2, детекторы из OpenVINO только с их родным фреймворком, YOLO — только с NCSDK2 (скорее всего, его можно запустить и на OpenVINO).\r\nТаблица FPS для разных детекторов выглядит так (числа приблизительные):\r\nYOLO оказался самым медленным и самым неустойчивым из всех. Он очень часто пропускает детекции и не может работать с засвеченными кадрами. \r\nДетектор, который я обучал, работает вдвое быстрее, более устойчив к искажениям на кадрах и обнаруживает даже мелкие лица. Тем не менее, он все равно иногда пропускает детекции, а иногда обнаруживает ложные. Если отрезать от него несколько последних слоев, он станет чуть быстрее, но крупные лица видеть перестанет. Тот же детектор, запущенный через OpenVINO, становится немного быстрее при использовании USB 2.0, качество визуально не меняется.\r\nДетекторы из OpenVINO, конечно, намного превосходят и YOLO, и мой детектор. (Я бы даже не стал обучать свой детектор, если бы OpenVINO существовал в его текущем виде в то время). Модель retail-0004 существенно быстрее и при этом практически не пропускает лица, но зато мне удалось ее слегка обмануть (хотя confidence у этих детекций низкий): \r\nДетектор adas-0001 существенно медленнее, но при этом работает с изображениями большого размера и должен быть точнее. Я разницы не заметил, но проверял я на довольно простых кадрах.\r\nВ целом, очень приятно, что на маломощном устройстве вроде Raspberry Pi можно использовать нейросети, да еще и почти в реальном времени. OpenVINO предоставляет очень обширный функционал для инференса нейросетей на множестве разных устройств — гораздо шире, чем я описал в статье. Думаю, Neural Compute Stick и OpenVINO будут очень полезны в моих робототехнических изысканиях.", "url": "https://habr.com/ru/post/436744/"},
{"title": "История одной проблемы со Speedometer, или Как Chromium управляет памятью", "article_text": "Современный браузер — это крайне сложный проект, в котором даже безобидные с виду изменения могут приводить к неожиданным сюрпризам. Поэтому существует множество внутренних тестов, которые должны такие изменения отловить до релиза. Тестов никогда слишком много не бывает, поэтому полезно использовать в том числе сторонние публичные бенчмарки.\r\nМеня зовут Андрей Логвинов, я работаю в группе разработки рендеринг-движка Яндекс.Браузера в Нижнем Новгороде. Сегодня я расскажу читателям Хабра о том, как устроено управление памятью в проекте Chromium на примере одной загадочной проблемы, которая приводила к падению производительности в тесте . Этот пост основан на моём докладе с мероприятия Яндекс.Изнутри.\r\nОднажды на нашем дашборде производительности мы увидели ухудшение скорости работы теста Speedometer. Этот тест измеряет совокупную производительность браузера на приближенном к реальности приложении — списке дел, где тест добавляет пункты в список и затем вычёркивает их. На результаты теста влияет как производительность JS-движка V8, так и скорость отрисовки страниц в движке Blink. Тест Speedometer состоит из нескольких подтестов, где тестовое приложение написано с использованием одного из популярных JS-фреймворков, например jQuery или ReactJS. Общий результат теста определяется как среднее для результатов по всем фреймворкам, но тест позволяет посмотреть производительность по каждому фреймворку в отдельности. Стоит отметить, что тест не ставит своей целью оценить производительность фреймворков, они используются только для того, чтобы сделать тест менее синтетическим и более приближенным к реальным веб-приложениям. Детализация по подтестам показала, что ухудшение наблюдается только для версии тестового приложения, созданного с использованием jQuery. А это уже интересно, согласитесь.\r\nРасследование таких ситуаций начинается достаточно стандартно — мы определяем, какой именно коммит в код привёл к проблеме. Для этого у нас хранятся сборки Яндекс.Браузера на каждый (!) коммит за последние несколько лет (собирать заново было бы непрактично, так как сборка занимает несколько часов). Пространства на серверах это занимает немало, но обычно помогает быстро найти источник проблемы. Но в этот раз быстро не получилось. Оказалось, что ухудшение результатов теста совпало с коммитом, интегрирующим очередную версию Хромиума. Результат не обнадеживающий, потому что новая версия Хромиума приносит огромное количество изменений разом.\r\nПоскольку информации, указывающей на конкретное изменение, мы не получили, пришлось заняться исследованием проблемы по существу. Для этого мы при помощи Developer Tools сняли трейсы теста. Заметили странную особенность — «рваные» интервалы исполнения Javascript-функций теста.\r\nСнимаем более технический трейс при помощи about:tracing и видим, что это  в Blink.\r\nНа трейсе памяти ниже видно, что эти GC-паузы не только занимают много времени, но и никак не помогают остановить рост потребляемой памяти.\r\nНо если вставить в тест явный вызов GC, то мы видим совсем другую картину — память держится в районе нуля и не утекает. Значит, утечек памяти у нас нет, а проблема связана с особенностями работы сборщика. Продолжаем копать. Запускаем отладчик и видим, что сборщик мусора обошел около 500 тысяч объектов! Такое количество объектов не могло не повлиять на производительность. Но откуда они взялись?\r\nИ здесь нам понадобится небольшой флешбек про устройство сборщика мусора в Blink. Он удаляет мертвые объекты, но не перемещает живые, что позволяет оперировать «голыми» указателями в локальных переменных в коде C++. Этот паттерн активно используется в Blink. Но он имеет и свою цену — при сборе мусора приходится  потока, и если там обнаруживается что-то похожее на указатель на объект из кучи (heap), то считать объект и всё, на что он ссылается прямо или косвенно, живыми. Это приводит к тому, что некоторые фактически недоступные и поэтому «мертвые» объекты идентифицируются как живые. Поэтому такая форма сбора мусора ещё называется консервативной.\r\nПроверяем связь со сканированием стека и пропускаем его. Проблема исчезла.\r\nЧто же может быть такого в стеке, что удерживает 500 тысяч объектов? Ставим точку остановки в функцию добавления объектов — в числе прочего видим там подозрительное:\r\nblink::TraceTrait<blink::HeapHashTableBacking<WTF::HashTable<blink::WeakMember… — вероятный подозреваемый! Проверяем гипотезу, пропуская добавление этой ссылки. Проблема исчезла. Отлично, мы стали ещё на шаг ближе к разгадке.\r\nВспоминаем другую особенность сборщика мусора в Blink: если он видит указатель на внутренности хэш-таблицы, то считает это признаком продолжающейся итерации по таблице, а значит, считает все ссылки этой таблицы полезными и продолжает их обходить. В нашем случае вхолостую. Но какая же функция является источником этой ссылки?\r\nПродвигаемся на несколько кадров стека выше, берем текущую позицию сканера, смотрим, в кадр стека какой функции она попадает. Это функция с названием . Казалось бы, вот он виновник, но… смотрим на исходный код функции и видим, что никаких хэш-таблиц там и в помине нет. Тем более что это уже часть собственно сборщика мусора, и ссылаться на объекты из кучи Blink ей просто незачем. Откуда же тогда взялась эта «плохая» ссылка?\r\nСтавим брейкпойнт на изменение ячейки памяти, в которой нашли ссылку на хэш-таблицу. Видим, что пишет туда одна из внутренних функций под названием V8PerIsolateData::AddActiveScriptWrappable. Там происходит добавление создаваемых HTML-элементов некоторых типов, в том числе input, в единую хэш-таблицу active_script_wrappables_. Эта таблица нужна для предотвращения удаления элементов, на которые нет больше ссылок из Javascript или дерева DOM, но которые связаны с какой-либо внешней активностью, которая, например, может генерировать события.\r\nСборщик мусора при нормальном обходе таблицы учитывает состояние содержащихся в ней элементов и либо помечает их как живые, либо не помечает, тогда они удаляются на следующем этапе сборки. Однако, в нашем случае указатель на внутреннее хранилище данной таблицы всплывает при сканировании стека, и все элементы таблицы помечаются как живые.\r\nНо как значение из стека одной функции попало в стек другой?!\r\nВспоминаем про ScheduleGCIfNeeded. Напомним, что в исходном коде этой функции ничего полезного найдено не было, но это лишь значит, что пора спуститься на более низкий уровень и проверить работу . Дизассемблированный пролог функции ScheduleGCIfNeeded выглядит так:\r\nВидно, что функция , и это место не используется дальше. Но из-за этого сканер стека видит то, что было ранее записано другими функциями. И случайно именно в эту «дыру» попадает указатель на внутренности хэш-таблицы, оставленный функцией AddActiveScriptWrappable. Как оказалось, причиной появления «дыры» в данном случае стал отладочный  внутри функции, который выводит в лог дополнительную информацию.\r\nНо почему в таблице active_script_wrappable_ оказались сотни тысяч элементов? Почему ухудшение производительности наблюдается только на тесте jQuery? Ответ на оба вопроса один — в данном конкретном тесте, на каждое изменение (вроде отметки в чекбоксе) весь UI пересоздается полностью. Тест плодит элементы, которые почти сразу превращаются в мусор. Остальные тесты в Speedometer более благоразумны и не создают лишних элементов, поэтому для них ухудшения производительности не наблюдается. Если вы разрабатываете веб-сервисы, то стоит это учесть, чтобы не создавать лишнюю работу браузеру.\r\nНо почему проблема возникла только сейчас, если макрос VLOG был раньше? Точного ответа нет, но, скорее всего, при обновлении изменилось взаимное расположение элементов в стеке, из-за чего указатель на хэш-таблицу стал случайно доступен сканеру. По сути, мы выиграли в лотерею. Чтобы быстро закрыть «дыру» и восстановить производительность, мы удалили отладочный макрос VLOG. Для пользователей он бесполезен, а для собственных нужд диагностики мы всегда сможем включить его обратно. Также мы рассказали о нашем опыте другим разработчикам из Chromium. Ответ подтвердил наши опасения: это фундаментальная проблема консервативного сбора мусора в Blink, не имеющая системного решения.\r\n1. Если вам интересно узнать о других необычных буднях нашей группы, то напомним , которая привела к ускорению не только Яндекс.Браузера, но и всего проекта Chromium. \r\n2. А ещё приглашаю послушать другие доклады на следующем мероприятии  16 февраля, регистрация открыта, трансляция тоже будет.", "url": "https://habr.com/ru/company/yandex/blog/436154/"},
{"title": "256 строчек голого C++: пишем трассировщик лучей с нуля за несколько часов", "article_text": "Публикую очередную главу из моего  (вот  оригинал на русском, хотя английская версия новее). На сей раз тема разговора — . Как обычно, я стараюсь избегать сторонних библиотек, так как это заставляет студентов заглянуть под капот.\r\nПодобных проектов в интернете уже море, но практически все они показывают законченные программы, в которых разобраться крайне непросто. Вот, например, очень известная . Очень впечатляющий результат, однако разобраться в этом коде очень непросто. Моей целью является не показать как я могу, а детально рассказать, как подобное воспроизвести. Более того, мне кажется, что конкретно эта лекция полезна даже не столь как учебный материал по комьпютерной графике, но скорее как пособие по программированию. Я последовательно покажу, как прийти к конечному результату, начиная с самого нуля: как разложить сложную задачу на элементарно решаемые этапы. \r\nИтак, сегодня я покажу, как отрисовывать подобные картинки:\r\nЯ не хочу заморачиваться с оконными менеджерами, обработкой мыши/клавиатуры и тому подобным. Результатом работы нашей программы будет простая картинка, сохранённая на диск. Итак, первое, что нам нужно уметь, это сохранить картинку на диск.  лежит код, который позволяет это сделать. Давайте я приведу его основной файл:\r\nВ функции main вызывается только функция render(), больше ничего. Что же внутри функции render()? Перво-наперво я определяю картинку как одномерный массив framebuffer значений типа Vec3f, это простые трёхмерные векторы, которые дают нам цвет (r,g,b) для каждого пикселя.\r\nКласс векторов живёт в файле geometry.h, описывать я его здесь не буду: во-первых, там всё тривиально, простое манипулирование двух и трёхмерными векторами (сложение, вычитание, присваивание, умножение на скаляр, скалярное произвдение), а во-вторых,  его уже  в рамках курса лекций по компьютерной графике.\r\nКартинку я сохраняю в ; это самый простой способ сохранения изображений, хотя и не всегда самый удобный для дальнейшего просматривания. Если хотите сохранять в других форматах, то рекомендую всё же подключить стороннюю библиотеку, например, . Это прекрасная библиотека: достаточно в проект включить один заголовочный файл stb_image_write.h, и это позволит сохранять хоть в png, хоть в jpg.\r\nИтого, целью данного этапа является убедиться, что мы можем а) создать картинку в памяти и записывать туда разные значения цветов б) сохранить результат на диск, чтобы можно было его просмотреть в сторонней программе. Вот результат:\r\nЭто самый важный и сложный этап из всей цепочки. Я хочу определить в моём коде одну сферу и показать её на экране, не заморачиваясь ни материалами, ни освещением. Вот так должен выглядеть наш результат:\r\nДля удобства в моём репозитории по одному коммиту на каждый этап; Github позволяет очень удобно просматривать внесённые изменения. , что изменилось во втором коммите по сравнению с первым.\r\nДля начала: что нам нужно, чтобы в памяти компьютера представить сферу? Нам достаточно четырёх чисел: трёхмерный вектор с центром сферы и скаляр, описывающий радиус:\r\nЕдинственная нетривиальная вещь в этом коде — это функция, которая позволяет проверить, пересекается ли заданный луч (исходящий из orig в направлении dir) с нашей сферой. Детальное описание алгоритма проверки пересечения луча и сферы можно , очень рекомендую это сделать и проверить мой код.\r\nКак работает трассировка лучей? Очень просто. На первом этапе мы просто замели картинку градиентом:\r\nТеперь же мы для каждого пикселя сформируем луч, идущий из центра координат, и проходящий через наш пиксель, и проверим, не пересекает ли этот луч нашу сферу. \r\nЕсли пересечения со сферой нет, то мы поставим цвет1, иначе цвет2:\r\nНа этом месте рекомендую взять карандаш и проверить на бумаге все вычисления, как пересечение луча со сферой, так и заметание картинки лучами. На всякий случай, наша камера определяется следующими вещами:\r\nВсё самое сложное уже позади, теперь наш путь безоблачен. Если мы умеем нарисовать одну сферу. то явно добавить ещё несколько труда не составит.  смотреть изменения в коде, а вот так выглядит результат:\r\nВсем хороша наша картинка, да вот только освещения не хватает. На протяжении всей оставшейся статьи мы об этом только и будем разговаривать. Добавим несколько точечных источников освещения:\r\nСчитать настоящее освещение — это очень и очень непростая задача, поэтому, как и все, мы будем обманывать глаз, рисуя совершенно нефизичные, но максимально возможно правдоподобные результаты. Первое замечание: почему зимой холодно, а летом жарко? Потому что нагрев поверхности земли зависит от угла падения солнечных лучей. Чем выше солнце над горизонтом, тем ярче освещается поверхность. И наоборот, чем ниже над горизонтом, тем слабее. Ну а после того, как солнце сядет за горизонт, до нас и вовсе фотоны не долетают. Применительно к нашим сферам: вот наш луч, испущенный из камеры (никакого отношения к фотонам, обратите внимание!) пересёкся со сферой. Как нам понять, как освещена точка пересечения? Можно просто посмотреть на угол между нормальным вектором в этой точке и вектором, описывающим направление света. Чем меньше угол, тем лучше освещена поверхность. Чтобы считать было ещё удобнее, можно просто взять скалярное произвдение между вектором нормали и вектором освещения. Напоминаю, что скалярное произвдение между двумя векторами a и b равно произведению норм векторов на косинус угла между векторами: a*b = |a| |b| cos(alpha(a,b)). Если взять векторы единичной длины, то простейшее скалярное произведение даст нам интенсивность освещения поверхности.\r\nТаким образом, в функции cast_ray вместо постоянного цвета будем возвращать цвет с учётом источников освещения:\r\nИзменения , а вот результат работы программы:\r\nТрюк со скалярным произведением между нормальным вектором и вектором света неплохо приближает освещение матовых поверхностей, в литературе называется диффузным освещением. Что же делать, если мы хотим гладкие да блестящие? Я хочу получить вот такую картинку:\r\nПосмотрите,  нужно было сделать изменений. Если вкратце, то отсветы на блестящих поверхностях тем ярче, чем меньше угол между направлением взгляда и направлением  света. Ну а углы, понятно, мы будем считать через скалярные произведения, ровно как и раньше.\r\nЭта гимнастика с освещением матовых и блестящих поверхностей известна как . В вики есть довольно детальное описание этой модели освещения, она хорошо читается при параллельном сравнении с моим кодом. Вот ключевая для понимания картинка:\r\nА почему это у нас есть свет, но нет теней? Непорядок! Хочу вот такую картинку: позволяют этого добиться: при отрисовке каждой точки мы просто убеждаемся, не пересекает ли луч точка-источник света объекты нашей сцены, и если пересекает, то пропускам текущий источник света. Тут есть только маленькая тонкость: я самую малость сдвигаю точку в направлении нормали:\r\nПочему? Да просто наша точка лежит на поверхности объекта, и (исключаяя вопрос численных погрешностей) любой луч из этой точки будет пересекать нашу сцену.\r\nЭто невероятно, но чтобы добавить отражения в нашу сцену, нам достаточно добавить только три строчки кода: при пересечении с объектом мы просто считаем отражённый луч (функция из подсчёта отбесков пригодилась!) и рекурсивно вызываем функцию cast_ray в направлении отражённого луча. Обязательно поиграйте с , я её поставил равной четырём, начните с нуля, что будет изменяться на картинке? Вот мой результат с работающим отражением и глубиной четыре:\r\nНаучившись считать отражения, . Одна функция позволяющая посчитать направление преломившегося луча (), и три строчки кода в нашей рекурсивной функции cast_ray. Вот результат, в котором ближайший шарик стал «стеклянным», он и преломляет, и немного отражает:\r\nА чего это мы всё без молока, да без молока. До этого момента мы рендерили только сферы, поскольку это один из простейших нетривиальных математических объектов. А давайте добавим кусок плоскости. Классикой жанра является шахматная доска. Для этого нам вполне достаточно  в функции, которая считает пересечение луча со сценой.\r\nНу и вот результат: \r\nКак я и обещал, ровно 256 строчек кода, !\r\nМы прошли довольно долгий путь: научились добавлять объекты в сцену, считать довольно сложное освещение. Давайте я оставлю два задания в качестве домашки. Абсолютно вся подготовительная работа уже сделана в ветке . Каждое задание потребует максимум десять строчек кода.\r\nНа данный момент, если луч не пересекает сцену, то мы ему просто ставим постоянный цвет. А почему, собственно, постоянный? Давайте возьмём сферическую фотографию (файл ) и используем её в качестве фона! Для облегчения жизни я слинковал наш проект с библиотекой stb для удобства работы со жпегами. Должен получиться вот такой рендер:\r\nМы умеем рендерить и сферы, и плоскости (см. шахматную доску). Так давайте добавим отрисовку триангулированных моделей! Я написал код, позволяющий читать сетку треугольников, и добавил туда функцию пересечения луч-треугольник. Теперь добавить утёнка нашу сцену должно быть совсем тривиально!\r\nМоя основная задача — показать проекты, которые интересно (и легко!) программировать, очень надеюсь, что у меня это получается. Это очень важно, так как я убеждён, что программист должен писать много и со вкусом. Не знаю как вам, но лично меня бухучёт и сапёр, при вполне сравнимой сложности кода, не привлекают совсем.\r\nДвести пятьдесят строчек рейтрейсинга реально написать за несколько часов.  софтверного растеризатора можно осилить за несколько дней. В следующий раз разберём по полочкам , и заодно я покажу простейшие игры, которые пишут мои студенты-первокурсники в рамках обучения программированию на С++. Stay tuned!", "url": "https://habr.com/ru/post/436790/"},
{"title": "Упрощаем работу с базами данных в Qt с помощью QSqlRelationalTableModel", "article_text": "Доброго времени суток, Хабровчане! В этой статье я хочу рассказать о своем опыте упрощения взаимодействия с базами данных SQL при разработке десктопного приложения с помощью класса QSqlRelationalTableModel кроссплатформенной библиотеки Qt.\r\nС Qt я познакомился еще будучи студентом 1 курса, только начиная программировать на C++, тогда же и серьезно заинтересовался библиотекой и, с тех пор слежу за ее апдейтами. Несколько месяцев назад на работе мне дали ТЗ, в котором требовалось разработать приложение, взаимодействующее с БД SQLite. Структура базы фиксирована и заранее известна мне из ТЗ. \r\nПриложение должно уметь удобно для оператора представлять данные, хранящиеся в базе, позволять добавлять новые записи, удалять и изменять уже существующие. \r\nДалее я кратко опишу процесс разработки с приведением кусков кода и попытаюсь аргументированно объяснить, почему в данном случае был сделан выбор в пользу .\r\nИзначально было принято решение основать взаимодейстие с бд с помощью простых запросов к базе, т.е. , , , которые позволяют реализовать все необходимые функции приложения. \r\nДля этого нам потребуются классы и :\r\nПосле этого все операции над базой совершаются следующим образом: 'ы выполняются аналогично, за исключением того, что данные еще нужно получить и куда-то положить:'ы выполняются в точности так же, как Insert из-за того, что ничего не возвращают.\r\nИ правда, ведь можно все реализовать через эти выражения и запросы, \r\nКогда у нас есть одна ни с чем не связанная таблица, то все кажется очень простым и не требующим введения дополнительных инструментов. А теперь представьте, что у нас таких таблиц, например, 5, в каждой по 5 столбцов, не включая id. Причем каждая имеет связь с предыдущей с помощью  через, т.е. при удалении необходимо каскадно удалять все «дочерние» записи. Это приводит к огромному количеству запросов, работа приложения сильно замедляется, более того, необходимо каждый раз обновлять таблицу и ее представление в интерфейсе, что приводит к написанию дополнительных функций для обновления, появлению багов или к риску их возникновения, да и в целом к снижению читаемости кода.\r\nИменно по этой причине в процессе разработки пришлось отказаться от концепции использования голых  запросов. \r\nДальнейший выбор был сделан в пользу  в связке с . Есть еще более простая версия реализации модели — , первая наследована от нее, имеет все те же методы, но добавляет возможность создания связи , что очень удобно, если пользователю нужно показать не id записи, а название записи «родителя», с которой она связана.\r\nПриведу отрывки пода, показывающие реализацию model/view.\r\nВ заголовочном файле:\r\nВ конструкторе: \r\nВ строчке ниже заключается одна из самых удобных фишек и преимуществ модели перед sql запросами — она редактирует, добавляет, удаляет, в зависимости от контекста, данные в sql таблице при изменении из в QTableView. Удобство в том, что больше не нужно контролировать корректность каскадного удаления данных и их обновление в рамках одного QTableView. \r\n Далее идет еще одна удобная фишка, предоставляемая этим классом: устанавливается связь между двумя колонками разных таблиц:\r\nДалее все более стандартно: select() выполнит SELECT выражение, а setHeaderData() установит текст в заголовки QTableView:\r\nТеперь модель и tableView работают вместе и выполняют свои функции. По ссылке на будут оставлены все исходники, в них я реализовал добавление записи в модель, ее удаление, а также фильтры.\r\nВ этой статье я хотел призвать всех тех, кто уже работает с БД в Qt отказываться от голых sql запросов для проектов уже хотя бы среднего уровня сложности и переходить на работу с моделями, чтобы упростить себе жизнь, сделать код более читабельным и универсальным, ну и просто сделать что-то хорошее и новое.\r\nНа этом все! Надеюсь, что мой опыт работы с данными классами поможет читателям успешно решить схожую проблему!", "url": "https://habr.com/ru/post/435134/"},
{"title": "Работа с API КОМПАС-3D → Урок 14 → Многострочный текст", "article_text": "На предыдущем уроке мы рассмотрели, как выводить многострочный текст с помощью параграфа. Описанный способ требует ручного обхода массива выводимых строк. На данном уроке мы рассмотрим альтернативный способ, лишенный этого недостатка. В его основе лежит интерфейс  и метод .\r\nИнтерфейс  представляет собой надстройку над интерфейсом  и массивом выводимых строк. Для его получения нужно вызвать метод  интерфейса  с константой .\r\nСвойств у интерфейса  нет, поэтому сразу переходим к рассмотрению его методов. – возвращает интерфейс параметров параграфа ksParagraphParam. Не имеет входных параметров. – возвращает динамический массив ksDynamicArray выводимых строк. Не имеет входных параметров. – сбрасывает параметры текста. Не имеет входных параметров. В случае успеха возвращает значение true. – устанавливает параметры параграфа. В качестве единственного параметра принимает интерфейс , содержащий устанавливаемые параметры. В случае успеха возвращает значение , а в случае ошибки – . – устанавливает массив выводимых строк. В качестве единственного параметра принимает интерфейс , содержащий выводимые строки. В случае успеха возвращает значение , а в случае ошибки – .\r\nДинамический массив, возвращаемый методом  и устанавливаемый методом , имеет тип . Это значит, что элементами массива являются интерфейсы .\r\nДля вывода многострочного текста используется метод  интерфейса . Ниже представлен его прототип:\r\nВ таблице ниже представлены допустимые значения параметра .\r\nВ случае успеха метод  возвращает целочисленный указатель на созданный текст. А в случае ошибки – . \r\nВ данном примере мы не обходим массив, а однократно вызываем нужный метод. Он сам находит флаги  и правильно интерпретирует их. Обратите внимание: каждая новая строка с этим флагом оформляется в отдельный интерфейс . Если оформить их в одном , то КОМПАС проигнорирует флаг . На рисунке ниже показан результат работы этой программы.\r\nНа этом уроке мы рассмотрели альтернативный вариант вывода многострочного текста. Он несколько сложнее того, что мы рассмотрели ранее, но не требует ручного обхода массива строк. Каким из них пользоваться – решать вам.\r\nНа следующем уроке мы вновь вернемся к теме составных строк и рассмотрим документированный способ их создания с помощью параграфов. Сергей Норсеев, к.т.н., автор книги «Разработка приложений под КОМПАС в Delphi».", "url": "https://habr.com/ru/company/ascon/blog/434576/"},
{"title": "Мысли о современном C++ и игровой разработке", "article_text": " На протяжении всей прошлой недели  шла , в ходе которой многие программисты – особенно те из них, кто работает в сфере игровой разработки – высказались о том, что нынешний вектор развития «современного C++» . В частности, с позиции обычного игрового разработчика, все выглядит так, будто производительность отладки в языке игнорируется, а оптимизация кода становится ожидаемой и необходимой.\r\nВ силу того, что на 2019 год я успел проработать в игровой индустрии более 23 лет, у меня имеется собственное мнение, основанное на наблюдениях по данной теме применительно к игровой разработке, которым мне и хотелось бы поделиться. Важна ли для игровых разработчиков «отлаживаемость» и почему? В чем заключаются вопросы, связанные с ней?\r\nДля начала — небольшой экскурс в историю.\r\nМногие игровые разработчики, пишущие на C++, работают в Microsoft Visual C++. Исторически сложилось, что вокруг платформ Microsoft сформировался огромный рынок для игр, и это отразилось на типичном опыте рядового игрового программиста. В 90-ые и 2000-ые большинство игр писалось с учетом этих обстоятельств. Даже с появлением консолей других производителей и ростом популярности мобильных игр, достоянием многих AAA-студий и многочисленных игровых программистов на сегодняшний день являются инструменты, произведенные Microsoft.\r\nVisual Studio — это, возможно, самый лучший отладчик для C++ на свете. Причем сильнее всего Visual Studio действительно выделяется именно по части отладки программ — больше, чем своими front-end, back-end, реализацией STL или чем-либо еще. В последние пять лет Microsoft добилась серьезных успехов в развитии инструментов для разработки на C++, но даже и до этих заслуг отладчик в Visual Studio всегда был очень крутым. Так что когда вы занимаетесь разработкой на ПК с Windows, у вас под рукой всегда есть дебаггер мирового класса.\r\nУчитывая вышесказанное, давайте рассмотрим процесс получения кода, в котором не будет багов; имеющиеся у нас возможности с точки зрения программиста, который не занимается играми; а также ограничения, с которыми сталкиваются игровые разработчики. Если перефразировать основной довод в пользу «вектора развития современного С++», то он сведется к типам, инструментам и тестам. Следуя этой мысли, отладчик должен выступать . Прежде, чем мы ее достигнем, у нас имеются следующие возможности.\r\nМы можем использовать столько сильной типизации, сколько потребуется, для того, чтобы исключить целые классы багов во время компиляции. Сильная типизация, вне сомнения, является возможностью, которую предоставила нам недавняя эволюция C++; например, начиная с C++11, мы успели получить:\r\nНекоторым из вас может не нравиться метапрограммирование шаблонов; другим может не нравиться стиль написания кода, при котором почти повсеместно используется . Вне зависимости от этих предпочтений, здесь явно прослеживается основной мотив для использования перечисленных стилей в C++ — это стремление помочь компилятору, чтобы он в свою очередь мог помочь нам, используя при этом то, что он знает лучше всего: систему типов.\r\nЕсли говорить об игровом программировании, здесь сильная типизация представляет собой широкое поле для исследования, и ее активно применяют знакомые мне игровые программисты, которые заинтересованы в том, чтобы на практике улучшить свои навыки применения C++. Здесь вызывают обеспокоенность две важные вещи: влияние на время компиляции, и влияние на читабельность кода.\r\nОткровенно говоря, вы легко можете проигнорировать время компиляции — но только при условии, что вы — программист в очень большой компании, которая не занимается играми и обладает устоявшейся внутренней инфраструктурой и бесконечными вычислительными мощностями для того, чтобы скомпилировать любой код, который вы только можете написать. Подобные огромные компании обеспокоены стоимостью компиляции — поэтому используют модули — но, как правило, у отдельных разработчиков боли это не вызывает. В то же время, для большинства игровых программистов это совсем не так. У инди-разработчиков нет ферм для создания сборок; разработчики AAA-игр часто используют что-то вроде , но, учитывая тот факт, что они запросто могут работать с кодовой базой, которой исполнилось 10 и более лет, процесс сборки все еще может занимать 15-20 минут.\r\nМы можем поспорить насчет относительной стоимости добавления «железа» против стоимости времени программиста, и я согласен с позицией, что «железо» обходится дешевле, однако:\r\nМожно также порассуждать на тему того, что время компиляции никогда не должно было дойти до такого состояния; и снова я с вами соглашусь. Цена этого в постоянной бдительности — исходящей, опять же, от релиз-инженера — и, в идеале, некоторого автоматизированного инструмента, позволяющего отслеживать изменения во времени, требуемом для сборки билда. К счастью, за счет появления CI-систем этой цели сегодня можно достичь гораздо легче.\r\nМы должны использовать максимум доступных нам инструментов — предупреждения (warnings), статический анализ, санитайзеры, инструменты динамического анализа, профилировщики и прочие.\r\nМой опыт говорит, что игровые разработчики используют эти инструменты там, где это возможно, но здесь у индустрии в целом имеется несколько проблем:\r\nИтак, раз эти инструменты так хорошо работают со стандартным C++, почему же игровые разработчики тогда не используют STL?\r\nС чего бы начать ответ на этот вопрос? Пожалуй, с очередного экскурса в историю игровой разработки:\r\nВ ходе этих сдвигов парадигм постоянно изменялись и сами платформы игровой разработки, причем изменялись серьезно. Сегментированая память уступила место плоскому адресному пространству. Платформы стали многопроцессорными, симметричными и не очень. Игровым разработчикам, привыкшим работать с архитектурами Intel, пришлось привыкать к MIPS (Playstation), затем к специальному «железу» с гетерогенными CPU (PS2), после этого к PowerPC (XBox 360), затем к еще большей гетерогенности (PS3)… С каждой новой платформой приходили новые рабочие характеристики для процессоров, памяти и дисков. Если вы хотели добиться оптимальной производительности, то вы были вынуждены переписывать ваш старый код, причем много и часто. Я даже не стану упоминать то, как сильно на игры повлияло появление и рост популярности Интернета, а также ограничения, которые накладывали на разработчиков держатели платформ.\r\nИсторически сложилось, что реализации STL на игровых платформах были неудовлетворительными. Не является секретом и то, что STL-контейнеры слабо подходят для игр. Если прижать игрового разработчика к стенке, то возможно он признается в том, что  — вполне себе ОК, и  — разумный вариант по умолчанию. Но у всех контейнеров, содержащихся в STL, имеется проблема контроля аллокации и инициализации. Во многих играх приходится беспокоиться по поводу ограничения памяти для различных задач — и для тех объектов, память для которых скорее всего придется выделять динамически во время геймплея, часто используются  или  аллокаторы.  — недостаточно хороший результат, поскольку аллокация потенциально является одной из самых «дорогих» вещей, что могут произойти во время выполнения программы, и мне не хочется пропускать кадр только из-за того, что она произошла тогда, когда я этого не ожидал. Я, как игровой разработчик, должен управлять своими требованиями к памяти заранее.\r\nПохожая история получается и для других зависимостей в общем. Игровые разработчики хотят знать, на что уходит каждый цикл процессора, где и когда и за что отвечает каждый байт памяти, а также где и когда контролируется каждый поток выполнения. До последнего времени, компиляторы Microsoft меняли ABI с каждым обновлением — поэтому, если у вас было много зависимостей, то перестраивание всех их могло быть болезненным процессом. Игровые разработчики обычно предпочитают небольшие зависимости, которые легко интегрируются, делают всего одну вещь и делают ее хорошо — желательно с API в стиле C — и при этом используются во многих компаниях, находятся в открытом доступе (public domain) или имеют бесплатную лицензию, которая не требует указания автора.  и  — хорошие примеры того, что предпочитают использовать игровые разработчики.\r\nПомимо этого, индустрия игр на С++ имеет богатую историю больных синдромом «Not invented here». Этого следует ожидать от индустрии, которая начиналась с одиночек-энтузиастов, которые мастерили что-то свое на совершенно новом оборудовании и не имели никаких других вариантов. Игровая индустрия, помимо прочего, единственная, где программисты указываются в титрах без определенного порядка.  А поскольку мы так беспокоимся о производительности, мы можем адаптировать наше решение таким образом, чтобы оно подходило именно для нашего проекта — вместо того, чтобы взять обобщенное решение, бездумно тратящее имеющиеся ресурсы. Неприязнь к Boost — основной пример того, как подобное мышление проявляется в игровой разработке. Я работал на проектах, которые прошли следующий путь:\r\nНам не нравится что-либо огромное, пытающееся сделать слишком много дел одновременно или способное повлиять на время компиляции — и это вполне разумно. В чем люди ошибаются снова и снова, так это в том, что они противостоят тому, чтобы принять предполагаемую боль сегодня — в то время как из-за этого решения их ждет весьма реальная и гораздо большая боль при поддержке чего-либо за счет чьего-то еще бюджета, которую им придется испытывать в течение трех следующих лет. Увы, но наличие доказательств в виде игр, успешно использующих блюдо из STL и Boost, никоим образом не может повлиять на психологию человека и переубедить игровых разработчиков.\r\nВ силу всех этих причин, многие игровые компании создали свои собственные библиотеки, которые покрывают то, что делает STL — и даже больше — и при этом поддерживают специфические для игровой разработки кейсы использования. Отдельные большие игровые компании даже смогли осилить разработку собственной, полноценной, практически полностью совместимой по API , что в дальнейшем повлекло за собой огромные расходы на поддержку данного проекта. , или применить  в . Гораздо менее приемлемо быть обреченным на поддержку своих собственных реализаций  или , что не принесет практически никакой пользы. Как по мне, прискорбно, что STL для большинства разработчиков — это одни лишь контейнеры. Поскольку при изучении STL на старте обучают именно им, то говоря об STL большинство подразумевает  — хотя на самом деле им следовало бы думать про .\r\nУтверждается, что должно осуществляться экстенсивное тестирование, TDD и/или BDD должно покрывать весь код, который можно покрыть, а с багами необходимо бороться написанием новых тестов.\r\nПоэтому давайте обсудим тему тестирования.\r\nСудя по моему опыту, автоматизированное тестирование в игровой индустрии практически не используется. Почему?\r\nБудучи молодым программистом в игровой индустрии, я быстро избавился от мысли о том, что я должен стремиться моделировать что-либо реалистично. Игры — это пускание пыли в глаза () и поиск коротких путуй. Никого не волнует, насколько реалистична ваша симуляция; главное, чтобы она была увлекательной. Когда у вас нет другой спецификации, кроме как «игра должна ощущаться правильно», отсутствует сам предмет тестирования. Благодаря багам геймплей может даже становиться лучше. Достаточно часто баг попадает в релиз, и даже завоевывает любовь пользователей (). Игры отличаются от других сфер, в которых используется C++; здесь нехватка корректности не приводит к тому, что кто-то в итоге лишается своих сбережений.\r\nРазумеется, вам хотелось бы производить автоматизированные тесты везде, где вы сможете. Это может быть осуществлено для некоторых подсистем, для которых есть четко сформулированные конечные результаты. Юнит-тестирование в игровой индустрии, конечно, присутствует, но как правило ограничивается низкоуровневым кодом — упомянутыми ранее аналогами STL, процедурами преобразования строк, методами физического движка и т.д. Те случаи, когда у исполняемого участка кода есть предсказуемые результаты, обычно тестируются юнит-тестами, хотя TDD здесь и не применяется — поскольку игровые программисты предпочитают упрощать себе жизнь, а не наоборот. Но как вы протестируете код геймплея (смотрите пункт первый)? Как только вы выходите за рамки юнит-тестирования, то сразу встречаетесь с еще одной причиной, почему тестирование игр является настолько сложным.\r\nТестирование нетривиальных систем возможно будет включать в себя предоставление контента, с участием которого оно будет осуществляться. Большинство инженеров не слишком хороши в плане изготовления этого контента своими силами, так что для получения осмысленного теста потребуется привлечь кого-либо с нужными навыками создания контента. После чего вы столкнетесь с проблемой измерения того, что вы получаете на выходе — ведь это больше не строка или число, а изображение на экране или звук, которые изменяются с течением времени.\r\nЮнит-тестирование — это функция, для которой мне известны возможные входы и выходы. Однако геймплей — это непредсказуемое, складывающееся динамически поведение, и я не знаю, как подобное явление можно было бы как следует протестировать. Что я могу протестировать — если, конечно, я получу разрешение от своего менеджера уделить этому достаточное время — это, например, производительность, или высокоуровневые возможности вроди матчмейкинга, которые я могу проанализировать. Подобная инфраструктурная работа может быть увлекательно для некоторых игровых программистов, но большинству она попросту неинтересна, — да еще и вдобавок требует одобрения и поддержки со стороны владельца кошелька. В роли игрового программиста, я никогда не имею возможности заняться практикой написания высокоуровневых тестов.\r\nНаша главная цель — это выпустить игру. Мы живем во времена индустрии, которая движется вперед за счет хитов, которые зарабатывают большую часть своих денег в первый месяц продаж, когда расходы на маркетинг этих хитов максимальны. Жизненный цикл консолей научил нас тому, что код в любом случае проживет не так уж и долго. Если мы работаем над онлайн-игрой, то скорее всего получим дополнительное время на тестирование матчмейкинга или нагрузки на сервера. Поскольку для релиза игры нам требуется, чтобы ее производительность была в порядке, мы должны как минимум произвести тестирование производительности, но мы не должны автоматизировать этот процесс. Для менеджмента в индустрии игр автоматизированное тестирование — это не более, чем трата времени и денег. Для его проведения приходится нанимать опытных инженеров, которые произведут работу, результат которой будет практически незаметен. Это же время можно было бы потратить на разработку новых фич. В краткосрочной перспективе для тестирования игры гораздо выгоднее использовать персонал QA, что приводит нас к следующему пункту. \r\nЯ обожаю хороших QA-специалистов. Для меня они на вес золота. Они знают, как сделать вашу игру лучше, ломая ее таким образом, который никогда бы не пришел вам в голову. Они — профильные эксперты в вашем геймплее в том плане, в котором вы не разбираетесь, и едва ли когда-либо разберетесь. Они — лучше, чем команда супер-способных компиляторов, помогающих вам делать все как надо. Я рад тому, что мне выпал шанс поработать с несколькими замечательными QA-специалистами за годы моей работы.\r\nЯ почти всегда был вынужден сражаться только за то, чтобы они остались в моей команде.\r\nВ больших AAA-компаниях, организация, занимающаяся QA — это обычно совершенно отдельный отдел от любой команды разработки, со своим собственным менеджментом и организационной структурой. Делается это якобы для того, чтобы они могли проявить объективность во время проведения тестирования. На практике, все оказывается далеко не так прекрасно.\r\nК ним относятся, как к шестеренкам в огромном механизме, которых часто перебрасывают между проектами без предупреждений и в целом относятся к ним так, будто с их работой может справиться любой. Когда проект «съезжает» с даты дедлайна, инженеры могут ощутить кранч на своей шкуре, но QA достается гораздо сильнее, ведь им приходится работать в ночную смену и по выходным, плюс им же еще и достается за то, что они приносят невеселые новости о текущем состоянии качества проекта.\r\nИм серьезно недоплачивают. Самые опытные тестировщики с годами экспертизы в предметной области получают меньше половины того, что платят разработчику среднего уровня. Мне приходилось работать с умнейшими QA-инженерами, которые создавали пайплайны для тестирования производительности с трекингом и оповещениями, создавали фреймворки для тестирования API и для нагрузочного тестирования и выполняли множество других задач, якобы недостойных времени «настоящих инженеров». Я уверен в том, что эти умнейшие люди получали бы гораздо больше, если бы работали в любой другой большой технологической компании.\r\nИм не доверяют. Не редкость, что тестировщиков держат отдельно от остальных разработчиков, а их бейджи позволяют им получать доступ только к тому этажу здания, где они работают сами — или же и вовсе использовать отдельный вход.\r\nОни вынуждены подчиняться. Тестировщикам часто говорят не беспокоить других инженеров. Когда им нужно сообщить о баге напрямую, их просят обращаться к инженерам уважительно, вроде «Миссис Х.» или «Мистер Y.». Иногда мне звонило раздраженное начальство QA-отделов — в тех случаях, когда я для совместного расследования связывался напрямую с теми, кто обнаруживал баг.\r\nВсе это звучит как страшная сказка, и пусть сталкиваться с подобными вещами приходится далеко не всем, к несчастью это происходит все еще довольно часто; настолько часто, что инженеры начинают думать — возможно, сами находясь под грузом постоянного стресса, но это их не извиняет — что работа QA состоит в том, чтобы искать их же баги, или, что еще хуже, начинают винить QA за баги.\r\nВ лучших командах, с которыми мне приходилось работать, мы настаивали на том, чтобы в наших командах были свои QA-инженеры, которые работали бы с нами вместе. При этом они не теряли своей объективности или желания добиться лучшего результата. Им было приятно получать помощь от программистов в написании автоматизированных тестов. В чем я точно не сомневаюсь, так это в том, что игровой индустрии было бы полезно заниматься автоматизацией чаще.\r\nС учетом всего вышесказанного — привычки заниматься отладкой, платформой для API и инструментов, которая до сих пор взрослеет, и сложностью (в совокупности с недостатком культуры) автоматизированного тестирования — становится ясно, почему игровые разработчики так настаивают на возможности отладки. \r\nНо при этом остаются проблемы с самой отладкой, и проблемы с тем, как игровые разработчики справляются с нынешним вектором развития C++.\r\nГлавная проблема отладки состоит в том, что она не масштабируется. Среди игровых разработчиков разработчиков, читающих данный пост, найдутся те, кто решит, что описанные мною явления не сходятся с тем, что они наблюдали на своей практике. Вполне возможно, это из-за того, что рано или поздно им самим пришлось столкнуться с проблемой масштабируемости отладки, и они нашли способ обойти ее.\r\nДругими словами, мы хотим иметь производительную отладку, потому что для того, чтобы ловить баги, нам часто нужно иметь возможность выполнять запуск приложений с достаточно большими и репрезентативными наборами данных. Но на самом деле, когда мы достигаем этой точки, то обычно дебаггер становится слишком грубым инструментом для использования — вне зависимости от того, производителен он или нет. Конечно, установка точек останова на данных () может быть полезна для поимки проблем среднего размера, но что делать, если мы столкнемся с реальными багами — теми, которые остаются после того, как мы казалось бы уже все пофиксили? С теми самыми, которые возникают под нагрузкой в сети, или в случае нехватки памяти, или работающей на пределе возможностей многопоточности, или случаются лишь для небольшого, еще не идентифицированного подмножества на фоне миллиона других игроков, или возникают только на дисковых версиях игры, или только в сборке на немецком языке, или спустя три часа, проведенных за тестированием стабильности ()?\r\nЧерта с два мы можем положиться на один лишь отладчик. В этом случае мы делаем то, что мы делали всегда. Мы пытаемся изолировать проблему, заставить ее происходить чаще; мы добавляем логирование и просеиваем нашу программу через него; мы подстраиваем таймеры и настройки потоков; мы применяем двоичный поиск по билдам; мы изучаем дампы ядра и крэшлоги; мы пытаемся воспроизвести проблему, урезая контент до минимума; мы размышляем насчет того, что может быть причиной проблемы, и обсуждаем ее.\r\nЗачастую, пока мы доберемся до настоящей причины «крэша», мы успеем исправить несколько других вещей. Другими словами, мы решаем проблемы, и в конце концов, использование дебаггера — это лишь небольшая часть данного процесса. Так что да, скорость отладки — приятное дополнение, но ее нехватка не мешает нам продолжать оставаться инженерами. Нам по-прежнему требуются другие наши навыки, вроде способностей анализировать дампы ядра и читать оптимизированный ассемблер.\r\nПри использовании «современного С++» я пользуюсь отладчиком тем же самым образом, что и обычно. Я прохожу им по свеженаписанному коду; ставлю брейкпоинты на тех данных, которые меня интересуют; использую дебаггер для того, чтобы исследовать незнакомый код. С приходом «современного C++» ничего из этого не меняется, — и да, даже несмотря на то, что STL использует _Уродливые _Идентификаторы, это не делает STL магией. Иногда бывает полезным посмотреть, что STL делает «под капотом», или же переступить через нее; или, как теперь можно сделать, .\r\nКогда я сталкиваюсь с проблемами производительности отладки, то дело обычно не в том, что «современный C++» замедляет меня — дело в том, что к этому моменту я уже пытаюсь сделать слишком много всего. Использование отладчика  — в отличие от типов, инструментов и тестов.\r\nЯ сам был обеспокоен проблемой того, что код на C++ требует все больше и больше оптимизации, и я интересовался мнением разработчиков компиляторов по этому поводу. Факт состоит в том, что здесь нет однозначного ответа. Мы уже находимся в континууме, и у нас есть возможность продвигаться дальше в этом направлении без причинения вреда возможности отладки кода. Сегодня наши компиляторы выполняют , даже если мы не просим их производить данную оптимизацию. На нашу возможности отладки приложений это никак не влияет. Сомневаюсь, что мы станем жаловаться на то, что отладочные билды стали включать NRVO или еще полдюжины оптимизаций, которые могут быть произведены таким образом, что во время отладки мы их и не заметим. Подозреваю, что C++ движется как раз в  направлении.\r\nЕсли вы работаете программистом в сфере игровой разработки и вам не нравится, куда движется C++, то у вас по сути есть два варианта возможных дальнейших действий.\r\nЕсли предположить, что вы все еще собираетесь писать код на C++, то вы можете просто продолжать использовать язык так же, как делали и до этого. Нет необходимости начинать использовать любые новые возможности, если вы не хотите этого делать. Практически все из того то, чем вы пользуетесь сейчас, будет продолжать поддерживаться — и при этом в последующие годы вы будете продолжать пожинать плоды совершенствования компилятора.\r\nЭто совершенно адекватная стратегия поведения для тех, кто работает на себя или с командой единомышленников. C++98, вместе с некоторым набором более новых функций, по-прежнему хорошо подходить для того, чтобы писать на нем игры.\r\nОднако, если вы работаете в большой компании, то рано или поздно вам придется столкнуться с изменениями в языке, поскольку вам придется увеличивать команду и нанимать новых людей. В свою очередь, когда вы будете нанимать C++-разработчиков, это будет означать найм разработчиков на «современном» C++. Произойдет смена поколений — как это уже приключилось с ассемблером, C и C++98. Вы сможете управлять процессом, если установите ограничения на то, что разрешено в вашей кодовой базе, а что – нет, но и это решение не спасет вас в долгосрочной перспективе. И что вам делать в таком случае?\r\nВместо того, чтобы раз в год ездить лишь на одну GDC, начните посещать , где вы получите гораздо большую пользу от денег, потраченных вашей компанией на билет. Участвуйте в обсуждениях стандартов; вступайте в  и подписывайтесь на рассылки; читайте  и предоставляйте авторам обратную связь. Если вы сможете еще и посетить встречи комитета, то это будет просто отлично, но даже если и нет — вы все еще можете сделать многое для того, чтобы донести до других вашу точку зрения.\r\nУчастие в комитете по C++ открыто для всех. Вся необходимая информация для тех, кто хочет принять участие в работе SG14, или SG7, или SG15 — или любой другой рабочей группе, касающейся сферы ваших интересов — . У комитета нет никаких тайных планов — в самом деле, вы и правда считаете, что свыше 200 программистов могут согласовать между собой единую повестку? Здесь даже у «начальства» комитета зачастую не удается «пропихнуть» свои идеи.\r\nЕсли вы хотите, чтобы ваше мнение было услышано, то вы должны начать говорить там, где ваше мнение может быть услышано, а не на Twitter или Reddit. Пожалуйста, воспользуйтесь этим советом — я с нетерпением ожидаю нашей дискуссии.", "url": "https://habr.com/ru/post/435036/"},
{"title": "Об опыте общения с генератором сигнала через QTcpSocket и SCPI", "article_text": "\r\nНа третьем курсе я пришел на практику в одно из предприятий отечественной ракетно-космической отрасли. Стажером я был амбициозным и довольно активным  и по своей просьбе был распределен в отдел, занимающийся разработкой (далее ). К слову, большой частью разработки является написание программной части для оборудования. В том числе, для проверки разрабатываемой аппаратной части в отделе имеются различные , все они подключены к общей сети. В итоге, в качестве одного из первых моих заданий стало написание приложения для управления генератором сигнала. \r\nОб этом в статье и пойдет речь.\r\nВсе приложения в отделе разрабатываются средствами C++ и библиотеки Qt. Опыт работы с данным фреймворком у меня был, поэтому с этой стороны никаких трудностей не возникло. К тому же у Qt есть обширная документация, а еще всегда можно  проконсультироваться у куратора.\r\nПоскольку все устройства подключены к одной сети, то вопрос, как к ним подключаться тоже решился очень быстро — используем сетевую часть Qt в виде QTcpSocket.\r\nСамый интересный вопрос возник, когда пришлось решить, как именно общаться с данными устройствами, как активировать ту или иную функцию, передать то или иное значение. Тогда же оказалось, что все довольно тривиально: существует протокол стандартных команд для программируемых инструментов — SCPI. Он позволяет с помощью стандартный команд управлять любыми устройствами, поддерживающими данный стандарт.\r\nИнтерфейс решено было сделать таким:\r\nОн довольно прост и интуитивно понятен. В двух лайнэдитах вверху задаются хост и порт устройства. Так же имеется возможность выбрать стандартные значения, тогда они примут следующий вид:\r\nДалее идет текстовое поле лога, ответа от устройства(туда же будут приходить ошибки, если они есть). Чуть ниже находятся кнопки соединения с устройством, отправки команды, проверки ошибок. В трех последних лайнэдитах можно либо задать свою команду и отправить ее на устройство, либо отдельно задать частоту и амплитуду. Радиокнопка справа включает/выключает ВЧ выход. Крутилка регулирует частоту, когда чекбокс снят и амплитуду, когда активирован.\r\nПонимаю, что статья может показаться оторванной от жизни и реальности для большого количества читателей, но удаленное управление контрольно-измерительной аппаратурой в сфере инженерии — достаточно распространенная тема, которая приносит много пользы и удобства (например, вам не нужно бегать к приборам и нажимать кнопочки).\r\nВ остальном это статья носит информационно-развлекательный характер и нацеленна, скорее, на энтузиастов и на людей, занимающихся разработкой и тестированием плат и другого железа. Остальным просто хотел бы рассказать о своем небольшом опыте разработки ПО для таких специфических целей.", "url": "https://habr.com/ru/post/435448/"},
{"title": "Реализация горячей перезагрузки С++ кода в Linux", "article_text": "* Ссылка на библиотеку в конце статьи. В самой статье изложены механизмы, реализованные в библиотеке, со средней детализацией. Реализация для macOS еще не закончена, но она мало чем отличается от реализации для Linux. Здесь в основном рассматривается реализация для Linux.Гуляя по гитхабу одним субботним днем, я наткнулся на , реализующую обновление c++ кода налету для windows. Сам я слез с windows несколько лет назад, ни капли не пожалел, и сейчас все программирование происходит либо на Linux (дома), либо на macOS (на работе). Немного погуглив, я обнаружил, что подход из библиотеки выше достаточно популярен, и msvc использует ту же технику для функции \"Edit and continue\" в Visual Studio. Проблема лишь в том, что я не нашел ни одной реализации под не-windows (плохо искал?). На вопрос автору библиотеки выше, будет ли он делать порт под другие платформы, ответ был отрицательный.Сразу скажу, что меня интересовал только вариант, в котором не пришлось бы менять существующий код проекта (как, например, в случае с  или , где весь потенциально перезагружаемый код должен быть в отдельной динамически загружаемой библиотеке).\"Как так?\" — подумал я, и принялся раскуривать фимиам.Я в основном занимаюсь геймдевом. Большую часть моего рабочего времени я трачу на написание игровой логики и верстку всякого визуального. Кроме этого я использую imgui для вспомогательных утилит. Мой цикл работы с кодом, как вы, наверное, догадались, это Write -> Compile -> Run -> Repeat. Происходит все довольно быстро (инкрементальная сборка, всякие ccache и т.п.). Проблема тут в том, что этот цикл приходится повторять достаточно часто. Например, пишу я новую игровую механику, пусть это будет \"Прыжок\", годный, управляемый Прыжок:1. Написал черновую реализацию на основе импульса, собрал, запустил. Увидел, что случайно прикладываю импульс каждый кадр, а не один раз.2. Пофиксил, собрал, запустил, теперь нормально. Но надо бы абсолютное значение импульса побольше взять.3. Пофиксил, собрал, запустил, работает. Но как-то ощущается не так. Надо попробовать на основе силы сделать.4. Написал черновую реализацию на основе силы, собрал, запустил, работает. Надо бы только мгновенную скорость в момент прыжка менять.\r\n...10. Пофиксил, собрал, запустил, работает. Но все еще не то. Наверное нужно попробовать реализацию на основе изменения .\r\n...20. Отлично, выглядит супер! Теперь выносим все параметры в редактор для геймдиза, тестируем и заливаем.\r\n...30. Прыжок готов.И на каждой итерации нужно собрать код и в запустившемся приложении добраться до места, где я могу попрыгать. На это обычно уходит не меньше 10 секунд. А если я могу попрыгать только на открытой местности, до которой еще надо добраться? А если мне нужно уметь запрыгивать на блоки высотой N единиц? Тут мне уже нужно собрать тестовую сцену, которую тоже надо отладить, и на которую тоже надо потратить время. Именно для таких итераций идеально бы подошла горячая перезагрузка кода. Конечно, это не панацея, подойдет далеко не для всего, да и после перезагрузки иногда нужно пересоздать часть игрового мира, и это нужно учитывать. Но во многих вещах это может быть полезно и может сэкономить концентрацию внимания и кучу времени.Это минимальный набор требований, которым должна удовлетворять реализация. Забегая вперед, вкратце опишу то, что было реализовано дополнительно:До этого момента я был совсем далек от предметной области, поэтому пришлось собирать и усваивать информацию с нуля.На высоком уровне механизм выглядит так:Начнем с самого интересного — механизма перезагрузки функций.Вот 3 более-менее популярных способа подмены функций в (или почти в) рантайме:Первые 2 варианта, очевидно, не подходят, поскольку работают только с экспортируемыми функциями, а мы не хотим помечать все функции нашего приложения какими-либо аттрибутами. Поэтому Function hooking — наш вариант!Если вкратце, то hooking работает так:К сожалению, в clang и gcc нет ничего похожего (по крайней мере под Linux и macOS). На самом деле это не такая большая проблема, будем писать прямо поверх старой функции. В этом случае мы рискуем попасть в неприятности, если наше приложение многопоточное. Если обычно в многопоточной среде мы ограничиваем доступ к данным одним потоком, пока другой поток их модифицирует, то тут нам нужно ограничить возможность выполнения кода одним потоком, пока другой поток этот код модифицирует. Я не придумал, как это сделать, поэтому реализация будет вести себя непредсказуемо в многопоточной среде.Тут есть один тонкий момент. На 32-битной системе нам достаточно 5 байт, чтобы \"прыгнуть\" в любое место. На 64-битной системе, если мы не хотим портить регистры, понадобится 14 байт. Суть в том, что 14 байт в масштабах машинного кода — достаточно много, и если в коде есть какая-нибудь функция-заглушка с пустым телом, она скорее всего будет меньше 14 байт в длину. Я не знаю всей правды, но я провел некоторое время за дизассемблером, пока думал, писал и отлаживал код, и я заметил, что все функции выровнены по 16-байтной границе (debug билд без оптимизаций, не уверен насчет оптимизированного кода). А это значит, что между началом любых двух функций будет не меньше 16 байт, чего нам с головой хватит, чтобы \"захукать\" их. Поверхностное гугление привело , тем не менее я точно не знаю, мне просто повезло, или сегодня все компиляторы так делают. В любом случае, если есть сомнения, достаточно просто объявить пару переменных в начале функции-заглушки, чтобы она стала достаточно большой.Итак, у нас есть первая крупица — механизм перенаправления функций из старой версии в новую.Теперь нам нужно как-то получить адреса всех (не только экспортированных) функций из нашей программы или произвольной динамической библиотеки. Это можно сделать достаточно просто, используя системные api, если из вашего приложения не вырезаны символы. На Linux это api из  и , на macOS —  и .Здесь есть одна тонкость. При загрузке elf файла система не загружает секцию  (поправьте, если неправ), а секция  нам не подходит, поскольку из нее мы не сможем выудить символы с видимостью  и . Проще говоря, мы не увидим таких функций:и таких переменных:Таким образом в 3-м пункте мы работаем не с программой, которую нам дала , а с файлом, который мы загрузили с диска и разобрали каким-нибудь elf парсером (либо на голом api). Так мы ничего не пропустим. На macOS процедура аналогичная, только названия функций из системных api другие.После этого мы фильтруем все символы и сохраняем только:Чтобы перезагружать код, нам нужно знать, откуда брать файлы с исходным кодом и как их компилировать.В первой реализации я читал эту информацию из секции , в которой лежит отладочная информация в формате DWARF. Чтобы в каждую единицу трансляции (ЕТ) в рамках DWARF попала строка компиляции этой ЕТ, необходимо при компиляции передавать флах . Сам же DWARF я парсил библиотекой , которая идет в комплекте с . Кроме команды компиляции из DWARF можно достать и информацию о зависимостях наших ЕТ от других файлов. Но я отказался от этой реализации по нескольким причинам:10 секунд на старте приложения — слишком много. После недолгих раздумий я переписал логику парсинга DWARF на парсинг . Этот файл можно сгенерировать, просто добавив  в свой CMakeLists.txt. Таким образом мы получаем всю нужную нам информацию.Поскольку мы отказались от DWARF, нужно найти другой вариант, как обрабатывать зависимости между файлами. Парсить файлы руками и искать в них 'ы очень не хотелось, да и кто знает о зависимостях больше, чем сам компилятор?В clang и gcc есть ряд опций, которые почти бесплатно генерируют так называемые depfile'ы. Эти файлы используют системы сборки make и ninja для разруливания зависимостей между файлами. Depfile'ы имеют очень простой формат:Компилятор кладет эти файлы рядом с объектными файлами для каждой ЕТ, нам остается распарсить их и положить в хэшмапу. Итого парсинг  + depfiles для тех же 500 ЕТ занимает чуть больше 1 секунды. Для того, чтобы все заработало, нам нужно глобально для всех файлов проекта в опции компиляции добавить флаг .Здесь есть одна тонкость, связанная с ninja. Эта система сборки генерирует depfile'ы вне зависимости от наличия флага  для своих нужд. Но после их генерации она их переводит в свой бинарный формат, а исходные файлы удаляет. Поэтому при запуске ninja необходимо передать флаг . Также, по неизвестным мне причинам, в случае с make (с опцией ) файл имеет название , в то время как с ninja он называется . Поэтому нужно проверять наличие обеих версий.Пусть у нас есть такой код (пример весьма синтетический):Мы хотим изменить функцию  на такую:При перезагрузке в динамическую библиотеку с новым кодом, кроме , попадет и статическая переменная , и метод . Как следствие, программа начнет вызывать новые версии обеих функций. Но статическая  в этой библиотеке еще не инициализирована, и поэтому при первом обращении к ней будет вызван конструктор класса . Мы этого, конечно, не хотим. Поэтому реализация переносит значения всех таких переменных, которые обнаружит в собранной динамической библиотеке, из старого кода в эту самую динамическую библиотеку с новым кодом вместе с их .Тут есть один тонкий и в общем случае неразрешимый момент.\r\nПусть у нас есть класс:Метод  вызывается 60 раз в секунду. Мы меняем его, добавляя новое поле:Если экземпляр этого класса располагается в динамической памяти или на стеке, после перезагрузки кода приложение скорее всего упадет. Аллоцированный экземпляр содержит только переменную , но после перезагрузки метод  будет пытаться изменить , меняя то, что на самом деле не принадлежит этому экземпляру, что приводит к непредсказуемым последствиям. В этом случае логика по переносу состояния перекладывается на программиста, который должен как-то сохранить состояние объекта и удалить сам объект до перезагрузки кода, и создать новый объект после перезагрузки. Библиотека предоставляет события в виде методов делегата  и , которые приложение может обработать.Я не знаю как (и можно ли) разрешить эту ситуацию в общем виде, буду думать. Сейчас этот случай \"более менее нормально\" отработает только для статических переменных, там используется такая логика:Это не очень корректно, но это лучшее, что я придумал.В результате код будет вести себя непредсказуемо в случае, если в рантайме меняется набор и расположение (layout) полей в структурах данных. То же самое относится и к полиморфным типам.Как все это работает вместе.Работает это весьма неплохо, особенно когда знаешь, что под капотом, и чего ожидать, хотя бы на высоком уровне.Лично меня очень удивило отсутствие подобного решения для Linux, неужели никто в этом не заинтересован?Буду рад любой критике, спасибо!", "url": "https://habr.com/ru/post/435260/"},
{"title": "Simple MCerver — небольшая оболочка для сервера Minecraft", "article_text": "Здравствуйте. Я изучаю C++ и хочу представить свою небольшую наработку — оболочку для сервера Minecraft с открытым исходным кодом.\r\nВот так выглядит главное окно программы:\r\nВот так выглядит программа при запущеннм сервере. Можно запустить и остановить сервер, в том числе и принудительно, а также выбрать уровень логгирования или отправить команду серверу:\r\nМожно управлять игроками (банить, кикать, давать или лишать административных привилегий):\r\nТакже можно управлять установленными мирами:\r\nСмотреть информацию о доступных модах:\r\nИ менять настройки сервера:\r\nБудет приятно услышать конструктивную критику и получить помощь в разработке программы. Исходный код: ", "url": "https://habr.com/ru/post/435348/"},
{"title": "PVS-Studio 7.00", "article_text": "Сегодня важный день – после 28 релизов шестой версии мы выпускаем PVS-Studio 7.00, где ключевым новшеством является поддержка языка Java. Однако за 2018 год накопилось много других важных изменений, касающихся С++, С#, инфраструктуры и поддержки стандартов кодирования. Поэтому предлагаем вашему вниманию заметку, которая обобщает основные изменения, произошедшие в PVS-Studio за последнее время. — это инструмент для выявления ошибок и потенциальных уязвимостей в исходном коде программ, написанных на языках С, C++, C# и Java. Работает в среде Windows, Linux и macOS. \r\n \r\nВозможности анализатора хорошо демонстрирует обширная  в коде, найденных нами в процессе  различных отрытых проектов.\r\nНачнём мы с изменения, из-за которого, собственно, и было решено сменить номер версии с 6.x на 7.x. Это поддержка в анализаторе языка Java, к которому мы давно .\r\nСамое важное в Java анализаторе то, что он появился :). Приглашаем Java разработчиков скачать инструмент и проверить проекты, над которыми они работают.\r\nМы сделали доступными для пользователей самые популярные способы интеграции анализатора в сборочную систему:\r\nВ случае использования самописных сборочных систем имеется возможность запускать анализатор напрямую, перечислив исходники и . \r\nПодробную информацию о всех способах запуска анализатора вы можете найти на странице документации \"\".\r\nМы не могли обойти стороной платформу контроля качества кода SonarQube, так популярную среди Java разработчиков, поэтому добавили поддержку языка Java в наш .\r\nВ 2018 году наша команда активно поработала над развитием C++ анализатора. Появилось много новых диагностик, а также усовершенствованы , позволяющие собирать и обрабатывать информацию, извлекаемую из синтаксического дерева.\r\nСообщения C++ анализатора (как и C# анализатора) были классифицированы согласно Common Weakness Enumeration (). CWE — это система классификации потенциальных и подтверждённых уязвимостей. Она поддерживается сообществом с целью выявления проблем программного обеспечения и создания автоматизированных инструментов, которые могут использоваться для выявления и устранения этих проблем.\r\nДополнительно сообщения были классифицированы согласно CERT C Coding Standard и CERT C++ Coding Standard.  — это набор стандартов написания программного обеспечения (ПО) на языках C, C++, Java и Perl, разрабатываемых координационным центром CERT (CERT Coordination Center, CERT/CC) для повышения надёжности и безопасности ПО.\r\nКлассификация C и C++ диагностик согласно этим предупреждениям позволяет использовать PVS-Studio как .\r\nВ 2018 году статический анализатор кода PVS-Studio начал классифицировать свои предупреждения согласно стандартам MISRA C и MISRA C++. Благодаря поддержке этих стандартов анализатор стало возможным эффективно использовать для улучшения безопасности, переносимости и надежности программ для встраиваемых систем.\r\nПодробнее: \"\".\r\nПоддержка MISRA стала актуальной в связи с развитием в анализаторе поддержки различных embedded систем, о чём будет рассказано в следующем разделе статьи.\r\nВ 2018 году в анализаторе PVS-Studio были поддержаны:\r\nДве заметки на тему поддержки embedded систем:\r\nИногда в проектах используются собственные реализации разных системных функций, например, ,  и т.п. Анализатор очень хорошо умеет искать ошибки с использованием стандартных функций, но в пользовательском коде было невозможно применять такие алгоритмы до недавнего времени. Теперь с помощью аннотации  вы можете ставить имена своих функций в соответствие системным.\r\nФормат комментария:\r\nРассмотрим пример:\r\nТеперь анализатор будет обрабатывать вызовы функции  так же, как вызовы . Например, на такой код будет выдаваться предупреждение V512:\r\nВ этом году существенных изменений C# анализатора не было. Были отдельные улучшения диагностик и правки недочётов. Сообщения C# анализатора, как и C++ анализатора были классифицированы согласно Common Weakness Enumeration (). Соответствие C# диагностик с идентификаторами CWE приведены  (см. диагностики с номерами 3xxx).\r\nМы планируем вернуться к более активному развитию C# анализатора в 2019 году. Планируется разработка новых диагностик и усовершенствование механизма анализа потока данных (Data-Flow Analysis).\r\nУтилиты PlogConverter.exe и plog-converter входят в дистрибутивы PVS-Studio для Windows и Linux/macOS соответственно. Также исходных код этих утилит доступен на .\r\nС появлением PVS-Studio для Java мы переработали подсветку кода для C, C++, C# и добавили Java в формате FullHtml ().\r\nТакже для отчёта в этом формате был добавлен столбец MISRA:\r\nКак и CWE ID, столбец MISRA является опциональным и включается исследователями безопасности кода при изучении результатов анализа.\r\nМы переписали наши плагины с использованием нового API. Это позволило добавить новый функционал и обеспечить совместимость с SonarQube 7.x. Минимальной поддерживаемый версией теперь является .\r\nВ новую версию плагинов добавлена поддержка диагностик для языка Java. Теперь вы можете добавить PVS-Studio к другим инструментам контроля качества своего Java-проекта.\r\nНедавно мы объявляли о  стандартов MISRA C и MISRA C++. В новых плагинах тоже появилась их поддержка. Например, был добавлен параметр (в дополнение к CWE):\r\nкоторый включает добавление идентификатора MISRA к предупреждениям анализатора:\r\nНезависимо от этого параметра будет доступен поиск по тегам  и  в результатах анализа. Информация о количестве найденных предупреждений MISRA добавилась и в метрики, о которых пойдёт речь далее.\r\nВ меню  доступны различные метрики кода, среди которых теперь есть различная информация от PVS-Studio:\r\nПо каждой из метрик можно строить графики и следить за динамикой появления тех или иных групп предупреждений анализатора.\r\nНекоторые диагностики анализатора выдают предупреждения на несколько строчек файла. Иногда они находятся очень далеко друг от друга. В новой версии мы добавили multiline-переходы:\r\nSonarQube также поддерживает переходы между разными файлами. Позже мы добавим и такие переходы для диагностик, в которых есть межмодульный анализ. претерпела большие изменения. PVS-Studio является кросс-платформенным и мультиязыковым продуктом, поэтому все переработки были направлены на написание более общих и понятных инструкций по работе на той или иной системе.\r\nДо недавнего времени в своих статьях мы позиционировали PVS-Studio как инструмент для выявления ошибок в коде. При этом мы почти не рассматривали PVS-Studio в контексте безопасности. В этом году мы исправили эту ситуацию и взглянули на инструмент с точки зрения тестирования защищённости приложений и DevSecOps практик.\r\nPVS-Studio является средством статического тестирования защищённости приложений (Static Application Security Testing, SAST). Другими словами, анализатор PVS-Studio выявляет не только опечатки, мёртвый код и другие ошибки, но и потенциальные уязвимости.\r\nДля удобства специалистов, которые будут использовать PVS-Studio как SAST инструмент, анализатор отображает свои предупреждения на , . Таблицы соответствий диагностик PVS-Studio различным стандартам:\r\nБолее подробно данная тема раскрыта в статье \"\".\r\nТакже предлагаем познакомиться с публикациями:\r\nВ канун празднования нового 2019 года команда PVS-Studio решила сделать приятный подарок всем контрибьюторам open-source проектов, хостящихся на GitHub или Bitbucket. Им предоставляется возможность бесплатного использования статического анализатора PVS-Studio для развития открытых проектов.\r\nПодробности: \"\".\r\nВ 2018 году PVS-Studio научился работать под управлением macOS. К этому событию наша команда приурочила проверку XNU Kernel: \"\".\r\nXNU — это ядро компьютерных операционных систем, разрабатываемое компанией Apple и используемое в ОС семейства OS X (macOS, iOS, tvOS, watchOS).\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: Andrey Karpov, Svyatoslav Razmyslov. .", "url": "https://habr.com/ru/company/pvs-studio/blog/436328/"},
{"title": "Проблемы использования функции NtQuerySystemInformation с недокументированными аргументами", "article_text": "Утро в тот день началось с того, что у нас «сломались if'ы». Это выражение было когда-то придумано одним моим коллегой, который демонстрировал, как у него отладчик при пошаговом проходе по коду заходит в блок if, при том, что условие, которое if проверял, было абсолютно точно равно false. Проблема в тот раз оказалась тривиальной — он использовал релизный оптимизированный билд, а при таком сценарии доверять пошаговой отладке, конечно, нельзя. Но само выражение «сломались if'ы» прижилось и использовалось у нас с тех пор для обозначения ситуации, когда перестало работать что-то настолько фундаментальное, что в это даже с трудом верилось.\r\nТак вот, в тот день у нас сломалась функция  — одна из важнейших функций ОС Windows, возвращающая информацию о процессах, потоках, системных дескрипторах и т.д. О пользе от использования данной функции я когда-то писал вот . Но оказалось, что иногда могут отказывать даже подобные краеугольные камни системы.\r\nИтак, что же произошло.\r\nДостаточно продолжительное время (уже несколько лет) мы использовали вызов функции NtQuerySystemInformation с аргументом SystemHandleInformation для получения информации обо всех дескрипторах в системе. Да, этот аргумент формально относится к недокументированным, но если вы начнёте искать информацию о том, как перечислить все дескрипторы во всех запущенных сейчас приложениях на ОС Windows, то комбинация NtQuerySystemInformation + SystemHandleInformation будет наиболее часто предлагаемым вариантом. И он действительно работает, на всех ОС начиная ещё с Windows NT. \r\nЗачем может понадобиться искать дескрипторы во всех процессах? Ну, по разным причинам. Утилиты типа  просто показывают их в информационных целях. Есть программы, которые делают это ради поиска заблокированного кем-то в данный момент ресурса (например, файла). А ещё можно, например, найти в чужом процессе мьютекс, использующийся для разрешения запуска лишь одной копии программы, закрыть его и позволить запустить два экземпляра такого приложения. Или перечислить дескрипторы ради их дублирования с целью организации песочницы. В общем, задач много.\r\nКод перечисления дескрипторов я здесь полностью приводить не буду, скажу лишь, что он был, в общем, аналогичен общераспространённым примерам, вроде :\r\nНо вот я запускаю наше приложения — и вдруг оказывается, что нужный мне дескриптор (а я точно знаю, что он существует!) в списке возвращённых функцией NtQuerySystemInformation() отсутствует. Всё, приехали — «сломались if'ы».\r\nПытаемся воспроизвести проблему на других компьютерах в офисе. На некоторых воспроизводится, на большинстве — нет. Пытаемся понять, чем те, на которых воспроизводится, отличаются от тех, на которых всё хорошо. Версия Windows везде одинаковая, обновления, билд нашей программы — всё идентично. Вдруг кто-то замечает, что все ноутбуки, на которых проблема воспроизвелась — одной модели. Аппаратная несовместимость? Но почему вдруг сейчас, раньше же работало… Кроме того, в офисе есть и другие ноутбуки той же модели, которые работают и сейчас. Сравнивали даже версии драйверов устройств — вроде всё одинаково. Но вот на одних ноутбуках всё работает, а на других нет.\r\nВырывание волос на голове продолжался примерно полдня, пока я случайно не обратил внимание на две вещи:\r\nДля обычного приложения является нормой открыть сотню-другую дескрипторов. Ну тысячу. Хром при активном использовании может открывать около 2000, Visual Studio на больших проектах может открыть 3000. Но кто же открыл 800 000? К счастью, упомянутый ранее Process Hacker позволяет показать количество дескрипторов для каждого процесса и даже отсортировать список процессов по количеству используемых дескрипторов. \r\nИ что же мы видим? А видим мы примерно вот такую картину:\r\nНадо сказать, что вышеуказанный скриншот я делал вот только что, поэтому у первого в списке процесса там «всего» около 20 000 дескрипторов. А тогда, когда я увидел проблему впервые, их там было около 650 000. И кто же наш герой? Бинго! Это процесс SynTPEnhService.exe.\r\nИ тут у меня в голове складывается весь пазл. SynTPEnhService.exe — это часть драйвера тачпада Synaptics. Он был установлен только на ноутбуках определённой модели у нас в офисе, на которых и случалась проблема. Короткое наблюдение показало, что каждые 5 секунд этот процесс запускает дочерний процесс SynTPEnh.exe, которые спустя 1-2 секунды закрывается. При этом родительский процесс продолжает держать дескриптор дочернего процесса, что приводит к утечке дескрипторов. По одному каждые 5 секунд. Это 17 280 дескрипторов в сутки. Оставьте компьютер включенным на недельку и вот у вас уже больше сотни тысяч зависших дескрипторов. Мой лично компьютер не перезагружался больше месяца — отсюда и PIDы новых процессов с номерами выше полумиллиона. Это же объясняет и то, почему проблема воспроизводилась на некоторых ноутбуках в нашем офисе, но не возникала на других таких же: кое-кто из моих коллег перезагружал свои ПК каждый день, а кто-то, как и я, оставлял их включенными на ночь.\r\nКстати в этом месте я вспомнил, что уже читал о какой-то проблеме с драйверами тачпадов Synaptics. Немного покопавшись, я нашел вот , которую написал Bruce Dawson (множество переводов его статей в разные времена публиковались и на Хабре, но не эта конкретная). Там он описывает проблему утечки памяти из-за этого бесконечного перезапуска процесса SynTPEnh.exe, но ничего не говорит о проблеме утечки дескрипторов, так что моя находка всё же отличается от его.\r\nИтак, драйвер тачпада «съедает» сотни тысяч дескрипторов — и что с того? А то, что написанная ещё во времена Windows NT функция NtQuerySystemInformation(SystemHandleInformation,...) имела (и имеет) некоторый вполне ограниченный внутренний буфер. Я не нашел нигде точного указания его размера, но, очевидно, что он не был рассчитан на миллион дескрипторов. В итоге функция возвращает их «сколько может», а значит среди них может оказаться, а может и не оказаться искомый.\r\nЧто же делать? Как говорил Рик из мультсериала «Рик и Морти»: «Когда ты изобретаешь телепортацию, то сразу обнаруживаешь неприятную вещь: ты последний во Вселенной, кто её изобрёл». Как оказалось, Microsoft осознала эту проблему с ограниченностью буфера в NtQuerySystemInformation при вызове её с аргументом SystemHandleInformation уже лет 20 назад и поэтому, начиная с WindowsXP, они добавили функции NtQuerySystemInformation ещё один (и тоже недокументированный) аргумент SystemExtendedHandleInformation. При вызове NtQuerySystemInformation(SystemExtendedHandleInformation, ...) вам будут возвращены все дескрипторы в системе, сколько бы их ни было. Ну, вернее, я не знаю этого точно, может быть какие-то ограничения есть и для этого аргумента, но то, что 800 000 дескрипторов он вернуть в состоянии — это точно.\r\nВ сети можно найти примеры использования SystemExtendedHandleInformation, например, . В общем, там всё аналогично, просто используются другие структуры, да и на этом всё.\r\nЭто была поучительная история об использовании недокументированных аргументов ОС Widnows, которое может быть весьма полезным, но требует внимательного тестирования и готовности к нестандартным проблемам.", "url": "https://habr.com/ru/company/infopulse/blog/433906/"},
{"title": "Как писать unit-тесты для акторов? Подход SObjectizer-а", "article_text": "Акторы упрощают многопоточное программирование за счет ухода от общего разделяемого изменяемого состояния. Каждый актор владеет собственными данными, которые никому не видны. Взаимодействуют акторы только посредством асинхронных сообщений. Поэтому самые кошмарные ужасы многопоточности в виде гонок и дедлоков при использовании акторов не страшны (хотя у акторов есть свои заморочки, но сейчас не об этом).\r\nВ общем, писать многопоточные приложения с использованием акторов легко и приятно. В том числе и потому, что сами акторы пишутся легко и непринужденно. Можно даже сказать, что написание кода актора — это самая простая часть работы. Но вот когда актор написан, то возникает очень хороший вопрос: «Как проверить правильность его работы?»\r\nВопрос, действительно, очень хороший. Нам его регулярно задают когда мы рассказываем про акторов вообще и про  в частности. И до недавнего времени мы могли отвечать на этот вопрос лишь общими словами.\r\nНо вот , в которой появилась экспериментальная поддержка возможности unit-тестирования акторов. И в данной статье мы попытаемся рассказать о том, что это, как этим пользоваться и с помощью чего это было реализовано.\r\nМы рассмотрим новые возможности SObjectizer-а на паре примеров, попутно рассказывая что к чему. Исходные тексты к обсуждаемым примерам могут быть найдены .\r\nПо ходу рассказа будут попеременно использоваться термины «актор» и «агент». Обозначают они одно и тоже, но в SObjectizer-е исторически используется термин «агент», поэтому далее «агент» будет использоваться чаще.\r\nПример с акторами Pinger и Ponger является, наверное, самым распространенным примером для акторных фреймворков. Можно сказать, классика. Ну а раз так, то давайте и мы начнем с классики.\r\nИтак, у нас есть агент Pinger, который в начале своей работы отсылает сообщение Ping агенту Ponger. А агент Ponger отсылает в ответ сообщение Pong. Вот так это выглядит в C++ном коде:\r\nНаша задача написать тест, который бы проверял, что при регистрации этих агентов в SObjectizer-е Ponger получит сообщение Ping, а Pinger в ответ получит сообщение Pong.\r\nOK. Пишем такой тест с использованием unit-тест-фреймворка  и получаем:\r\nВроде бы несложно. Давайте посмотрим, что же здесь происходит.\r\nПрежде всего, мы загружаем описания средств поддержки тестирования агентов:\r\nВсе эти средства описаны в пространстве имен so_5::experimental::testing, но чтобы не повторять такое длинное имя мы вводим более короткий и удобный псевдоним:\r\nДалее идет описание единственного test-кейса (а более нам здесь и не нужно).\r\nВнутри test-кейса можно выделить несколько ключевых моментов.\r\nВо-первых, это создание и запуск специального тестового окружения для SObjectizer-а:\r\nБез этого окружения «тестовый прогон» для агентов выполнить не получится, но об этом мы поговорим чуть ниже.\r\nКласс testing_env_t очень похож на имеющийся в SObjectizer-е класс . Точно так же в конструкторе запускается SObjectizer, а в деструкторе останавливается. Так что при написании тестов не приходится задумываться о запуске и останове SObjectizer-а.\r\nДалее нам нужно создать и зарегистрировать агентов Pinger и Ponger. При этом нам нужно использовать этих агентов при определении т.н. «тестового сценария». Поэтому мы отдельно сохраняем указатели на агентов:\r\nИ вот дальше мы начинаем работать с «тестовым сценарием».\r\nТестовый сценарий — это состоящая из прямой последовательности шагов штука, которая должна быть выполнена от начала до конца. Фраза «из прямой последовательности» означает, что в SObjectizer-5.5.24 шаги сценария «срабатывают» строго последовательно, без каких-либо ветвлений и циклов.\r\nНаписание теста для агентов — это определение тестового сценария, который должен быть исполнен. Т.е. должны сработать все шаги тестового сценария, начиная от самого первого и заканчивая самым последним.\r\nПоэтому в своем test-кейсе мы определяем сценарий из двух шагов. Первый шаг проверяет, что агент Ponger получит и обработает сообщение Ping:\r\nВторой шаг проверяет, что агент Pinger получит сообщение Pong:\r\nЭтих двух шагов для нашего test-кейса вполне достаточно, поэтому после их определения мы переходим к исполнению сценария. Запускаем сценарий и разрешаем ему работать не дольше 100ms:\r\nСта миллисекунд должно быть более чем достаточно для того, чтобы два агента обменялись сообщениями (даже если тест будет запущен внутри очень тормозной виртуальной машины, как это иногда бывает на Travis CI). Ну а если мы ошиблись в написании агентов или неправильно описали тестовый сценарий, то ждать завершения ошибочного сценария больше 100ms нет смысла.\r\nИтак, после возврата из run_for() наш сценарий может быть либо успешно завершен, либо нет. Поэтому мы просто проверяем результат работы сценария:\r\nЕсли сценарий не был успешно завершен, то это приведет к провалу нашего test-кейса.\r\nЕсли бы мы запустили вот такой код внутри нормального SObjectizer-а:\r\nто, скорее всего, агенты Pinger и Ponger успели бы обменяться сообщениями и завершили бы свою работу еще до возврата из introduce_coop (чудеса многопоточности — они такие). Но внутри тестового окружения, которое создается благодаря testing_env_t, этого не происходит, агенты Pinger и Ponger терпеливо ждут, пока мы не запустим наш тестовый сценарий. Как такое происходит?\r\nДело в том, что внутри тестового окружения агенты оказываются как бы в замороженном состоянии. Т.е. после регистрации они в SObjectizer-е присутствуют, но ни одно свое сообщение обработать не могут. Поэтому у агентов даже so_evt_start() не вызывается до того, как будет запущен тестовый сценарий.\r\nКогда же мы запускаем тестовый сценарий методом run_for(), то тестовый сценарий сперва размораживает всех замороженных агентов. А потом сценарий начинает получать от SObjectizer-а уведомления о том, что с агентами происходит. Например, о том, что агент Ponger получил сообщение Ping и что агент Ponger это сообщение обработал, а не отверг.\r\nКогда к тестовому сценарию начинают приходить такие уведомления, сценарий пытается «примерить» их к самому первому шагу. Так, у нас есть уведомление о том, что Ponger получил и обработал Ping — это нам интересно или нет? Оказывается, что интересно, ведь в описании шага именно так и сказано: срабатывает когда Ponger реагирует на Ping. Что мы и видим в коде:\r\nOK. Значит первый шаг сработал, переходим к следующему шагу.\r\nСледом прилетает уведомление о том, что агент Pinger среагировал на Pong. И это как раз то, что нужно, чтобы сработал второй шаг:\r\nOK. Значит и второй шаг сработал, есть ли у нас что-то еще? Нет. Значит и весь тестовый сценарий завершен и можно возвращать управление из run_for().\r\nВот, в принципе, как работает тестовый сценарий. На самом деле все несколько сложнее, но более сложных аспектов мы коснемся когда будем рассматривать более сложный пример.\r\nБолее сложные примеры тестирования агентов можно увидеть в решении широко известной задачи «Обедающие философы». На акторах эту задачу можно решить несколькими способами. Далее мы будем рассматривать самое тривиальное решение: в виде акторов представлены и сами философы, и вилки, за которые философам приходится бороться. Каждый философ некоторое время думает, затем пытается взять вилку слева. Если это удалось — он пытается взять вилку справа. Если и это удалось, то философ некоторое время ест, после чего кладет вилки и начинает думать. Если же вилку справа взять не удалось (т.е. она взята другим философом), то философ возвращает вилку слева и думает еще какое-то время. Т.е. это не самое хорошее решение в том плане, что какой-то философ может слишком долго голодать. Но зато оно очень простое. И обладает простором для демонстрации возможностей по тестированию агентов.\r\nИсходные коды с реализацией агентов Fork и Philosopher могут быть найдены , в статье мы их рассматривать не будем для экономии объема.\r\nПервый тест для агентов из «Обедающих философов» мы напишем для агента Fork.\r\nЭтот агент работает по простой схеме. У него есть два состояния: Free и Taken. Когда агент находится в состоянии Free, он реагирует на сообщение Take. При этом агент переходит в состояние Taken и отвечает ответным сообщением Taken.\r\nКогда агент находится в состоянии Taken, он реагирует на сообщение Take уже по другому: состояние агента не меняется, а в качестве ответного сообщения отсылается Busy. Также в состоянии Taken агент реагирует на сообщение Put: агент возвращается в состояние Free.\r\nВ состоянии Free сообщение Put игнорируется.\r\nВот этот вот все мы и попробуем протестировать посредством следующего test-кейса:\r\nКода много, поэтому будем разбираться с ним по частям, пропуская те фрагменты, которые уже должны быть понятны.\r\nПервое, что нам здесь понадобится — это замена реального агента Philosopher. Агент Fork должен от кого-то получать сообщения и кому-то отвечать. Но мы не можем в этом test-кейсе использовать настоящего Philosopher-а, ведь у реального агента Philosopher своя логика поведения, он сам отсылает сообщения и эта самостоятельность нам здесь будет мешать.\r\nПоэтому мы делаем , т.е. вводим вместо реального Philosopher-а его заменитель: пустой агент, который ничего сам не отсылает, а отосланные сообщения только принимает, без какой-либо полезной обработки. Это и есть реализованный в коде псевдо-Философ:\r\nДалее мы создаем кооперацию из агента Fork и агента PseudoPhilospher и начинаем определять содержимое нашего тестового сценария.\r\nПервый шаг сценария — это проверка того, что Fork, будучи в состоянии Free (а это его начальное состояние), не реагирует на сообщение Put. Вот как эта проверка записывается:\r\nПервая штука, которая обращает на себя внимание — это конструкция impact.\r\nНужна она потому, что наш агент Fork сам ничего не делает, он только реагирует на входящие сообщения. Поэтому сообщение агенту кто-то должен отослать. Но кто?\r\nА вот сам шаг сценария и отсылает посредством impact. По сути, impact — это аналог привычной функции send (и формат такой же).\r\nОтлично, сам шаг сценария будет отсылать сообщение через impact. Но когда он это будет делать?\r\nА будет он это делать, когда до него дойдет очередь. Т.е. если шаг в сценарии первый, то impact будет выполнен сразу после входа в run_for. Если шаг в сценарии не первый, то impact будет выполняться как только сработает предыдущий шаг и сценарий перейдет к обработке очередного шага.\r\nВторая штука, которую нам здесь нужно обсудить — это вызов ignores. Эта вспомогательная функция говорит, что шаг срабатывает когда агент оказывается от обработки сообщения. Т.е. в данном случае агент Fork должен отказаться обрабатывать сообщение Put.\r\nРассмотрим еще один шаг тестового сценария подробнее:\r\nВо-первых, мы здесь видим when_all вместо when. Это потому, что для срабатывания шага нам нужно выполнение сразу нескольких условий. Нужно, чтобы агент fork обработал Take. И нужно, чтобы Philosopher обработал ответное Taken. Поэтому мы и пишем when_all, а не when. Кстати говоря, есть еще и when_any, но в рассматриваемых сегодня примерах мы с ним не встретимся.\r\nВо-вторых, нам здесь нужно еще и проверить тот факт, что после обработки Take агент Fork окажется в состоянии Taken. Проверку мы делаем следующим образом: сперва указываем, что как только агент Fork закончит обрабатывать Take, имя его текущего состояние должно быть сохранено с использованием тега-маркера «fork». Вот эта конструкция как раз и предписывает сохранить имя состояния агента:\r\nА далее, уже когда сценарий завершен успешно, мы проверяем это сохраненное имя:\r\nТ.е. мы просим у сценария: дай нам имя, которое было сохранено с тегом-маркером «fork» для шага с именем «take_when_free», после чего сравниваем имя с ожидаемым значением.\r\nВот, пожалуй, и все, что можно было бы отметить в test-кейсе для агента Fork. Если у читателей остались какие-то вопросы, то задавайте в комментариях, с удовольствием ответим.\r\nДля агента Philosopher мы рассмотрим только один test-кейс — для случая, когда Philosopher сможет взять обе вилки и поесть.\r\nВыглядеть этот test-кейс будет следующим образом:\r\nДовольно объемно, но тривиально. Сперва проверяем, что Philosopher закончил думать и начал готовится к еде. Затем проверяем, что он попытался взять левую вилку. Далее он должен попытаться взять правую вилку. Затем он должен поесть и прекратить это занятие. После чего он должен положить обе взятые вилки.\r\nВ общем-то все просто. Но следует заострить внимание на двух вещах.\r\nВо-первых, класс testing_env_t, как и его прообраз, wrapped_env_t, позволяет настроить SObjectizer Environment. Мы этим воспользуемся для того, чтобы включить механизм message delivery tracing:\r\nДанный механизм позволяет «визуализировать» процесс доставки сообщений, что помогает при разбирательстве с поведением агентов (об этом мы уже ).\r\nВо-вторых, ряд действий агент Philosopher выполняет не сразу, а спустя какое-то время. Так, начав работать агент должен отсылать себе отложенное сообщение StopThinking. Значит прийти это сообщение к агенту должно спустя сколько-то миллисекунд. Что мы и указываем задавая для определенного шага нужное ограничение:\r\nТ.е. здесь мы говорим, что нас интересует не любая реакция агента Philosopher на StopThinking, а только та, которая произошла не раньше, чем через 250ms после начала обработки этого шага.\r\nОграничение вида not_before указывает сценарию, что все события, которые происходят до истечения заданного тайм-аута, должны игнорироваться.\r\nЕсть также ограничение вида not_after, оно работает наоборот: учитываются лишь те события, которые происходят пока не истек заданный тайм-аут.\r\nОграничения not_before и not_after могут комбинироваться, например:\r\nно в этом случае SObjectizer не проверяет непротиворечивость заданных значений.\r\nХотелось бы сказать пару слов о том, как получилось все это заставить работать. Ведь, по большому счету, перед нами стоял один большой идеологический вопрос «Как в принципе тестировать агентов?» и один вопрос поменьше, уже технический: «Как это реализовать?»\r\nИ если по поводу идеологии тестирования можно было изгаляться как угодно, то вот по поводу реализации ситуация была сложнее. Требовалось найти такое решение, которое, во-первых, не требовало бы кардинальной переделки внутренностей SObjectizer-а. И, во-вторых, это должно было быть решение, которое можно было бы реализовать в обозримое и, крайне желательно, небольшое время.\r\nВ результате непростого процесса выкуривания бамбука решение таки было найдено. Для этого потребовалось, по сути, внести всего одно небольшое нововведение в штатное поведение SObjectizer-а. А основу решения составляет .\r\nВнутри тестового окружения каждое отсылаемое сообщение оборачивается в специальные конверт. Когда конверт с сообщением отдается агенту на обработку (либо, наоборот, отвергается агентом), об этом становится известно тестовому сценарию. Именно благодаря конвертам тестовый сценарий знает, что происходит и может определять моменты, когда «срабатывают» шаги сценария.\r\nНо как заставить SObjectizer оборачивать каждое сообщение в специальный конверт?\r\nВот это был интересный вопрос. Решился он следующим образом: было придумано такое понятие, как . Это специальный объект с двумя методами — on_bind и on_unbind.\r\nКогда какой-либо агент привязывается к конкретному диспетчеру, диспетчер выдает агенту персональный event_queue. Через этот event_queue заявки для агента попадают в нужную очередь и становятся доступны диспетчеру для обработки. Когда агент работает внутри SObjectizer-а, у него хранится указатель на event_queue. Когда агент изымается из SObjectizer-а, у него указатель на event_queue обнуляется.\r\nТак вот, начиная с версии 5.5.24 агент при получении event_queue обязан вызвать метод on_bind у event_queue_hook-а. Куда агент должен передать полученный указатель на event_queue. А event_queue_hook в ответ может вернуть либо тот же самый указатель, либо другой указатель. И агент должен использовать возвращенное значение.\r\nКогда агент изымается из SObjectizer-а, то он обязан вызвать on_unbind у event_queue_hook-а. В on_unbind агент передает то значение, которое было возвращено методом on_bind.\r\nВся эта кухня выполняется внутри SObjectizer-а и пользователю ничего этого не видно. Да и, в принципе, об этом можно вообще не знать. Но тестовое окружение SObjectizer-а, тот самый testing_env_t, эксплуатирует именно event_queue_hook. Внутри testing_env_t создается специальная реализация event_queue_hook. Эта реализация в on_bind оборачивает каждый event_queue в специальный прокси-объект. И уже этот прокси-объект кладет отсылаемые агенту сообщения в специальный конверт.\r\nНо это еще не все. Можно вспомнить, что в тестовом окружении агенты должны оказаться в замороженном состоянии. Это также реализуется посредством упомянутых прокси-объектов. Пока тестовый сценарий не запущен, прокси-объект хранит отосланные агенту сообщения у себя. Но когда сценарий запускается, прокси-объект передает все ранее накопленные сообщения в актуальную очередь сообщений агента.\r\nВ заключение статьи хочется сказать две вещи.\r\nВо-первых, мы реализовали в SObjectizer-е свой взгляд на то, как можно тестировать агентов. Свой взгляд потому, что хороших образцов для подражания вокруг не так уж и много. Мы смотрели в сторону . Но Akka и SObjectizer  чтобы переносить в SObjectizer подходы, которые работают в Akka. Да и C++ не Scala/Java, в которых какие-то вещи, связанные с интроспекцией, можно делать за счет рефлексии. Так что пришлось придумывать подход, который лег бы на SObjectizer.\r\nВ версии 5.5.24 стала доступна самая первая, экспериментальная реализация. Наверняка можно сделать лучше. Но как понять, что окажется полезным, а что бесполезные фантазии? К сожалению, никак. Нужно брать и пробовать, смотреть, что получается на практике.\r\nВот мы и сделали минималистичную версию, которую можно взять и попробовать. Что мы и предлагаем сделать всем желающим: попробуйте, поэкспериментируйте и поделитесь с нами своими впечатлениями. Что вам понравилось, что не понравилось? Может чего-то не хватает?\r\nВо-вторых, еще более актуальными стали слова которые были сказаны : Все вышесказанное имеет еще большее значение когда дело касается тестирования акторов. Поэтому, при выборе акторного фреймворка для себя обращайте внимание на то, что в нем есть, а чего нет. Вот в нашем, например, уже и средства для упрощения тестирования есть :)", "url": "https://habr.com/ru/post/435606/"},
{"title": "Основные понятия стандартной библиотеки С++", "article_text": "Данная статья определяет основные понятия стандартной библиотеки С++. Она приводится для того чтобы на неё ссылаться в дальнейшем.\r\nНаибольшей частью стандартной библиотеки С++ является библиотека STL (Standard Template Library – Стандартная Библиотека Шаблонов). Библиотека STL содержит пять основных видов компонентов:\r\nВсе компоненты удовлетворяют ряду требований, поэтому хорошо согласуются друг с другом.\r\nИз определения контейнера следует, что любая пользовательская структура данных является контейнером. В нашем случае , такие как список (list), вектор (vector), словарь (map) и многие другие. Формальные требования к контейнерам довольно обширны, но основным является правило доступа к элементам. Доступ к элементам контейнера осуществляется через специальные объекты —  (см. ниже). Вы можете не знать, как располагаются элементы контейнера в памяти, однако вы точно знаете, что итераторы можно перебрать последовательно, и каждый из них предоставит доступ к элементу. Итератор, указывающий на первый элемент, можно получить при помощи метода  контейнера. Итератор, указывающий , можно получить при помощи метода  контейнера. Другими словами, итераторы располагаются в (или полуотрезке), что можно формально записать как [begin, end). Пример объявления контейнера: Итератор является свойством контейнера. В первых реализациях стандартной библиотеки С++ итератор реализовывался как указатель на элемент контейнера. В современных реализациях это класс, инкапсулирующий указатель на объект контейнера.\r\nОсновные требования к итераторам — наличие операторов разыменования и инкремента. Ниже объявление контейнера с итератором.\r\nЯ не могу дать лучшего определения алгоритма чем стандартное: .\r\nВ случае STL, алгоритмы реализуются шаблонными функциями, которые в качестве входных параметров принимают полуинтервалы итераторов. Общая сигнатура данных алгоритмов описывается следующим образом:\r\nВ объявлении класса можно переопределить оператор (). Если этот оператор в классе переопределен, то объекты этого класса получают свойства функций (их можно использовать как функции). Такие объекты называются функциональными или . Функторы удобно использовать, когда функция должна обладать «памятью», а также, как замена указателей на функции. Каких-либо специальных требований к функторам нет. Разве что иногда может требоваться наследование от функтора  (до стандарта С++11 — unary_function или binary_function). Небольшой пример реализации функтора:\r\nТакже STL предлагает ряд классов и функций (фукнторов), которые преобразуют интерфейс к нужному. В частности, есть адаптер stack, который на основе контейнеров реализует, соответственно, стэк. В качестве примера можно рассмотреть адаптер бинарной функции к унарной (на данный момент эта функция объявлена в стандарте С++ устаревшей):", "url": "https://habr.com/ru/post/434986/"},
{"title": "explicit в деталях", "article_text": "Если спросить C++-программиста о значении ключевого слова explicit, большинство ответит, что это ключевое слово ставится перед объявлением конструктора с одним параметром (или с большим числом параметров, но когда все параметры, начиная со второго, имеют значения по умолчанию) и предотвращает неявное преобразование типов при инициализации.В старом добром C++03 сценарии применения ключевого слова на этом заканчивались, однако, начиная с C++11, область применения explicit расширилась: теперь оно имеет смысл не только в конструкторах с одним параметром, и даже не только в конструкторах.В 2011 году в Стандарт добавили универсальную инициализацию (uniform initialization), которая должна навести порядок в зоопарке способов инициализации объектов, доставшемся C++ в наследство от языка C. Я не буду здесь подробно рассказывать про универсальную инициализацию, на эту тему есть множество подробных статей, их несложно найти по ключевым словам. В двух словах: объекты предлагается инициализировать при помощи фигурных скобок, по сути это расширение т.н. агрегатной инициализации (aggregate initialization), унаследованной ещё со времён C.С появлением универсальной инициализации explicit обрёл смысл для конструкторов с 0,2,3 и более параметров:Помимо этого, начиная с C++11 ключевое слово explicit может также применяться к операторам преобразования типа, также запрещая их неявный вызов:В заключение хочется порекомендовать использовать универсальную инициализацию в любом новом коде на C++, а также явно объявлять конструкторы explicit всегда, кроме случаев, когда неявное преобразование семантически оправдано.", "url": "https://habr.com/ru/post/436296/"},
{"title": "Мысли о Rust 2019", "article_text": "Коллеги, доброго вечера всем!\r\nМы с радостью предлагаем вам перевод по-настоящему программной статьи от , чей титанический труд над развитием языка Rust вызывает уважение и пиетет:\r\nБез ложной скромности и без шапкозакидательства, предметно и увлеченно уважаемый автор откликнулся на призыв сообщества Rust, опубликованный по ссылке в начале этой статьи. Надеемся, получилось интересно и жизнеутверждающе. \r\nНедавно команда Rust Core Team  с мнениями о том, как Rust должен развиваться в 2019 году. Вот мое мнение.\r\nВ этой статье я рассмотрю жизненный цикл созревания в предельно упрощенном виде. Пусть он состоит всего из трех этапов: исследования, разработка, шлифовка. Различные элементы Rust отличаются разной степенью зрелости. Это важно учитывать, пытаясь точно охарактеризовать актуальный этап развития языка, а в идеале – вывести его на следующий этап. Например, мне представляется, что язык в основном находится в стадии «шлифовки». Если упорствовать в том, что стадия «исследования» еще не пройдена, то язык можно обогатить зависимыми типами,  и т.д., что было бы интересно, но контрпродуктивно. Верно и обратное: мы не можем точно сформулировать, чего нам не хватает в графическом пользовательском интерфейсе, поэтому преждевременные попытки привести эти поиски к стандартному решению, скорее всего, обернутся неоптимальными результатами.\r\nВо многих зрелых продуктах перемежаются релизы, одни из которых посвящены обкатке новых возможностей, а другие – их стабилизации. Такова, например, система tick-tock у Intel. Версии Android Kit Kat и Marshmallow были стабильными, и в то же время Lollipop активно перелопачивали). В 2018 году Rust обогатился множеством новых возможностей, поэтому я считаю, что пришло время для этапа стабилизации. В этом я согласен с , а также со многими другими.\r\nДумаю, что в общем и целом язык Rust готов. Создается впечатление, что сообщество достигло согласия по поводу необходимости «приземлять» те фичи, которые до сих пор остаются «на лету» (в стадии разработки): речь об async/await, const generics, и интерпретаторе (что, вероятно, обеспечит нам доработку ). Однако, думаю, что сверх этого мы не должны чрезмерно усердствовать с наполнением конвейера новыми фичами.\r\nИзменения стоят денег. По состоянию на 2018 год о Rust написаны две отличные книги, но обе уже слегка устарели. Соглашения для квалифицированных путей в них отличаются, теперь мы используем , т.д. Чем динамичнее изменения, тем больше неудобств для пользователей.\r\nСуществует масса факторов, ограничивающих успех Rust; не думаю, что большинство из этих недостатков присущи самому языку.\r\nОснастка Rust могла бы быть куда лучше. Я экспериментировал с RLS, но всегда возвращался к обычному текстовому редактору и циклу командной строки (честно говоря, в последнее время таких опытов не ставил). Думаю, в долгосрочной перспективе требуется существенно дорабатывать инструментарий Rust, чтобы хоть как-то облегчить кривую обучения. У меня есть некоторые идеи (надеюсь, найдется время изложить их подробнее) о более тепличном языке, в реализуемости которого я не уверен, где не было бы четкого различия между значением и ссылкой на него, значение можно было бы использовать после перемещения и т.д. В принципе, такой язык позволял бы трактовать строку как число. Сервер принимает программы, написанные на этом языке, быстро правит их и преобразует в полноценный Rust.\r\nЕстественно, RLS лишь наполовину этому соответствует, пользователи взаимодействуют с ней через редактор. Работать с  удобно, хотя, при этом обычно требуется некоторое руководство и поддержка. Эту работу взяло на себя сообщество во главе с , и мне просто радостно смотреть, как этот редактор улучшается (он уже стал у меня основным). Там предусмотрена поддержка языкового сервера, а также новые возможности, например, общий механизм аннотаций, будут значительно лучше доработаны в 2019 году.\r\nСамая жаркая работа сейчас кипит в деле создания библиотек для Rust. Ниже перечислю вещи, которыми планирую заняться сам.\r\nОдна из тем, которую я хотел бы поднять – это «когерентность», которая, на мой взгляд, является одной из самых ценных черт Rust, наряду с . Многие составляющие «игрового движка» в пределах C++ — это тщательно подготовленная подборка библиотек, отлично взаимодействующих друг с другом. Но в Rust многие подобные вещи происходят органически. Контейнеры действительно обычно заточены на использование в связках, а если грамотно применять такие вещи как , то все тем более налаживается. Особенно убедительный пример второго рода — , обеспечивающий интероперабельность множества математических контейнеров, даже притом, что в них не совпадают соглашения, применяемые при определении векторных типов и т.д. \r\nДумаю, SIMD-библиотеки пока находятся на стадии исследования. Есть множество библиотек-оберток, каждая из которых предлагает немного иную перспективу и иной ряд компромиссов: , ,  и, конечно же, моя собственная . Эти компромиссы далеко не безусловны, ведь некоторым пользователям потребуется выжать из языка всю производительность до последней капли и, если вы тяготеете к таким крайностям, то придется прибегать к наилучшим инструкциям для конкретных процессоров. Другие в большей степени оценят портируемость и безопасность.\r\nОдна из важнейших закавык SIMD заключается в том, что гораздо больше работы приходится делать в компиляторе, во многом ради взаимодействия с архитектурами AVX-512 и не -x86 SIMD. Также возможно, что библиотеки-обертки требуют внести некоторые изменения на уровне языка, чтобы работать стало максимально удобно; так, на настоящий момент встраивание и  взаимодействуют плохо. На мой взгляд, это еще один вопрос, требующий исследования. Интересно понять, как далеко мы сможем зайти без дополнительной поддержки на уровне языка, и какие именно возможности помогут принципиально повысить удобство работы с ним? \r\nЕсть удобные низкоуровневые аудио-контейнеры, среди которых следует особо отметить . Однако, с ним возможны сложности на уровне производительности (контейнер не всегда использует поток реального времени), каких-то возможностей. Необходимо найти оптимальный путь: либо доработать cpal, либо разработать новый контейнер, который позволил бы исправить конкретные проблемы. Для этого, в частности, нужно внимательно присмотреться к библиотекам C++, например, , хорошо решающим эти проблемы.\r\nДля более высокоуровневого аудио-синтеза у меня большие планы на . Этот вариант подойдет не всем, но, думаю, это хороший базис для разнообразных приемов синтеза и аудиоэффектов. Представляется, что сегодня этот участок работы находится где-то между этапами исследования и разработки. \r\nЧтобы следить за этой работой, ознакомьтесь с  в нашем чате Zulip. В ноябре я читал лекцию об этом, на основе которой вскоре планирую написать пост.\r\nВ настоящее время графические пользовательские интерфейсы – одно из самых слабых мест Rust. Думаю, в 2019 году мы увидим в Rust-сообществе достаточно много статей на эту тему.\r\nЛично мне кажется, что растовские GUI в настоящее время следует отнести к фазе «исследования». Прорабатывается множество альтернативных подходов, и пока нет общего мнения о том, который из них лучший. Насколько активно в системной архитектуре должна использоваться 2D-графика и другие примитивы пользовательского интерфейса, либо нам стоит реализовать весь этот стек самостоятельно? Является ли необходимым развертывание в веб (при помощи wasm)? Должен ли весь процесс программирования восприниматься “Rust-нативный”, либо лучше приспособиться к соглашениям, устоявшимся в каком-нибудь зрелом GUI? Хватит ли у Rust-сообщества ресурсов, чтобы создать новый GUI-инструментарий, и если так – то стоит ли это делать? \r\nЯ начал проект , чтобы сделать GUI для моего синтезатора и игры, но этот проект – исследовательский. В нем представлена моя точка зрения, мои ответы на все вопросы, сформулированные выше, и, на мой взгляд, этот проект развивается хорошо. Но, повторюсь, это исследовательский проект, и было бы весьма глупо на данном этапе внедрять его в другие проекты.\r\nКроме того, ведется и ряд других проектов по разработке GUI. На мой взгляд, наиболее многообещающим из них является , поскольку WebRender нравится мне в качестве основы для построения GUI. Другой очень перспективный проект — , сделанный на основе Redox, но кроссплатформенный и реально продвинутый. Многому можно научиться и на примерах , , а также на обертках инструментариев из других языков.\r\nНеудивительно, что наиболее бурная деятельность по разработке GUI в Rust тесно связана с играми, и мне кажется, что это хорошо. Инновации лучше приживаются в сегменте игр, а необходимость в зрелых инструментариях здесь стоит не так остро. Но, как только появится отличный подход к реализации GUI в Rust, думаю, он найдет самое широкое применение. Также отмечу, что мой Druid зародился на основе GUI-уровня из .\r\nБиблиотека  используется достаточно хорошо, в частности, для rustdoc, но в некоторых отношениях подустарела. Ее эволюция не успевает за развитием спецификации CommonMark. Одна из причин, по которой она немного застряла, связана с алгоритмом парсинга; у меня уже есть идея, как написать новый алгоритм для этой цели, гораздо лучше прежнего; но детали я пока не проработал. В последнее время я вновь  и готовлюсь выпустить алгоритм. Когда ветка  добавится в master, думаю, сообществу стоит взяться за его дальнейшую доработку, обогащать его новыми фичами. Я размышляю о полной GFM-совместимости, математике и, возможно, о чем-нибудь еще в этом духе.\r\nСпасибо всем в сообществе Rust за доработку языка, с которым мне так нравится жить.", "url": "https://habr.com/ru/company/piter/blog/433910/"},
{"title": "Внепроцессный отладчик для C++ в Visual Studio 2019", "article_text": "В Visual Studio 2019 Preview 1 представлен улучшенный отладчик для C++, который использует внешний 64-разрядный процесс для размещения своих ресурсозатратных компонентов. Если у вас ранее возникали проблемы с памятью при отладке приложений C++, теперь эти проблемы должны быть в значительной степени решены с помощью Visual Studio 2019.\r\nНиже практический пример отладки Gears of War 4.\r\nДавая фидбек, C++ разработчики часто рассказывали о проблемах, связанных с большим использованием памяти во время отладки сложных C++ приложений. Большое потребление памяти связано с огромным количеством symbol data, которую дебаггер должен загружать и показывать в окне отладчика. Причем объем этой информации во время работы все время растет. В конечном итоге процесс Visual Studio может завершиться сбоем из-за нехватки памяти.\r\nМы внесли значительные улучшения в Visual Studio 2017, чтобы смягчить эту проблему. Например, в обновлении 15.6 введена оптимизация памяти для /Debug:fastlink, что привело к снижению потребления памяти отладчиком на 30%. Поскольку мы стремимся избежать этой проблемы в Visual Studio 2019, мы переместили компоненты с интенсивным использованием памяти в отдельный 64-битный процесс.\r\nМы тесно сотрудничали с внутренними и внешними партнерскими командами, чтобы гарантировать, что изменения, которые мы вносили в отладчик, были проверены и обоснованы в больших реальных приложениях. Ниже мы продублировали видео из кдпв. В нем показано параллельное сравнение использования памяти между Visual Studio 2017 и Visual Studio 2019 при отладке Gears of War 4, разработанной The Coalition. Использование памяти Visual Studio 2017 увеличивается до 1,3 ГБ после нескольких минут просмотра кода игры и проверки переменных. Visual Studio 2019 обеспечивает гораздо лучшее использование памяти в том же сценарии: объем используемой памяти остается на уровне около 285 МБ, поскольку symbol data хранится в 64-разрядном рабочем процессе отладчика.\r\nВ runtime теперь все тоже работает намного лучше.\r\nЕсли вам необходимо продолжить использование отладчика in-process, вы можете отключить фичу, перейдя на вкладку «Debugging» в «Tools» -> «Options» и сняв флажок «Load debug symbols in external process (native only)».\r\nПодготовить эту статью нам помогли ребята из  @msdevru, канала сообщества Microsoft Developer для разработчиков и всех, кто интересуется новыми технологиям.", "url": "https://habr.com/ru/company/microsoft/blog/433992/"},
{"title": "Тесты на Си без SMS и регистрации", "article_text": " Недавно  написал интересную статью , в которой рассматривается минималистический фреймворк для тестирования Си++ кода. Автору (почти) удалось избежать использования макросов для регистрации тестов, однако вместо них в коде появились «волшебные» шаблоны, которые лично мне кажутся, простите, невообразимо уродскими. После прочтения статьи у меня оставалось смутное чувство неудовлетворённости, так как я , что можно сделать лучше. Я сразу не смог вспомнить где, но я  код тестов, который не содержит ни единого лишнего символа для их регистрации:Наконец-то я вспомнил, что этот фреймворк называется  и он использует по-своему гениальный способ идентификации тестовых функций.(КДПВ взята с сайта Cutter под CC BY-SA.)Тестовый код собирается в отдельную разделяемую библиотеку. Функции-тесты извлекаются из экспортируемых символов библиотеки и идентифицируются по именам. Тесты исполняет специальная внешняя утилита. Sapienti sat.Вот . Можно смело проматывать всё, что связано с Autotools, и смотреть только на код. Фреймворк немного странный, да, как и всё японское.Я не буду слишком уж подробно разбирать особенности реализации. У меня также нет полноценного (и даже хотя бы чернового) кода, так как лично мне он не очень-то и нужен (в Rust всё есть из коробки). Однако, для заинтересовавшихся людей это может быть хорошим упражнением.Рассмотрим некоторые задачи, которые потребуется решить при написании фреймворка для тестирования с помощью подхода Cutter.Для начала, до тестовых функций необходимо как-то добраться. Стандарт Си++, естественно, не описывает разделяемые библиотеки вовсе. Windows с недавних пор обзавелась Linux-подсистемой, что позвляет все три главные операционные системы свести к POSIX. Как известно, POSIX-системы предоставляют функции , , , с помощью которых можно получить адрес функции, зная имя её символа, и… в общем-то всё. Список функций, содержащихся в загруженной библиотеке, POSIX уже не раскрывает.К сожалению (хотя, скорее, к счастью), не существует стандартного, переносимого способа обнаружить все функции, экспортируемые из библиотеки. Возможно, здесь как-то замешан тот факт, что не на всех платформах (читай: embedded) вообще существует понятие . Но не в этом суть. Главное, что вам  использовать платформоспецифичные возможности.В качестве начального приближения можно просто вызывать утилиту :разбирать её вывод и пользоваться .Для более глубокой интроспекции пригодятся библиотеки вроде , , , позволяющие программно разбирать исполнимые файлы и библиотеки интересующих вас платформ. На самом деле  и компания как раз ими и пользуются.Как вы могли заметить, в библиотеках содержатся какие-то странные символы:Вот что это за , когда мы называли функцию просто ? И что это за левая ?«Лишние» символы  — это так называемое  (name mangling). Особенность компиляции Си++, ничего не поделаешь, живите с этим. Именно так называются функции с точки зрения системы (и ). Для того, чтобы показывать их человеку в нормальном виде, можно воспользоваться библиотеками вроде . Конечно же нужная библиотека зависит от используемого вами компилятора, но формат декорирования обычно одинаков в рамках платформы.Что касается странных функций вроде , то это тоже особенности платформы, которые придётся учитывать. Какие-то функции вызывать при запуске тестов не надо, так как там рыбы нет.Логичным продолжением этой идеи будет фильтрация функция по именам. Например, можно запускать только функции с  в названии. Или только функции из пространства имён . А также использовать вложенные пространства имён для группировки тестов. Нет предела вашему воображению.Объектные файлы с тестами собираются в разделяемую библиотеку, исполнение кода которой полностью контролируется внешней утилитой-драйвером —  для Cutter. Соответственно, внутренние тестовые функции могут этим пользоваться.Например, контекст исполняемого теста ( в исходной статье) можно спокойно передавать через глобальную (thread-local) переменную. За управление и передачу контекста отвечает драйвер.В таком случае тестовые функции не требуют аргументов, но сохраняют все расширенные возможности, вроде произвольного именования тестируемых случаев:Функция  получает доступ к условному  через глобальную переменную и таким образом может передать фреймворку комментарий для человека. Безопасность использованя глобального контекста гарантируется фреймворком и не является ответственностью писателя тестов.При таком подходе в коде будет меньше шума с передачей контекста в утверждения сравнения и внутренние тестовые функции, которые может потребоваться вызывать из основной.Так как исполнение тестов полностью контролируется драйвером, то он может выполнять дополнительный код  тестов.В библиотеке Cutter для этого используются следующие функции:Эти функции вызываются только если определены в тестовом файле. В них можно поместить подготовку и очистку тестового окружения (fixture): создание нужных временных файлов, сложную настройку тестируемых объектов, и прочие антипаттерны тестирования.Для Си++ возможно придумать более идиоматичный интерфейс:Но мне пока опять размышлять над этим всем в деталях сейчас.Cutter для удобства использует подход с разделяемыми библиотеками. Различные тесты компилируются в набор библиотек, которые находит и исполняет отдельная тестовая утилита. Естественно, при желании весь код драйвера тестов можно вшить прямо в исполнимый файл, получая привычные отдельные файлы. Однако, для этого потребуется сотрудничество с системой сборки, чтобы организовать компоновку этих исполнимых файлов правильным образом: без вырезания «неиспользуемых» функций, с правильными зависимостями, и т. д.У Cutter и других фреймворков также есть множество других полезняшек, которые могут облегчить жизнь при написании тестов:Стоит оглядываться на существущие фреймворки при написании своего велосипеда. UX — гораздо более глубокая тема.Подход, используемый фреймворком Cutter, позволяет проводить идентификацию тестовых функций с минимальной когнитивной нагрузкой на программиста: просто пиши тестовые функции и всё. В коде не требуется использовать никаких специальных шаблонов и макросов, что повышает его читабельность.Особенности сборки и запуска тестов можно спрятать в переиспользуемые модули для систем сборки вроде Makefile, CMake, и т. д. Вопросами отдельной сборки тестов всё равно придётся так или иначе задаваться.Из недостатков такого подхода можно отметить сложность размещения тестов в том же файле (той же единице трансляции), что и основной код. К сожалению, в таком случае без дополнительных подсказок уже не разобраться, какие функции запускать надо, а какие нет. К счастью, в Си++ обычно и так принято разносить тесты и реализацию в разные файлы.Что касается окончательного избавления от макросов, мне кажется, что  от них отказываться не стоит. Макросы позволяют, например, более коротко записывать утверждения сравнения, избегая дублирования кода:но при этом сохраняя ту же информативность выдачи в случае ошибок:Имя тестируемой функции, имя файла и номер строки начала функции в теории можно извлечь из отладочной информации, содержащейся в собираемой библиотеке. Ожидаемое и фактическое значение сравниваемых выражений известны функции . Макрос же позволяет «восстановить» исходное написание тестового утверждения, из которого более понятно, почему ожидается именно значение .Впрочем, это на любителя. Заканчиваются ли на этом преимущества макросов для тестового кода? Я пока особо не думал над этим моментом, который может оказаться хорошим полем для дальнейших  исследований. Гораздо более интересный вопрос: возможно ли как-то сделать  для Си++ без макросов?Внимательный читатель также заметил, что в реализации действительно отсутствуют SMS и асбест, что является несомненным плюсом для экологии и экономики Земли.", "url": "https://habr.com/ru/post/435028/"},
{"title": "История одного эксперимента с Cython и C++ vector", "article_text": "Одним  холодным зимним вечером, хотелось согреться в офисе и проверить теорию одного коллеги, что C++ vector мог бы быстрее справиться с задачей, чем CPython list.В компании мы разрабатываем продукты на базе Django и случилось так, что нужно было обработать один большой массив словарей. Коллега предположил, что реализация на C++ была бы гораздо быстрее, а меня не покидало чувство, что Гвидо и сообщество наверное немного круче нас в Си и возможно уже решили и обошли все подводные камни, реализовав всё гораздо быстрее.Для проверки теории, я решил написать небольшой тестовый файл, в котором решил прогнать в цикле вставку 1М словарей одинакового содержания в массив и в vector 100 раз подряд.Результаты хоть и были ожидаемые, но так же и внезапные.Так уж вышло, что мы активно используем Cython, поэтому в целом результаты будут отличаться на полностью CPython реализации.К слову, здесь пришлось повозиться. Чтобы получить максимально реальные числа (т.е. не просто сделать супероптимизировано, но и так, что мы потом сможем это использовать без танцев с бубном), пришлось всё делать основном скрипте, а все дополнительные  свести к минимуму.Первая проблема заключалась в том, что обёртка Cython для vector не хочет работать в таком виде:При всём при этом получали ошибку, что невозможно привести dict к PyObject. Конечно же это проблемы Cython, но так как мы его используем, нам нужно решить эту конкретную проблему.\r\nПришлось сделать маленький костылик в виде Самое удивительное, что это заработало. Больше всего меня пугает, что я до конца не понимаю почему и какие последствия влечёт.Очень хочется, чтобы можно было собирать *.whl для проекта и чтобы это всё завелось на практически любой системе, поэтому сперва был выставлен флаг оптимизации в 0. Это привело к странному результату:Немного поразмыслив, решил что мы всё равно используем флаг -O1, поэтому выставил всё же его и получил:Как-то немного взгруснулось: всё же вера в профессионализм Гвидо и Ко меня подвела. Но потом, я заметил что как-то подозрительно жрёт память скрипт и к концу он подъедал примерно 20Гб ОЗУ. Проблема была в следующем: в итоговом скрипте, можно наблюдать функцию free, после прохода цикла. На этой итерации его ещё не было. Тогда я подумал...Между попытками я сделал  и после попытки . Запускаю сборку и скрипт и получаю:В целом, разница не большая, поэтому я подумал, что нет смысла  стараться как-то извратиться и просто использовать CPython, но собирать его по прежнему Cython'ом.\r\nНаверное у многих возник вопрос: \"А что там с памятью?\" Самое удивительное (нет), что ничего. Она росла с такой же скоростью и в таком же количестве. На ум пришла , но лезть в исходники Python совсем не хотелось. Да и означало это лишь одно — проблема в реализации вектора.После долгих мучений с приведением типов, а именно, чтобы вектор принимал в себя pointer на словарь, был получен тот самый итоговый скрипт и с включённым gc я получал в среднем разницу в 2.6 раза (вектор быстрее) и относительно хорошую работу с памятью.Вдруг до меня дошло, что я собираю всё только под Py2.7 и даже не попробовал сделать что-либо с 3.6.И вот тут я реально удивился (после предыдущих результатов, удивление было закономерным):При всём при этом, gc по прежнему работал, память не отжиралась и это был один и тот же скрипт. Понимая, что через уже чуть больше года, нужно будет распрощаться с 2.7, мне всё равно не давало покоя, что между ними такая разница. Чаще всего, я слышал/читал/экспериментировал и Py3.6 был медленнее Py2.7. Однако ребята из Cython-разработчиков сделали что-то невероятное и поменяли ситуацию на корню.После этого эксперимента, мы решили сильно не заморачиваться с поддержкой Python 2.7 и переделкой каких-либо частей приложений на C++, просто потому что оно того не стоит. Всё уже написали до нас, нам остаётся это лишь правильно применить для решения конкретной задачи.UPD 24.12.2018:\r\nПо совету  и после выпадов в сторону, что проверяется непонять что и как, постарался переписать C++ часть максимально удобным для разработки в дальнейшем способом, а так же минимизировать абстракции. Получилось ещё хуже:Есть идеи, что можно было бы улучшить в копараторе, чтобы это работало быстрее?", "url": "https://habr.com/ru/post/433852/"},
{"title": "Написание системы попарно взаимодействующих частиц на C++ с использованием DirectX 11", "article_text": "На Хабре уже    про использование вычислительных шейдеров с Unity, однако статью о использовании вычислительного шейдера на \"чистом\" Win32 API + DirectX 11 найти затруднительно. Однако эта задача ненамного сложнее, подробнее — под катом.Для этого будем использовать:Объявим функцию обработки Windows-событий, которая будет определена позже:Напишем функции для создания и уничтожения окнаДалее — инициализация интерфейса обращения к видеокарте (Device и DeviceContext) и цепочки буферов вывода (SwapChain):Инициализация доступа из шейдеров к буферу, в который будет производиться отрисовка:До инициализации шейдеров нужно их создать. Visual Studio умеет распознавать расширение файла, поэтому мы можем просто создать исходник с расширением , или же напрямую создавать шейдер через меню. Я выбрал первый способ, т.к. все равно через свойства придется задавать использование Shader Model 5.Аналогично создаем вершинный и пиксельный шейдеры.В вершинном шейдере будем просто преобразовывать координаты из двумерного вектора (т.к. позиции точек у нас именно двухмерные) в четырехмерный (принимаемый видеокартой):В пиксельном шейдере будем возвращать белый цвет:Теперь вычислительный шейдер. Зададим такую формулу для взаимодействий точек:При массе, принятой 1Так будет выглядеть реализация этого на HLSL:Можно заметить, что в шейдер включается файл . Это тот заголовочный файл с константами, который включается в . Вот содержание этого файла:Просто объявление количества частиц и количества потоков в одной группе. Мы выделим по одному потоку каждой частице, поэтому количество групп зададим как . Это число должно быть целым, поэтому нужно, чтобы число частиц делилось на число потоков в группе.Загрузку скомпилированного байткода шейдеров будем производить при помощи механизма ресурсов Windows. Для этого создадим следующие файлы:, где будут содержаться ID соответствующего ресурса:И , файл для генерации соответствующего ресурса следующего содержания:Где  — тип ресурса, а ,  и  — соответствующие названия файлов Compiled Shader Object в выходной директории.Чтобы файлы были найдены, следует в свойствах  прописать путь до выходной директории проекта:Visual Studio автоматически распознала файл как описание ресурсов и добавила его в сборку, вручную это делать не нужноТеперь можно написать код инициализации шейдеров:Код инициализации буферов:И код инициализации доступа к буферам из вычислительного шейдера:Далее стоит указать драйверу использовать созданные шейдеры и связки с буферами:Для подсчета среднего времени кадра будем использовать следующий код:А на каждом кадре — вызывать такую функцию:На случай, если размер окна изменился, нам нужно также изменить размер буферов отрисовки:Наконец, можно определить функцию обработки сообщений:И функцию :Скриншот работающей программы можно увидеть в заголовке статьи.→ Проект целиком выложен на ", "url": "https://habr.com/ru/post/430202/"},
{"title": "Работа с API КОМПАС-3D → Урок 13 → Параграфы", "article_text": "Прежде чем перейти к рассмотрению документированных способов создания составных строк, нам нужно познакомиться с таким объектом, как параграф. Он представляет собой автоматически форматируемый блок текста, состоящий из нескольких строк. На данном уроке мы рассмотрим вопросы построения простых параграфов. \r\nПараграф описывается интерфейсом . Для его получения нужно использовать метод  интерфейса , для этого ему нужно передать константу  (). Рассмотрим свойства интерфейса . – угол наклона текста в градусах. Откладывается от горизонтальной линии против часовой стрелки. Аналогичен параметру  метода . – высота параграфа в миллиметрах. – форматирование текста по горизонтали. Данное свойство используется, когда текст не умещается в параграф по ширине. Допустимые значения перечислены в таблице ниже. – стиль текста (описывался на ).– форматирование текста по вертикали. Данное свойство используется, когда текст не умещается в параграф по высоте. Допустимые значения перечислены в таблице ниже.\r\nПри работе со свойством  нужно помнить два момента: – ширина параграфа в миллиметрах.\r\nСвойства , ,  и  позволяют решать задачу размещения текста в заданном прямоугольнике. Этот метод гораздо надежнее и эффективнее в отличие от метода , обсуждавшегося на . и  – координаты точки привязки. Положение параграфа относительно точки привязки вдоль горизонтальной оси настраивается методом  интерфейса  (правда, такая возможность не документирована). По вертикали точка привязки всегда совпадает с низом первой строки параграфа. Изменить это поведение нельзя.\r\nМетод у интерфейса  всего один: . Он инициализирует значения свойств интерфейса. Не имеет входных параметров. В случае успеха возвращает значение .\r\nСоздание параграфа состоит из трёх последовательных этапов.\r\nКак всегда, здесь для простоты опущен код, ответственный за создание и оформление документа (эта тема рассматривалась на прошлых уроках).\r\nВ данном примере КОМПАС сам определяет размер параграфа на основе его содержимого. На рисунке ниже показан сформированный параграф.\r\nОбратите внимание: текст выводится как одна строка. Мы не указали ширину параграфа, поэтому КОМПАС автоматически увеличивает ее по мере необходимости. Если бы ширина была задана, то поведение КОМПАС определялось бы значением свойства  интерфейса .\r\nДля формирования многострочного и составного текста нужно использовать признаки начертания, частично рассмотренные на предыдущем уроке.\r\nДля явного переноса на новую строку используется флаг  (). \r\nВ данном примере создается параграф из трёх строк. Первая строка выводится как обычно. Для второй устанавливается флаг . Он говорит о начале новой строки. Третья выводится как обычно, но для нее по-прежнему действует флаг , так как мы работаем с тем же экземпляром интерфейса . На рисунке ниже показан параграф, сформированный этой программой.\r\nТеперь строки выводятся правильно.\r\nВыравнивание текста задается методом  интерфейса . У него всего один целочисленный параметр – устанавливаемое выравнивание. Его допустимые значения перечислены в таблице ниже.\r\nВ случае успеха метод  возвращает предыдущий признак выравнивания, а в случае ошибки – число .\r\nУчтите, что метод  может использоваться только внутри блока (в нашем случае он используется внутри параграфа). Это значит, что с его помощью нельзя задавать выравнивание для текста, выводимого методом . Данное ограничение связано с тем, что в этом случае КОМПАС не знает, относительно каких границ нужно выравнивать текст.\r\nДругой важный момент связан с областью действия метода  – на какие выводимые строки он действует. Рассмотрим пример (здесь используется сильно упрощенный синтаксис по сравнению с их оригиналами):\r\nКак будут выровнены строки? Вопреки нашим ожиданиям обе строки будут выровнены по правому краю. Почему? Дело в том, что метод  в первую очередь изменяет выравнивание последней выведенной строки. Вот что происходит в нашем примере: в первой строке устанавливается выравнивание по центру. Поскольку предыдущей выводимой строки нет, данный вызов меняет выравнивание по умолчанию (по левому краю).\r\nЗатем мы выводим строку «По центру». Изначально для нее используется выравнивание по центру, установленное ранее.\r\nВ третьей строке мы вновь меняем выравнивание. В первую очередь метод изменяет выравнивание предыдущей строки («По центру»). Поэтому она выравнивается по правому краю, а не по центру, как мы планировали. Это же выравнивание становится выравниваем по умолчанию.\r\nМы выводим строку «По правому краю». Поскольку метод  больше не вызывается, то для нее используется ранее установленное выравнивание (по правому краю).\r\nТаким образом, обе строки выравниваются по правому краю. Теперь немного изменим пример:\r\nВсе что мы изменили – добавили вывод пустой строки без изменения выравнивания. Теперь строки выводятся правильно. Это происходит, потому что вывод пустой строки «поглощает» устанавливаемое выравнивание по правому краю. Второй вызов метода  влияет на пустую строку и никак не влияет на строку «По центру».\r\nПример ниже показывает правильное выравнивание без вывода пустой строки.\r\nВызовы  и  поменяны местами. Поскольку метод  в первую очередь влияет на последнюю выведенную строку, то выравнивания устанавливаются правильно, и строки выводятся так, как мы того и хотели.\r\nВ данном примере помимо выравнивания текста также демонстрируется использование свойств  и  интерфейса . Они используются для ограничения его ширины. Если бы мы их не изменили, КОМПАС увеличил бы ширину параграфа, и мы не увидели бы выравнивания по левому краю и по ширине.\r\nПустые строки выводятся для улучшения читаемости параграфа. Они никак не влияют на правильность выравнивания.\r\nНа рисунке ниже показан параграф, сформированный данной программой.\r\nНа  мы рассматривали флаги, управляющие начертанием (, , ,  и ). Тогда мы рассматривали их применительно к методу . Важное отличие их применения в параграфе заключается в том, что действие не ограничивается вызовом метода , а простирается на весь параграф. Рассмотрим несколько примеров.\r\nПервая строка будет выведена полужирным шрифтом. С этим вопросов не возникает. Но как будет выведена вторая строка? Для нее флаг  сброшен. Поэтому можно предположить, что она будет выведена обычным шрифтом. Но это не так. Встретив флаг , КОМПАС понимает команду так: все последующие строки данного параграфа выводятся полужирным шрифтом. Поэтому все последующие строки выводятся полужирным шрифтом до тех пор, пока параграф не будет завершен или КОМПАС не встретит парный ему флаг . Рассмотрим пример:\r\nПервая строка выводится полужирным шрифтом. Для второй строки мы сбрасываем флаг  и взводим парный ему флаг , который отменяет полужирное начертание. Благодаря этому вторая и третья строки выводятся без полужирного начертания.\r\nТакое поведение распространяется на флаги , ,  и , но не распространяется на флаг , так как для него нет парного отменяющего флага.\r\nСамая важная часть данной программы – правильная установка флагов для выводимых строк. Разберем ее более подробно (соответствующие строки программы помечены парой символов «»).\r\nПервая строка выводится без каких-либо изменений. Поэтому для нее не устанавливаются никакие флаги.\r\nВторая строка должна выводиться без наклона и с новой строчки. Поэтому для нее устанавливаются флаги:  (начинать с новой строки) и  (отключить курсивное начертание).\r\nТретья строка должна выводиться курсивом и полужирным шрифтом. Для этого мы взводим флаги: ,  (включаем курсив) и  (включаем полужирное начертание). Все остальные флаги сбрасываем.\r\nЧетвертая строка должна быть выведена курсивом, подчеркнутым и не полужирным начертанием. Для этого мы взводим флаги: ,  (отключить полужирное начертание, оставшееся включенным от предыдущей строки) и  (включить подчеркнутое начертание).\r\nЕсли бы в параграфе были еще строки, то они выводились бы курсивным подчеркнутым шрифтом. Для отключения подчеркнутого начертания нужно сбросить флаг UNDERLINE_ON и взвести флаг .\r\nНа рисунке ниже показан результат работы этой программы.\r\nЕсли вы следите за структурой своих программ, то наверняка заметили серьезный недостаток предыдущего примера: код, ответственный за формирование выводимой информации, перемешан с кодом, отвечающим за реализацию ее вывода. При хорошем стиле программирования принято отделять информацию от ее представления.\r\nЕсли выводимая информация состоит из нескольких строк , то их можно объединить в один интерфейс . Метод  умеет обрабатывать оба этих интерфейса. Но у такого подхода есть неприятное ограничение: если метод  принимает интерфейс , то флаги  (и ) игнорируются. То есть вся информация будет выведена в одну строку, даже если для некоторых экземпляров  взведен флаг . Для обхода этого ограничения придется вручную вызывать  для каждой строки. \r\nВ этом примере выводимые строки сначала заносятся в динамический массив , а уже потом выводятся в параграф. Это позволяет отделить информацию от ее представления. Если бы в нашем примере не использовался флаг , то мы могли бы обойтись одним вызовом метода .\r\nРезультат работы этой программы аналогичен результату работы предыдущего примера.\r\nНа данном уроке мы рассмотрели, как строить параграф и как с помощью него выводить многострочный текст. Также мы научились отделять информацию от ее представления. К сожалению, корректный вывод многострочного текста требует ручного обхода массива строк. Это не очень удобно. На следующем уроке я покажу, как решить эту проблему. Сергей Норсеев, к.т.н., автор книги «Разработка приложений под КОМПАС в Delphi».", "url": "https://habr.com/ru/company/ascon/blog/434336/"},
{"title": "Операционная система Haiku: портирование приложений и создание пакетов", "article_text": "Осенью этого года, спустя 6 лет разработки, вышла первая бета-версия «R1/beta1» операционной системы . Я давно слежу за этим интересным проектом, который нацелен на воссоздание и последующее развитие существовавшей в 1994-2000 годах системы . Поэтому, как только на новостных IT-сайтах я увидел новость о выходе бета-версии Haiku, я незамедлительно решил посмотреть, что же было добавлено в этот долгожданный релиз. После установки системы в виртуальную машину  и небольшого ознакомления с её основной функциональностью, я подумал, что было бы неплохо немного помочь OpenSource-сообществу, которое сегодня развивает эту операционную систему. Начать я решил с того, в чём у меня накопился небольшой опыт: с портирования некоторых игровых проектов.\r\nПозже я попытался доработать некоторые уже существующие приложения и библиотеки. Именно этой моей небольшой деятельности в различных репозиториях с открытым исходным кодом и будет посвящена эта статья. В ней я последовательно опишу те проблемы, с которыми столкнулся и расскажу про методы их решения. Большинство патчей, которые были сделаны в процессе этой работы, я попытался отправить в  существующих проектов, дабы обеспечить в них поддержку Haiku и заинтересовать их разработчиков существованием альтернативных операционных систем.\r\nОперационная система Haiku использует , которое представляет собой реализацию микроядерной архитектуры с возможностью динамической подгрузки необходимых модулей. Оно базируется на форке ядра , которое было разработано бывшим инженером , Travis'ом Geiselbrecht'ом. Сегодня этот разработчик работает в Google над ядром, которое называется , для новой операционной системы , но это уже другая история. Итак, поскольку разработчики Haiku декларируют бинарную совместимость с BeOS, то они вынуждены поддерживать не две привычных всем архитектурных ветки, а три: x86_64, x86 и x86_gcc2. Последняя архитектура представляет собой груз совместимости с компилятором старой версии  2.95. Именно благодаря ей имеется возможность запуска приложений, написанных для оригинальной операционной системы BeOS. К сожалению, из-за этого груза совместимости, разработчики Haiku не могут использовать современные возможности языка программирования C++ в системных API. Тем не менее, установочные образы они подготавливают только для двух архитектур: x86_64 и x86. Всё дело в том, что дистрибутив Haiku для x86 является гибридным: несмотря на то, что все системные компоненты собраны под x86_gcc2 для обеспечения бинарной совместимости, пользователю предоставляется возможность установки или сборки любых современных приложений, которые были сделаны с расчётом на современные компиляторы и архитектуру x86. Дистрибутив Haiku для архитектуры x86_64 является полностью 64-битным и не имеет возможности запуска 32-битных приложений BeOS и Haiku. Однако, совместимость на уровне API имеется, поэтому если у вас есть на руках исходный код приложения под BeOS или Haiku x86, вы без проблем сможете скомпилировать его под Haiku x86_64 и всё должно работать. Образ операционной системы под архитектуру x86_64 рекомендуется для установки на реальное железо, если вам не требуется поддержка каких-либо специфичных приложений BeOS или 32-битных приложений Haiku.\r\nСтоит сказать, что в этой операционной системе имеется частичная поддержка стандарта . Этот фундамент делает её родственной UNIX-like системам и позволяет легко переносить их программное обеспечение. Основным языком программирования является C++, он активно используется, поскольку публичные API у Haiku в основном преследуют объектно-ориентированную парадигму программирования. Тем не менее, никто не запрещает использовать и язык программирования C, только для большинства случаев придётся писать соответствующие прослойки совместимости. Программный интерфейс операционной системы сгруппирован в отдельные системные фреймворки, которые отвечают за ту или иную возможность, например, за интерфейс или поддержку сети. Это немного похоже на то, что имеется в  или во фреймворке . Обязательно нужно отметить, что эта операционная система является однопользовательской, хотя некоторые подвижки в сторону обеспечения многопользовательского режима работы у разработчиков Haiku имеются.\r\nНе могу не поделиться с читателями этой статьи положительным опытом использования продвинутой системы управления окнами приложений, которая имеется в Haiku. На мой взгляд она одна из самых удобных и в своём роде является визитной карточкой этой OS.\r\nОкошки можно скреплять между собой во вкладки, как это сделано в современных браузерах, прикреплять их друг к другу и удобно изменять их размер. Поддерживается простенький , перенос контекстов некоторых приложений из одного окна в другое и . Более подробно обо всех возможностях местной оконной системы можно прочитать в , там же описаны все необходимые сочетания клавиш быстрого доступа.\r\nЯ не буду писать в этой статье полный обзор всех особенностей и возможностей Haiku, так как те, кому это интересно, легко смогут самостоятельно найти нужную информацию в интернете.\r\nПо сравнению с оригинальной BeOS, в Haiku появилось значимое нововведение: система управления пакетами, которая включает в себя различные инструменты для получения и установки программного обеспечения из различных источников. Такими источниками могут служить официальные репозитории  и , неофициальные репозитории и просто отдельные и специально подготовленные HPKG-пакеты. Подобные возможности по установке и обновлению ПО давно известны в мире Unix-like операционных систем, теперь же вся их мощь и удобство успешно добрались и до Haiku, что не может не радовать рядовых пользователей этой операционной системы. Благодаря выстроенной вокруг пакетного менеджера инфраструктуры, теперь любой разработчик может легко портировать новое или доработать уже существующее приложение с открытым исходным кодом, затем добавить результаты своего труда в репозиторий портов программного обеспечения HaikuPorts, после чего они станут доступны всем пользователям Haiku. В итоге получившаяся экосистема напоминает таковую у операционных систем macOS с их , FreeBSD с их , Windows с  или Arch Linux c его 'ом.\r\nИнструмент для сборки пакетов и портирования программного обеспечения, называемый , поставляется отдельно от операционной системы и устанавливается по небольшому , расположенному в репозитории на GitHub. После установки этой утилиты с того же GitHub'а скачивается всё дерево рецептов, над которым и работает разработчик. Рецепт представляет собой обычный Shell-скрипт с инструкциями, по которым HaikuPorter и будет собирать требуемый HPKG-пакет. Примечательно, что сам инструмент написан на языке программирования  2, тесно взаимодействует со существующей системой управления пакетами, а для фиксации изменений исходного кода ПО и генерации набора патчей, внутри себя использует стандартный инструмент — . Именно благодаря подобному стеку технологий делать рецепты для сборки HPKG-пакетов и наборы патчей к ПО в виде patchset-файлов очень удобно и просто. В большинстве случаев мне пришлось использовать всего три команды при работе с HaikuPorter'ом:\r\nПервая команда просто собирает выбранный пакет, вторая команда очищает директорию сборки, а третья создаёт или обновляет набор патчей в соответствии с вашими изменениями, которые были зафиксированы в Git-репозитории рабочей директории посредством коммитов.\r\nТаким образом, чтобы опубликовать какой-либо пакет в репозиторий HaikuPorts и сделать его доступным для всех пользователей Haiku, разработчик должен установить у себя HaikuPorter, развернуть дерево рецептов, локально собрать HPKG-пакет и протестировать его, затем сделать коммит в свой форк дерева рецептов, после чего оформить  на GitHub'е. Опубликованную работу должны рассмотреть разработчики Haiku, после чего они принимают решение влить ваши изменения в репозиторий или же отправить их на доработку. Если изменения приняты, то такой же HaikuPorter, установленный на сборочном сервере, удалённо соберёт пакет и автоматически опубликует его в репозиторий.\r\nВ бета-версию «R1/beta1» операционной системы Haiku была добавлена специальная программа , которая позволяет работать с пакетами и репозиториями через графический интерфейс пользователя, а не через консольные команды в терминале.\r\nБлагодаря этому инструменту неискушённые и начинающие пользователи Haiku могут удобно управлять своей пакетной базой. Стоит отметить, что это приложение не просто является GUI-оболочкой над существующим пакетным менеджером, но и реализует дополнительную функциональность. Например, авторизированные пользователи могут выставлять оценки и писать отзывы к доступным для установки пакетам. Кроме того, у HaikuDepot имеется специальный сайт , позволяющий просматривать изменения пакетной базы в интернете или скачивать отдельные HPKG-пакеты.\r\nПосле того, как я ознакомился с функциональностью операционной системы в виртуальной машине VirtualBox, я решил оценить работу библиотеки SDL2 в ней и портировать на Haiku игру , о переносе которой на платформу Android я писал ранее. Сборка программы не потребовала каких-либо изменений исходного кода, я просто установил из репозитория все нужные инструменты, библиотеки, их заголовочные файлы и выполнил следующее:\r\nПоскольку в Haiku имеется POSIX, то дефайны  или  разрешают многие проблемы, связанные с определением платформы. Однако, стоит заметить, что лучше всего отказаться от их использования и реализовывать поддержку Haiku в исходном коде проекта, если существуют подобные проблемы со сборкой. Вызов системной утилиты  с определённым аргументом позволяет получить корректный путь к заголовочным файлам для различных архитектур.\r\nИтак, выполнив команды выше, я скомпилировал исполняемый файл, который прекрасно запускался, а игра отлично работала. Я подумал, что было бы классно подготовить самодостаточный HPKG-пакет с игрой и для этого углубился в интернет на поиски необходимой мне информации. Тогда я не знал ни о каких удобных инструментах для портирования программного обеспечения, вроде HaikuPorter'а, о котором я написал в разделе выше, поэтому для осуществления своей цели я решил схитрить и разобрать какой-нибудь системный пакет, чтобы посмотреть как он устроен внутри и сделать по аналогии.\r\nНа просторах интернета я нашёл желаемую , после чего распаковал случайный системный пакет с помощью встроенного в местный файловый менеджер архиватора , нашёл файл , отредактировал его и, в соответствии со структурой своего приложения, подменил файлы. Затем я просто выполнил команды для сборки HPKG-пакета и его установки в систему:\r\nК сожалению, запуск игры из меню «Applications» не увенчался успехом. Запустив исполняемый файл в терминале, я получил ошибку, говорившую о невозможности найти файлы данных, которые были необходимы для запуска и работы приложения. При этом, если в терминале перейти в директорию пакета приложения, то всё запускалось нормально. Это натолкнуло меня на мысль о том, что при запуске игры из меню нужно делать принудительное изменение директории приложения. Подобное можно сделать либо Shell-скриптом, либо изменением исходников игры. Я выбрал второй вариант и добавил нечто похожее на этот код:\r\nВ самое начало стартовой функции , что полностью решило данную проблему и пакет получился работоспособным. В комментариях к новости про релиз бета-версии Haiku на сайте  я скинул ссылку на мой собранный пакет и попросил кого-нибудь направить меня в какие-нибудь активные сообщества пользователей этой операционной системы, после чего лёг спать.\r\nНа утро мне на e-mail написал человек, использующий ник . Как позже оказалось, за этим именем скрывался  — один из активных разработчиков Haiku и автор порта фреймворка Qt для этой операционной системы. Он показал мне репозиторий HaikuPorts и рассказал как пользоваться утилитой HaikuPorter. Кроме того, он написал рецепт для сборки HPKG-пакета игры Adamant Armor Affection Adventure и добавил её в HaikuDepot.\r\nПроанализировав все изменения, внесённые этим разработчиком, я заметил, что в моём собранном вручную пакете были некоторые недостатки, например, не сохранялись настройки, поскольку подмонтированные директории установленных пакетов не имели возможности записи. Эта проблема с записью настроек или сохранений в его пакете изящно решалась с помощью симлинков в специальную директорию, доступную для записи и предназначенную для сохранения пользовательских данных. Ещё у моего пакета не было собственной оригинальной иконки.\r\nКроме того, я узнал, что в Haiku нет аппаратного ускорения 3D-графики и тот же OpenGL отрисовывается программно с помощью мощностей CPU. Для тяжёлых графических приложений это, конечно, никуда не годится, но для старых игр этого более чем достаточно. Я даже решил специально проверить пакет игры и установил Haiku на свой старый ноутбук, то есть на реальное железо. На моё удивление, картинка Adamant Armor Affection Adventure рендерилась настолько быстро, что если бы мне не сказали про отсутствие аппаратного ускорения, я бы и не заметил того, что рендеринг осуществляется моим процессором.\r\nРучное создание HPKG-пакетов я отложил до лучших времён и полностью перешёл на использование инструмента HaikuPorter и написание рецептов. Но иногда бывают ситуации, когда требуется ручная пересборка пакета. Например, если HaikuPorter выставил в файле  слишком высокую «ночную» версию Haiku, а пакет нужно протестировать на релизной версии операционной системы. Стоит отметить, что именно благодаря отзывчивости и опыту Герасима я смог разобраться во многих тонкостях создания пакетов для операционной системы Haiku и продолжил свою работу далее.\r\nЯ был несказанно удивлён, обнаружив в репозитории HaikuPorts рецепт, который ссылался на мой форк движка , который я очень давно разбирал в своём блоге. Рецепт и патчи подготовил разработчик по имени , использующий ник  и являющийся активным мейнтейнером множества пакетов для Haiku.\r\nПоверхностный анализ, установка пакета и запуск приложения выявил те же проблемы, которые я описывал в предыдущем разделе этой статьи: сохранения игры не работали, настройки тоже не сохранялись, кроме того у пакета не было оригинальной иконки. Я решил исправить эти недочёты и начал работать над патчем, сперва интегрировав все наработки extrowerk'а. Я написал оригинальный  для операционной системы Haiku и поправил запись и сохранение различных пользовательских данных.\r\nПоскольку игра предполагала русскую и английскую версии с разным набором исполняемых файлов и файлов данных, мной было решено сделать общий пакет, объединяющий сразу две версии и автоматически выбирающий нужную на основе выбранного пользователем системного языка. Это было реализовано простейшим Shell-скриптом:\r\nЭтот скрипт запускается при выборе пункта игры в меню «Applications» и определяет текущую системную локаль. В том случае, если пользователь выбрал русский язык в качестве системного, запустится русская версия игры, а во всех остальных случаях — английская.\r\nА вот с созданием оригинальной иконки для приложения пришлось изрядно повозиться. Дело в том, что в операционной системе Haiku разрешены только векторные иконки специального формата , которые устанавливаются в качестве атрибутов файловой системы . В официальной документации существует два больших мануала, посвящённых созданию собственных иконок для приложений:  описывает стилистику рисовки и дизайн, а  подробно рассказывает как пользоваться системной программой , предназначенной для создания иконок.\r\nIcon-O-Matic позволяет импортировать простейшие SVG-файлы и экспортировать получившуюся иконку в необходимый для HaikuPorter'а формат, называемый HVIF RDef и представляющий собой тот же HVIF, но преобразованный в текстовый вид. RDef-файлы могут содержать не только изображения, но и дополнительную информацию, например, версию приложения и его описание. Чем-то эти файлы напоминают RES-файлы, используемые в Windows. Следующие команды в рецепте компилируют RDef-файлы и устанавливают получившийся результат в специальные атрибуты:\r\nКроме того, в рецептах определена функция , позволяющая автоматизировать эту работу. Проблема с программой Icon-O-Matic имеется одна, но очень серьёзная: те SVG-файлы, которые сохраняет популярный векторный редактор , либо не открываются, либо импортируются без поддержки некоторых необходимых возможностей, например, градиентов. Поэтому приключенческий квест с конвертированием растровых изображений в векторные через использование различных платных и бесплатных online- и offline-конверторов, а потом открытием получившихся SVG-файлов в программе Icon-O-Matic, я с треском провалил. Позже я решил проблему открытия SVG-файлов и нашёл обходной путь, но об этом я напишу ниже. А пока я решил воспользоваться стандартными возможностями программы Icon-O-Matic и нарисовать иконку самостоятельно. Спустя полчаса работы по усердному копированию пикселей у меня получилось следующее художество:\r\nДа, я использовал векторный редактор для создания изображения в жанре Pixel Art. На мой дилетантский взгляд человека, который слабо разбирается в искусстве, получилось вполне неплохо. Я сохранил эту иконку в нужном формате, подготовил все изменения, обновил рецепт и отправил всё в репозиторий HaikuPorts.\r\nПолучившиеся пакеты я отправил на всякий случай и на фанатский сайт игры , администрация которого добавила операционную систему Haiku в раздел загрузок.\r\nСледующим проектом, который я решил перенести на Haiku, стала игра , которую ранее я уже переносил на Android. В репозитории HaikuPorts был рецепт для недоделанной свободной реализации игры под названием , поэтому я решил добавить туда ещё и оригинальную игру, но без файлов данных, так как они, в отличие от движка, поставляются отдельно и вовсе не бесплатны.\r\nНикаких особых проблем с портированием этой игры у меня не возникло. Исполняемый файл собрался сразу же после выполнения следующих команд сборки:\r\nДалее я реализовал возможность запуска игры из меню «Applications» и обеспечил поддержку сохранения пользовательских данных в доступную для записи и предназначенную для этого директорию:\r\nФункция  с помощью функции  из Haiku API формирует полный путь до необходимой мне директории.\r\nОставалось решить следующий вопрос: каким образом пользователь должен выбирать директорию с оригинальными файлами игры Gish? Проблему можно было попытаться решить с помощью Shell-скриптов и системной утилиты , но я решил подойти к этой проблеме более основательно и реализовать удобный GUI-лаунчер, используя Haiku API и фреймворк .\r\nМой проект BeGameLauncher было решено писать на языке C++ старого стандарта 1998 года, используя родные средства операционной системы для создания приложений с графическим интерфейсом пользователя. Так как названия многих программ для Haiku и BeOS начинаются с перефикса «Be», мной было тоже решено выбрать именно такое название для проекта. Начать я решил с ознакомления с фреймворком Interface Kit, который входит в состав Haiku API. Кроме достаточно подробной документации на официальном сайте Haiku, я нашёл два просто отличных курса уроков от , которые позволяют быстро понять начинающему разработчику как работают те или иные системные классы. Первый курс называется  и в самом начале затрагивает основы языка программирования C++, что будет очень полезно начинающим программистам. Второй курс называется  и предназначен для тех, кто уже знаком с C++ и имеет базовые знания этого языка. Оба курса рассказывают о самых различных аспектах Haiku API и поэтому будут очень полезны любому человеку, который хочет начать создавать приложения для этой операционной системы.\r\nПрочитав по диагонали этот отличный материал, я составил общее впечатление о Haiku API и начал обдумывать свои дальнейшие действия. У меня уже имелся небольшой опыт разработки прикладных приложений с использованием фреймворка Qt, который тоже написан на языке программирования C++ и использует объектно-ориентированную парадигму построения программ. Так вот, Haiku API очень сильно на него похож, за исключением отсутствия системы сигналов и слотов, поэтому я буду часто проводить некоторые параллели и сравнения с Qt. Кроме того, стоит отметить распространённое в Haiku API использование принципа , который позволяет взаимодействовать различным сущностям между собой посредством передачи событий или сообщений. Аналогом класса  здесь является класс , вокруг которого и построена система взаимодействия объектов. Экземпляр класса  в общем случае получает уникальное число, которое позволяет идентифицировать отправителя и его действие в общем фильтре событий.\r\nДля моего проекта нужно было выбрать подходящие классы Haiku API, которые позволяли бы реализовать задуманную функциональность. Во-первых, для запуска внешнего приложения, нужно было найти аналог класса  или POSIX-функции , которая, к слову, тоже отлично работает в операционной системе Haiku, однако я решил, что использовать родные средства будет предпочтительнее, но на всякий случай оставил возможность запуска приложений и через POSIX-функцию. Класс , занимающийся межпроцессным взаимодействием, отлично подходил для этой цели. В нём нашёлся подходящий метод , позволяющий задать путь до исполняемого файла и передать ему аргументы. Поскольку лаунчер должен иметь возможность сохранения некоторых параметров, например, выбранной пользователем директории с файлами данных игры, мне нужен был класс, который занимается всем этим. В Qt такой класс имеет название , а в Haiku API, как мне подсказал Герасим, имеется уже знакомый мне класс , который имеет очень полезную особенность. Всё дело в том, что информацию этого класса можно легко сериализовать и, например, сохранить на диск. Это очень удобно и часто используется для записи каких-либо пользовательских данных в программах, поэтому именно этот класс я и выбрал для сохранения настроек в своём проекте реализации лаунчеров. К сожалению, в Haiku API не нашлось аналога класса , поэтому требуемый мне отладочный вывод в процессе разработки я просто отправлял в , средствами функции  из стандартного языка программирования C:\r\nЭту функцию я обернул в удобную мне сущность , которая в зависимости от выбранного стандарта языка является либо макросом, либо тоже функцией. Так было сделано из-за того, что C++98 не поддерживает макросы с переменным количеством аргументов.\r\nЕщё во фреймворке Qt имеется полезный класс , через который можно создать модальный диалог с какой-либо информацией, на которую должен обратить внимание пользователь, например, на ошибку или предупреждение. В Haiku API для этих целей имеется класс , реализация которого несколько отличается от того, что доступно в Qt. Например, объект этого класса обязательно должен быть создан в куче, а не на стеке, поскольку после какого-либо действия пользователя он должен удалить сам себя. Что же касается других классов графического интерфейса, то здесь у меня не возникло абсолютно никаких трудностей и всё необходимое я нашёл без каких-либо проблем.\r\nТеперь мне следовало подумать о простенькой архитектуре проекта. Я решил остановиться на создании статической библиотеки, в которой бы имелось два класса, предназначенных для унаследования от них собственных производных классов. Первый и самый важный класс, , отвечает за создание главного окна лаунчера, передачу всех пользовательских параметров и предоставляет возможность добавления собственных GUI-элементов. Второй класс, , просто отвечает за открытие диалога «О программе...» с информацией, которая показывается в отдельном окне. Таким образом, программисту для создания своего лаунчера, например, для игры Gish, требуется сделать два простых действия:\r\nВо-первых, создать подходящую стартовую функцию , а во-вторых просто унаследоваться от двух вышеперечисленных классов и реализовать в них необходимые методы. После этого компилируем полученный C++-файл с линковкой к моей статической библиотеке и наш лаунчер для игры Gish готов.\r\nДалее я задумался о том, каким образом мне передавать из своего лаунчера параметры в сам движок или в исполняемый файл игры. Я увидел только два пути решения этой проблемы. Первый путь заключался в изменении переменных окружения. На практике лаунчер после нажатия на кнопку «Run» просто помещает все параметры в переменные окружения посредством вызовов функции , а движок игры потом читает эти параметры с помощью функции , что выглядит достаточно просто. Единственная проблема, которая могла здесь возникнуть, находилась в классе  и его методе : я не знал, унаследует ли запускаемое с помощью этого класса приложение все те переменные окружения, которые были выставлены в лаунчере. После небольшого эксперимента наследование переменных окружения подтвердилось и этот способ я полностью реализовал в своём проекте. Второй путь решения проблемы заключался в задании специальных параметров командной строки. На практике лаунчер просто складывал все настройки в соответствующие аргументы и вызывал с ними исполняемый файл приложения. А вот движок игры уже должен был самостоятельно их обработать, что создавало некоторые сложности. Например, если игра не предполагала возможность задания пути до игровых файлов через параметры командной строки, то нужно было модифицировать парсер аргументов в самом движке. Несмотря на эти проблемы, я реализовал и этот способ взаимодействия и в итоге получил отличную возможность совмещать всё вместе. Это позволило мне создавать в некоторых лаунчерах строку задания пользовательских аргументов.\r\nКогда всё было спроектировано, я решил выбрать сборочную систему для своего проекта. Рассматривалось только два варианта: Makefile «на стероидах» и . В первом случае, разработчики операционной системы Haiku подготовили удобный пакет , в котором собрали все необходимые возможности, с которыми столкнулся бы разработчик, начав писать приложение на Haiku API, например, автоматическую генерацию переводов и компиляцию ресурсов приложения. Но я не из тех, кто ищет лёгкие пути, поэтому я выбрал CMake и перенёс в него некоторые наработки из пакета makefile-engine. В итоге получившийся монструозный сборочный скрипт вы можете посмотреть в репозитории проекта, ссылку на который я оставлю ниже.\r\nХотелось бы написать пару слов о локализации приложений. Во фреймворке Qt для этого имеется удобная функция-обёртка , две вспомогательные утилиты  и , которые занимаются генерацией файлов перевода. В комплекте с фреймворком доступна даже специальная программа  с удобным графическим интерфейсом пользователя, предназначенная для переводчиков. В Haiku API инструменты для локализации приложений менее удобные и более архаичные. Строки, которые нужно перевести, предлагается оборачивать в специальный макрос , а в исходный файл добавлять определение , которое отделяет одну группу переводимых строк от другой. После этого требуется выполнить очень странную вещь: натравить препроцессор компилятора с флагом  на абсолютно все исходные файлы проекта, сделать какую-то магию с помощью утилиты  и в итоге получить PRE-файл громадного размера. Именно с этим файлом и будет работать утилита , которая уже создаст человекочитаемые и удобные для редактирования переводчику CATKEYS-файлы. После локализации строк необходимо воспользоваться утилитой , которая добавляет переводы в ресурсы исполняемого файла. Таким образом, при выборе определённого системного языка приложение отображает переведённые строки. Странно, но в документации Haiku API о локализации приложений содержится очень мало информации. Однако, на официальном сайте я нашёл отличную статью , в которой подробно рассмотрены многие аспекты переводов приложений для этой операционной системы. Как я понял, в оригинальном BeOS не было фреймворка  и он был добавлен уже только в Haiku.\r\nСледующим моим шагом стал выбор среды для разработки приложений на языке программирования C++. Благодаря тому, что на Haiku был портирован фреймворк Qt, в репозитории HaikuPorts доступны такие IDE, как  и . Кроме того, имеется порт , что позволяет использовать IDE, написанные на языке программирования Java, например,  или . Я остановил свой выбор на среде разработки Qt Creator, тем более в её последних версиях имеется качественный разбор кода с помощью парсера , который работает на порядок точнее и быстрее стандартного парсера.\r\nВ плане общеизвестных и кроссплатформенных IDE в Haiku всё хорошо. Но что насчёт эксклюзивных решений? Я не могу не упомянуть очень интересный проект, автором которого является  и который в настоящее время поддерживает , он называется . Эта программа превращает доступный в дистрибутиве операционной системы продвинутый текстовый редактор  практически в настоящую IDE.\r\nС помощью встроенного в оконную систему Haiku тайлинга можно прикрепить окно Paladin сбоку редактора Pe и добавить терминал. Ещё в репозитории HaikuPorts имеется удобный редактор текста , напоминающий собой популярную программу  для Windows и так же базирующийся на наработках проекта . Для своего приложения я создал проектный PLD-файл и теперь любой разработчик, который пользуется Paladin IDE, может без проблем открыть в этой программе мой проект.\r\nКогда среда разработки Qt Creator была настроена и готова к работе, я начал реализовывать все задуманные возможности. Первая проблема, с которой я столкнулся, была связана с масштабированием контролов при изменении размера системного шрифта. Изначально в BeOS весь код размещения GUI-элементов задавался явно в координатах. Это было очень неудобно, многословно и создавало огромный ворох проблем, например, при том же изменении размера шрифта вся форма приложения разъезжалась и становилась непригодной к использованию. К счастью, в Haiku попытались решить эту проблему и добавили программный интерфейс , который является частью фреймворка Interface Kit.\r\nЭто нововведение полностью решало мою проблему с позиционированием контролов и я переписал приложение с использованием Layout API, что серьёзно сократило длину кода в некоторых местах. На официальном сайте Haiku я нашёл цикл интересных статей , в которых как раз рассказываются причины того, почему был создан этот программный интерфейс и показаны примеры его использования.\r\nЕщё одну проблему обозначил Герасим, когда попробовал воспользоваться моей библиотекой для создания лаунчера к игре, которую он портировал. Дело было в том, что я часто обращался к исходному коду самой операционной системы Haiku для реализации различной функциональности. В частности, пример использования метода  у объекта класса  я обнаружил именно там. Проблема проявлялась в том, что этот пример оказался некорректным и движок игры, которую портировал Герасим, не мог правильно распарсить заданные лаунчером аргументы. Глубже изучив исходный код Haiku мне удалось выяснить, что первый аргумент, который должен содержать полный путь до исполняемого файла, в случае с методом  не требуется задавать явно, так как он будет задан автоматически.\r\nВ документации на метод  ничего не сказано про то, что первый аргумент задавать не требуется, наверное именно поэтому разработчик написал этот код некорректно. Я исправил эту ошибку в своём проекте и проблема Герасима разрешилась сама собой. Но что насчёт этой небольшой ошибки в самой операционной системе Haiku? Я решил исправить и её. К счастью, это оказалось сделать ну очень просто! Нужно авторизоваться с помощью GitHub на Gerrit-ресурсе , добавить свой публичный SSH-ключ, форкнуть исходный код Haiku, создать коммит с исправлением и отправить получившийся патч на  привилегированным разработчикам:\r\nЕсли нужно обновить уже отправленные патчи, то перед отправкой изменённых или новых коммитов обязательно добавляем в конец commit-сообщения тот ID, который выдал нам сервис Haiku Code Review. После того, как патч отправлен, разработчики Haiku должны его подтвердить, отклонить или отправить на доработку. В моём случае исправление было принято сразу и этот небольшой недочёт теперь устранён везде. Если вам требуется протестировать ваши патчи перед отправкой в репозиторий, то вы можете попробовать с помощью утилиты , которая является форком сборочной системы  и используется для сборки всей кодовой базы операционной системы Haiku, скомпилировать отдельное приложение. В репозитории исходного кода имеется файл , который поможет вам разобраться со всеми премудростями компиляции.\r\nДорабатывая свой проект, я нашёл причину по которой программа Icon-O-Matic не открывает SVG-файлы, созданные с помощью векторного редактора Inkscape. Всё дело в том, что Icon-O-Matic не умеет обрабатывать атрибут , однако, если найти простой SVG-файл без этого атрибута, отредактировать его с помощью Inkscape и сохранить как , то он откроется и в программе Icon-O-Matic. Поэтому я положил в свой репозиторий такой специально подготовленный SVG-файл, который можно редактировать и который будет открываться в Icon-O-Matic без проблем. Дополнительно я добавил в ReadMe-файл проекта небольшую инструкцию о том, как создавать иконки для своих лаунчеров с помощью Inkscape.\r\nКод своего проекта я решил проверить самыми различными статическими анализаторами, но никаких серьёзных проблем они не нашли. А я вот позже нашёл одну проблему, которую не смогли обнаружить они. Дело в том, что статический метод  класса  мог вернуть NULL:\r\nИ в методе  я по невнимательности забыл проверить поле класса  на валидность. Поэтому приложение ожидаемо падало, если не находило определённую картинку, а по плану должно было нарисовать красный квадрат вместо этого. Эту историю я рассказал к тому, что статические анализаторы далеко не панацея и внимательность при работе с кодом на языке программирования C++ требуется в любом случае.\r\nИсходный код проекта BeGameLauncher и все свои наработки я выкладываю в репозиторий на GitHub. Надеюсь, эта программа окажется кому-нибудь полезной и может быть станет неким учебным пособием в качестве простого приложения для Haiku:\r\nНебольшой совет для тех, кто будет использовать мой лаунчер в своих рецептах для репозитория HaikuPorts. Если вы хотите скрыть исполняемый файл игры из списка приложений Haiku, которые читают некоторые программы, и оставить там только лаунчер, вы можете воспользоваться следующим трюком:\r\nЭто позволит исключить возможность запуска исполняемых файлов без переданных лаунчером параметров из различных программ вроде , которые занимаются быстрым запуском приложений. При этом ваша оригинальная иконка на исполняемом файле будет сохранена.\r\nПроект  представляет собой свободную реализацию движка GoldSrc, который используется в игре  и в её официальных дополнениях. За разработкой Xash3D стоит отечественный программист , который до сих пор координирует его развитие и улучшение. Чуть позже к проекту присоединились другие разработчики, которые сделали форк , с поддержкой огромного количества операционных систем, отличных от Windows. Сегодня ключевыми программистами проекта FWGS Xash3D являются  и  (), последний человек был активным участником некогда популярного форума , который я до сих пор администрирую в своё свободное время.\r\nЯ задался вопросом: почему бы не портировать этот движок на Haiku, добавив в проект Xash3D поддержку такой интересной операционной системы, а пользователям Haiku дать возможность поиграть в легендарный Half-Life, игру всех времён и народов? Дело оставалось за малым — требовалось незамедлительно начать работу по портированию и в случае успеха опубликовать результаты этой работы.\r\nПотратив несколько часов на изучение структуры проекта и тех частей кода, которые отвечают за поддержку различных платформ, я начал вносить изменения в движок Xash3D, чтобы обеспечить возможность поддержки операционной системы Haiku. По-старинке, я задефайнил компилятору  и попытался собрать исполняемый файл и кучу библиотек. На удивление дело пошло достаточно быстро и уже к вечеру, пробросив файлы данных для игры, у меня получилось запустить Half-Life и доехать на поезде до начальной станции в Black Mesa.\r\nБлагодаря тому, что проект использует кроссплатформенную библиотеку SDL2, портирование движка очень сильно упрощается, так как не нужно писать каких-либо кусков кода, которые зависят от платформы, например: вывод звука, создание окна с OpenGL-контекстом, или обработку событий ввода. Всё это уже реализовано в библиотеке SDL2 и готово к использованию. Небольшая проблема возникла с поддержкой сети, потому что в Haiku имеется отдельная библиотека, реализующая сетевой стек, соответственно, её требовалось прилинковать к движку.\r\nПроект по созданию лаунчеров, про который я написал чуть выше, мне очень сильно пригодился. С помощью наследования C++-классов я серьёзно расширил его функциональность и реализовал возможность выбора различных дополнений игры:\r\nИдея была следующей: определить три переменных окружения, которые бы позволили гибко настраивать движок игры на запуск определённого дополнения. При этом было бы полезно дать пользователю поиграться с различными аргументами исполняемого файла и оставить возможность портативного запуска движка, когда он лежит просто в директории с требуемыми файлами данных. Итак, первая переменная окружения  отвечает за директорию с файлами игры, которую выбирает пользователь из лаунчера. Вторая переменная  отвечает за то, какое дополнение выбрал для запуска пользователь в лаунчере. А вот третья переменная , пригодится лишь продвинутым пользователям. Она позволяет зеркалировать системную директорию Xash3D в любое доступное для записи пользователю место на диске. Таким образом, человеку, который хочет выпустить свою игру-дополнение на движке Xash3D под Haiku требуется просто собрать из исходного кода своего проекта несколько динамических библиотек для разных архитектур:\r\n• ./cl_dlls/libclient-haiku.so\r\n• ./dlls/libserver-haiku.so\r\n• ./cl_dlls/libclient-haiku64.so\r\n• ./dlls/libserver-haiku64.so\r\nИ затем положить их в соответствующие директории своего дополнения. Для своего порта Xash3D я решил предкомпилировать библиотеки популярных дополнений к игре Half-Life, а именно  и , что позволит пользователям просто скачать их файлы данных, выбрать директорию и начать игру без каких-либо компилирований библиотек.\r\nВ процессе портирования движка Xash3D я столкнулся с некоторыми забавными проблемами. Оказывается, для определения длины сообщения справки по аргументам исполняемого файла, которая генерируется при передаче параметра , в движке был использован предустановленный размер константы , которая является псевдонимом другой константы , значение которой уже берётся из Haiku API. Так вот, я долго не мог понять, почему же эта справка выдаётся неполной и обрезается в самом интересном месте. Сначала я грешил на то, что каким-то странным образом к стандартному потоку вывода ошибок  подключилась буферизация и даже пытался принудительно её отключить. Спустя какое-то время я вспомнил, что меня удивил очень маленький размер константы  в операционной системе Haiku. Эта константа предполагает размер пути всего в 1024 байт. Моя догадка полностью оправдала себя, как только я увеличил размер сообщения до стандартных 4096 байт, проблема разрешилась. Из этой забавной истории следует сделать следующий вывод: не стоит использовать константу  в массивах символов, которые никак не связаны с файловыми путями.\r\nЕщё одной проблемой был вылет при использовании функциональности самого движка для выбора дополнения игры. Оказалось, что при выставленном дефайне  клиентская библиотека загружалась не один, а два раза. Что и повлекло за собой подобную проблему. Как мне разъяснил , так было сделано для того, чтобы была возможность статически прилинковать библиотеку  к клиентской библиотеке. В моём порте Xash3D на Haiku эта библиотека никак не используется, поэтому я просто ушёл от использования дефайна  и зарепортил этот баг разработчикам движка.\r\nДалее я наткнулся на невозможность открытия встроенного в Haiku браузера  при нажатии на ссылки внутри запущенной в Xash3D игры. При этом проблема была действительно странной, так как при запуске движка из терминала браузер открывался, а вот при запуске с помощью лаунчера он отказывался это делать. Немного изучив код я нашёл там вызов , который я попробовал заменить на , после чего браузер стал открываться без каких-либо проблем.\r\nДвижок Xash3D при возникновении ошибок активно использует вызовы функций  и , вот только текущий порт библиотеки SDL2 для Haiku не поддерживает создание этих диалогов. В нашей версии библиотеки просто отсутствует эта функциональность. Но об исправлении этой проблемы я расскажу ниже.\r\nСтоит ещё отметить, что перед моим переносом движка Xash3D на Haiku, Герасим Троеглазов реализовал в SDL2 захват курсора мыши; до этого играть в 3D-игры было практически невозможно. Чуть позже он же исправил хитрый баг, при котором перемещение игрока в пространстве постепенно замедлялось, а игра начинала жутко тормозить. Оказывается, дело было в том, что по умолчанию события курсора мыши передавались со всей его историей передвижения по экрану. Соответственно, эта история в процессе игры быстро раздувалась и всё начинало сильно тормозить. Отключение подобной возможности в порте SDL2 на Haiku решило эту проблему и в Half-Life теперь можно играть без особых проблем. Хотя, отсутствие 3D-ускорения на слабом железе даёт о себе знать. И если игра прилично работает в окне и вообще не тормозит, то в полноэкранном режиме значительно снижается FPS. Но тут поможет лишь добавление в видеодрайвера операционной системы аппаратного ускорения хотя бы для тех GPU, которые встроены в популярные процессоры Intel.\r\nВсе изменения исходного кода я отправил разработчикам проекта FWGS Xash3D, которые приняли их в репозиторий, а пакеты с этим движком уже давно доступны в HaikuPorts и в программе HaikuDepot для любого пользователя Haiku.\r\nНедавно разработчики из компании  выложили исходный код движка , который используется в играх серии Serious Sam:  и . Я решил заняться его портированием на операционную систему Haiku, скачал исходный код и начал работу.\r\nСборка исполняемого файла после внесённых изменений обошлась без каких-либо проблем, а вот запустить игру так просто не удалось из-за того, что ошибки сыпались в диалоги SDL2, реализация которых отсутствует в версии этой библиотеки для Haiku. Поэтому пришлось брать в руки проверенный временем стандартный поток вывода ошибок  и потихоньку разбираться в проблемах, которые оказались в основном в отсутствии требуемых файлов данных игры.\r\nРазложив скачанные файлы по требуемым директориям я без проблем смог запустить вторую часть этой замечательной игры и даже немного побегал по красивейшим джунглям. Несмотря на отсутствие 3D-ускорения, процессор вытягивает графические прелести игры, если запускать её в окне, а не в полноэкранном режиме. Работает этот движок, конечно, куда с меньшим FPS, чем движок Xash3D, про который я писал выше, но и графика здесь современнее и лучше. После небольших манипуляций удалось запустить и первую часть игры, которая требует другой исполняемый файл и другой набор динамических библиотек. На удивление, она заработала немного быстрее, видимо графика в ней не такая требовательная. Полазив по настройкам движка, я обнаружил огромное количество графических параметров, позволяющих значительно снизить нагрузку на процессор, что в случае с Haiku оказалось очень полезным.\r\nЯ решил сделать один пакет сразу для двух частей игры, переключение между которыми будет осуществляется просто выбором директории с соответствующим набором файлов данных. Например, если пользователь в лаунчере выбирает директорию с файлами игры Serious Sam: The First Encounter, то запускается соответствующий исполняемый файл и подгружается соответствующий набор динамических библиотек. А если он выберет каталог с файлами игры Serious Sam: The Second Encounter, то лаунчер соответственно запустит уже другой исполняемый файл, который подгрузит свой набор разделяемых библиотек.\r\nК сожалению, без проблем не обошлось. Повторное изменение разрешения видеорежима в игре приводило к падению всего движка. При этом в моём дистрибутиве Linux этого вылета не было. Я потратил очень много времени на локализацию проблемы и на её устранение. Оказалось, всё дело было в том, что при каждом изменении разрешения разрушалось и снова создавалось окно , при этом OpenGL-рендерер вовремя не мог переключиться и пытался что-то там рисовать в разрушенном окне. Такие выкрутасы порт библиотеки SDL2 на Haiku не позволял проворачивать. Все простые попытки решения этой проблемы не помогали и мне пришлось серьёзно влезть в логику и изменить поведение таким образом, чтобы окно при смене разрешения не разрушалось, а просто изменялись его параметры. Это помогло убрать вылет, но добавило дополнительное ограничение: теперь, чтобы активировать полноэкранный режим, требуется перезапустить движок.\r\nЕщё одной проблемой было отсутствие музыки в игре. При этом на Linux, опять же, эта проблема не проявлялась. Исследуя исходный код движка, я обнаружил что воспроизведение музыки зависит от библиотеки , но сам движок при этом не линкуется с ней, а использует системную функцию , чтобы скормить этой библиотеке поток OGG-аудиофайла. Проблема заключалась в том, что на Haiku эта библиотеку движок не мог найти, так как симлинка на файл библиотеки без обозначения версии не было.\r\nНебольшой трюк, который подставлял в функцию полный путь до требуемой библиотеки, оказался вполне рабочим решением. А поскольку библиотека при её отсутствии ищется движком несколько раз, я на будущее оставил возможность подгрузки следующей мажорной версии. Надеюсь, они не сломают в ней API.\r\nСледующая проблема, с которой я столкнулся, заключалась в невозможности определения частоты процессора на архитектуре x86, хотя на x86_64 всё работало нормально. При запуске на x86 движок просил выставить переменную окружения с именем  и задать в ней соответствующую частоту, что меня очень сильно удивило. Я попробовал это сделать и игра действительно запустилась, но почему-то работала слишком медленно. Полазив по исходному коду игры, я долго не мог найти источник проблемы и даже написал кусочек кода, который с помощью Haiku API получает правильную частоту процессора и подставляет её в движок игры, вот так он выглядел:\r\nНо это не помогало. Тогда я проверил логи движка на x86_64 и увидел, что там у CPU частота вообще определяется в 1 MHz, но всё прекрасно работает. Продолжив исследовать код дальше, я наткнулся на отрицание дефайна , который автоматически выставляется тогда, когда приложение собирается под архитектуру x86, но не под x86_64. Ниже за этим дефайном как раз и скрывался флажок, который говорил использовать таймеры SDL2, вместо получения частоты процессора с помощью различной магии вроде inline-ассемблера и инструкции  или чтения файла , поэтому я сделал так, чтобы этот флаг был активирован и для x86, что решило мою проблему.\r\nПоследний недочёт был связан с моей невнимательностью. Я пропустил в сборочном файле  установку флага , который буквально говорит компилятору: при генерации блоков машинного кода используй все навороченные и современные инструкции, которые доступны в процессоре твоего компьютера.\r\nИз-за этого пакеты в репозитории собрались эксклюзивно под мощнейший build-сервер и отказывались запускаться на компьютерах простых смертных людей, ругаясь на неправильные инструкции и опкоды. Отключение этого флага и ручное добавление поддержки инструкций MMX, SSE и SSE2 не только решило эту проблему, но и позволило скомпилировать огромную кучу inline-ассемблера в этом проекте, которая отвалилась после того, как был убран этот флаг.\r\nК моему большому сожалению, разработчики Croteam не принимают какие-либо патчи в репозиторий движка, поэтому я сделал форк и выложил все свои наработки там:\r\nГотовые к установке пакеты, позволяющие запустить игры серии Serious Sam, уже доступны в репозитории HaikuPorts. Только не забудьте скачать файлы данных игры.\r\nСкажу честно, до недавнего времени я был совсем незнаком с этой игрой, которую в далёких 90-ых годах сделала отечественная студия разработчиков K-D Lab. Но участники , которая посвящёна обсуждению операционной системы Haiku, попросили меня портировать  и дали мне ссылку на , в котором находились исходники этой игры.\r\nСтянув исходники в Haiku я попытался их скомпилировать и у меня это удалось без каких-либо особых проблем. Немного пришлось повозиться с отсутствием некоторых заголовочных файлов и с путями к библиотекам , которые используются движком этой игры. Я сразу начал подготавливать исходный код к пакетированию, поэтому добавил переменную окружения  и перенёс лог движка в пользовательскую директорию, доступную для записи.\r\nЯ запустил саму игру и спустя некоторое время по достоинству оценил всю ту атмосферу, которую удалось создать ребятам из K-D Lab. Через некоторое время я начал беспечно возить «Нимбус» в «Инкубатор» и «Флегму» в «Подиш», после чего мне даже удалось привезти «Элика» третьим. Вдоволь наигравшись, я начал подготавливать лаунчер для этой игры на основе своей библиотеки, про которую я написал выше.\r\nПервая проблема, с которой я столкнулся, заключалась в том, что файлы данных игры, которые могли быть официально получены с помощью сервисов цифровой дистрибуции  и , не хотели работать с движком. Мне пришлось связаться с человеком, который использует ник  и который занимался портированием Вангеров на Linux. Он рассказал мне какие именно файлы требуется подменить, чтобы всё запустилось и начало работать. Я последовал его рекомендациям и получил то, что мне требовалось.\r\nКак и в случае с портом NXEngine (Cave Story), о котором я писал выше, русская и английская версия различаются между собой разными исполняемыми файлами, а вот директория с файлами данных у них общая, отличия имеются лишь в скриптах. По подсказке  я попробовал скомпилировать движок игры с опцией , которая активировала динамическую компиляцию этих скриптов во время исполнения, в том случае, если они имеются в каталоге файлов данных игры. Всё это позволило мне создать лаунчер, в котором имеется возможность переключения языка. Идея такая: предварительно проверяется директория игры, и если в ней нет необходимых скриптов, то они копируются из внутренностей пакета, после чего уже запускается исполняемый файл русской или английской версии.\r\nПри портировании Вангеров я задействовал одну интересную особенность, связанную с разделяемыми библиотеками, которая мне нравится в Haiku. Движок игры зависит от динамической библиотеки , которая отвечает за генерацию бинауральных звуков в реальном времени. И если в Linux, я должен ломать пальцы, подставляя в переменную окружения  путь до этой библиотеки, таким образом, чтобы и то что было в этой переменной до этого, тоже было сохранено, то в Haiku это сделано удобно, как и в Windows. Достаточно положить разделяемую библиотеку рядышком с исполняемым файлом и она будет подхвачена, с тем лишь отличием, что в случае с Haiku библиотеку необходимо положить в директорию , что на мой взгляд позволяет сильно сэкономить время и нервы. Поэтому статическую компиляцию этой библиотеки я решил не рассматривать.\r\nРазработчики Вангеров приняли мои изменения в движок своей игры, а готовые к установке пакеты доступны для скачивания из репозитория HaikuPorts или программы HaikuDepot, несмотря на недавний факап в инфраструктуре репозиториев, случившийся после обновления Linux-дистрибутива Fedora на новую версию.\r\nПри портировании движков Xash3D и Serious Engine, про которые я писал выше, я наткнулся в местном порте библиотеки  на полное отсутствие реализации диалогов. Диалоги вызываются двумя функциями  и , которые позволяют проинформировать пользователя о какой-либо важной информации, например, об ошибке. Реализация этих диалогов доступна на многих платформах и операционных системах: Windows, macOS, iOS, X11 и Android, но почему-то отсутствует в Haiku. Я решил исправить это упущение и добавить эту функциональность в порт библиотеки SDL2.\r\nВ Haiku API, а точнее во фреймворке Interface Kit, имеется прекрасный класс , который отлично подходит для реализации подобных диалогов. Я решил выбрать его в качестве базового. Единственное, что меня смущало, это то, что я не был уверен в том, что в диалоге, который конструирует , можно разместить более трёх кнопок. Ещё я помнил про особенности управления памятью в этом классе, о которых я писал выше: его объекты можно создавать только в куче, и нельзя создавать на стеке, так как после вызова метода  и последующего действия пользователя он удаляет сам себя. Проведя некоторые эксперименты, я развеял все свои сомнения, унаследовался от этого класса и начал писать реализацию.\r\nПервая трудность, с которой я столкнулся, состояла в том, что при использовании любого объекта класса  или его наследников, необходимо было обязательно создать экземпляр системного класса , видимо чтобы зарегистрировать приложение в  для возможности взаимодействия с ним. Я создал экземпляр этого класса, но при вызове диалога  из другого процесса или из созданного окна я получил другую ошибку, связанную с тем, что приложение не может иметь два объекта класса , к счастью я нашёл решение и этой проблемы. В Haiku API имеется глобальный указатель на текущий экземпляр класса , который называется , его аналогом во фреймворке Qt является специальный макрос , тоже определяющий указатель на текущий объект приложения. Так вот, достаточно просто проверять указатель  на NULL, и в том случае, если проверка завершилось успешно, создавать требуемый объект. Таким образом все эти проблемы были решены.\r\nСтоит обязательно отметить то, что библиотека SDL2 написана на языке программирования C, а в Haiku API, как известно, используют язык программирования C++. Из-за этого некоторые части кода следует обязательно обмазать соглашениями о связывании , чтобы не было никаких проблем с разрешением символов в процессе линковки. Кроме того, вместо  следует использовать оператор , чтобы иметь возможность проверять выделенную память по NULL, вместо выброса исключения, обработку которых SDL2, конечно же, не поддерживает.\r\nВ остальном ничего сложного не было. Пишем несколько функций, которые конвертируют сущности и представления SDL2 таким образом, чтобы они были совместимы с Haiku API и проверяем их корректную работу. Для различных проверок мной был расширен , который я периодически запускал на разных операционных системах, анализировал полученные результаты и оценивал свою работу. В конце-концов я так увлёкся, что сделал даже поддержку кастомизации, вроде задания разных цветов кнопкам и фону диалога. Это поддерживается в API библиотеки SDL2, но изначально я не планировал реализовывать такие вещи.\r\nЕсли программист решит выплюнуть в этот диалог очень-очень длинную строку, то у объекта класса , который используется внутри объекта класса , требуется вызвать метод  с аргументом , чтобы ударить такого программиста по рукам и сделать так, чтобы диалог мог поместиться на экран. Казалось бы, нет ничего проще: проверяем длину строки с помощью функции  и делаем нужное. Вот только проблема в том, что SDL2 работает так же и с UTF-8, а это значит, что функция  будет возвращать количество байт, а не количество символов. На помощь приходит Haiku API и класс строк , в котором имеется метод , позволяющий узнать длину строки в символах, а не в байтах:\r\nЭта функция проверяет текст сообщения на строки длинной более 120-ти символов и если такие имеются возвращает истину. Насчёт UTF-8 обнаружился ещё такой момент, что в некоторых системных шрифтах Haiku отсутствует поддержка китайских иероглифов. Поэтому, к примеру, установить какую-нибудь китайскую надпись в заголовок окна, нельзя. А вот текст на русском языке устанавливается без проблем.\r\nПри подготовке пакета я столкнулся с ошибкой сборки под архитектуру x86_gcc2, которая активирована в рецепте библиотеки SDL2. Оказалось, что древнейший компилятор GCC 2.95 не может догадаться, что закомментированный код эквивалентен тому, что находится ниже:\r\nПоэтому мне пришлось переписать этот фрагмент в старом стиле и ещё убрать инициализацию некоторых констант в классе прямо в их объявлениях, это тоже не понравилось старому компилятору.\r\nЯ отправил патчи реализации диалогов SDL2 в репозиторий HaikuPorts, благодаря чему теперь движки Xash3D и Serious Engine могут корректно выдавать пользователю какую-либо информацию, например, об ошибках. А вот с разработчиками SDL2 я пока не связывался, но было бы прекрасно перенести все патчи из репозитория HaikuPorts в upstream библиотеки SDL2. Хотя работа по переносу наших патчей немного усложнилась из-за  префиксов функций с  на , но это не является такой уж серьёзной проблемой.\r\nЯ уже давно развиваю форк программы , которую написал  (), соответствующая статья про это имеется на моём сайте. В комментариях к той статье постоянно отписываются читатели моего блога, которые либо хотят увидеть какую-нибудь новую возможность в своём любимом приложении для чтения электронных книг, либо хотят исправить ошибки и недочёты в уже реализованных функциях программы.\r\nВ репозитории HaikuPorts я обнаружил рецепт для сборки оригинальной программы Cool Reader, однако из-за каких-то постоянных изменений, происходящих с ресурсом , этот рецепт оказался нерабочим, поскольку исходный код приложения стал недоступен для скачивания. Тогда я решил перенести свой форк в репозиторий HaikuPorts, в качестве новой версии программы Cool Reader. Я наложил все патчи Герасима на код, поправил некоторые недочёты в рецепте и на его основе создал новый пакет, который уже доступен всем пользователям Haiku. Исходный код моего форка программы Cool Reader вы сможете найти в этом GitHub-репозитории:\r\nЕдинственной проблемой, с которой я столкнулся, были неточности переноса патчей Герасима. Кроме дефайна , где-то в системе сборки выставлялся ещё и дефайн  и, поскольку в большинстве случаев последний в листинге исходного кода стоял первым, условная компиляция подвела меня. В соответствии с правилами приоритета препроцессора, для Haiku компилировались именно те куски кода, которые были обрамлены дефайном , хотя мне нужно было совсем другое. Но даже несмотря на это программа запускалась и работала, вот только сохраняла свои настройки не там, где это требовалось. Я правильно расставил приоритеты, пересобрал пакет и проблема полностью разрешилась.\r\nВ последнее время многие популярные операционные системы перешли на новое сочетание клавиш  для переключения раскладки клавиатуры. Мне оно показалось очень удобным тем, что теперь не нужно ничего менять и настраивать. Садишься за любой компьютер под управлением macOS, Windows или Linux с оболочкой GNOME 3 и эта удобная комбинация смены языка ввода просто везде работает. Даже в мобильной операционной системе Android имеется её аналог. В общем, я давно полностью перешёл на эту клавиатурную комбинацию и сильно привык к ней.\r\nК моему большому сожалению, программа , которая поставляется с Haiku, не позволяла задать такое удобное сочетание клавиш для переключения раскладок, из-за чего я постоянно испытывал неудобство при работе с текстом в этой операционной системе. Поэтому я решил немного доработать это приложение и занялся поисками его исходного кода. Оказалось, что эта программа хоть и входит в дистрибутив Haiku, но поставляется отдельно от исходного кода самой операционной системы. Кроме того, приложение доступно в репозитории HaikuPorts и обновляется оно тоже через него. Как мне сообщили, KeymapSwitcher не включили в состав Haiku, потому что планируется реализовать специальное API для смены раскладок клавиатуры и когда-нибудь надобность в этой программе полностью отпадёт.\r\nНесмотря на то, что меня пугали сложностью кода KeymapSwitcher, я довольно быстро нашёл нужное место благодаря комментариям и внедрил в код программы небольшой патч, который очень сильно облегчил мне набор каких-либо текстов в Haiku. Единственный небольшой недочёт, который я так и не смог побороть, заключается в том, что клавишу  требуется отпускать для переключения языка. То есть, зажать  и пробелом переключаться между выбранными языками не получится. Но это абсолютно никак не мешает переключению языков во время набора текста, поэтому я отправил патч в репозиторий программы и обновил пакет приложения в HaikuPorts, после чего новая версия KeymapSwitcher стала доступна для установки всем пользователям Haiku.\r\nНадеюсь, я не единственный пользователь этого сочетания клавиш для переключения раскладок клавиатуры.\r\nИзучение Haiku API, а также разрешение различных экзотических проблем, возникших вследствие портирования новых и доработки существующих приложений для этой операционной системы, принесли мне огромное количество ценного опыта и удовольствия. Я смог продвинуть патчи поддержки Haiku в репозитории исходного кода некоторых крупных проектов и познакомился с новыми интересными людьми, так или иначе связанными с этой прекрасной операционной системой.\r\nЯ искренне надеюсь, что в будущем все сегодняшние проблемы вроде отсутствия аппаратного 3D-ускорения и популярных браузеров, а также слабой поддержки современного железа, будут успешно решены и Haiku получит приток новой крови разработчиков и пользователей, которые по достоинству оценят её уникальные возможности и самобытный дизайн. К счастью, разработка далеко не стоит на месте и уже сегодня на местном форуме этой операционной системы поднимаются горячие темы про  и про портирование библиотеки , а в репозиториях HaikuPorts обсуждается возможность переноса компонента . Порт GTK+3 может повлечь за собой возможность запуска и работы популярных браузеров Firefox и Chromium, а QtWebEngine позволит использовать движок Blink в современных браузерах, основанных на фреймворке Qt, таких как  или .\r\nУже сейчас я могу порекомендовать эту операционную систему тем, у кого имеются старые и слабые ноутбуки или нетбуки, например, вместо дистрибутива  или Windows XP. Вы будете поражены тем, насколько быстро и отзывчиво она работает. Да, придётся немного ограничить себя в просмотре некоторых сайтов из-за старых браузеров и кучи глюков, которые связаны с ними, однако для большинства случаев на старом железе это ограничение не является сколько бы то ни было значимым.\r\nВсе мои порты и доработки уже опубликованы и доступны для установки всем пользователям Haiku. Все изменения исходного кода доступны в соответствующих репозиториях под их оригинальными лицензиями. В этой работе я использовал огромное количество материалов, основные из них я выделю в полезных ссылках ниже. Огромное спасибо ресурсам  и  за то, что они есть......................\r\nПоздравляю всех пользователей ресурса  с наступающим Новым Годом и желаю им счастливых рождественских праздников! Добра вам, ребята, в новом 2019 году!", "url": "https://habr.com/ru/post/434690/"},
{"title": "Разрушительные исключения", "article_text": "Многие знатоки C++ (например, ) учат нас, что бросать исключения в деструкторах плохо, потому что в деструктор можно попасть во время раскрутки стека при уже выброшенном исключении, и если в этот момент будет выброшено ещё одно исключение, в результате будет вызван . Стандарт языка C++17 (здесь и далее я ссылаюсь на свободно доступную версию драфта ) на эту тему сообщает нам следующее:Проверим на простом примере:Результат:Обратите внимание, что деструктор  всё же вызывается, т.е. после выбрасывания второго исключения раскрутка стека не прерывается. В Стандарте (тот же самый пункт 18.5.1) на эту тему сказано следующее:Я проверял этот пример на нескольких версиях  (8.2, 7.3) и  (6.0, 5.0), везде раскрутка стека продолжается. Если вы встретите компилятор, где implementation-defined по-другому, пожалуйста, напишите об этом в комментариях. Следует заметить также, что  при раскрутке стека вызывается только тогда, когда исключение выбрасывается наружу из деструктора. Если внутри деструктора находится try/catch блок, который ловит исключение и не пробрасывается дальше, это не приводит к прерыванию раскрутки стека внешнего исключения.выводитКак же избегать неприятных ситуаций? В теории всё просто: никогда не бросать исключения в деструкторе. Однако, на практике красиво и изящно реализовать это простое требование бывает не так просто.Например, мы разрабатываем библиотеку с классом-обёрткой, инкапсулирующей работу с неким ресурсом. В соответствии с принципами RAII мы захватываем ресурс в конструкторе и должны освободить его в деструкторе. Но что если попытка освободить ресурс заканчивается ошибкой? Варианты решения этой проблемы:Как же понять, находимся ли мы в данный момент в процессе раскрутке стека по исключению или нет? В C++ для этого есть специальная функция . С её помощью мы можем безопасно кидать исключение в обычной ситуации, либо делать что-либо менее правильное, но не приводящее к выбросу исключения во время раскрутки стека.Результат:Обратите внимание, что функция  является  начиная со Стандарта C++17, поэтому чтобы скомпилировать пример, соответствующий ворнинг приходится подавлять (с.м. ).Проблема с этой функцией в том, что она проверяет находимся ли мы в процессе раскрутки стека по исключению. Но вот понять, вызван ли текущий деструктор в процессе раскрутки стека, с помощью этой функции невозможно. В результате, если происходит раскрутка стека, но деструктор какого-то объекта вызывается нормальным образом,  всё равно вернёт .Результат:В новом Стандарте C++17 на замену  была представлена функция  (обратите внимание на множественное число), которая вместо булевого значения возвращает количество активных в данный момент исключений (вот подробное ).Вот как описанная выше проблема решается при помощи :Результат: позволяет избежать вызова , но не помогает корректно обрабатывать множественные исключения. В идеале хотелось бы иметь механизм, который позволял бы сохранять все выброшенные исключения, а затем обработать их в одном месте.Суть идеи состоит в том, чтобы ловить исключения и сохранять их в контейнер, а затем по одному доставать и обрабатывать. Для того, чтобы сохранять объекты исключений, в языке C++ есть специальный тип . Структура типа в Стандарте не раскрывается, но говорится, что это по сути своей  на объект исключения.Как же потом обработать эти исключения? Для этого есть функция , которая принимает указатель  и выбрасывает соответствующее исключение. Нам нужно только поймать его соответствующей catch-секцией и обработать, после чего можно переходить к следующему объекту исключения.Результат:В примере выше для сохранения объектов исключений используется стек, однако обработка исключений будет производиться по принципу FIFO (т.е. логически это очередь — выброшенное первым исключение будет первым же и обработано).Выбрасывание исключений в деструкторах объектов действительно является плохой идеей, и в любом новом коде я настоятельно рекомендую этого не делать, объявляя деструкторы . Однако, при поддержке и отладке legacy-кода может возникнуть потребность корректно обрабатывать исключения, выбрасываемые из деструкторов, в том числе и при раскрутке стека, и современный C++ предоставляет нам механизмы для этого. Надеюсь, представленные в статье идеи помогут вам на этом нелёгком пути.", "url": "https://habr.com/ru/post/433944/"},
{"title": "И снова в космос: как единорог Stellarium посещал", "article_text": "За все время своего существования люди приложили колоссальное количество усилий, чтобы изучить практически всю площадь звездного неба. На сегодняшний день мы рассмотрели сотни тысяч астероидов, комет, туманностей и звезд, галактик и планет. Чтобы увидеть всю эту красоту самостоятельно, не обязательно выходить из дома и покупать себе телескоп. Можно установить на компьютер Stellarium — виртуальный планетарий, и посмотреть на ночное небо, с комфортом лежа на диване… Но с комфортом ли? Чтобы выяснить ответ на этот вопрос, проверим Stellarium на наличие ошибок в компьютерном коде.\r\nСогласно  на сайте Wikipedia,  — это виртуальный планетарий с открытым исходным кодом, доступный для платформ Linux, Mac OS X, Microsoft Windows, Symbian, Android и iOS, а также MeeGo. Программа использует технологии OpenGL и Qt, чтобы создавать реалистичное небо в режиме реального времени. Со Stellarium возможно увидеть то, что можно видеть средним и даже крупным телескопом. Также программа предоставляет наблюдения за солнечными затмениями и движением комет.\r\nStellarium создан французским программистом Фабианом Шеро, который запустил проект летом 2001 года. Другие видные разработчики включают Роберта Спирмана, Джохэйннса Гадждозика, Мэтью Гейтса, Тимоти Ривза, Богдана Маринова и Джохана Меериса, который является ответственным за художественные работы.\r\nАнализ проекта проводился с помощью статического анализатора кода PVS-Studio. Это инструмент для выявления ошибок и потенциальных уязвимостей в исходном коде программ, написанных на языках С, C++ и C# (в скором времени и на Java!). Работает в среде Windows, Linux и macOS. Он разработан для тех, кому важно повышать качество своего кода. \r\nПровести анализ было достаточно просто. Сначала я  проект Stellarium с GitHub, после чего установил все необходимые для сборки пакеты. Так как проект собирается с помощью Qt Creator, я использовал систему отслеживания запуска компиляторов, которая является встроенной в -версию анализатора. Там же можно просмотреть готовый отчёт об анализе.\r\nНовые читатели и пользователи  возможно задались вопросом: почему в заголовке статьи фигурирует единорог и как он связан с анализом кода? Отвечаю: я являюсь одним из разработчиков PVS-Studio, а единорог — это наш любимый озорной маскот. Итак, вверх! \r\nЯ надеюсь, что благодаря этой статье читатели узнают для себя что-то новое, а разработчики Stellarium смогут устранить часть ошибок и улучшить качество кода. \r\nПриносите себе кофе с воздушным круассаном и устраивайтесь поудобнее, ведь мы переходим к самому интересному — обзору результатов анализа и разбору ошибок!\r\nДля большего удовольствия от чтения предлагаю не смотреть сразу на предупреждение анализатора, а попробовать здесь и далее найти ошибки самостоятельно.  The condition 'start_of_directory == — 1' of loop is always true. qzip.cpp 617\r\nСмогли найти ошибку? Если да, то хвалю.\r\nОшибка кроется в условии цикла . Оно всегда верно, так как переменная  не меняется в теле цикла. Скорее всего, цикл не будет вечным, так как он содержит  и , но выглядит такой код странно.\r\nКак мне кажется, в коде забыли сделать присваивание  в том месте, где идёт проверка сигнатуры. Тогда и оператор , пожалуй, лишний. В этом случае код можно переписать так:\r\nВпрочем, я не уверен, что код должен быть именно таким. Лучше всего, чтобы сами разработчики проекта проанализировали эту часть программы и внесли нужные правки.\r\nЕще одно странное условие:  There are identical sub-expressions 'cap.intersects(cap2)' to the left and to the right of the '&&' operator. StelProjectorClasses.hpp 175\r\nКак вы уже, наверное, догадались, ошибка кроется в последней строчке функции: программист допустил опечатку, и в итоге получилось, что функция возвращает результат независимо от значения .\r\nПодобный тип ошибок встречается крайне часто: практически в каждом проверенном проекте мы встречали опечатки, связанные с именами вида и  и им подобными. Как правило, такие ошибки связаны с copy-paste.\r\nДанный экземпляр кода является ярким примером ещё одного распространенного паттерна ошибок, по поводу которого мы даже проводили отдельное мини-исследование. Мой коллега Андрей Карпов назвал его \"\". Если вы ещё не знакомы с этим материалом, то предлагаю открыть вкладку в браузере, чтобы почитать позже, а пока продолжим.\r\nЗначение параметра  всегда перезаписывается до того, как будет использовано, т.е. функция отработает одинаково, независимо от переданного ей значения.\r\nВыглядит странно, не так ли? Во всех местах, где участвует параметр , он имеет значение . Это значит, что условия  и  будут всегда истинны.\r\nЕще один фрагмент: \r\nАнализатор выявил подозрительное выражение в аргументах функций  и . Действительно: по обеим сторонам от битового оператора  находятся значения, имеющие тип . Вместо оператора  стоит использовать оператор , и сейчас я объясню почему. \r\nДа, результат этого выражения будет всегда корректен. Перед применением побитового «и» оба операнда будут повышаться до типа . В языке C++ такая конвертация : false конвертируется в 0, а true конвертируется в 1. Поэтому результат у данного выражения будет таким же, как если бы использовался оператор . \r\nНо есть нюанс. При подсчете результата операции  используется так называемое «ленивое вычисление». Если значение левого операнда является , то правое значение даже не вычисляется, ведь логическое «и» в любом случае вернет . Это сделано для экономии вычислительных ресурсов и позволяет писать более сложные конструкции. Например, можно проверить, что указатель не нулевой, и, если это так, разыменовать его для выполнения дополнительной проверки. Пример: .\r\nТакое «ленивое вычисление» не производится при использовании побитового оператора : выражения  будут вычисляться каждый раз, независимо от значения . \r\nВ редких случаях это бывает сделано специально. Например, если вычисление правого операнда имеет «побочные эффекты», результат которых используется позже. Так тоже делать не очень хорошо, потому что это затрудняет понимание кода и усложняет уход за ним. К тому же, порядок вычисления операндов  не определен, поэтому в некоторых случаях использования таких «трюков» можно получить неопределенное поведение. \r\nЕсли нужно сохранить побочные эффекты — сделайте это в отдельной строке и сохраните результат в отдельную переменную. Люди, которые будут работать с этим кодом в дальнейшем, будут вам благодарны :)\r\nПереходим к следующей теме.\r\nНачнем тему динамической памяти с вот такого фрагмента: \r\nФункция выделяет память для нескольких структур и передает её указателям ,  (интересные имена, правда?) и . Если один из них оказывается нулевым, то освобождается вся зарезервированная внутри функции память, после чего поток управления покидает функцию. \r\nЧто же произойдет, если память под все три структуры выделится корректно, а функция  вернет ? Поток управления достигнет второго по счету .\r\nТак как указатели ,  и  являются локальными переменными, то после выхода из функции они прекратят своё существование. Но освобождения памяти, которая им принадлежала, не произойдет. Она останется зарезервированной, но доступа к ней мы больше иметь не будем. \r\nТакие ситуации называются «утечка памяти». Типичный сценарий при такой ошибке: при продолжительной работе программы она начинает потреблять все больше и больше оперативной памяти, вплоть до полного её исчерпания. \r\nСледует отметить, что в данном примере третий  не является ошибочным. Функции  и  передают адреса выделенной памяти в другие структуры данных, тем самым делегируя ответственность за её освобождение.\r\nСледующая недоработка находится в методе, который занимает 90 строк. Для удобства я сократил его, оставив только проблемные места.\r\nОсталась всего одна строчка. Дам подсказку: это единственное упоминание объектов  и . \r\nВекторы  и  создаются, но нигде не используются. Получается, что при каждом использовании метода  происходит лишнее создание и удаление пустого контейнера. Думаю, это объявление осталось в коде после рефакторинга. Это, конечно, не ошибка, но стоит удалить лишний код.\r\nЕще один пример после небольшого форматирования выглядит вот так:\r\nДля того, чтобы понять, в чем ошибка, вам придется посмотреть на прототипы конструкторов :\r\nУ класса  не существует конструкторов, принимающих тип , поэтому аргументы в примере будут неявно преобразовываться в . Это приводит к тому, что поля , ,  объекта  будут иметь значения .\r\nЕсли программист намеревался создать объект из значений типа , ему следовало использовать другой конструктор.\r\nНапример, можно было использовать конструктор, принимающий , написав:\r\nМожно было сделать и по-другому. В Qt для обозначения RGB-цветов используются вещественные значения в диапазоне [0.0, 1.0] или целочисленные в диапазоне [0, 255].\r\nПоэтому программист мог перевести значения из вещественных в целочисленные, написав вот так:\r\nили просто \r\nЗаскучали? Не переживайте: впереди нас ждут более интересные ошибки.\r\nНапоследок я оставил вам еще несколько вкусняшек :) Приступим к одной из них.  The priority of the '*' operation is higher than that of the '<<' operation. It's possible that parentheses should be used in the expression. StelHips.cpp 271\r\nНу что, смогли обнаружить ошибку? Рассмотрим подробнее выражение . Анализатор напоминает, что операция '' имеет более высокий приоритет, чем операция битового сдвига ''. Легко понять, что умножение  на  бессмысленно, а скобки вокруг  не нужны. \r\nПримечание. Дополнительно хочу отметить, что если значение правого операнда '' больше или равно количеству битов левого операнда, то результат не определен. Так как численные литералы по умолчанию имеют тип , который занимает  бита, значение параметра  не должно превышать . Иначе вычисление выражения может закончиться неопределенным поведением.\r\nПродолжаем. Приведенный ниже метод является весьма запутанным, но я уверен, что искушенный читатель справится с обнаружением ошибки :)   Unreachable code detected. It is possible that an error is present. qcustomplot.cpp 19512.\r\nДело в том, что все ветви  имеют . Поэтому поток управления никогда не дойдет до последних двух строк.\r\nПо большому счету, данный пример будет нормально выполняться и работать корректно. Но присутствие недостижимого кода само по себе является сигналом. В данном случае оно указывает на неправильную структуру метода, которая сильно усложняет читабельность и понятность кода.\r\nДанный фрагмент кода следует подвергнуть рефакторингу, получив на выходе более опрятную функцию. Например, так:\r\nПоследней в нашем обзоре будет ошибка, которая понравилась мне больше всего. Код проблемного места краток и прост:\r\nЗаметили что-то подозрительное? Не каждый сможет :)  The object was created but it is not being used. If you wish to call constructor, 'this->Plane::Plane(....)' should be used. Plane.cpp 29\r\nПрограммист рассчитывал, что часть полей объекта будет инициализирована внутри вложенного конструктора, но получилось так: когда вызывается конструктор , внутри него создается безымянный временный объект, который сразу же удаляется. В результате часть послей объекта остается неинициализированной. \r\nЧтобы код заработал правильно, следует использовать удобную и безопасную фичу C++11 — делегирующий конструктор:\r\nНо если вы используете компилятор для более старых версий языка, то можно написать так:\r\nИли так:\r\nЗамечу, что последние два способа являются . Поэтому следует быть очень осторожным и хорошо понимать, как такие способы работают.\r\nКакие выводы можно сделать о качестве кода Stellarium? Честно говоря, ошибок было не очень много. Также во всем проекте я не обнаружил ни одной ошибки, в которой код завязан на неопределенном поведении. Для opensource-проекта качество кода оказалось на высоком уровне, за что я снимаю шляпу перед разработчиками. Ребята, вы молодцы! Мне было приятно и интересно делать обзор на ваш проект.\r\nЧто же насчет самого планетария — я пользуюсь им достаточно часто. К сожалению, живя в городе, я очень редко могу насладиться ясным ночным небом, а Stellarium позволяет мне оказаться в любой точке планеты, не вставая с дивана. Это действительно комфортно! \r\nОсобенно мне нравится режим «Constellation art». От вида огромных фигур, застилающих все небо в странном танце, захватывает дух.\r\nНам, землянам, свойственно ошибаться, и нет ничего постыдного в том, что эти ошибки просачиваются в код. Для этого и разрабатываются инструменты анализа кода, такие, как PVS-Studio. Если вы один из землян —  предлагаю .\r\nНадеюсь, что вам было интересно читать мою статью, и вы узнали для себя что-нибудь новое и полезное. А разработчикам желаю скорейшего исправления найденных ошибок.\r\nПодписывайтесь на наши каналы и следите за новостями из мира программирования!\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: George Gribkov. ", "url": "https://habr.com/ru/company/pvs-studio/blog/432954/"},
{"title": "Тесты на C++ без макросов и динамической памяти", "article_text": "Многие популярные библиотеки для тестирования, например Google Test, Catch2, Boost.Test тяжело завязаны на использование макросов, так что в качестве примера тестов на этих библиотеках вы обычно увидите картину вроде такой:К макросам в C++ отношение настороженное, почему же они так процветают в библиотеках для создания тестов? Библиотека юнит-тестов должна предоставить её пользователям способ написания тестов, так чтобы среда выполнения тестов могла их как-то найти и выполнить. Когда вы подумаете о том как это сделать, то использование макросов кажется кажется проще всего. Макрос TEST() обычно как-то определяет функцию (в случае с Google Test макрос также создает класс) и обеспечивает попадание адреса этой функции в какой-нибудь глобальный контейнер.Хорошо известная мне библиотека, в которой реализован подход без единого макроса, это . Посмотрим её пример из туториала:Идея которая лежит в основе довольно интересная и работает это все не очень сложно. Если вкратце, то у вас базовый класс, в котором реализована шаблонная функция, которая предполагает параметризацию целым числом:Теперь когда вы пишете такой тест:Вы фактически создаете специализацию тестового метода для конкретного числа N=1 (именно для этого стоят ). Вызвав  среда исполнения тестов может понять был ли это реальный тест или это была заглушка глядя на значение  после исполнения теста.Далее, когда вы объявляете группу тестов:Вы, во-первых, совершаете перечисление всех  до некоторой константы, зашитой в библиотеку, и, во-вторых, побочным эффектом добавляете в глобальный контейнер информацию о группе (имя группы и адреса всех тестовых функций).В качестве условий проверки в tut используются исключения, так что функция  просто бросит исключение если переданные ей два значения не будут равны, а среда запуска теста поймает исключение и засчитает тест как failed. Мне нравится такой подход, любому разработчику C++ становится сразу понятно, где можно использовать такие ассерты. Например, если мой тест создал вспомогательный поток, то там ассерты расставлять бесполезно, их никто не поймает. Кроме того, мне понятно, что мой тест должен иметь возможность освободить ресурсы в случае возникновения исключения, как будто это обычный exception-safe код.В принципе библиотека tut-framework выглядит довольно неплохо, но в её реализации есть некоторые недостатки. Например, для моего случая я бы хотел, чтобы у теста был бы не только номер, но и другие атрибуты, в частности имя, а также \"размер\" теста (например интеграционный ли это тест или это unit тест). Это решаемо в рамках API tut, и даже что-то уже есть, а что-то можно реализовать, если добавить в API библиотеки метод, а в тело теста его вызов чтобы установить какие-нибудь его параметры:Другая проблема в том, что среда запуска тестов tut ничего не знает о таком событии как начало теста. Среда выполняет  и она заранее не знает реализован ли тест для данного N, или это просто заглушка. Узнает она только когда тест закончится, проанализировав значение . Эта особенность не очень хорошо показывает себя в системах CI, которые умеют группировать вывод, который делала программа между началом и окончанием теста. Однако на мой взгляд главная вещь которую можно улучшить (\"фатальный недостаток\") это наличие лишнего вспомогательного кода, требуемого для написания тестов. В tutorial tut-framework довольно много всего: предлагается сначала создать некий класс , а тесты описывать как методы объекта связанные с этим. В этом классе можно определить методы и данные, которые вы хотите использовать в группе тестов, а конструктор и деструктор обрамляют выполнение теста, создавая такую штуку как fixture из jUnit. На моей практике работы с tut этот объект почти всегда пустой, однако он тащит за собой какое-то количество строк кода. Итак, заходим в вело-мастерскую и пробуем оформить идею в виде небольшой библиотеки. Вот так выглядит минимальный файл теста в библиотеке \"tested\":Кроме отсутствия макросов бонусом идет отсутствие использование динамической памяти внутри библиотеки. Для регистрации тестов используется шаблонная магия начального уровня на том же принципе что и tut. Где-то в tested.h есть шаблонная функция такого вида:Тест кейсы, которые пишут пользователи библиотеки — это просто специализации этого метода. Функция объявлена статической, т.е. в каждом translation unit мы создаем специализации, которые не пересекаются по именам друг с другом при линковке. Есть такое правило что вначале надо вызывать , которому можно передать такие вещи как имя теста и возможно некоторые другие штуки, которые пока в разработке.Когда тест вызывает  могут случится интересные вещи. Во-первых, если тесты сейчас в режиме запуска, то вы можете сообщить куда-то о том, что тест начал выполнение. Во-вторых, если сейчас идет режим сбора информации о доступных тестах  выбросит специального рода исключение которое будет означать что тест реальный, а не заглушка.В какой-то момент нужно собрать адреса всех тест-кейсов и где-то их сложить. В tested это делается с помощью групп. Делает это конструктор класса tested::Group в виде побочного эффекта:Конструктор создает группу с указанным именем и добавляет в нее все кейсы  которые найдет в текущем translation unit. Получается, что в одном translation unit у вас не может быть две группы. Это значит также что вы не можете одну группу разбить на несколько translation units. Параметром шаблона идет сколько тест-кейсов искать в текущем translation unit для создаваемой группы.В приведенном примере создание объекта tested::Group() происходит внутри функции, которую мы должны позвать из нашего приложения чтобы зарегистрировать тесты:Функция не всегда требуется, иногда можно просто объявить объект класса  внутри файла. Однако мой опыт такой что линкер иногда \"оптимизирует\" файл целиком, если он собран внутри библиотеки, и никто из основного приложения не использует каких-либо символов этого cpp файла:Когда из исходников run_test.exe никак не связываются calc_test.cpp, то линкер просто убирает этот файл из рассмотрения целиком, вместе с созданием статического объекта, не смотря на то, что него есть нужные нам побочные эффекты. Если какая цепочка приводит из run_test.exe, то статический объект появится в исполняемом файле. Причем неважно как именно это будет сделано, как в примере:или так:Первый вариант на мой взгляд лучше тем что вызов конструктора выполняется после начала работы main(), и у приложения есть некоторый контроль над этим процессом. Я думаю что эта установка костылей требуется для любой библиотеки юнит-тестирования, которая использует глобальные переменные и побочные эффекты конструктора для создании базы тестов. Однако наверное ее можно избежать если линковать тестовую библиотеку с ключом --whole-archive (аналог в MSVC появился только в Visual Studio 2015.3).Я обещал, что здесь не будет макросов, но он есть — . Рабочий вариант что это используется , макрос, который компилятор увеличивает на один каждый раз, когда он используется внутри translation unit.\r\nПоддерживается GCC, CLANG, MSVC, но не стандартом. Если это расстраивает, то вот какие есть альтернативы:Проблема с  в том, что использование больших чисел в параметрах шаблона создает большой размер исполняемого файла. Именно поэтому я ограничил тип шаблона signed char, получая 128 как максимальное количество тестов в группе. Оказалось, что при регистрации тестов можно не использовать динамическую память, чем я и воспользовался. Возможно, в вашей среде нет динамической памяти или вы используете поиск утечек памяти в тест-кейсах, так что вмешательство среды исполнения тестов — это не то, что вам нужно. Google Test с этим борется, вот фрагмент оттуда:А мы можем просто не создавать трудностей.Как же мы тогда получаем список тестов? Это больше технические внутренности, которые проще посмотреть в исходном коде, но я все равно расскажу.При создании группы ее класс получит указатель на функцию , которая соберет все тесты translation unit в список. Вот как это устроенно:Получается что в каждом translation unit создается много статических переменных вида CaseListEntry CaseCollector\\::s_caseListEntry, которые являются элементами списка тестов, а метод collect() собирает эти элементы в односвязный список. Примерно таким же образом список формирует группы тестов, но без шаблонов и рекурсии.Тестам нужна различная обвязка, вроде вывода в консоль красными буквами Failed, создание тест-репортов в формате понятном для CI или GUI в котором можно посмотреть список тестов и запустить выбранные — в общем много чего. У меня есть виденье как это можно сделать, которое отличается от того, что я видел раньше в библиотека тестирования. Претензия главным образом к библиотекам которые называют себя \"header-only\", при этом включая большой объем кода, который по сути совсем не для заголовочных файлов.Подход, который я предполагаю в том, что мы разделяем библиотеку на front-end — эта сама tested.h и back-end — библиотеки. Для написание тестов нужен только tested.h, который сейчас C++17 (из-за здоровского std::string_view) но предполагается что будет C++98. Tested.h осуществляет фактически регистрацию и поиск тестов, минимально удобный вариант запуска, а также возможность экспорта тестов (группы, адреса функций тест-кейсов). Back-end библиотеки, которых еще не существует, могут делать все что нужно, в плане вывода результатов и запуска, использовав функционал экспорта. Таким же образом можно приспособить запуск под нужды своего проекта.Библиотеке tested () предстоит еще некоторая стабилизация. В ближайших планах добавить возможность выполнения асинхронных тестов (нужно для интеграционный тестов в WebAssembly) и указания размера тестов. На мой взгляд библиотека еще не вполне готова к production применению, но я потратил уже неожиданно много времени и наступил такой этап чтобы остановится, перевести дух и спросить обратной связи от сообщества. Интересно ли вам было бы воспользоваться такого рода библиотекой? Может быть в арсенале С++ есть какие-нибудь еще идеи как было бы можно создать библиотеку без макросов? Интересна ли вообще такая постановка задачи?", "url": "https://habr.com/ru/post/434906/"},
{"title": "Иголка в стоге сессий, или Байт-код регулярных выражений", "article_text": "17 млрд событий, 60 млн пользовательских сессий и огромное количество виртуальных свиданий происходят в Badoo ежедневно. Каждое событие аккуратно сохраняется в реляционные базы данных для последующего анализа на SQL и не только.Современные распределённые транзакционные базы данных с десятками терабайт данных — настоящее чудо инженерной мысли. Но SQL как воплощение реляционной алгебры в большинстве стандартных реализаций пока не позволяет формулировать запросы в терминах упорядоченных кортежей.В последней статье из серии, посвящённой  , я расскажу про альтернативный подход к поиску интересных сессий — движок регулярных выражений (), определённых для последовательностей событий.Виртуальная машина, байт-код и компилятор прилагаются бесплатно!Предположим, у нас уже есть хранилище данных, позволяющее быстро и последовательно просматривать события каждой из пользовательских сессий.Мы хотим находить сессии по запросам вроде «посчитать все сессии, где имеется указанная подпоследовательность событий», «найти части сессии, описанные заданным шаблоном», «вернуть ту часть сессии, которая случилась после заданного шаблона» или «посчитать, сколько сессий достигли определённых частей шаблона». Это может пригодиться для самых разных типов анализа: поиск подозрительных сессий, вороночный анализ и т. д.Искомые подпоследовательности надо как-то описывать. В самой простой форме эта задача похожа на поиск подстроки в тексте; нам же хочется иметь инструмент помощнее — регулярные выражения. Современные реализации движков регулярных выражений чаще всего используют (вы угадали!) виртуальные машины.Созданием небольших виртуальных машинок для сопоставления сессий с регулярными выражениями мы и займёмся ниже. Но для начала уточним определения. состоит из типа события, времени, контекста и набора атрибутов, специфичных для каждого из типов. и  каждого из событий это целые числа из предопределенных списков. Если с типами событий все понятно, то контекст это, например, номер экрана, на котором произошло заданное событие. события это произвольное целое число, смысл которого определяется типом события. Атрибутов у события может не быть, или их может быть несколько.. — это последовательность событий, отсортированных по времени.Но давайте, наконец, перейдём к делу. Гул, как говорится, затих, а я вышел на подмостки.Особенность данной виртуальной машины — пассивность по отношению к входным событиям. Мы не хотим держать всю сессию в памяти и позволять виртуальной машине самостоятельно переходить от события к событию. Вместо этого мы будем одно за другим подавать события из сессии в виртуальную машинку.Определимся с интерфейсными функциями:Если с функциями matcher_create и matcher_destroy всё понятно, то matcher_accept стоит прокомментировать. Функция matcher_accept получает на вход экземпляр виртуальной машины и очередное событие (32 бита, где 16 бит — на тип события и 16 бит — на контекст), а возвращает код, поясняющий, что пользовательскому коду делать дальше:Опкоды виртуальной машины:Главный цикл виртуальной машины:В этом простеньком варианте наша виртуальная машина последовательно сопоставляет шаблон, описанный байт-кодом, со входящими событиями. В таком виде это просто не слишком лаконичное сопоставление  двух строк: искомого шаблона и входной строки.Префиксы префиксами, но мы хотим находить искомые шаблоны не только в начале, но и в произвольном месте сессии. Наивное решение — перезапуск сопоставления с каждого события сессии. Но это подразумевает многократный просмотр каждого из событий и поедание алгоритмических младенцев. из  серии, в сущности, имитирует перезапуск сопоставления при помощи отката (англ. backtracking). Код в примере выглядит, конечно, стройней приведённого здесь, но проблема никуда не делась: каждое из событий придётся проверить многократно.Так жить нельзя.Давайте ещё раз обозначим задачу: надо сопоставлять шаблон со входящими событиями, от каждого из событий начиная новое сопоставление. Так почему бы нам именно это и не делать? Пускай виртуальная машина ходит по входящим событиям в несколько потоков!Для этого нам потребуется завести новую сущность — поток. Каждый поток хранит единственный указатель — на текущую инструкцию:Естественно, и в самой виртуальной машине мы теперь явный указатель хранить не будем. Его заменят два списка потоков (о них чуть ниже):А вот и обновлённый главный цикл:На каждом полученном событии мы сначала вносим в список current_threads новый поток, проверяющий шаблон с самого начала, после чего начинаем обход списка current_threads, для каждого из потоков выполняя инструкции по указателю.Если встречается инструкция NEXT, то поток помещается в список next_threads, то есть ждёт получения следующего события.Если шаблон потока не совпадает с полученным событием, то такой поток просто не добавляется в список next_threads.Инструкция MATCH немедленно выходит из функции, сообщая кодом возврата о совпадении шаблона с сессией.По завершении обхода списка потоков текущий и следующий списки меняются местами.Собственно, всё. Можно сказать, что мы буквально делаем то, что хотели: одновременно сверяем несколько шаблонов, запуская по одному новому процессу сопоставления на каждое из событий сессии.Искать шаблон, описывающий линейную последовательность событий, конечно, полезно, но мы же хотим получить полноценные регулярные выражения. И потоки, которые мы создали на предыдущем этапе, тут тоже пригодятся.Предположим, мы хотим найти последовательность из двух или трёх интересных нам событий, что-то вроде регулярного выражения на строках: \"a?bc\". В этой последовательности символ \"а\" опционален. Как это выразить в байт-коде? Легко!Мы можем запустить  потока, по одному для каждого случая: с символом \"a\" и без него. Для этого введём дополнительную инструкцию (вида SPLIT addr1, addr2), которая запускает два потока с указанных адресов. Помимо SPLIT, нам пригодится ещё JUMP, которая просто продолжает исполнение с указанной в непосредственном аргументе инструкции:Сам цикл и остальные инструкции не меняются — мы просто внесём два новых обработчика:Обратите внимание на то, что инструкции добавляют потоки в текущий список, то есть они продолжают работу в контексте текущего события. Поток, в рамках которого произошло ветвление, в список следующих потоков уже не попадает.Самое удивительное в этой виртуальной машине для регулярных выражений то, что наших потоков и этой пары инструкций достаточно для того, чтобы выразить почти все общепринятые при сопоставлении строк конструкции.Теперь, когда у нас есть подходящая виртуальная машина и инструменты для неё, можно заняться, собственно, синтаксисом для наших регулярных выражений.Ручная запись опкодов для более серьёзных программ быстро утомляет. В прошлый раз я не стал делать полноценный парсер, но пользователь  на примере мини-языка  показал возможности своей библиотеки . Я был так впечатлён лаконичностью кода, что при помощи raddsl написал небольшой компилятор регулярных выражений строк в сто-двести на Python.  и инструкция по его применению есть на GitHub. Результат работы компилятора на языке ассемблера понимает утилита, читающая два файла (программу для виртуальной машины и список событий сессии для проверки).Для начала ограничимся типом и контекстом события. Тип события обозначаем единственным числом; если требуется указать контекст, указываем его через двоеточие. Простейший пример:Теперь пример с контекстом:Последовательные события должны быть как-то разделены (например, пробелами):Шаблон поинтереснее:Обратите внимание на строки, заканчивающиеся двоеточием. Это метки. Инструкция SPLIT создаёт два потока, продолжающие выполнение с меток L0 и L1, а JUMP в конце первой ветки исполнения просто переходит к концу ветвления.Можно выбирать между цепочками выражений подлиннее, группируя подпоследовательности скобками:Произвольное событие обозначается точкой:Если мы хотим показать, что подпоследовательность опциональна, то ставим после неё знак вопроса:Разумеется, поддерживаются и обычные в регулярных выражениях многократные повторения (плюс или звёздочка):Здесь мы просто многократно выполняем инструкцию SPLIT, запуская на каждом цикле новые потоки.Аналогично со звёздочкой:Могут пригодиться и другие расширения описанной виртуальной машины.Например, её легко можно расширить проверкой атрибутов событий. Для реальной системы я предполагаю использовать синтаксис вроде «1:2{3:4, 5:>3}», что означает: событие 1 в контексте 2 с атрибутом 3, имеющим значение 4, и значением атрибута 5, превышающим 3. Атрибуты здесь можно просто передавать массивом в функцию matcher_accept.Если передавать в matcher_accept ещё и временной интервал между событиями, то в язык шаблонов можно добавить синтаксис, позволяющий пропускать время между событиями: \"1 mindelta(120) 2\", что будет означать: событие 1, потом промежуток минимум в 120 секунд, событие 2. В сочетании с сохранением подпоследовательности это позволяет собирать информацию о поведении пользователей между двумя подпоследовательностями событий.Другие полезные вещи, которые относительно легко добавить: сохранение подпоследовательностей регулярного выражения, разделение «жадных» и обычных операторов звёздочку и плюс и так далее. Наша виртуальная машина в терминах теории автоматов представляет собой недетерминированный конечный автомат, для реализаций которого такие вещи сделать несложно.Наша система разрабатывается под быстрые пользовательские интерфейсы, поэтому и движок хранения сессий самописный и оптимизирован именно под проход по всем сессиям. Все миллиарды событий, разбитые на сессии, проверяются на соответствие шаблонам за секунды на единственном сервере.Если для вас скорость не столь критична, то похожую систему можно оформить в виде расширения для какой-нибудь более стандартной системы хранения данных вроде традиционной реляционной базы данных или распределённой файловой системы.К слову, в последних версиях  уже появилась похожая на описанную в статье возможность, и отдельные базы данных ( и ) уже реализовали её. В свою очередь Yandex ClickHouse реализует собственный SQL-подобный язык, но там тоже есть .Отвлекаясь от событий и регулярных выражений, хочу повторить, что применимость виртуальных машин гораздо шире, чем может показаться на первый взгляд. Эта техника подходит и широко применяется во всех случаях, когда есть необходимость чётко разделить примитивы, которые понимает движок системы, и «парадную» подсистему, то есть, к примеру, какой-нибудь DSL или язык программирования.На этом я заканчиваю серию статей, посвящённых различным применениям интерпретаторов байт-кода и виртуальным машинам. Надеюсь, читателям Хабра серия понравилась и, разумеется, буду рад ответить на любые вопросы по теме.Интерпретаторы байт-кода для языков программирования тема специфичная, и литературы по ним относительно немного. Лично мне понравилась книга Айана Крейга  (\"Virtual Machines\"), хотя в ней описываются не столько реализации интерпретаторов, сколько абстрактные машины — математические модели, лежащие в основе различных языков программирования.В более широком смысле виртуальным машинам посвящена другая книга —  (\"Virtual Machines: Versatile Platforms for Systems and Processes\"). Это введение в различные сферы применения виртуализации, охватывающее виртуализацию и языков, и процессов, и архитектур компьютеров в целом.Практические аспекты разработки движков регулярных выражений обсуждаются в популярной литературе по компиляторам редко. «Поросячий Матчер» и пример из первой статьи базируются на идеях из потрясающей  Расса Кокса, одного из разработчиков движка Google RE2.Теория регулярных выражений излагается во всех академических учебниках, посвящённых компиляторам. Принято ссылаться на знаменитую , но я бы рекомендовал начать с приведённой выше ссылки.Работая над статьёй, я впервые использовал интересную систему для быстрой разработки компиляторов на Python , принадлежащую перу пользователя  (спасибо, Пётр!). Если перед вами стоит задача прототипирования языка или быстрой разработки какого-то DSL, стоит обратить на неё внимание.", "url": "https://habr.com/ru/company/badoo/blog/433054/"},
{"title": "Проверка проекта LibrePCB с помощью PVS-Studio внутри Docker контейнера", "article_text": "\r\nЭто классическая статья о том, как наша команда проверила открытый проект LibrePCB с помощью статического анализатора кода PVS-Studio. Однако статья интересна тем, что проверка осуществлялась внутри Docker контейнера. Если вы использует контейнеры, то надеемся, что статья продемонстрирует ещё один простой способ встроить анализатор в процесс разработки. — это свободное ПО для проектирования электронных схем и печатных плат. Код программы написан на языке C++, а для построения графического интерфейса используется Qt5. Недавно состоялся первый официальный релиз этого приложения, ознаменовавший собою стабилизацию собственного формата файлов (*.lp, *.lplib). Бинарные пакеты подготовлены для Linux, macOS и Windows.\r\nLibrePCB — это маленький проект, содержащий всего около 300 000 непустых строк кода на языке C и C++. При этом 25% непустых строк — это комментарии. Кстати, это большой процент для комментариев. Скорее всего, это связано с тем, что в проекте много маленьких файлов, существенную часть которых занимают заголовочные комментарии с информаций о проекте и лицензии. Код на сайте GitHub: .\r\nПроект показался нам интересным, и мы решили проверить его. А вот результаты проверки оказались уже не такими интересными. Да, нашлись настоящие ошибки. Но не было чего-то особенного, о чём непременно надо рассказать читателям наших статей. Возможно, мы бы не стали писать статью и ограничились отправкой найденных ошибок разработчикам проекта. Однако интересным моментом стало то, что проект был проверен внутри Docker образа, и поэтому мы решили, что написать статью всё же стоит. — программное обеспечение для автоматизации развёртывания и управления приложениями в среде виртуализации на уровне операционной системы. Оно позволяет «упаковать» приложение со всем его окружением и зависимостями в контейнер. Хотя этой технологии около пяти лет и многие компании давно внедрили Docker в инфраструктуры своих проектов, в мире open source это было не очень заметно до недавнего времени.\r\nНаша компания очень плотно работает с open source проектами, проверяя исходный код с помощью собственного статического анализатора PVS-Studio. На данный момент проверено . Самым сложным в этой деятельности всегда была компиляция чужих проектов, но внедрение Docker-контейнеров сильно упростило этот процесс.\r\nПервый опыт проверки open source проекта в Docker был с . Там разработчики сделали монтирование каталога исходных файлов к контейнеру и интеграция анализатора ограничилась редактированием одного из скриптов, выполняющихся в контейнере:\r\nОтличие проекта LibrePCB заключается в том, что они сразу предоставили  для сборки образа и проекта в нём. Это оказалось ещё более удобным для нас. Вот часть Docker-файла, которая нам интересна:\r\nКомпиляцию и установку проекта при сборке образа мы делать не будем. Таким образом, нами был собран образ, в котором автор проекта гарантирует успешную сборку проекта.\r\nПосле запуска контейнера был установлен анализатор и выполнены следующие команды для сборки и анализа проекта:\r\nКстати, все действия выполнялись в Windows 10. Очень радует, что разработчики всех популярных операционных систем тоже развиваются в этом направлении. К сожалению, контейнеры с Windows не так удобны. Особенно из-за невозможности также легко устанавливать софт.\r\nТеперь классический раздел, содержащий описание найденных нами ошибок с помощью статического анализатора кода PVS-Studio. Кстати, пользуясь случаяем, хочу напомнить, что в последнее время мы развиваем анализатор в сторону поддержки анализа кода для встраиваемых систем. Вот пара статей, которые некоторые наши читатели могли пропустить:\r\nПредупреждение PVS-Studio:  CWE-571 There are identical sub-expressions 'symbVarItemUuid' to the left and to the right of the '&&' operator. symbolpreviewgraphicsitem.cpp 74 опечатка: два раза подряд проверяется переменная . Выше находится аналогичная проверка, и, глядя на неё, становится ясно, что второй проверяемой переменной должна быть .\r\nСледующий фрагмент кода с опечаткой:\r\nПредупреждение PVS-Studio:  CWE-682 Two similar code fragments were found. Perhaps, this is a typo and 'eMaxPair' variable should be used instead of 'e'. clipper.cpp 2999\r\nСкорее всего, код писался с помощью Copy-Paste. Из-за недосмотра во втором блоке текста забыли заменить  на .\r\nПредупреждение PVS-Studio:  CWE-571 Expression 'content' is always true. html.c 162\r\nЭто скорее всё-таки не ошибка, а просто избыточный код. Не нужно повторно проверять указатель . Если он нулевой, то функция сразу завершает свою работу.\r\nАналогичная ситуация:\r\nПредупреждение PVS-Studio:  CWE-571 Expression 'e->OutIdx >= 0' is always true. clipper.cpp 2983\r\nПовторная проверка  не имеет смысла. Впрочем, возможно это ошибка. Например, можно предположить, что проверяться должна переменная . Однако это только догадка. Мы не знакомы с кодом проекта и не можем отличить ошибки от избыточного кода :).\r\nИ ещё один случай:\r\nПредупреждение PVS-Studio:  CWE-571 Recurring check. The 'child.isLineBreak()' condition was already verified in line 208. sexpression.cpp 209\r\nПредупреждение PVS-Studio:  CWE-571 Expression 'layer' is always true. footprintpreviewgraphicsitem.cpp 177\r\nПоскольку условие во втором операторе  всегда истинно, то ветка  никогда не выполняется.\r\nПредупреждение PVS-Studio:  CWE-476 The 'szComment' pointer was utilized before it was verified against nullptr. Check lines: 2068, 2073. unzip.c 2068\r\nЕсли , то разыменовывается указатель . Это опасно, так как этот указатель может быть нулевым. Такое заключение анализатор делает на основании того, что далее этот указатель проверяется на равенство .\r\nПредупреждение PVS-Studio:  CWE-457 Not all members of a class are initialized inside the constructor. Consider inspecting: isBad. edge.h 14\r\nВсе конструкторы, кроме первого, инициализируют поле класса . Скорее всего, в первом конструкторе просто случайно забыли сделать эту инициализацию. В результате, первый конструктор создаёт не до конца инициализированный объект, что может привести к неопределённому поведение программы.\r\nЕсть ещё 11 срабатываний диагностики . Однако, поскольку мы не знакомы с кодом, сложно говорить, указывают ли эти предупреждения на реальные проблемы. Думаю, эти предупреждения лучше изучить авторам проекта.\r\nПредупреждение PVS-Studio:  CWE-401 The exception was thrown without releasing the 'element' pointer. A memory leak is possible. projectlibrary.cpp 245\r\nЕсли некий элемент уже присутствует в списке, то будет сгенерировано исключение. Но при этом не уничтожается ранее созданный объект, указатель на который хранится в переменной .\r\nПредупреждение PVS-Studio:  CWE-755 An exception was thrown by pointer. Consider throwing it by value instead. cmdremoveselectedschematicitems.cpp 143\r\nАнализатор обнаружил исключение, брошенное по указателю. Чаще всего принято бросать исключения по значению, а перехватывать по ссылке. Бросание указателя может привести к тому, что исключение не будет поймано, так как перехватывать его будут по ссылке. Также использование указателя вынуждает перехватывающую сторону вызвать оператор  для уничтожения созданного объекта, чтобы не возникали утечки памяти.\r\nВ общем, оператор  написан здесь случайно и должен быть удалён. То, что это ошибка, подтверждается тем, что во всех остальных местах написано:\r\nПредупреждение PVS-Studio:  CWE-628 Dereferencing of the null pointer 'event' might take place. The potential null pointer is passed into 'handleMouseWheelEvent' function. Inspect the first argument. Check lines: 143, 252. graphicsview.cpp 143\r\nУказатель, являющийся результатом работы оператора , передаётся в функцию . В ней этот указатель разыменовывается без предварительной проверки.\r\nЭто опасно, так как оператор  может вернуть . Получается, что этот код ничем не лучше, чем просто использовать более быстрый .\r\nВ этот код следует добавить явную проверку указателя перед использованием.\r\nТакже, очень часто встречается код вот такого вида:\r\nПредупреждение PVS-Studio:  CWE-690 There might be dereferencing of a potential null pointer 'e'. graphicsview.cpp 206\r\nУказатель проверяется с помощью макроса . Вот его описание: плохой способ проверки указателей перед использованием. Как правило в Release версии  не определён. Я не знаю, как обстоит дело в проекте LibrePCB. Однако, если  определён в Release, то это странное и нестандартное решение.\r\nЕсли макрос раскрывается в пустоту, то получается, что никакой проверки нет. И тогда непонятно зачем вообще было использовать . Почему тогда не использовать ?\r\nВ общем, этот код с запахом и стоит провести обзор всех схожих фрагментов кода. И их, кстати, весьма много. \r\nВ целом проект LibrePCB показался нам качественным. Тем не менее, мы рекомендуем авторам проекта вооружиться инструментом PVS-Studio и самостоятельно провести Code Review участков кода, на которые указывает анализатор. Мы готовы предоставить им бесплатную лицензию на месяц для полноценного анализа проекта. Более того, они могут использовать бесплатный вариант лицензирования анализатора, так как код проекта является открытым и размещён на сайте GitHub. Про этот вариант лицензирования мы скоро напишем.\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: Andrey Karpov, Svyatoslav Razmyslov. .", "url": "https://habr.com/ru/company/pvs-studio/blog/433562/"},
{"title": "Профилирование кода с LLVM", "article_text": "\r\nНедавно я столкнулся с интересной задачей — мне понадобился детерминированный и кросплатформенный способ определения времени выполнения кода С++. Под словом «детерминированный» я подразумеваю, что один и тот же код будет выполняться за одно и то же количество единиц времени. Под кроссплатформенностью я понимаю, что один и тот же код под Windows и под Ubuntu будет выполняться за одно и то же количество единиц времени.\r\nЕстественно, измерение времени на CPU не удовлетворяет этим условиям. Машинный код меняется в зависимости от архитектуры и операционной системы, и один и тот же код займёт различное количество времени при выполнении. Даже на одной и той же машине, такие факторы, как промахи кэша, будут играть большую роль — достаточную для того, чтобы исказить результаты измерения времени выполнения одного и того же кода. Мне нужно было что-либо более умное…\r\nЯ столкнулся с этой проблемой, когда работал над моим проектом, Code Character. Code Character — это онлайновое соревнование AI, в котором участники пишут ботов для управления армией в пошаговой стратегии. Я хотел ограничить количество кода, которое участник может выполнить за один ход.\r\nМоей первой мыслью было просто измерять время выполнения кода, но, как мы видим, эта стратегия не является детерминированной, и участник, пославший один и тот же код два раза, получит совершенно разные результаты. Фактически, мы пытались реализовать это решение, и результаты меняются настолько сильно, что участник может выиграть или проиграть с одним и тем же кодом. Результат будет совершенно случайным, и мы отбросили идею об измерении времени.\r\nТак как мы не можем измерять время мы решили вместо этого измерять количество выполненных инструкций. Следовательно, нам необходим инструментировать код участников. Если вам не знаком этот термин, это добавление некоторого кода к приложению, с целью мониторинга какого-либо параметра, например, использования CPU или времени исполнения. Естественно, мы не ожидаем, что участники будут делать это сами, мы должны автоматизировать процесс.\r\nМы хотели избежать накладных расходов на рантаймовые инструменты при работе на нашем сервере, и поэтому что-либо типа инструмента не подходит для наших целей. Вместо этого, мы решили напрямую инструментировать код участников для того, чтобы подсчитать количество инструкций, которое будет выполнено. Вместо того, чтобы инструментировать бинарники (машинный код), мы решили использовать Clang для компиляции кода и инструментировать байткод LLVM.\r\nЕсли вы не знакомы с LLVM, он представляет собой коллекцию модульных и повторно используемых технологий компилятора и тулчейна. Одним из главных проектов является LLVM IR и бэкенд. В простых терминах, разработано промежуточное представление (Intermediate Representation), в которое компилирующий фронтенд компилирует код. Затем этот код, LLVM IR, компилируется в машинный код бэкендом LLVM. Таким образом, если вы делаете новый язык, вы можете решить позволить LLVM поддерживать генерацию машинного кода и его оптимизацию, и написать фронтенд для преобразования вашего языка в LLVM IR.\r\n \r\nClang является фронтендом LLVM. Так как нам нужен кроссплатформенный метод измерения кода, мы не можем инструментировать бинарный код. LLVM IR, однако, является платформенно-независимым, так как это только промежуточное представление кода. Инструментирование IR кода с помощью библиотек LLVM является простым кросс-платформенным решением.\r\nПростой подсчёт инструкций LLVM IR очевидно, не подходит, так как нам нужно количество инструкций, которые будут реально выполняться, а не просто количество инструкций в коде. В конце концов, мы разработали простой алгоритм, основанный на концепции базовых блоков кода.\r\nБазовым блоком называется набор инструкций, в котором входной точкой может быть только первая инструкция, а выходной точкой — только последняя инструкция. () Чтобы понять это, попробуйте разделить код на куски, в которых инструкции ветвления (переходов, циклов и возвратов) могут быть только последними в наборе, а вход в блок (первая инструкция в функции, цикле или блоке if/else) возможен только на первую инструкцию. В результате получается набор базовых блоков — блоков последовательного кода, который просто выполняется последовательно, без принятия решений о том, какая инструкция выполняется следующей.\r\n \r\nПочему бы нам не попробовать прямо сейчас? Это фрагмент кода, предоставленного участником Code Character:\r\nСсылка на Github:\r\nИспользуя факт, что базовый блок имеет только одну входную точку (первую инструкцию), мы можем разделить этот фрагмент на следующие базовые блоки:\r\nЭто помогло нам понять, как работают базовые блоки, теперь рассмотрим этот алгоритм в LLVM IR:\r\nЕсли вы посмотрите внимательно, вы заметите, что фрагмент кода, приведённый выше, представляет собой первые три блока фрагмента кода С++, скомпилированный в LLVM IR (каждая строка  — это начало базового блока).\r\nВ LLVM есть библиотеки, которые позволяют нам писать «проходы» — код, который может преобразовывать LLVM IR. LLVM API позволяет нам легко читать и анализировать LLVM IR путём итераций по модулям, функциям и базовым блокам, и модифицировать LLVM IR перед тем, как он будет скомпилирован в машинный код.\r\nСейчас у нас есть базовые блоки и LLVM API, становится простым делом подсчитать количество выполняемых инструкций при помощи такого простого алгоритма:\r\nНаш инструментированный IR работает так:\r\nКак мы видим, вызов IncrementCount сделан в конце каждого базового блока прямо перед последней инструкцией. Используя статический int, с которым работает IncrementCount, мы можем получить число инструкций в конце каждого хода участника. Этот способ детерминированный и кросс-платформенный, т.к. один и тот же исходный код гарантированно порождает один и тот же LLVM IR, если мы используем ту же версию компилятора и те же флаги.\r\nПрофилирование кода не такая простая вещь, как я когда-то думал. В процессе работы над такой относительно простой задачей, я ознакомился с тем, как работает компилятор, и как писать проходы LLVM. Если вам интересна генерация кода и вы хотите писать собственные проходы, LLVM имеет . также есть отличная в блоге, которую я использовал при написании моего собственного прохода. Так как LLVM API не имеет обратной совместимости между мажорными версиями, обращайте внимание на то, какую версию LLVM вы используете.\r\nИсходный код прохода вы можете взять .", "url": "https://habr.com/ru/post/417029/"},
{"title": "Удивительная производительность параллельных алгоритмов C++17. Миф или Реальность?", "article_text": "Добрый вечер!\r\nОт нашего курса  предлагаем вам небольшое и интересное исследование про параллельные алгоритмы. \r\nПоехали.\r\nС появлением параллельных алгоритмов в C++17, вы с легкостью можете обновить свой “вычислительный” код и получить выгоду от параллельного выполнения. В этой статье, я хочу рассмотреть STL алгоритм, который естественным образом раскрывает идею независимых вычислений. Можно ли ожидать 10-кратного ускорения при наличии 10-ядерного процессора? А может больше? Или меньше? Поговорим об этом.\r\nC++17 предлагает параметр политики выполнения для большинства алгоритмов:\r\nКратко:\r\nВ качестве быстрого примера вызовем  параллельно:\r\nОбратите внимание, как просто добавить параметр параллельного выполнения в алгоритм! Но удастся ли добиться значительного улучшения производительности? Увеличит ли это скорость? Или есть случаи замедления?\r\nВ этой статье, я хочу обратить внимание на алгоритм , который потенциально может быть основой для других параллельных методов (наравне с , , , ...).\r\nНаш тестовый код будет строиться по следующему шаблону:\r\nПредположим, что у функции нет никаких методов синхронизации, в таком случае у кода есть потенциал параллельного выполнения или даже векторизации. Каждое вычисление элемента независимо, порядок не имеет значения, поэтому реализация может порождать несколько потоков (возможно в пуле потоков) для независимой обработки элементов.\r\nЯ бы хотел поэкспериментировать со следующими вещами:\r\nКак видите, я хочу не только протестировать количество элементов, которые “хороши” для использования параллельного алгоритма, но и ALU-операции, которые занимают процессор.\r\nПрочие алгоритмы, такие как сортировка, накопление (в виде std::reduce) также предлагают параллельное выполнение, но и требуют больше работы для вычисления результатов. Поэтому будем считать их кандидатами для другой статьи.\r\nПримечание об бенчмарках\r\nДля своих тестов я использую Visual Studio 2017, 15.8 — поскольку это единственная реализация в популярной реализации компилятора/STL на текущий момент (Ноябрь, 2018) (GCC в пути!). Более того, я сосредоточился только на , так как  недоступна в MSVC (работает аналогично ).\r\nЕсть два компьютера:\r\nКод скомпилирован в x64, Release more, автовекторизация включена по-умолчанию, также я включил расширенный набор команд (SSE2) и OpenMP (2.0).\r\nКод находится в моем github’е: \r\nДля OpenMP (2.0) я использую параллельность только для циклов:\r\nЗапускаю код 5 раз и смотрю на минимальные результаты.\r\nБолее подробно о MSVC реализации можно прочитать в . А  Билла О’Нила с CppCon 2018 (Билл реализовал Parallel STL в MSVC).\r\nНу что ж, начнем с простых примеров!\r\nРассмотрим случай, когда вы применяете очень простую операцию к входному вектору. Это может быть копирование или умножение элементов.\r\nНапример:\r\nВ моем компьютере 6 или 4 ядра… могу ли я ожидать 4..6-кратного ускорение последовательного выполнения? Вот мои результаты (время в миллисекундах):\r\nНа более быстрой машине можем увидеть, что понадобится около 1 миллиона элементов, чтобы заметить улучшение производительности. С другой стороны, на моем ноутбуке все параллельные реализации были медленнее.\r\nТаким образом, заметить какое-либо значительное улучшение производительности при помощи таких трансформаций сложно, даже при увеличении количества элементов.\r\nПочему же?\r\nПоскольку операции элементарные, ядра процессора могут вызывать его практически мгновенно, используя всего несколько циклов. Однако, ядра процессора тратят больше времени, ожидая основную память. Так что, в этом случае, по большей части они будут ждать, а не совершать вычисления.\r\nМожно грубо заметить, что если ваш алгоритм зависит от памяти, то не стоит ожидать улучшения производительности с параллельным вычислением.\r\nПоскольку пропускная способность памяти крайне важна и может влиять на скорость вещей… давайте увеличим количество вычислений, влияющих на каждый элемент.\r\nМысль в том, что лучше использовать циклы процессора, а не тратить время на ожидание памяти.\r\nДля начала, я использую тригонометрические функции, например,  (это условные вычисления в неоптимальной форме, просто чтобы занять процессор).\r\nМы используем , и , которые могу занять ~20 на и ~100 на тригонометрическую функцию. Такое количество вычислений может покрыть задержку на доступ к памяти.\r\nБолее подробно о задержках команд написано в прекрасной статье .\r\nВот бенчмарк-код:\r\nИ что же теперь? Можем ли мы рассчитывать на улучшение производительности по сравнении с предыдущей попыткой?\r\nВот некоторые результаты (время в миллисекундах):\r\nНаконец-то мы видим неплохие числа :)\r\nДля 1000 элементов (здесь не показанных), время параллельного и последовательного вычисления было схожи, поэтому для более 1000 элементов мы видим улучшение в параллельном варианте.\r\nДля 100 тысяч элементов результат на более быстром компьютере почти в 9 раз лучше последовательной версии (аналогично для OpenMP версии).\r\nВ наибольшем варианте из миллиона элементов — результат быстрее в 5 или 8 раз.\r\nДля таких вычислений я добился “линейного” ускорения, зависящего от количества ядер процессора. Чего и стоило ожидать.\r\nВ разделе выше я использовал “выдуманные” вычисления, но что насчет настоящего кода?\r\nДавайте, решим уравнения Френеля, описывающие отражение и искривление света от гладкой, плоской поверхности. Это популярный метод для генерации реалистичного освещения в трехмерных играх.\r\nВ качестве хорошего образца я нашел .\r\nВместо создания собственной реализации, я использовал . Я часто ей пользуюсь в своих OpenGl проектах.\r\nК библиотеке легко получить доступ через , поэтому им я тоже буду пользоваться.  на пакет.\r\nФайл Conan: \r\nи командная строка для установки библиотеки (она генерирует props-файлы, которые я могу использовать в проекте Visual Studio):\r\nБиблиотека состоит из заголовка, поэтому вы можете просто скачать ее вручную, если хотите.\r\nЯ адаптировал код для glm из :\r\nКод использует несколько математических инструкций, скалярное произведение, умножение, деление, так что процессору есть, чем заняться. Вместо вектора double мы используем вектор из 4х элементов, чтобы увеличить количество используемой памяти.\r\nБенчмарк:\r\nИ вот результаты (время в миллисекундах):\r\nС “настоящими” вычислениями видим, что параллельные алгоритмы обеспечивают хорошую производительность. Для таких операций на двух моих машинах с Windows я добился ускорения с почти линейной зависимостью от количества ядер.\r\nДля всех тестов я также показал результаты из OpenMP и двух реализаций: MSVC и OpenMP работают аналогично.\r\nВ этой статье я разобрал три случая применения параллельного вычисления и параллельных алгоритмов. Замена стандартных алгоритмов на версию std::execution::par может показаться очень заманчивой, но делать это стоит не всегда! Каждая операция, используемая вами внутри алгоритма может работать иначе и быть более зависимой от процессора или памяти. Поэтому рассматривайте каждое изменение отдельно. \r\nО чем стоит помнить:\r\nОсобое спасибо JFT за помощь со статьей!\r\nТакже обратите внимание на мои другие источники о параллельных алгоритмах:\r\nОбратите внимание на другую статью, связанную с Параллельными Алгоритмами: \r\nTHE END\r\nЖдём и комментарии, и вопросы, которые можно оставить тут или у нашего на .", "url": "https://habr.com/ru/company/otus/blog/433588/"},
{"title": "Усложняя стандартный пример", "article_text": "Стандартная библиотека С++ предлагает не только набор классов, но также определяет способ написания программ. В рамках данной статьи рассматриваются общие требования к реализации программ при помощи STL. \r\nРассмотрим следующую задачу:Можно написать следующее решение:\r\nНесколько слов о «магии» в коде:\r\nЭтот пример, на самом деле, довольно прост. Однако он может нам помочь в решении следующей задачи: В принципе, решение будет практически таким же. Однако, для сохранения решения необходимо провести подготовительную работу, а именно:\r\nНу и, собственно, точка входа в программу:\r\nКак можно заметить, изменения функции main минимальные, касаются только типа элементов вектора. Плюс добавлен вызов алгоритма copy_if. Этот полезный алгоритм появился со стандартом С++11, он копирует элементы из одного контейнера в дргой только те элементы, которые удовлетворяют условию.  \r\nСпасибо, что дотерпели!", "url": "https://habr.com/ru/post/433218/"},
{"title": "Уязвимости EOS Blockchain на ZeroNights 2018", "article_text": "\r\nВ рамках данной статьи будут рассмотрены несколько реальных уязвимостей в EOS blockchain (одном из конкурентов Ethereum) и то, как они были встроены в  на ZeroNights 2018. Если вам интересно познакомиться с тем, как обстоят дела с безопасностью в этой сети blockchain, то welcome под кат.\r\nВсе началось с того, что недавно, во время аудита смарт-контрактов Etherium на безопасность, один наш знакомый скидывает нам  про уязвимости в смарт-контрактах в сети EOS. Нас это сильно заинтересовало, и мы решили разобраться в уязвимостях более детально. \r\nВсё это в итоге и привело к созданию конкурса на ZeroNights 2018 под названием «Однорукий бандит» с уязвимостями в смарт-контракте.\r\nНачнем непосредственно с рассмотрения сети блокчейн EOS, как с ним работать, и как у него все устроено внутри. Статей, описывающих технологию, в Интернете много, поэтому, скорее всего, всех технических деталей не будет, но общий смысл мы постараемся передать так, чтобы и обычный пользователь смог получить элементарное представление о механизмах работы blockchain EOS. \r\nEOS.io – блокчейн нового поколения от компании , основанный на концепции PoS (). \r\nИз описания самих создателей сети: «EOS — это бесплатное программное обеспечение сети блокчейн с открытым исходным кодом, который предоставляет разработчикам и предпринимателям платформу для создания, развертывания и запуска высокопроизводительных децентрализованных приложений (DAPP).»\r\nЕсли в двух словах попытаться объяснить концепцию, то её хорошо отражает выдержка из  на Википедии: Сеть совсем новая, и первый запуск главной сети (mainnet) состоялся 10 июня 2018 года. Основной крипто-валютой является EOS, а главный портал для разработчиков \r\nБлокчейн EOS.io поддерживает приложения, созданные пользователями с использованием кода WebAssembly (WASM) – нового веб-стандарта с широкой поддержкой крупных компаний, таких как Google, Microsoft, Apple и других.\r\nНа данный момент наиболее свежим инструментарием для создания приложений, которые компилируют код в WASM, является clang / llvm с их компилятором C / C ++. \r\nДля лучшей совместимости разработчики рекомендуют использовать EOSIO CDT (Contract Development Toolkit) – набор утилит от самих разработчиков для удобной и корректной работы над созданием смарт контрактов. \r\nПредыдущий компилятор eosiocpp уже deprecated и не поддерживается, поэтому всем рекомендуется переходить на новый (на момент написания статьи) EOSIO CDT 1.5.\r\nЭфир в своей концепции использует PoW (Proof of Work), что требует дорогостоящих вычислений и награду получает тот, кто первый решил математическую задачу. То есть те, кто решал параллельно, но не успел решить, попусту затратили электроэнергию. В этой ситуации майнеры воюют между собой за более совершенные технологии и оборудование. Чтобы быстрее генерировать блоки и, тем самым, зарабатывать. \r\nВ отличие от Эфира в сети ЕОС по концепции PoS создателя нового блока выберет система, и определяется это по количеству личного состояния – доли от общего количества криптовалюты. Таким образом, у кого больше состояние, у того больше шансы быть выбранным системой. Но в отличие от PoW (эфира) вознаграждение за генерацию нового блока отсутствует в принципе, и доход майнеров составляют исключительно комиссии с транзакций.\r\nВывод — криптовалюты на базе PoW могут быть в 1000 раз более энергоэфективными.\r\nТак, с теорией вроде покончили, переходим к практике. А на практике всё выглядит гораздо интереснее. С документацией на момент, когда пытались разобраться летом и начать что-то делать для ZeroNights 2018, было всё совсем плохо, а основной портал для разработки глючил, был наполовину пуст и иногда даже не работал.\r\nТестовые сети еще толком не были запущены, поэтому пришлось разворачивать свою ноду. Кстати, в отличие от мнения в интернете, завести ее оказалось не так сложно. Пользуясь официальной документацией, мы запустили ее из докера \r\nРасскажем о основных утилитах, программах для работы с блокчейном EOS, с которыми пришлось иметь дело в момент работы над конкурсом:\r\nУфф!.. Да, программок много, разобраться в них тоже не совсем легко. Описание всего этого заслуживает отдельного поста и выходит за рамки данной статьи. Но давайте представим, что мы установили ноду на свой сервер и даже научились при помощи cleos вызывать методы контракта, если бы он у нас был. \r\nДа, самое главное. Надо бы нам набросать сам смарт-контракт. Писать мы его будем на C++ и, чтобы сделать хоть что-то толковое, пришлось прочитать немало документации.\r\nДля понимания контрактов везде приводят пример контракта . Основным файлом является hello.cpp и весь контракт описан в нем\r\nЕсли в двух словах постараться объяснить, то тут – . Подгружаем библиотеку eosio.hpp, затем создаем класс (он же контракт) hello и унаследуем класс contract. Создаем void метод hi и в параметры заносим переменную user c типом account_name, он же uint64_t. В методе выводим “Hello, ” и имя, которое мы укажем при вызове метода. Последняя строчка, где находится EOSIO_ABI –это вспомогательный макрос, который принимает наш класс и общедоступные методы из этого класса, а также участвует в формировании файла .abi, где указываются все общедоступные методы контракта.\r\nПри вызове контракта нода проверяет тип параметра, и если данные, которые мы пытаемся ей скормить, не подходят, то нода начнет ругаться и такое бесчинство не пропустит. НО! Если внутри контракта есть какой-нибудь алгоритм изменения числа, сумма чисел или, допустим, умножение, то число может измениться уже внутри контракта. А это значит, что можно указать такое число, которое нода пропустит, а вот контракт умножит, и число выйдет за рамки допустимого типа данных, что и приведет к переполнению. \r\nЧто это может дать? К примеру, есть проверка на какой-то числовой параметр, допустим, int Number < 0, и известно, что int у – знаковое число, и если произойдет переполнение числа, то знак числа при больших значениях изменится на отрицательный. Тем самым, проверка будет пройдена переполнением. И тут, конечно, всё зависит от критичности данной проверки. \r\nК примеру, в той же статье про уязвимости есть , где злоумышленники смогли повлиять на параметр balance, тем самым обманув систему. В комментариях к коду более подробно описан механизм взаимодействия с контрактом:\r\nВзлом скорее всего был осуществлен следующим образом. Злоумышленник предварительно создал 4 аккаунта и вызвал метод  напрямую, приблизительно так:\r\nОговорюсь сразу, это лишь предположение; как точно произвели взлом – мы не знаем, и если будут другие мысли по этому поводу или более точная информация, то пишите в комментариях.\r\nОтсутствие проверки метода контракта require_auth() на авторизации пользователя приведет к тому, что любой человек, не обладающий нужными правами, сможет воспользоваться привилегированными методами контракта, например, вывод денег с контракта.\r\nПри отправке на контракт денег (EOS) можно указать в специальном макросе, что будет происходить дальше и что делать. Скажем, при получении денег будет вызываться некий алгоритм, например, запускаться рулетка или еще что-нибудь, а также проверка:\r\nВ этой проверке нет ограничения вызова метода transfer, из-за чего можно метод трансфер вызвать напрямую, без пересылки денег на контракт. А это означает запуск механизма с дальнейшим выигрышем, не тратя ни копейки. \r\nИдея конкурса родилась сама по себе: раз всё связано с играми и тремя уязвимостями, следовательно, будем делать игру на механизме смарт-контракта в блокчейне EOS.io. Игра должна быть максимально простой, но интересной.\r\nИгровой автомат «Однорукий бандит»! Всегда удивляли люди, жаждущие легкой наживы — помните, халявы в мире не бывает, или почти не бывает. Тут, кстати, она вполне есть, вернее, появится, когда в ход пойдут уязвимости.\r\nФронтенд игры решили сделать модным, красивым и трехмерным. Спасибо , за то, что не отказался поучаствовать и помог нам сделать полностью фронтенд на Unity3d движке. \r\nТрехмерный игровой аппарат «однорукий бандит»; отправив на него 1 ЕОС и дернув за шикарный рычаг, игрок получает возможность запустить колесо фортуны и сорвать куш!\r\nПо задумке игры, выигрышем считалось выпадение трёх матрёшек ZeroNights, что в числовом коэффициенте будет либо 777, либо 0.Шансы на выигрыш приравнивались к 0.02%, и некий невнимательный программист попытался усложнить алгоритм рандома, добавив в него всего лишь умножение (multiplication overflow) на количество присланных денег, и поленился обдумывать условия детальнее, поэтому просто написал if (result == 777 || result < 1 ), что дает возможность подсунуть отрицательное значение.\r\nСам смарт-контракт выложен на , так что все желающие могут его повнимательнее рассмотреть со всех сторон и определить остальные уязвимости. О них уже написано чуть выше, так что сложностей в их поиске быть не должно.\r\nПравила участия очень просты: необходимо было попытаться выиграть или взломать механизмы системы. При выпадении 3 матрешек – Джек-пот!!! Система начисляет 100 единиц крипто-валюты. Если участник получает джек-пот 3 раза подряд, он становится победителем и получает призы от организаторов — фирменные худи, значки, разнообразный мерч.\r\nКонечно, можно было выиграть, долго дергая рычаг и надеясь на удачу, но фортуна — штука непредсказуемая, да и процент выигрыша очень мал, так что проще было взломать.\r\nВ итоге конкурс, на наш взгляд, прошел идеально. Были запланированы награды для 3 человек, и как раз троим удалось справиться с конкурсом до назначенной даты окончания. Конкурс проводился 2 дня, в течение которых участники должны были решить таск. Официальное награждение и вручение подарков было на закрытии конференции на главной сцене ZeroNights 2018.\r\nОсновной упор делался на познавание технологии блокчейн ЕОС, и нами была оставлена пара подсказок, одну из которых так никому не удалось найти. Эту загадку мы оставим на потом… (1 место) (2 место) (3 место)\r\nНе скажем, что все справились легко. Для кого-то это были сложные 2 дня, и только под конец счастливчикам удалось победить, используя недостатки любого блокчейна — если информация попала в блокчейн, то доступна каждому, и если кто-то уже что-то взломал, то и другой может посмотреть его путь.\r\nБлагодарим всех участников и тех, кто помогал в организации конкурса.\r\nДо встречи на ZeroNights 2019, вас будут ждать новые приключения!", "url": "https://habr.com/ru/company/dsec/blog/433552/"},
{"title": "Алгоритм резервуарной выборки", "article_text": "Резервуарная выборка (eng. «reservoir sampling») — это простой и эффективный алгоритм случайной выборки некоторого количества элементов из имеющегося вектора большого и/или неизвестного заранее размера. Я не нашел об этом алгоритме ни одной статьи на Хабре и поэтому решил написать её сам.\r\nИтак, о чём же идёт речь. Выбрать один случайный элемент из вектора — это элементарная задача: \r\nЗадача «вернуть K случайных элементов из вектора размером N» уже хитрее. Здесь уже можно ошибиться — например, взять K первых элементов (это нарушит требование случайности) или взять каждый из элементов с вероятностью K/N (это нарушит требование взять ровно K элементов). Кроме того, можно реализовать и формально корректное, но крайне неэффективное решение «перемешать случайно все элементы и взять K первых». И всё становится ещё интереснее, если добавить условие того, что N — число очень большое (нам не хватит памяти сохранить все N элементов) и/или не известно заранее. Для примера представим себе, что у нас есть какой-то внешний сервис, присылающий нам элементы по одному. Мы не знаем сколько их придёт всего и не можем сохранить их все, но хотим в любой момент времени иметь набор из ровно K случайно выбранных элементов из уже полученных. \r\nАлгоритм резервуарной выборки позволяет решить эту задачу за O(N) шагов и O(K) памяти. При этом не требуется знать N заранее, а условие случайности выборки ровно K элементов будет чётко соблюдено.\r\nПусть K=1, т.е. нам нужно выбрать всего один элемент из всех пришедших — но так, чтобы у каждого из пришедших элементов была одинаковая вероятность быть выбранным. Алгоритм напрашивается сам собой:: Выделяем память на ровно один элемент. Сохраняем в неё первый пришедший элемент.\r\nПока всё ок — нам пришел всего один элемент, с вероятностью в 100% (на данный момент) он должен являться выбранным — так и есть.: Второй пришедший элемент с вероятностью 1/2 перезаписываем в качестве выбранного.\r\nЗдесь тоже всё хорошо: нам пока пришло только два элемента. Первый остался выбранным с вероятностью 1/2, второй перезаписал его с вероятностью 1/2.: Третий пришедший элемент с вероятностью 1/3 перезаписываем в качестве выбранного.\r\nС третьим элементом всё хорошо — его шанс быть выбранным равен ровно 1/3. Но не нарушили ли мы каким-либо образом равенство шансов предыдущих элементов? Нет. Вероятность того, что на этом шаге выбранный элемент не будет перезаписан равна 1 — 1/3 = 2/3. А поскольку на шаге 2 мы гарантировали равенство шансов каждого из элементов быть выбранным, то после шага 3 каждый из них может оказаться выбранным с шансом 2/3 * 1/2 = 1/3. Ровно такой же шанс, как и у третьего элемента.: С вероятностью 1/N элемент номер N перезаписываем в качестве выбранного. У каждого из предыдущих пришедших элементов остаётся тот же шанс 1/N остаться выбранным.\r\nНо это была упрощённая задача, при K=1. : Выделяем память на K элементов. Записываем в неё первые K пришедших элементов.\r\nЕдинственный способ взять K элементов из K пришедших элементов — это взять их все :) : (для каждого N > K): генерируем случайное число X от 1 до N. Если X > K то отбрасываем данный элемент и переходим к следующему. Если X <= K, то перезаписываем элемент под номером X. Поскольку значение X будет равномерно случайно на диапазоне от 1 до N, то при условии X <= K оно будет равномерно случайно и на диапазоне от 1 до K. Таким образом мы обеспечиваем равномерность выбора перезаписываемых элементов.\r\nКак можно заметить — каждый следующий пришедший элемент имеет всё меньшую и меньшую вероятность быть выбранным. Она, тем ни менее, всегда будет равна ровно K/N (как и для каждого из предыдущих пришедших элементов). \r\nПлюс этого алгоритма в том, что мы можем в любой момент времени остановиться, показать пользователю текущий вектор K — и это будет вектор честно выбранных случайных элементов из пришедшей последовательности элементов. Возможно, пользователя это устроит, а возможно, он захочет продолжить обработку входящих значений — мы можем это сделать в любой момент. При этом, как упоминалось в начале, мы никогда не используем больше, чем О(K) памяти.\r\nАх да, совсем забыл, в стандартную библиотеку С++17 наконец вошла функция , делающая ровно то, что описано выше. Стандарт не обязывает её использовать именно резервуарную выборку, но обязывает работать за O(N) шагов — ну и вряд ли разработчики её реализации в стандартной библиотеке выберут какой-то алгоритм, использующий более, чем О(K) памяти (а меньше тоже не получится — результат же нужно где-то хранить).", "url": "https://habr.com/ru/company/infopulse/blog/431652/"},
{"title": "Прикручиваем мультиплеер к мобильной игре «Составь слова из слова» на iOS и Android, написанной на C++", "article_text": "Ранее я уже писал о своем опыте разработки мобильной  на Android и iOS, которая пользуется определенной популярностью, и я решил прикрутить к ней режим мультиплеера, когда два игрока соревнуются между собой, составляя слова по очереди, как заключительном раунде телепередачи Сергея Супонева «Звездный час».\r\nНа изучение и реализацию мультиплеера у меня ушло полтора месяца, в статье я постараюсь описать концпецию без примеров исходного кода, сделав выжимку из объема проделанной работы.\r\nПриложение было написано на языке С++ c использованием Marmalade SDK. С тех пор вендор прекратил поддержку этой платформы, продав сорцы японцам, и будущее этой среды разработки стало очень туманным.\r\nВстал вопрос о том, на что же портировать текущие проекты для их дальнейшей поддержки. — один из самых распространенных движков разработки кроссплатформенных мобильных игр на C++. Видимо, засчет своей бесплатности и открытого исходного кода. Движок плохо документирован. Описание покрывает скудную часть движка и большая часть материала давно устарела.\r\nПо результатам какого-то периода мне все-таки удалось создать прототип своего приложения. Но впечатления были очень нехорошие: такое ощущение, что cocos2d-x собран на коленке. Уровни абстракции Scene, Sprite, Application Delegate показались мне очень неудобными, а необходимость искать ответы на вопросы на кокосовом форуме все чаще приводят тебя к мысли, что ты занимаешься чем-то не тем. Наверное руки у меня не из того места растут., так же как и Marmalade SDL, это не движок, это платформа. Он предоставляет низкоуровневое API, из которого я потом выстраиваю удобные мне уровни абстракции. Написано все это на языке C, исходный код открыт.\r\nЕсли в двух словах, то SDL — это свободная кроссплатформенная библиотека для работы с графикой, звуком, и обработки сообщений от операционной системы. Очень удобно делать win32-сборку и отлаживать логику игры на винде, оставляя для мобильных эмуляторов и физических устройств только отладку специфичного для ОС функционала.\r\nК счастью или сожалению, в SDL не предусмотрены инструменты, для такой узкой задачи, как разработка мультиплеера для iOS и Android, поэтому мне пришлось интегрироваться с соответствующими сервисами самому.\r\nЛогика приложения и вся работа с графикой реализована в основном потоке, который представляет из себя цикл обработки сообщений и стартует в функции main. Назовем этот поток SDL Thread. В свою очередь другие потоки, бросают ему события (SDL_PushEvent) для обработки в очередь, а тот читает их из нее с помощью SDL_WaitEvent и SDL_PollEvent. Это либо системные события, бросаемые системой и поддержка которых уже реализована в SDL, либо вызовы Callback-ов и Listener-ов, которые мы реализуем уже сверх функционала SDL.\r\nВся логика игры написана на C++. Каталог проекта содержит набор *.cpp файлов, которые можно разделить на три группы:\r\nСоответственно есть три отдельных каталога под проект каждой платформы: \r\nТеперь нам нужно приклеить отдельный слой, который будет отвечать за такой функционал как:\r\nОбе платформы iOS и Android поддерживают Real-time Multiplayer (RTMP). В случае с Android мы интегрируемся с Google Play Services (GPS), в случае с iOS — Game Center. Ранее Google поддерживал и интеграцию с iOS, но в этом году решил от нее отказаться.\r\nВ данной статье я не буду описывать те действия, которые нужно выполнить в Google Play Console и AppStoreConnect для настройки мультиплеера, не буду описывать спецификацию классов и методов интеграции — все это описано на сайтах вендоров.\r\nДалее я кратко опишу, какие изменения нужно сделать в проекте для каждой из платформ.\r\nКак? Я об этом еще не сказал? Для компиляции C++ кода используется . Хотя, если Вы Android-разработчик, то и так знаете. для интеграции Google Play Services в Android-проект описана на сайте для Android-разработчиков. В своем проекте я использую следующие зависимости:\r\nИзначально была мысль заюзать , которое поставляется в виде скомпилированных статических библиотек без исходников. Из-за того, что в списке библиотек отсутствует сборка под платформу x86_64, я решил, что ребята из Google не очень-то и следят за актуальностью этого SDK и решил  написать этот слой на Java, обернув его -врапперами. Да и потом, зачем мне лишняя зависимость в виде либ без исходников, которые внутри себя все равно дергают Java? Помимо актуальности Java-классов нужно будет следить еще и за актуальностью этих либ.\r\nВ качестве пособия использовал наглядный пример из . Спасибо Google за это. Apple, бери пример с Google!\r\nДля интеграции с Game Center необходимо подключить GameKit framework. Весь слой интеграции с Game Center опишем в одном *.m-файле и интерфейс к нему предоставим через отдельный *.h файл. Так как C++ является подмножеством языка objective-C, то и со сборкой *.cpp и *.m файлов в одном проекте проблем не возникнет.\r\nПомимо  руководствовался этим проектом: . Правда некоторые вещи из примера уже устарели, XCode 10 Вам на это укажет и Вы замените устаревший функционал новым.\r\nИзучив особенности работы с мультиплеерам на обоих платформах, для своего приложения я создал единую C++ асбстракцию и в момент компиляции под нее «подкладывается» соответствующая реализация в зависимости от конкретной платформы. То есть, мое приложение не знает ни о каких Google Play Services, Game Center и их особенностях. Оно знает только предоставленное ей C++ api, где например, есть такие методы, как:\r\nИгрок может пригласить друга из списка своих контактов, либо начать игру со случайным соперником. Игрок, получивший приглашение, может его принять, либо отклонить. Для всех этих сценариев я использую стандартный интерфейс используемого сервиса. Хочется отметить, что гугловые мордочки смотрятся гораздо приятнее iOS-овских. Может быть когда-нибудь руки доберутся и я напишу свой интерфейс с домино и барышнями.\r\nКогда два игрока подключились к виртуальной игровой комнате, они получают соответствующие Callback-и. Теперь надо выбрать, кто будет хостом.\r\nСреди игроков нужно выбрать хоста, чтобы именно он определил начальное состояние игры.\r\nРассмотрим возможные способы маршрутизации сообщений между игроками в общем случае. Обратите внимание, что во втором варианте хосту еще отводится и роль маршрутизатора.\r\nПоскольку у меня всегда в игре только два игрока, то, выходит, у меня частный случай peer-to-peer соединения. И поэтому на роль хоста выпадает только определение начального состояния, а именно — выбор слова, из которого будут составляться слова.\r\nИтак, после того, как произошло подключение игроков к игровой комнате, каждому из игроков известен список идентификаторов участников начавшейся игры. Будем называть его список of . participantID — это некий уникальный строковый идентификатор участника игры, который присваивается сервисом. Нужно выбрать, кто из них будет хостом, донести это до самого хоста и сообщить другому, что в качестве хоста выбран его соперник. Как это сделать?\r\nВ гугловой доке я не нашел советов по выбору хоста. Молчат, партизаны. Но добрые люди на  кинули ссылку на , где подробно объясняется следующий принцип:\r\nДля iOS есть метод , который значительно упрощает сценарий выбора хоста по сравнению с тем, что я описал для Android. Но, судя по заметным задержкам во время вызова этого метода, он оценивает параметры отклика сети, меряет ping-и и на основе этой статистики решает, кому быть хостом. Это скорее подходит для приведенной выше клиент-серверной архитектуры, где хост выполняет роль маршрутизатора. В моем же варианте частного peer-to-peer соединения это не имеет смысла и в целях экономии времени я юзаю принцип, аналогичный тому, что я сделал для Android.\r\nЧто представляет собой сообщение? Сообщение — это массив байт.\r\nСуществует 2 типа отправки сообщений: \r\nКак правило Unreliable доставляется быстрее, чем Reliable. Подробнее можно прочитать на сайте вендоров:\r\nКак мы будем использовать это массив? Очень просто: \r\nИтак, определяем  с типами сообщений, которыми игроки будут обмениваться между собой в процессе игры:\r\nКогда приложение получает входящее сообщение от соперника, вызывается соответствующий Callback, который в свою очередь передает его основному потоку SDL Thread для обработки.\r\nИгровые сервисы (что у Google, что у Apple) имеют функционал listener-ов, которые в том или ином виде призваны оповещать нас о разрыве связи с соперником. Но, я заметил, что если одного из игрока отключить от интернета, то второй далеко не сразу узнает, что первый отключился и играть-то не с кем. Callback-и в таких случаях не вызываются, либо вызываются по прошествии достаточно долгого времени. Чтобы в этом случае второму игроку не ждать, когда рак на горе свистнет, мне пришлось сделать собственный мониторинг соединения, работающий по принципу:\r\nВ результате проделанной работы я получил игру, в которую играю сам со своими друзьями и семьей. Играю как на iOS, так и на Android-е.\r\nПравда на iOS есть нюанс — почему-то не фиксируются очки в Leaderboards, о чем в настоящий момент я веду переписку со службой поддержки Apple.\r\nНадеюсь, эта статья будем полезна как и участникам моей команды, так и тем, кто интересуется разработкой мобильных приложений. Спасибо за внимание.", "url": "https://habr.com/ru/post/433172/"},
{"title": "Три вида утечек памяти", "article_text": "Здравствуйте, коллеги.\r\nНаши долгие поиски неустаревающих бестселлеров по оптимизации кода пока дают лишь первые результаты, но мы готовы вас порадовать, что буквально только что закончен перевод легендарной книги Бена Уотсона \"\". В магазинах — ориентировочно в апреле, следите за рекламой.\r\nА сегодня предлагаем вам почитать сугубо практическую статью о наиболее насущных видах утечек оперативной памяти, которую написал  (Nelson Elhage) из компании . \r\nИтак, у вас получилась программа, на выполнение которой тратится чем дальше — тем больше времени. Вероятно, вам не составит труда понять, что это верный признак утечки в памяти.\r\nОднако, что именно мы понимаем под «утечкой в памяти»? По моему опыту, явные утечки в памяти делятся на три основные категории, для каждой из которых характерно особое поведение, а для отладки каждой из категорий нужны особые инструменты и приемы. В этой статье я хочу описать все три класса и подсказать, каким образом правильно распознать, с \r\nкоторым из классов вы имеете дело, и как найти утечку.\r\nТип (1): выделен недостижимый фрагмент памяти\r\nЭто классическая утечка памяти в C/C++. Кто-то выделил память при помощи  или , и так и не вызвал  или , чтобы высвободить память по окончании работы с ней.\r\nТакие ситуации не являются “утечками” в классическом смысле слова, так как ссылка откуда-нибудь на этот участок памяти все-таки сохраняется, поэтому в конце концов он может быть высвобожден (если программа успеет туда добраться, не израсходовав всю память).\r\nСитуации из этой категории могут возникать по многим специфическим причинам. Наиболее распространенные таковы:\r\nПользуйтесь профилировщиками или инструментами для дампа кучи, которые имеются в вашей среде. Я знаю, есть  в Python или  в Ruby, а еще я сам написал  прямо на Ruby.\r\nОхарактеризовать эту категорию сложнее всего, но именно ее наиболее важно понимать и учитывать.\r\nУтечки такого типа возникают в серой зоне, между памятью, которая считается «свободной» с точки зрения распределителя внутри VM или среды времени выполнения, и памятью, которая «свободна» с точки зрения операционной системы. Наиболее распространенная (но не единственная) причина такого явления – . Некоторые распределители попросту берут и не возвращают память в операционную систему после того как та была выделена. \r\nСлучай такого рода можно рассмотреть на примере короткой программы, написанной на Python:\r\nМы выделяем 200 000 1-кб буферов, а затем сохраняем каждый последующий. Мы каждую секунду выводим состояние памяти с точки зрения операционной системы и с точки зрения собственного сборщика мусора Python.\r\nУ меня на ноутбуке получается примерно такой вывод:\r\nМы можем убедиться, что Python на самом деле высвободил половину буферов, ведь уровень gcsize упал практически наполовину от пикового значения, но не смог вернуть операционной системе ни байта этой памяти. Освобожденная память остается доступна все тому же процессу Python, но ни одному другому процессу на этой машине.\r\nТакие свободные, но неиспользуемые фрагменты памяти могут быть как проблемными, так и безобидными. Если программа на Python так действует, а затем выделяет еще горсть 1kb-фрагментов, то данное пространство просто переиспользуется, и все хорошо.\r\nНо, если бы мы делали это в ходе начальной настройки, а в дальнейшем выделяли память по минимуму, либо если бы все выделяемые впоследствии фрагменты были бы по 1,5kb и не вмещались в эти заблаговременно оставленные буферы, то вся выделенная таким образом память вечно простаивала бы впустую.\r\nПроблемы такого рода особенно актуальны в специфической среде, а именно, в многопроцессных серверных системах для работы с такими языками как Ruby или Python. \r\nДопустим, мы настроили систему, в которой:\r\nРаз в минуту прибывает такой «китообразный» запрос, обработку которого мы поручаем одному из 10 работников, допустим, случайным образом: . В идеале, на время обработки этого запроса данный работник должен выделить 1GB оперативной памяти, а после окончания работы вернуть эту память операционной системе, чтобы в дальнейшем ее можно было снова использовать. Чтобы неограниченно долго обрабатывать запросы по такому принципу, серверу потребуется всего 10 * 500MB + 1GB = 6GB RAM.\r\nОднако, давайте предположим, что из-за фрагментации или по какой-то другой причине, виртуальная машина никогда больше не сможет вернуть эту память операционной системе. То есть, объем оперативной памяти, который она требует от ОС, равен крупнейшему объему памяти, который когда-либо приходится выделять единовременно. В таком случае, когда конкретный работник обслуживает такой ресурсозатратный запрос, участок, занимаемый таким процессом в памяти, навсегда разбухает на целый гигабайт.\r\nПри запуске сервера вы увидите, что объем используемой памяти равен 10 * 500MB = 5GB. Как только поступит первый большой запрос, первый работник заграбастает 1GB памяти, а потом не отдаст ее обратно. Общий объем используемой памяти подскочит до 6GB. Следующие поступающие запросы могут время от времени перепадать тому процессу, который ранее уже обрабатывал «кита», и в таком случае объем используемой памяти не изменится. Но иногда такой крупный запрос будет доставаться уже другому работнику, из-за чего память будет раздуваться еще на 1GB, и так до тех пор, пока каждому работнику не доведется обработать такой крупный запрос как минимум однократно. В таком случае вы займете этими операциями до 10 * (500MB + 1GB) = 15GB оперативной памяти, что гораздо больше идеальных 6GB! Более того, если рассмотреть, как парк серверов используется с течением времени, то можно заметить, как объем используемой памяти постепенно вырастает с 5GB до 15GB, что будет очень напоминать «реальную» утечку.\r\n \r\nКак уже упоминалось, эта категория немного коварнее предыдущих, поскольку проблема зачастую возникает, даже когда все компоненты работают «как задумано». Тем не менее, есть ряд полезных приемов, помогающих смягчить или сократить воздействие таких «виртуальных утечек»:", "url": "https://habr.com/ru/company/piter/blog/432072/"},
{"title": "DEV Labs 2018. Онлайн-митап для C++ разработчиков. 15 декабря", "article_text": "Уважаемые коллеги!\r\nПриглашаем вас на финальный митап серии DEV Labs в 2018 году, который состоится 15 декабря и будет посвящён разработке на C++. \r\nДля этого митапа мы собрали программу из трёх докладов, основанных на реальных примерах из каждодневной рабочей практики. . Дмитрий Микушин расскажет о том, почему программировать GPU трудно, но нужно и покажет реализацию некоторых подходов с помощью Thrust; Станислав Ивочкин, отвечая на вопрос – «Что происходит после нажатия Enter в строке браузера?», заглянет под капот одного из простейших действий, совершаемых пользователем. Посмотрим на работу парсеров, компиляторов и интерпретаторов, графических фрейворков и системных библиотек.\r\nВсе мероприятия серии проходят на платформе zoom.us. Для подключения к онлайн сессии и бытрого доступа к видеозаписям после ивента, необходимо . Участие – беплатное. Количество мест ограничено. Коллеги, к сожалению, мы вынуждены перенести доклад Андрея Вуколова — «Агрегатирование сборки сложного проекта. Мы проведём его на следующей неделе в один из будних дней, либо предоставим вам запись доклада. Приносим наши извинения за возможные неудобства.", "url": "https://habr.com/ru/company/luxoft/blog/432406/"},
{"title": "Краткий гид по обучению С++: что, когда и на чём создавать", "article_text": "\r\nНедавно у нас на GeekBrains стартовал свежий курс \"\". Программа позволит всего за 9 месяцев освоить этот непростой язык и стать специалистом уровня junior. А это непростая задача. К примеру, в школах и ВУЗах на изучение С++ уходит минимум 2 года, чаще 4-5. Чтобы показать из чего состоит этот нелегкий путь, мы схематично описали для вас основные этапы.\r\nДля современных языков это может показаться парадоксальным, но классическое обучение языку C++ начинается с изучения нескольких других языков. Вы изначально должны привыкнуть к структурам программ и выучить основные понятия. Поэтому на первых занятиях вместо компьютера студенты используют листы бумаги, а вместо кодов — блок-схемы со стрелками.\r\nНесмотря на универсальность подобного метода, его редко встретишь даже на первых занятиях по Java или C#, хотя там он тоже был бы полезен. Чаще всего алгоритмическое и блочное программирование проходят, когда студенты уже знакомы с синтаксисом. А вот в С++ это фундамент.\r\nНа следующем этапе мы наконец включаем компьютер и начинаем создавать простые программы на языках, которые не имеют прямого отношения к С и С++. Идея классического образования, как и в прошлом пункте: приучить студентов правильно создавать структуру, помнить о служебных символах, использовать «правильные» обозначения и оформление.\r\nКогда Pascal и Basic полностью исчерпают себя, а для этого достаточно нескольких часов, можно понемногу перемещаться к C, дублируя заученный код в новом синтаксисе. Сортировки разными методами, работа со строками и массивами, калькуляторы, игры — все эти базовые упражнения и программы помогут сжиться с новыми знаниями.\r\nВ любом языке программирования надо начинать писать программы не в сложных IDE, а в простых универсальных редакторах. Notepad++ для этого отлично подойдёт, тем более, что название намекает на правильность выбора. Всё, что вам нужно сейчас, это подсветка синтаксиса и функция проверки. В студенческом образовании также практикуется написание кода на бумаге. Причина проста: экзамены по программированию в 21 веке всё ещё иногда сдаются без компьютеров.\r\nЕсли у вас есть Linux (а если вы планируете стать программистом, то лучше установите его немедленно), то вопроса с выбором среды может вообще не стоять — просто откройте командую строку.\r\nЛюбители олдскула могут попробовать установить себе на компьютер Borland C++, благо многие нынешние «крестоносцы» с теплотой и любовью относятся к этой серии (работать в ней реально удобно). Но для нормальной работы у вас есть незначительный выбор между Visual Studio и Qt Creator, в зависимости от задач.\r\nНа данном этапе остановим свой выбор на блокноте. \r\nДо тех пор, пока вы не напишите первое крутое приложение с кодом хотя бы десять листов, увлекаться графикой просто вредно. В командной строке можно реализовать кучу идей, от чатботов до RPG-игр, задействовав массу всевозможных библиотек и собственных знаний.\r\nА потом на эту основу можно накладывать минимальные графические примочки, играть с физикой моделей, шлифовать моменты пересечений, наложений, отрабатывать взаимодействие с интерфейсом.\r\nКогда и этот этап будет пройден, можно подключать серьёзные библиотеки и среды программирования, где многие пройденные ранее действия выполняются автоматически.\r\nООП — лестница от примитивной возни с кодом к комплексным структурам, лежащих в основе\r\nтаких продуктов, как Chrome, World of Warcraft и Linux. Также ООП является ключевой разницей между C и C++. В классическом образовании уделяется много времени изучению принципов ООП, ведь без досконального понимания, что это и зачем, вы будете создавать тонны лишнего и неправильного кода, пытаясь оправдать это личным удобством.\r\nТак что на этом этапе придётся вернуться к процедурному и алгоритмическому программированию при помощи бумаги и ручки, потренировавшись чётко описывать объекты пути наследования и инкапсуляции. Совсем скоро это понадобится.\r\nОдно дело просто выучить постулаты ООП, другое — научиться применять их на практике. Для этого попробуйте проделать следующие упражнения:\r\n«Классическое» образование на этом этапе сразу мигрирует в сторону Visual Studio – к созданию простых GUI-приложений в самой популярной IDE. Однако в качестве промежуточного варианта полезно будет использовать Qt благодаря его встроенным графическим библиотекам, позволяющим полноценно задействовать все ваши свежеиспечённые познания в C++ и ООП.\r\nЭту остановку полезно будет сделать любому изучающему C++ ради будущих профессиональных перспектив и общего развития навыков. Благо, в Qt есть отличный встроенный помощник и много руководств по созданию разных типов приложений, так что проблем с освоением быть не должно. Даже если дело касается продвинутых навыков. \r\nGUI-приложения, чаще всего, это конечная остановка в ВУЗовском образовании. Ничего нового здесь студенты уже не узнают, скорее, привыкают к основному инструменту, окончательно закрепляют в сознании правильную структуру приложения и файлов. \r\nТак как C++ невероятно востребованный язык почти во всех областях программирования, на этом этапе вы можете подумать, чем бы вы хотели заниматься в будущем. К примеру, если вы планируете работать с железом, то есть с микроконтроллерами, то придётся изучить библиотеки для работы с конкретными устройствами и средства отладки. Захотите работать в гейм-дизайне — путь лежит в Unity и схожие программы.\r\nЭти 9 этапов не сделают из вас профессионала, но позволят более-менее осознать возможности языка и то, чем занимаются «крестоносцы». Вы можете попробовать преодолеть этот путь самостоятельно, а можете присоединиться к нам. Обещаем, это будет эффективнее и куда интереснее.", "url": "https://habr.com/ru/company/mailru/blog/430694/"},
{"title": "Как Clang компилирует функцию", "article_text": "Я планировал написать статью о том, как LLVM оптимизирует функцию, но сначала необходимо написать, как Clang транслирует C или C++ в LLVM.\r\nРассмотрим высокоуровневые аспекты, не погружаясь в глубины Clang. Я хочу обратить внимание на то, как вывод Clang соотносится с входом, при этом мы не будем рассматривать нетривиальные возможности С++. Мы используем эту маленькую функцию, которую я позаимствовал из прекрасных :\r\nТак как Clang не делает никаких оптимизаций, и так как LLVM IR был изначально спроектирован для работы с C и C++, преобразование выполняется относительно легко. Я буду использовать Clang 6.0.1 (или близкую версию, поскольку эта ещё не выпущена) на x86-64.\r\nКомандная строка следующая:\r\nДругими словами: компилируем файл is_sorted.cpp как С++ и затем говорим тулчейну LLVM следующее: не оптимизировать, выводить ассемблер, в виде текстового представления LLVM IR. LLVM IR объёмный, и не может быстро выводиться или парситься, бинарный формат биткода всегда является более предпочтительным, если человеку не нужно смотреть на этот код. находится полный LLVM IR, мы рассмотрим его по частям.\r\nНачнём с верхней части файла:\r\nВесь тескт между точкой с запятой и концом строки является комментарием, значит, первая строка не делает ничего, но, если вам интересно, в LLVM «модуль»- это единица компиляции, контенер для кода и данных. Вторая строка также не должна нас беспокоить. Третья строка описывает некие допущения, сделанные компилятором, они не играют роли в этой статье, но вы можете прочитать больше .  — наследие gcc и далее нам не понадобится.\r\nФункция LLVM имеет опциональные атрибуты:\r\nНекоторые из них (как эти), поддерживаются фронтендом, другие добавляются позже проходами оптимизации. Эти атрибуты не имеют ничего общего со смыслом кода, я не буду обсуждать их здесь, но вы можете прочитать о них , если вам интересно.\r\nИ вот наконец, наша функция:\r\n“zeroext” означает, что возвращаемое значение функции (i1, однобитное целое), должно быть расширено нулями в бэкенде, до ширины, которую требует ABI. Затем идёт «дополненное» (mangled) имя функции, затем список параметров, в основном, такой же, как в коде С++, за исключением того, что i32 определяет 32-битную переменную. #0 соединяет функцию с  в конце файла.\r\nВот первый базовый блок:\r\nКаждая инструкция LLVM должна находиться внутри базового блока: набора инструкций, имеющего один вход в начале и один выход в конце. Последняя инструкция базового блока должна быть : «проваливание» в следующий базовый блок недопустимо. Каждая функция должна иметь входной блок, не имеющий предшественников (predecessors), которые выполняют переход на данный блок. Это и  проверяются при парсинге IR, эти проверки также могут быть вызваны многократно в процессе компиляции «верификатором модулей» (“module verifier”). Верификатор полезен для отладки, когда проход генерирует неверный IR.\r\nПервые четыре инструкции в этом базовом блоке — «alloca»: выделение стековой памяти. Первые три создают переменные, неявно созданные при компиляции, четвёртая — переменная цикла. Переменные, аллоцированные таким образом, могут быть доступны только через инструкции load и store. Следующие три инструкции инициализируют три стековых слота, a.addr и n.addr инициализируются с использованием значений, переданных в функцию в качестве парметров, и i инициализируется нулём. Возвращаемое значение не нужно инициализировать, об этом должен будет позаботиться любой код, не являющийся неопределённым в С и С++. Последняя инструкция — это безусловный переход на следующий базовый блок (мы пока не беспокоимся об этом, большинство ненужных переходов будут удалены бэкендом LLVM).\r\nВы можете спросить: почему Clang выделяет стековые слоты для a и n? Почему он просто не использует эти значения напрямую? В этой функции, так как a и n не изменяются, такая стратегия будет работать, но этот случай будет учтён оптимизатором, и находится вне компетенции Calng. В случае, если a и n могут модифицироваться, они должны находится в памяти, и не должны быть SSA-значениями, которые, по определению, могут принимать значение только в одной точке программы. Ячейки памяти находятся вне мира SSA и могут быть модифицированы когда угодно. Это может показаться странным, но такое решение позволяет организовать работу всех частей компилятора естественным и эффективным образом.\r\nЯ думаю о Clang, как о генераторе вырожденного SSA-кода, который удовлетворяет всем требованиям SSA, но только потому, что обмен информацией между базовыми блоками происходит через память. Генерация невырожденного кода требует некоторой внимательности и некоторого анализа, и разработчики Clang отказались делать это, для того, чтобы разделить обязанности генерации и оптимизации кода. Я не видел результатов измерений, но в моём понимании, генерируется множество операций с памятью, и затем, практически немедленно большинство из них удаляется оптимизатором, не приводя к большим накладным расходам времени компиляции, \r\nРассмотрим, как транслируется цикл for. В общем виде он выглядит так:\r\nЭто транслируется приблизительно так:\r\nКонечно, такая трансляция не специфична для Clang, любой компилятор С и С++ делает то же самое.\r\nВ нашем примере, инициализатор цикла сворачивается во входной базовый блок. Следующий базовый блок является проверкой условия цикла:\r\nClang также делает полезный комментарий, что этот базовый блок может быть достигнут либо из for.inc, либо из входного базового блока. Этот блок загружает i и n из памяти, уменьшает n (флаг nsw отражает то свойство языка C, что знаковое переполнение не определено; без этого флага LLVM использует семантику дополнительного кода), сравнивает уменьшенное значение с i, используя команду slt (signed less than, знаковое меньше, чем) и затем наконец выполняет ветвление на базовый блок for.body или for.end.\r\nВход в тело цикла возможен только из блока for.cond:\r\nПервые две строки загружают a и i в регистры SSA; i затем расширяется до 64 бит и может принимать участие в вычислении адреса. Команда (или сокращённо gep) — известная своей вычурностью команда LLVM, она имеет даже свой собственный . В отличие от машинного языка, LLVM не рассматривает указатели как целые. Это облегчает alias -анализ и другие оптимизации памяти. Этот код загружает a[i] и a[i + 1], сравнивает их и выполняет ветвление в зависимости от результата.\r\nБлок if.then сохраняет 0 в стековый слот для возвращаемого значения функции и выполняет безусловный переход на выходной блок функции:\r\nБлок else тривиальный:\r\nИ блок для прибавления единицы к переменной цикла также очень прост:\r\nЭтот код выполняет переход назад на проверку условия цикла.\r\nЕсли цикл завершается нормально, мы возвращаем true:\r\nИ наконец, то, что мы загрузили в стековый слот возвращаемого значения, загружается и возвращается:\r\nВ конце функции нет ничего особенного. Пост получился длиннее, чем я думал, в следующем посте мы рассмотрим оптимизацию уровня IR для этой функции.\r\n(Благодарю Xi Wang и Alex Rosenberg за присланные исправления)", "url": "https://habr.com/ru/post/431688/"},
{"title": "Полное руководство по CMake. Часть вторая: Система сборки", "article_text": "В данной статье рассмотрено использование системы сборки CMake, применяемой в колоссальном количестве проектов на C/C++. Строго рекомендуется прочитать  руководства во избежание непонимания синтаксиса языка CMake, явным образом фигурирующего на протяжении всей статьи.Ниже приведены примеры использования языка CMake, по которым Вам следует попрактиковаться. Экспериментируйте с исходным кодом, меняя существующие команды и добавляя новые. Чтобы запустить данные примеры, установите CMake с . представляет из себя оболочку над другими платформенно зависимыми утилитами (например,  или ). Таким образом, в самом процессе сборки, как бы парадоксально это ни звучало, она непосредственного участия не принимает.Система сборки CMake принимает на вход файл  с описанием правил сборки на формальном языке CMake, а затем генерирует промежуточные и нативные файлы сборки в том же каталоге, принятых на Вашей платформе.Сгенерированные файлы будут содержать конкретные названия системных утилит, директорий и компиляторов, в то время как команды CMake орудуют лишь абстрактным понятием компилятора и не привязаны к платформенно зависимым инструментам, сильно различающихся на разных операционных системах.Команда  проверяет запущенную версию CMake: если она меньше указанного минимума, то CMake завершает свою работу фатальной ошибкой. Пример, демонстрирующий типичное использование данной команды в начале любого CMake-файла:Как  в комментариях, команда  выставляет все флаги совместимости (смотреть ). Некоторые разработчики намеренно выставляют низкую версию CMake, а затем корректируют функционал вручную. Это позволяет одновременно поддерживать древние версии CMake и местами использовать новые возможности.В начале любого  следует задать характеристики проекта командой  для лучшего оформления интегрированными средами и прочими инструментами разработки.Стоит отметить, что если ключевое слово  опущено, то по умолчанию задаются языки . Вы также можете отключить указание любых языков путём написания ключевого слова  в качестве списка языков или просто оставить пустой список.Команда  заменяет строку своего вызова кодом заданного файла, действуя аналогично препроцессорной команде  языков C/C++. Этот пример запускает скриптовый файл  описанной командой:В данном примере, первое сообщение уведомит о том, что переменная  ещё не определена, однако если скрипт  определит данную переменную, то второе сообщение уже будет информировать о новом значении тестовой переменной. Таким образом, скриптовый файл, включаемый командой , не создаёт собственной области видимости, о чём  в комментариях к .Команда  компилирует исполняемый файл с заданным именем из списка исходников. Важно отметить, что окончательное имя файла зависит от целевой платформы (например,  или просто ). Типичный пример вызова данной команды:Команда  компилирует библиотеку с указанным видом и именем из исходников. Важно отметить, что окончательное имя библиотеки зависит от целевой платформы (например,  или ). Типичный пример вызова данной команды:Бывают случаи, требующие многократного добавления исходных файлов к цели. Для этого предусмотрена команда , способная добавлять исходники к цели множество раз.Первым аргументом команда  принимает название цели, ранее указанной с помощью команд  или , а последующие аргументы являются списком добавляемых исходных файлов.Повторяющиеся вызовы команды  добавляют исходные файлы к цели в том порядке, в каком они были вызваны, поэтому нижние два блока кода являются функционально эквивалентными:Местоположение выходных файлов, сгенерированных командами  и , определяется только на стадии генерации, однако данное правило можно изменить несколькими переменными, определяющими конечное местоположение двоичных файлов:Исполняемые файлы всегда рассматриваются целями выполнения, статические библиотеки — архивными целями, а модульные библиотеки — библиотечными целями. Для \"не-DLL\" платформ динамические библиотеки рассматриваются библиотечными целями, а для \"DLL-платформ\" — целями выполнения. Для объектных библиотек таких переменных не предусмотрено, поскольку такой вид библиотек генерируется в недрах каталога .Важно подметить, что \"DLL-платформами\" считаются все платформы, основанные на Windows, в том числе и .Команда  компонует библиотеку или исполняемый файл с другими предоставляемыми библиотеками. Первым аргументом данная команда принимает название цели, сгенерированной с помощью команд  или , а последующие аргументы представляют собой названия целей библиотек или полные пути к библиотекам. Пример:Стоит отметить, что модульные библиотеки не подлежат компоновке с исполняемыми файлами или другими библиотеками, так как они предназначены исключительно для загрузки техниками выполнения.Как  в комментариях, цели в CMake тоже подвержены ручному манипулированию, однако весьма ограниченному.Имеется возможность управления свойствами целей, предназначенных для задания процесса сборки проекта. Команда  присваивает предоставленной переменной значение свойства цели. Данный пример выводит значение свойства  цели  на экран:Команда  устанавливает указанные свойства целей заданными значениями. Данная команда принимает список целей, для которых будут установлены значения свойств, а затем ключевое слово , после которого следует список вида :Пример выше задал цели  свойства, влияющие на процесс компиляции, а именно: при компиляции цели  CMake затребует компилятора о использовании стандарта C11. Все известные именования свойств целей перечисляются на .Также имеется возможность проверки ранее определённых целей с помощью конструкции :Команда  побуждает CMake к незамедлительной обработке указанного файла подпроекта. Пример ниже демонстрирует применение описанного механизма:В данном примере первым аргументом команды  выступает подпроект , а второй аргумент необязателен и информирует CMake о папке, предназначенной для генерируемых файлов включаемого подпроекта (например,  и ).Стоит отметить, что все переменные из родительской области видимости унаследуются добавленным каталогом, а все переменные, определённые и переопределённые в данном каталоге, будут видимы лишь ему (если ключевое слово  не было определено аргументом команды ). Данную особенность  в комментариях к .Команда  находит и загружает настройки внешнего проекта. В большинстве случаев она применяется для последующей линковки внешних библиотек, таких как  и . Данный пример вызывает описанную команду для поиска библиотеки  и последующей линковки:В приведённом выше примере команда  первым аргументом принимает наименование пакета, а затем требуемую версию. Опция  требует печати фатальной ошибки и завершении работы CMake, если требуемый пакет не найден. Противоположность — это опция , требующая CMake продолжать свою работу, даже если пакет не был найден.Далее исполняемый файл  линкуется с библиотекой GSL командой  с помощью переменной , инкапсулирующей расположение уже скомпилированной GSL.В конце вызывается команда , информирующая компилятора о расположении заголовочных файлов библиотеки GSL. Обратите внимание на то, что используется переменная , хранящая местоположение описанных мною заголовков (это пример импортированных настроек пакета).Вам, вероятно, захочеться проверить результат поиска пакета, если Вы указали опцию . Это можно сделать путём проверки переменной , автоматически определяемой после завершения команды . Например, в случае успешного импортирования настроек GSL в Ваш проект, переменная  обратится в истину.В общем случае, команда  имеет две разновидности запуска: модульную и конфигурационную. Пример выше применял модульную форму. Это означает, что во время вызова команды CMake ищет скриптовый файл вида  в директории , а затем запускает его и импортирует все необходимые настройки (в данном случае CMake запустила стандартный файл ).Информировать компилятора о располжении включаемых заголовков можно посредством двух команд:  и . Вы решаете, какую из них использовать, однако стоит учесть некоторые различия между ними (идея предложена в ).Команда  влияет на область каталога. Это означает, что все директории заголовков, указанные данной командой, будут применяться для всех целей текущего , а также для обрабатываемых подпроектов (смотреть ).Команда  влияет лишь на указанную первым аргументом цель, а на другие цели никакого воздействия не оказывается. Пример ниже демонстрирует разницу между этими двумя командами:В комментариях , что в современных проектах применение команд  и  является нежелательным. Альтернатива — это команды  и , действующие лишь на конкретные цели, а не на всю текущую область видимости.Команда  генерирует установочные правила для Вашего проекта. Данная команда способна работать с целями, файлами, папками и многим другим. Сперва рассмотрим установку целей.Для установки целей необходимо первым аргументом описанной функции передать ключевое слово , за которым должен следовать список устанавливаемых целей, а затем ключевое слово  с расположением каталога, в который установятся указанные цели. Данный пример демонстрирует типичную установку целей:Процесс описания установки файлов аналогичен, за тем исключением, что вместо ключевого слова  следует указать . Пример, демонстрирующий установку файлов:Процесс описания установки папок аналогичен, за тем исключением, что вместо ключевого слова  следует указать . Важно подметить, что при установке будет копироваться всё содержимое папки, а не только её название. Пример установки папок выглядит следующим образом:После завершения обработки CMake всех Ваших файлов Вы можете выполнить установку всех описанных объектов командой  (если CMake генерирует ), или же выполнить данное действие интегрированной средой разработки, поддерживающей CMake.Данное руководство было бы неполным без демонстрации реального примера использования системы сборки CMake. Рассмотрим схему простого проекта, использующего CMake в качестве единственной системы сборки:Главный файл сборки  описывает компиляцию всей программы: сперва происходит вызов команды , компилирующей исполняемый файл, затем вызывается команда , побуждающая обработку подпроекта, и наконец, исполняемый файл линкуется с собранной библиотекой:Файл  вызывается главным файлом сборки и компилирует статическую библиотеку , предназначенную для линковки с исполняемым файлом:После череды команд  работа системы сборки CMake завершается успешно. Первая команда запускает обработку файла  в корневом каталоге проекта, вторая команда окончательно компилирует необходимые двоичные файлы, а третья команда устанавливает скомпонованный исполняемый файл  в систему.Теперь Вы способны писать свои и понимать чужие CMake-файлы, а подробно прочитать про остальные механизмы Вы можете на . данного руководства будет посвящена тестированию и созданию пакетов с помощью CMake и выйдет через неделю. До скорых встреч!", "url": "https://habr.com/ru/post/432096/"},
{"title": "Внутренняя и внешняя линковка в C++", "article_text": "Всем добрый день!\r\nПредставляем вам перевод интересной статьи, который подготовили для вас рамках курса . Надеемся, что она будет полезна и интересна для вас, как и нашим слушателям.\r\nПоехали.\r\nСталкивались ли вы когда-нибудь с терминами внутренняя и внешняя связь? Хотите узнать, для чего используется ключевое слово extern, или как объявление чего-то static влияет на глобальную область? Тогда эта статья для вас.\r\nВ единицу трансляции включены файл реализации (.c/.cpp) и все его заголовочные файлы (.h/.hpp). Если внутри единицы трансляции у объекта или функции есть внутреннее связывание, то этот символ виден компоновщику только внутри этой единицы трансляции. Если же у объекта или функции есть внешнее связывание, то компоновщик сможет видеть его при обработке других единиц трансляции. Использование ключевого слова static в глобальном пространстве имен дает символу внутреннее связывание. Ключевое слово extern дает внешнее связывание.\r\nКомпилятор по умолчанию дает символам следующие связывания:\r\nПоговорим сначала о двух простых концепциях, необходимых для обсуждения связывания.\r\nТакже обратите внимание на названия: мы будем использовать понятие “символ”, когда речь идет о любой “сущности кода”, с которой работает компоновщик, например с переменной или функцией (или с классами/структурами, но на них мы не будем акцентироваться).\r\nКратко обсудим разницу между объявлением и определением символа: объявление (или декларация) говорит компилятору о существовании конкретного символа, и позволяет обращение к этому символу в случаях не требующих точного адреса памяти или хранилища символа. Определение говорит компилятору, что содержится в теле функции или сколько памяти нужно выделить переменной.\r\nВ некоторых ситуациях компилятору недостаточно объявления, например, когда элемент данных класса имеет тип ссылки или значения (то есть не ссылка, и не указатель). В то же время, разрешен указатель на объявленный (но неопределенный) тип, так как ему нужен фиксированный объем памяти (например, 8 байт в 64-битных системах), не зависящий от типа, на который указывает. Чтобы получить значение по этому указателю, потребуется определение. Также для объявления функции нужно объявить (но не определить) все параметры (не важно взятые ли по значению, ссылке или указателю) и возвращаемый тип. Определение типа возвращаемого значения и параметров необходимо только для определения функции.\r\nРазница между определением и объявлением функции весьма очевидна.\r\nС переменными все немного иначе. Объявление и определение обычно не разделяются. Главное, что это:\r\nНе только объявляет , но и определяет его. Происходит это благодаря вызову дефолтного конструктора int. (В C++ в отличие от Java, конструктор простых типов (таких как int) по умолчанию не инициализирует значение в 0. В примере выше х будет иметь равен любому мусору, лежащему в адресе памяти, выделенном компилятором).\r\nНо вы можете явно разделить объявление переменной и ее определение при помощи ключевого слова .\r\n \r\nОднако, при инициализации и добавлении к объявлению, выражение превращается в определение и ключевое слово становится бесполезным.\r\nВ C++ существует концепция предварительного объявления символа. Это значит, что мы объявляем тип и имя символа для использования в ситуациях, не требующих его определения. Так нам не понадобится включать полное определение символа (обычно — заголовочный файл) без явной необходимости. Тем самым, мы снижаем зависимость от файла, содержащего определение. Главное преимущество — при изменении файла с определением, файл, где мы предварительно объявляем этот символ, не потребует повторной компиляции (а значит, и все прочие файлы его включающие).\r\nПредположим, у нас есть объявление функции (называемое прототипом) для f, принимающее объект типа по значению:\r\nСразу включить определение  — наивно. Но так как мы пока только объявили , достаточно предоставить компилятору объявление . Таким образом, компилятор сможет узнать функцию по ее прототипу, а мы сможем избавиться от зависимости file.hpp от файла, содержащего определение , скажем class.hpp:\r\nДопустим, file.hpp содержится в 100 других файлах. И, допустим, мы меняем определение Class в class.hpp. Если вы добавим class.hpp в file.hpp, file.hpp и все 100 содержащих его файла будут должны перекомпилироваться. Благодаря предварительному объявления Class единственными файлами, требующими повторной компиляции, будут class.hpp и file.hpp (если считать, что f определен там).\r\nВажное отличие объявления от определения состоит в том, что символ может быть объявлен много раз, но определен только однажды. Так вы можете предварительно объявить функцию или класс сколько угодно раз, но определение может быть только одно. Это называется . В C++ работает следующее:\r\nА это не работает:\r\nПрограммисты обычно работают с заголовочными файлами и файлами реализации. Но не компиляторы — они работают с единицами трансляции (translation units, кратко — TU), которые иногда называют единицами компиляции. Определение такой единицы довольно простое — любой файл, переданный компилятору, после его предварительной обработки. Если быть точным, это файл, получаемый в результате работы препроцессора расширяющего макрос, включающего исходный код, который зависит от  и выражений, и копипасты всех файлов .\r\nЕсть следующие файлы:\r\nheader.hpp:\r\nprogram.cpp:\r\nПрепроцессор выдаст следующую единицу трансляции, которая затем передается компилятору:\r\nОбсудив основы, можно приступить к связям. В целом, связь — это видимость символов для компоновщика при обработке файлов. Связь может быть либо внешней, либо внутренней.\r\nКогда символ (переменная или функция) обладает внешней связью, он становится видимым компоновщикам из других файлов, то есть “глобально” видимым, доступным всем единицами трансляции. Это значит, что вы должны определить такой символ в конкретном месте одной единицы трансляции, обычно в файле реализации (.c/.cpp), так чтобы у него было только одно видимое определение. Если вы попытаетесь одновременно с объявлением символа выполнить его определение, или поместить определение в файл к объявлению, то рискуете разозлить компоновщик. Попытка добавить файл больше чем в один файл реализации, ведет к добавлению определения больше чем в одну единицу трансляции — ваш компоновщик будет плакать.\r\nКлючевое слово extern в C и C++ (явно) объявляет, что у символа есть внешняя связь.\r\nОба символа имеют внешнюю связь. Выше отмечалось, что const глобальные переменные по умолчанию имеют внутреннее связывание, non-const глобальные переменные — внешнее. Это значит, что int x; — то же самое, что и extern int x;, верно? Не совсем. int x; на самом деле аналогичен extern int x{}; (используя синтаксис универсальной/скобочной инициализации, для избежания самого неприятного синтаксического анализа (the most vexing parse)), так как int x; не только объявляет, но и определяет x. Следовательно, не добавить extern к int x; глобально настолько же плохо, как определить переменную при объявлении ее extern:\r\nДавайте объявим функцию с внешней связью в file.hpp и там же определим ее:\r\nОбратите внимание, что добавлять здесь extern не нужно, так как все функции явно extern. Разделения объявления и определения тоже не потребуется. Поэтому давайте просто перепишем это следующим образом:\r\nТакой код можно было бы написать до прочтения этой статьи, либо после ее чтения под воздействием алкоголя или тяжелых веществ (например, булочек с корицей).\r\nДавайте посмотрим, почему так делать не стоит. Теперь у нас есть два файла реализации: a.cpp и b.cpp, оба включены в file.hpp:\r\nТеперь пусть поработает компилятор и сгенерирует две единицы трансляции для двух файлов реализации выше (помните что  буквально означает копировать/вставить):\r\nНа этом этапе вмешивается компоновщик (связывание происходит после компиляции). Компоновщик берет символ  и ищет определение. Сегодня ему повезло, он находит аж два! Одно в единице трансляции A, другое в B. Компоновщик замирает от счастья и говорит вам примерно следующее:\r\nКомпоновщик находит два определения для одного символа . Поскольку у  есть внешнее связывание, он виден компоновщику при обработке и A, и B. Очевидно, это нарушает Правило Одного Определения и вызывает ошибку. Точнее это вызывает ошибку повторяющегося символа (duplicate symbol error), которую вы будете получать не реже, чем ошибку неопределенного символа (undefined symbol error), возникающую, когда вы объявили символ, но забыли определить.\r\nСтандартным примером объявления переменных extern являются глобальные переменные. Предположим, вы работаете над самовыпекаемым тортом. Наверняка есть глобальные переменные, связанные с тортом, которые должны быть доступны в разных частях вашей программы. Допустим, тактовая частота съедобной схемы внутри вашего торта. Это значение естественно требуется в разных частях для синхронной работы всей шоколадной электроники. (Злой) C-способ объявления такой глобальной переменной имеет вид макроса:\r\nПрограммист C++, испытывающий к макросам отвращение, лучше напишет настоящий код. Например такой:\r\n(Современный программист C++ захочет использовать разделительные литералы: unsigned int clock_rate = 1'000'000;)\r\nЕсли у символа есть внутренняя связь, то он будет виден только внутри текущей единицы трансляции. Не путайте видимость с правами доступа, например private. Видимость означает, что компоновщик сможет использовать этот символ только при обработке единицы трансляции, в которой был объявлен символ, а не позже (как в случае символов с внешней связью). На практике, это значит, что при объявлении символа с внутренней связью в заголовочном файле, каждая единица трансляции, включающая в себя этот файл, получит уникальную копию этого символа. Как если бы вы предопределили каждый такой символ в каждой единице трансляции. Для объектов это значит, что компилятор будет буквально выделять совершенно новую, уникальную копию для каждой единицы трансляции, что, очевидно, может привести к высоким расходам памяти.\r\nДля объявления символа с внутренней связью, в C и C++ существует ключевое слово static. Такое использование отличается от применения static в классах и функциях (или, в целом, в любых блоках).\r\nПриведем пример:\r\nheader.hpp:\r\nfile1.hpp:\r\nfile2.hpp:\r\nfile1.cpp:\r\nfile2.cpp:\r\nmain.cpp:\r\nКаждая единица трансляции, включающая header.hpp получает уникальную копию переменной, в силу наличия у нее внутренней связи. Есть три единицы трансляции:\r\nПри вызове function1 копия переменной file1.cpp получает значение 10. При вызове function2 копия переменной file2.cpp получает значение 123. Однако, значение, которое выдается в main.cpp, не меняется и остается равным 42.\r\nВ С++ существует другой способ объявления одного и более символов с внутренней связью: анонимные пространства имен. Такое пространство гарантирует, что символы, объявленные внутри него, видны только в текущей единице трансляции. По сути, это просто способ объявить несколько символов static. Какое-то время от использования ключевого слова static в целях объявления символа с внутренней связью отказались в пользу анонимных пространств имен. Однако, им снова стали пользоваться в силу удобства объявления одной переменной или функции с внутренней связью. Есть еще несколько незначительных отличий, на которых я не буду останавливаться.\r\nВ любом случае, это:\r\nДелает (почти) то же самое, что и:\r\nТак в каких же случаях пользоваться внутренними связями? Использовать их для объектов — плохая идея. Расход памяти больших объектов может быть очень высок из-за копирования под каждую единицу трансляции. Но, в основном, это просто вызывает странное, непредсказуемое поведение. Представьте, что у вас есть синглтон (класс, в котором вы создаете экземпляр только одного инстанса) и неожиданно появляется несколько инстансов вашего “синглтона” (по одному на каждую единицу трансляции).\r\nОднако, внутреннюю связь можно использовать для скрытия из глобальной области локальных хелпер-функций единицы трансляции. Допустим, есть хелпер-функция foo в file1.hpp, которую вы используете в file1.cpp. В то же время у вас есть функция foo в file2.hpp, используемая в file2.cpp. Первая и вторая foo отличаются друг от друга, но вы не можете придумать другие имена. Поэтому вы можете объявить их static. Если вы не будете добавлять и file1.hpp, и file2.hpp в одну и ту же единицу трансляции, то это скроет foo друг от друга. Если этого не сделать, то они будут неявно иметь внешнюю связь и определение первой foo столкнется с определением второй, вызвав ошибку компоновщика о нарушении правила одного определения. \r\nTHE END\r\nВы всегда можете оставить свои комментарии и\\или вопросы тут или зайти к нам на ", "url": "https://habr.com/ru/company/otus/blog/432834/"},
{"title": "﻿Технологии, используемые в анализаторе кода PVS-Studio для поиска ошибок и потенциальных уязвимостей", "article_text": "\r\nКраткое описание технологий, используемых в инструменте PVS-Studio, которые позволяют эффективно обнаруживать большое количество паттернов ошибок и потенциальных уязвимостей. Статья описывает реализацию анализатора для С и C++ кода, однако приведённая информация справедлива и для модулей, отвечающих за анализ C# и Java кода.\r\nСуществуют заблуждения, что статические анализаторы кода — это достаточно простые программы, в основе которых лежит поиск паттернов кода с помощью регулярных выражений. Это далеко от истины. Более того, выявление подавляющего большинства ошибок с помощью регулярных выражений просто .\r\nЗаблуждение возникло на основе опыта программистов при работе с некоторыми инструментами, которые существовали 10-20 лет тому назад. Работа инструментов часто действительно сводилась к поиску опасных паттернов кода и таких функций, как ,  и т.д. В качестве представителя такого класса инструментов можно назвать .\r\nТакие инструменты хоть и могли приносить пользу, но в целом были бестолковы и неэффективны. Именно с тех времён у многих программистов и остались воспоминания, что статические анализаторы — это весьма бесполезные инструменты, которые больше мешают работе, чем помогают ей.\r\nПрошло время, и статические анализаторы начали представлять из себя сложные решения, выполняющие глубокий анализ кода и находящие ошибки, которые остаются в коде даже после внимательного code review. К сожалению, в силу прошлого негативного опыта, многие программисты по-прежнему считают методологию статического анализа бесполезной и не спешат внедрять её в процесс разработки.\r\nВ этой статье я попытаюсь немного исправить ситуацию. Прошу читателей уделить 15 минут времени и познакомиться с технологиями, используемыми в статическом анализаторе кода PVS-Studio для обнаружения ошибок. Возможно, после этого вы по-новому взглянете на инструменты статического анализа и захотите применить их в своей работе.\r\nАнализ потока данных позволяет находить разнообразнейшие ошибки. Среди них: выход за границу массива, утечки памяти, всегда истинные/ложные условия, разыменование нулевого указателя и так далее.\r\nТакже анализ данных может быть использован для поиска ситуаций, когда используются непроверенные данные, пришедшие в программу извне. Злоумышленник может подготовить такой набор входных данных, чтобы заставить программу функционировать нужным ему образом. Другими словами, он может использовать ошибку недостаточного контроля входных данных как уязвимость. Для поиска использования непроверенных данных в PVS-Studio реализована и продолжает усовершенствоваться специализированная диагностика .\r\nАнализ потока данных () заключается в вычислении возможных значений переменных в различных точках компьютерной программы. Например, если указатель разыменовывается, и при этом известно, что в этот момент он может быть нулевым, то это ошибка, и статический анализатор сообщит о ней.\r\nДавайте рассмотрим практический пример использования анализа потока данных для поиска ошибок. Перед нами функция из проекта Protocol Buffers (protobuf), предназначенная для проверки корректности даты.\r\nАнализатор PVS-Studio обнаружил в функции сразу две логические ошибки и выдаёт следующие сообщения:\r\nОбратим внимание на подвыражение «time.month < 1 || time.month > 12». Если значение  лежит вне диапазона [1..12], то функция прекращает свою работу. Анализатор учитывает это и знает, что если начался выполняться второй оператор , то значение  точно лежит в диапазоне [1..12]. Аналогично он знает о диапазоне других переменных (year, day и т.д.), но они нам сейчас не интересны.\r\nТеперь взглянем на два одинаковых оператора доступа к элементам массива: .\r\nМассив задан статически, и анализатор знает значения всех его элементов:\r\nТак как месяцы нумеруются с 1, то анализатор не рассматривает 0 в начале массива. Получается, что из массива может быть извлечено значение в диапазоне [28..31].\r\nВ зависимости, является год високосным или нет, к количеству дней прибавляется 1. Но это тоже нам сейчас неинтересно. Важны сами сравнения:\r\nДиапазон [1..12] (номер месяца) сравнивается с количеством дней в месяце.\r\nУчтя, что в первом случае месяц всегда февраль (), получаем что сравниваются следующие диапазоны:\r\nКак видите, результатом сравнения всегда является истина, о чём и предупреждает анализатор PVS-Studio. И действительно, код содержит две одинаковых опечатки. В левой части выражения следовало использовать член класса , а вовсе не .\r\nКорректный код должен быть таким:\r\nРассмотренная здесь ошибка также ранее была описана в статье \"\".\r\nВ предыдущем разделе был рассмотрен метод, когда анализатор вычисляет возможные значения переменных. Однако, чтобы найти некоторые ошибки, знать значения переменных не обязательно. Символьное выполнение () подразумевает решение уравнений в символьном виде.\r\nЯ не нашёл подходящий демонстрационный пример в нашей , поэтому рассмотрим синтетический пример кода.\r\nАнализатор PVS-Studio выдаёт предупреждение V609 / CWE-369 Divide by zero. Denominator 'A — B' == 0. test.cpp 12\r\nЗначение переменных  и  неизвестны анализатору. Зато анализатор знает, что в момент вычисления выражения  переменные  и  равны. Следовательно, произойдёт деление на 0.\r\nЯ сказал, что значения  и  неизвестны. Для общего случая это действительно так. Однако, если анализатор видит вызов функции с конкретными значениями фактических аргументов, то он учтёт это. Рассмотрим пример:\r\nАнализатор PVS-Studio предупреждает о делении на ноль: V609 CWE-628 Divide by zero. Denominator 'X' == 0. The 'Div' function processes value '[0..4]'. Inspect the first argument. Check lines: 106, 110. consoleapplication2017.cpp 106\r\nЗдесь уже работает смесь технологий: анализ потока данных, символьное выполнение и автоматическое аннотирование методов (мы рассмотрим эту технологию в следующем разделе). Анализатор видит, что переменная  используется в функции  как делитель. На основании этого для функции  автоматически строится специальная аннотация. Далее учитывается, что в функцию в качестве аргумента  передаётся диапазон значений [0..4]. Анализатор приходит к выводу, что должно возникнуть деление на 0.\r\nНаша команда проаннотировала тысячи функций и классов, предоставляемых в:\r\nВсе функции проаннотированы вручную, что позволяет задать множество характеристик, важных с точки зрения поиска ошибок. Например, задано, что размер буфера, переданный в функцию , должен быть не меньше, чем количество байт, которое планируется прочитать из файла. Также указана взаимосвязь между 2-м, 3-м аргументами и значением, которое может вернуть функция. Всё это выглядит так:\r\nБлагодаря такой аннотации в следующем коде, в котором используется функция , будет выявлено сразу две ошибки.\r\nПредупреждения PVS-Studio:\r\nВо-первых, анализатор перемножил 2-й и 3-й фактический аргумент и вычислил, что функция может прочитать до 1000 байт данных. При этом, размер буфера составляет всего 100 байт, и может произойти его переполнение.\r\nВо-вторых, раз функция может прочитать до 1000 байт, то диапазон возможных значений переменной  равен [0..1000]. Соответственно, может произойти доступ к массиву по некорректному индексу.\r\nДавайте рассмотрим ещё один простой пример ошибки, выявление которой стало возможно благодаря разметке функции . Перед нами фрагмент кода проекта CryEngine V. \r\nАнализатор PVS-Studio нашёл опечатку: V575 The 'memset' function processes '0' elements. Inspect the third argument. crythreadutil_win32.h 294\r\nПерепутан 2-й и 3-й аргумент функции. В результате, функция обрабатывает 0 байт и ничего не делает. Анализатор замечает эту аномалию и предупреждает о ней программистов. Ранее мы уже описывали эту ошибку в статье \"\".\r\nАнализатор PVS-Studio не ограничивается аннотациями, заданными нами вручную. Помимо этого, он самостоятельно пытается создавать аннотации, изучая тела функций. Это позволяет находить ошибки неправильного использования функций. Например, анализатор запоминает, что функция может вернуть nullptr. Если указатель, который вернула эта функция, используется без предварительной проверки, то анализатор предупредит об этом. Пример:\r\nПредупреждение: V522 CWE-690 There might be dereferencing of a potential null pointer 'Get()'. test.cpp 129 К поиску только что рассмотренной ошибки можно подойти противоположным способом. Ничего не запоминать, а каждый раз, когда встречается вызов функции , анализировать её зная фактические аргументы. Такой алгоритм теоретически позволяет найти больше ошибок, но он имеет экспоненциальную сложность. Время анализа программы вырастает в сотни-тысячи раз, и мы считаем такой подход тупиковым с практической точки зрения. В PVS-Studio мы развиваем направление автоматического аннотирования функций.\r\nТехнология сопоставление с шаблоном, на первый взгляд, может показаться тем самым поиском с помощью регулярных выражений. На самом деле, это не так, и всё намного сложнее.\r\nВо-первых, как я уже , регулярные выражения вообще никуда не годятся. Во-вторых, анализаторы работают не со строками текста, а с синтаксическими деревьями, что позволяет распознавать более сложные и высокоуровневые паттерны ошибок.\r\nРассмотрим два примера, один попроще и один посложнее. Первую ошибку я обнаружил, проверяя исходный код Android.\r\nАнализатор PVS-Studio распознаёт классический паттерн ошибки, связанный с неправильным представлением программиста о приоритете операций в языке C++: V593 / CWE-783 Consider reviewing the expression of the 'A = B != C' kind. The expression is calculated as following: 'A = (B != C)'. TagMonitor.cpp 50\r\nВнимательно посмотрим на эту строчку:\r\nПрограммист предполагает, что в начале выполняется присваивание, а только затем сравнение с . На самом деле сравнение происходит в первую очередь. Классика. Подробнее эта ошибка разобрана в , посвященной проверке Android (см. главу «Другие ошибки»).\r\nТеперь рассмотрим более высокоуровневый вариант сопоставления с шаблоном.\r\nПредупреждение PVS-Studio: V597 CWE-14 The compiler could delete the 'memset' function call, which is used to flush 'chunkBuffer' buffer. The RtlSecureZeroMemory() function should be used to erase the private data. sha1.cpp 189\r\nСуть проблемы заключается в том, что после заполнения нулями буфера с помощью функции  этот буфер нигде не используется. При сборке кода с флагами оптимизации компилятор примет решение, что этот вызов функции избыточен и удалит его. Он имеет на это право, так как с точки зрения языка C++ вызов функции не оказывает никакого наблюдаемого поведения на работу программы. Сразу после заполнения буфера  функция  заканчивает работу. Так как буфер создан на стеке, то после выхода из функции он станет недоступен для использования. Следовательно, с точки зрения компилятора, и заполнять его нулями смысла нет.\r\nВ результате, где-то в стеке останутся лежать приватные данные, что может повлечь неприятности. Более подробно эта тема рассмотрена в статье \"\".\r\nЭто пример высокоуровневого сопоставления с шаблоном. Во-первых, анализатор должен знать о существовании этого дефекта безопасности, классифицируемого согласно Common Weakness Enumeration как .\r\nВо-вторых, он должен найти в коде все места, где буфер создан на стеке, затёрт с помощью функции  и далее нигде не используется.\r\nКак видите, статический анализ — эта очень интересная и полезная методология. Она позволяет устранить на самых ранних этапах большое количество ошибок и потенциальных уязвимостей (см. ). Если вы ещё не до конца прониклись статическим анализом, то приглашаю почитать наш , где мы регулярно разбираем ошибки, найденные с помощью PVS-Studio в различных проектах. Вы просто не сможете остаться равнодушным.\r\nМы будем рады видеть вашу компанию среди  и поможем сделать ваши приложения более качественными, надёжными и безопасными.\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: Andrey Karpov. .", "url": "https://habr.com/ru/company/pvs-studio/blog/430604/"},
{"title": "0xc00007b или установка драйверов из-под программы", "article_text": "Доброго времени суток. Знакомо ли вам исключение ? С момента перевода движка  приходило очень много репортов о проблеме 0cx00007b. В 90% случаев, это была проблема с отсутствием 64 битного драйвера OpenAL. Первое время мы постоянно отвечали, что нужно установить драйвер, спустя пару месяцев написали FAQ по запуску и вероятным проблемам. Но подобные репорты не уходили, народ у нас в СНГ читать не особо любит, поэтому мы решили решить проблему радикально: устанавливать драйвер из-под движка, если таковой отсутствует. Самый простой способ подключения библиотек друг к другу — компоновка(), но в нашем случае так делать нельзя. Итак, шаг 1:  или привет .Что нам требуется: отвязать exe от библиотек движка. Делается это следующим способом: 1) Выносим функцию запуска движка в динамическую библиотеку: 2) Вызываем функцию из нашего exe:Ну, тут всё просто, получаем системный(может кто-то удивится, но OS не всегда на C:) раздел и проверяем dll в папке с драйверами: Первым делом нам нужно попросить права администратора у пользователя, т.к. работать придётся с системным каталогом: Этап второй: копируем библиотеку в системуКонечно, способ весьма забавный, но для подобных проектов подойдёт. Всем удачи!", "url": "https://habr.com/ru/post/431842/"},
{"title": "﻿PVS-Studio: поддержка стандартов кодирования MISRA C и MISRA C++", "article_text": "\r\nНачиная с версии 6.27 статический анализатор кода PVS-Studio может классифицировать свои предупреждения согласно стандартам MISRA C и MISRA C++. Благодаря поддержке этих стандартов анализатор стало возможным эффективно использовать для улучшения безопасности, переносимости и надежности программ для встраиваемых систем.\r\nВ этом году мы занялись поддержкой в анализаторе  таких стандартов, как  и . В основном поддержка свелась к классификации уже реализованных в анализаторе диагностик согласно этим стандартам. Дополнительно было реализовано несколько новых или расширено несколько старых диагностик, чтобы более полно соответствовать этим стандартам.\r\nТаблицы соответствий  PVS-Studio различным стандартам:\r\nТеперь настало время стандартов MISRA C и MISRA C++. Это стандарты разработки программного обеспечения на языке C и C++, созданные организацией  (Motor Industry Software Reliability Association). Цель стандартов — улучшить безопасность, переносимость и надежность программ для встраиваемых систем. Текст стандартов является платным.\r\nМы считаем сильной стороной нашего анализатора возможность взять и начать использовать его в уже существующем большом проекте. Можно запустить PVS-Studio на кодовой базе, выявить старые ошибки и затем использовать анализатор регулярно, чтобы находить новые дефекты как можно раньше.\r\nМногие анализаторы идут по другому пути и реализуют диагностики, связанные со стандартами кодирования. Они подсказывают, как лучше именовать переменные, напоминают вставлять комментарии в начало файла и так далее. Это нужно и полезно. Однако в этом случае анализаторы очень «шумные» и генерируют огромное число предупреждений, в которых тонут предупреждения, касающиеся ошибок.\r\nМы решили, что PVS-Studio будет анализатором, который ищет именно ошибки. Это его конкурентное преимущество. Программист может запустить его на большой кодовой базе и быть уверен, что его не завалит невероятным количеством сообщений про оформление кода и он сможет сосредоточиться именно на багах.\r\nПоэтому мы изначально  к стандартам MISRA и долгое время не планировали их реализовывать. Стандарты MISRA предназначены для упрощения и улучшения качества кода в целом, что помогает предотвращать ошибки. То есть в нем как раз большинство диагностик относится к стилю написания кода. Лучше всего это пояснить на примере.\r\nВ стандарте MISRA есть правило, согласно которому тела операторов  должны быть заключены в фигурные скоки. В MISRA C это правило 15.6, а в MISRA C++ это 6-4-1. Пример неправильного кода:\r\nПравильный код:\r\nПодобные диагностики невозможно применять к уже существующим проектам, написанным для работы под управлением операционной системы Winodws, Linux или macOS. Например, одно только описанное правило про фигурные скобки даёт  срабатываний диагностики  (MISRA C 15.6, MISRA C++ 6-4-1) для проекта WinMerge. А ведь WinMerge — это маленький проект! Всего около 250 000 строк кода на языке C и C++.\r\nДо 2018 года анализатор PVS-Studio был ориентирован на проверку десктопных приложений, работающих под управлением Windows, Linux и macOS. Соответственно, поддержка MISRA имела мало практического смысла. Никто не будет внедрять в большой существующий десктопный проект этот стандарт.\r\nВсё изменилось, когда в 2018 году мы начали поддержку встраиваемых систем. В этом году в анализаторе были поддержаны:\r\nВ отличие от десктопных проектов, многие embedded-разработчики уже пишут проекты с учетом MISRA рекомендаций, и их поддержка в нашем анализаторе будет разработчикам однозначно полезна. \r\nТем не менее, мы всё равно опасаемся, что кто-то из разработчиков, не разобравшись, может посчитать, что мы «испортили» анализатор внедрением в него «странных диагностик». Поэтому MISRA диагностики по умолчанию выключены. Мы считаем это очень правильным решением. Эти диагностики можно включать, только если вы точно понимаете для чего они нужны и как их использовать.\r\nНапример, для прикладных программистов может быть непонятным, почему вдруг анализатор запрещает им использовать динамическую память. Т.е. почему вдруг нельзя выделять память, используя функцию  или оператор . Но такие ограничения () хорошо понятны разработчикам встраиваемых устройств. В некоторых устройствах, работающих непрерывно, действительно недопустимо использование программ, для которых вдруг может кончиться память.\r\nИтак, теперь вы можете установить или обновить PVS-Studio и начать использовать диагностики, реализующие правила из MISRA C и MISRA C++. Набор поддерживаемых правил неполон, но это не должно быть препятствием для начала использования PVS-Studio. На данный момент не существует ни одного статического анализатора, реализующего абсолютно все MISRA правила. В дальнейшем мы планируем расширить набор диагностических правил, реализованных в MISRA, и надеемся стать лидирующим инструментом по полноте их поддержки.\r\nЧтобы включить MISRA диагностики в Visual Studio или в утилите PVS-Studio Standalone, необходимо в настройках сменить значение Disabled на Show All.\r\nПоскольку Disabled означает, что предупреждения вообще не генерируются и не попадают в отчёт, то понадобится перезапуск анализа. Режим Disabled по умолчанию установлен для того, чтобы сократить размер отчёта. Включение MISRA диагностик может приводить к огромному количеству срабатываний и сильному увеличению файлов с отчётом (*.plog — файлов).\r\nДля анализа проектов в операционных системах Linux и macOS существует утилита pvs-studio-analyzer. По умолчанию там включены только диагностики общего назначения (General Analysis, GA). Включить дополнительные правила можно с помощью опции \"-a\":\r\nДля включения предупреждений GA и MISRA необходимо запустить анализ со следующими параметрами:\r\nЗначение 36 — это побитовое ИЛИ для 4 (GA — диагностики общего назначения) и 32 (MISRA).\r\nДалее рекомендуется создать несколько отчётов с разными типами предупреждений, например, так:\r\nПервый отчёт «ga_results.tasks» будет содержать предупреждения общего назначения уровня достоверности High и Medium.\r\nА во второй отчёт «misra_results.tasks» попадут только предупреждения, относящиеся к MISRA всех уровней. Ключ \"-m misra\" указывает, что в отчёт, помимо номеров в формате PVS-Studio, будут включены номера диагностик согласно классификации MISRA.\r\nВсе режимы запуска анализатора в Linux и macOS, а также форматы отчётов, описаны в .\r\nP.S. Мы хотим оценить, насколько мы угадали, выбрав MISRA в качестве одного из направлений развития PVS-Studio. Если Вас заинтересовала эта тема, просьба . Даже если вы пока не планируете использовать PVS-Studio, всё равно просим написать. Мы хотим задать вам несколько уточняющих вопросов.\r\nДополнительные ссылки:\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: Andrey Karpov. .", "url": "https://habr.com/ru/company/pvs-studio/blog/432660/"},
{"title": "Что мне не нравится в C и С++", "article_text": "Просьба не читать профессиональным Си/ С++ программистам).\r\nВ статье я выражаю свою точку зрения, если несогласны — обоснуйте в комментариях.\r\nЦель данной статьи: указать на недостатки С и С++, которые мне очень не нравятся и побудить Вас использовать новую версию языка или возможно даже предложить какие-то идеи по улучшению стандарта.\r\nЧто ж, самое время разжечь холивар.\r\nЯ думаю все в курсе, что в курсе что в C++ ужасные строки. Особенно, если мы говорим о старом типе, в новом string многое было исправлено и улучшено, но до сих пор нет поддержки юникода(!).\r\nВ стандарте C++ 20 вроде как собираются вводить unicode строки.\r\nС++ 20! И это несмотря на то, что С++ .\r\nОткроем вашу любимую IDE и попробуем скомпилировать следующий код:\r\nUPD1: комментатор говорит, что кракозябры только на винде. Это точно, забыл об этом написать.\r\nНо все равно неприятно.\r\nЯ компилировал в Dev Cpp, компилятор GCC.\r\nСкомпилируем и видим:\r\nХороший вывод на экран, да?\r\nА теперь давайте заменим char string[256] на char* string.\r\nЯ не говорю, что это должно работать, но компилятор должен был выкинуть ошибку как максимум.\r\nМы получили рабочую программу, которая зависла.\r\nЛучше бы компилятор выкинул ошибку.\r\nПричем вся фигня в том, что компилятор мало того, что скомпилировал ее, он еще не\r\nвывел предупреждения.\r\nВот еще прикол:\r\nЧто мы ожидаем? Компилятор скажет нам, что нельзя обратиться к 101 элементу массива, раз элементов всего 100. Но компилируем, запускаем и видим… 32765( по крайней мере на моем железе).\r\nМда.\r\nА теперь давайте протестируем вот этот код:\r\nКак вы думаете, что он выведет?\r\nПравильный ответ — зависит от компилятора.\r\nВ GCC это будет 14, но в зависимости от флагов оптимизации.\r\nА в другом компиляторе это легко может быть 12…\r\nДумаю, все знают что в С и в плюсиках куча синтаксического сахара, который далеко не всегда нужен.\r\nНапример  это валидный код\r\nОн выводит n, так же как и \r\nЗдорово, да?\r\nА теперь о больном.\r\nС++ и сеть.\r\nЭто 2 ооочень плохо состыкующихся понятия.\r\nПопробуйте просто скачать изображение котика с Вашего любимого сайта с помощью стандартной библиотеки C++.\r\nЭто было невозможно до принятия стандарта С++ 17.\r\nВ той же стандартной библиотеки нельзя работать с JSON.\r\nОтличный комментарий по этому поводу. .\r\nДумаете, условие всегда будет ложно?\r\nНет, Вы ошибаетесь.\r\nЕсли скомпилировать это как с++ проект то условие скорее всего не выполнится.\r\nНе должно.[1]\r\nА если как Си проект, то в таком случае sizeof('a')==sizeof(int).\r\nВот такие дела.\r\n[1] Вообще множество разных компиляторов C и C++ это тоже проблема.\r\nПотому что множество решений нестандартизовано и они будут работать только в определенных компиляторах.\r\nНапример, 128 битные числа в C++. В gcc и clang есть тип __int128, в то время как в Visual Studio его нет, потому что он не является стандартом. Или, например, строки в Visual Studio.\r\nИли, например, в старичке Borland C++ Builder можно код, написанный на Object Pascal.\r\nИ таких моментов много.\r\nОсобую боль вызывает отсутствие списка пакетов Си и С++.\r\nЧто из этого следует? Используйте новую версию C++, например С++ 17 и некоторые проблемы будут решены.\r\nНадо сказать, что в ближайшем конкуренте C++ — Rust нет большинства проблем из этого списка, например есть замечательный cargo, но разумеется он тоже неидеален.\r\nА какие проблемы С и С++ знаете Вы?\r\nПишите в комментариях.\r\nUPD: похоже многие люди неправильно поняли мою статью:\r\nУ всего есть свои минусы, я просто поделился мыслями.\r\nUPD2:\r\nВ комментариях многие пишут, что так работает ос и вообще это фичи. Ребята, вы неправы.\r\nТот же раст доказательство, что можно сделать язык системного программирования в котором не так просто выстрелить себе в ногу.\r\nПросто в С/С++ полно легаси решений, которые никто не исправит, потому что это может сломать обратную совместимость.\r\nИ да, это мое мнение, оно .\r\nЕсли Вы не согласны — лучше прокомментируйте, а не тупо минусуйте, потому что мнение всех нас \r\nсубъективно.", "url": "https://habr.com/ru/post/432488/"},
{"title": "Время фрагментарно; немного о сходстве распределенных систем и слабой модели памяти", "article_text": "Привет всем!\r\nСегодня мы хотели бы в очередной раз затронуть тему одновременного и последовательного выполнения в различных программах, особенно — в распределенных системах. Еще в сентябре мы публиковали статью \"\" на эту тему, а теперь публикуем перевод более серьезного исследования, которое, надеемся, поможет вам лучше сориентироваться с распределенными системами. – Автор неизвестен\r\nВремя – штука странная.\r\nВремя такое странное, поскольку нам очень, очень хочется считать, что оно совершенно упорядочено. Нам кажется, что любое событие в 15.00 происходит (как мы бы сказали) до любого события в 16.00 – без исключений, доводов или компромиссов.\r\nОднако, информатика знает массу примеров, когда к данному требованию приходится подходить не столь строго. Оно проявляется на уровне процессоров, компиляторов, узлов сети. Снова и снова при вычислениях, на разных уровнях стека мы оказываемся в ситуациях, когда перед нами два события, и мы не знаем, в каком порядке они произошли. Время очевидно не является тотальным; она фрагментарно.\r\nПочему? Дело в том, что нам это не известно, поскольку уровень абстракции, над которым мы существуем, не дает ответа на этот вопрос. Случайно это или нет, но наши вычислительные абстракции не дают гарантий относительно порядка действий. Свобода переупорядочивать события зачастую позволяет создавать гораздо более производительные и доступные системы.\r\nВ процессоре может действовать ; в ней отражено, какие гарантии процессор не желает давать вам на этапе выполнения сборки никаких гарантий – например, какая инструкция была выполнена раньше, а какая – позже. Процессор сам решает, как именно конвейеризовать инструкции и выполняет их не в порядке поступления – то есть, использует свои микросхемы эффективнее, чем догадался бы использовать я.\r\nВ языке может действовать  (“модель памяти” для краткости); в ней отражено, каких гарантий язык вам не дает при генерировании сборки, например, при распределении инструкций по множеству потоков. Такое переупорядочивание по определению присуще аппаратной модели памяти и в значительной степени объясняет, почему в компиляторах предоставляется такая «слабая» концепция времени. Именно в рамках такой модели памяти, реализованной в языке, вы и программируете, когда пишете неблокирующий код. \r\nЗнаменитый пример модели памяти, реализованный на уровне языка – это с в стандарте C++11. По умолчанию C++ обеспечивает атомарные операции с синхронизацией, но в нем также можно ослабить модель доступа к памяти для повышения производительности. Обеспечиваемое таким образом поведение призвано послужить абстракцией над основными архитектурами процессоров, используемыми сегодня (x86, POWER и ARM).\r\nНаконец, в распределенной системе может быть своя модель согласованности; в ней отражено, каких гарантий не собирается давать вам система относительно порядка событий на клиентах и репликах в глобальной вычислительной сети. Переупорядочивания, непосредственно связанные с запаздыванием при коммуникации или с отсутствием синхронизации в основном объясняют, почему в распределенной системе вы не обойдетесь без упомянутой слабой модели времени. Именно такую модель согласованности вы программируете, когда пишете распределенное приложение.\r\nНа практике существует огромный  моделей согласованности, которыми можно воспользоваться при программировании распределенной системы. Во всех подобных ситуациях эти модели описывают (желаемое) поведение системы, наблюдаемое извне этой системы. Если я – конкретный клиент или конкретный поток – записываю значение, затем немедленно его считываю, гарантируется ли, что я обязательно увижу запись не старше моей? Если бы время не было фрагментарным, если бы мы всегда четко представляли, в каком порядке происходят операции в нашей системе – естественно, ответ на этот вопрос был бы утвердительным. Странно было бы вообще задавать такой вопрос.\r\nНо время фрагментарно – поэтому, ставить такой вопрос приходится.\r\nРассуждать о таком фрагментарном порядке зачастую сложно и всегда неприятно. Нам хотелось бы исходить из того, что на всех уровнях стека время всегда абсолютно – будь то при ACID-транзакциях, либо при атомарных операциях/блокировках. Чем строже гарантии, тем, естественно, проще с ними программировать!\r\nНо все мы стремимся к скорости. Идет ли речь о распределенных системах, где приходится жертвовать строгой согласованностью ради обеспечения доступности, либо о неблокирующем программировании, где берется за основу слабая модель памяти, позволяющая избежать издержек синхронизации, программисту, работающему с любым уровнем стека, обычно бывает целесообразно пускаться в эти сложные рассуждения.\r\nСогласованность моделей с разделяемой памятью и согласованность моделей с распределенной памятью – обе они . Они описывают программисту, работающему с системой, интерфейс этой системы. Дают понять, на какие виды поведения, соответствующие слабой модели памяти, мы можем рассчитывать, учитывая теперь, что общие свойства упорядоченности событий в системе, которые мы принимаем как данность, больше в ней не действуют. Может показаться, что две этих модели памяти аналогичны, однако, в обоих сообществах выработались собственные дискурсы для их обсуждения. Применяемые в них значения отличаются, хотя и пересекаются.\r\nМы уже представляем, насколько в этом можно запутаться. Что же делать?\r\nВ  Себастьян Буркхардт пытается дать исчерпывающую характеристику многочисленных вариантов моделей согласованности. При такой характеристике, наряду с другими математическими структурами, применяется два варианта логического упорядочения событий: «видимость» (visibility) и «произвольность» (arbitration), ранее также упоминавшиеся в других работах Буркхардта с соавторами, см. например,  об указании и проверке реплицируемых типов данных (2014).\r\n“Видимость” – это частичный порядок, присущий потенциальной обусловленности. Он позволяет отслеживать, какие события (возможно, в других репликах) видны каким другим событиям. К видимости не предъявляется никаких требований кроме ацикличности; события в объекте могут быть видимы событиям в другом объекте, а операция считывания или записи события никак не влияет на его видимость для других событий.\r\n“Произвольность” – это общий порядок, позволяющий отслеживать, как распределенная система, в которой возникает ситуация выбора, будет судить, какому событию произойти ранее, а какому позже.\r\nПоскольку модели распределенной согласованности аналогичны моделям памяти, оказывается, что такие феномены видимости и произвольности также могут пригодиться при обсуждении моделей памяти. В частности,  Буркхардт демонстрирует, «насколько близка» слабая модель памяти из C++11 к пообъектной причинной согласованности, но с некоторыми интересными отклонениями. Об этом и пойдет речь в оставшейся части поста. \r\nДля начала давайте конкретизируем видимость и произвольность с учетом «считывания» и «порядка следования изменений». При «считывании» видимость между любыми двумя объектами будет учитываться лишь в ситуациях, когда и чтение, и запись касаются одного и того же объекта, а при считывании может быть видна всего одна запись (или не одной).\r\nЭто соответствует ситуации, в которой процессор с разделяемой памятью в любой момент времени может записывать информацию всего в одну ячейку памяти для любого конкретного объекта, даже если разные потоки могут обращаться к нему в разные причинно-следственные моменты (с другой стороны, в распределенной системе логический объект может записываться сразу во множество отдельных реплик).\r\n“Порядок модификации” соответствует тому же этапу при конкретизации произвольности, он пообъектный и допускает только записи. Опять же, такая специализация основана на том факте, что при слабой спецификации памяти категорические гарантии даются только на уровне одного объекта.\r\nДалее давайте обсудим аксиомы согласованности, сформулированные Буркхардтом и др. и посмотрим, как они применяются к слабой модели памяти. Обратите внимание: даже несмотря на слово «аксиомы», это просто свойства, которые могут обеспечиваться или не обеспечиваться в различных моделях памяти. В статье Буркхардта основное внимание уделено свойствам, определяющим кросс-объектную причинную согласованность.\r\nДля любого конкретного события не может существовать неопределенно многого количества событий, которые его не видят. То есть, любое событие  видимо системе.\r\nЛогически выстроить такие условия в системе со слабой моделью памяти должно быть несколько сложнее: приходится утверждать, что для любой конкретной  не может существовать бесконечного количества операций считывания, которые бы не считывали эту запись или более ранние записи (в порядке модификации).\r\nВ спецификации C++11 соблюдение этой аксиомы не гарантируется, хотя, на практике найти контрпример сложно.\r\nПри отслеживании “потенциальной обусловленности” на уровне потоков/клиентских операций и что касается видимости/считываемости нужно понимать, что время обратного хода не имеет. Именно поэтому требуется, чтобы замыкания при упорядочивании потоков, подразумевающих считывание, были ациклическими. Как правило, можно не сомневаться, что это свойство будет соблюдаться в распределенных системах, однако, именно это свойство не позволяет обеспечить пользовательскую видимость при некоторых вариантах спекулятивного выполнения, если в системе действует слабая модель памяти.\r\nБуркхардт и др. указывают, что эта аксиома «не подтверждается» в спецификации C++11, и неясно, “does not validate” можно ли  «удовлетворяющие циклы».\r\nЧтобы конкретизировать, к чему именно относится феномен обусловленности при слабой модели памяти, мы должны в точности определить, какие события могут влиять на результаты каких других событий. Для начала рассмотрим наши стандартные причинно-следственные аксиомы: . Это четыре взаимосвязанные качества отражающие свойства когерентности операций чтения и записи, происходящих в разных потоках, причем, они должны конкретизироваться на уровне каждого объекта (см. .).\r\nИсходные версии WFR и MW существуют в двух вариантах, для произвольности и видимости; но это важно лишь при работе с более сложными ячейками данных, чем с регистрами для целых чисел.\r\nЭти свойства отражают представления об обусловленности, соответствующие нашему здравому смыслу; однако, в них упускается самое интересное. В частности, при анализе в слабой модели памяти такие явления обусловленности ограничены пределами потока/реплики/сеанса и конкретной ячейки/объекта, куда производится запись: . в данном случае говорится о «пообъектной условной видимости» и «пообъектной условной произвольности», также см. рис. 23. Эти феномены совершенно не ограничивают поведение системы, когда разные потоки записывают информацию в разные ячейки.\r\nЗатем аксиомы кросс-объектной обусловленности описывают влияние причинно-следственных связей на уровне различных объектов/ячеек памяти.\r\nВ спецификации C++11 отражены эти свойства. Обратите внимание: они определены так, что ограничения на видимость при записи и произвольность порядка модификации не слишком отражаются на этих определениях.\r\nНо это не касается последнего свойства.\r\nКонкретно, COCA в слабой модели памяти – это значительно более слабое свойство. Именно поэтому при слабой модели памяти следующий код может вернуть .\r\nПорядок внутри каждого потока может быть рассогласован с пообъектным порядком и порядком модификации. Обратите внимание: при RYW не бывает  в порядке модификации и для  – аналогично; таким образом, в порядке модификации должно содержаться  и . Таким образом, порядок модификации очевидно образует цикл в порядке потоков.\r\nТакой цикл допускается в COCA при слабой модели памяти. Речь не о том, что порядок потоков/считываний противоречит порядку модификации, а о том, что каждый поток видит непротиворечивую историю записей. Эти истории согласуются с историями других потоков лишь в том случае, если мы пообъектно ограничиваем область их применения.\r\nВремя фрагментарно.\r\nДаже хотя нам и кажется, что время течет совершенно упорядоченно, изучение распределенных систем и слабой модели памяти со всей ясностью вам демонстрирует, что это не так. Именно поэтому в обоих данных ситуациях наша стандартная чрезмерная аппроксимация, согласно которой время тотально, ограничивает производительность – чего мы не можем себе позволить. \r\nЗатем, признав, что время действительно фрагментарно, мы обнаружим множество маленьких, но важных отличий между разновидностями такой частичности. Даже два вышеупомянутых поля, которые кажутся настолько схожими на первый взгляд, во множестве тонких нюансов позволяют различать, какие именно виды событий при них считаются взаимовлияющими. \r\nНеобходимо подробнее разбираться в технических деталях различных свойств уже после того, как кто-то сможет выразить свойства одного поля на языке другого. \r\nВремя фрагментарно. Возможно, нам просто требуется к этому привыкнуть.", "url": "https://habr.com/ru/company/piter/blog/430926/"},
{"title": "Полное руководство по CMake. Часть третья: Тестирование и пакетирование", "article_text": "Данная статья повествует о тестировании и пакетировании программ при помощи CMake — гибкого и универсального набора утилит для разработки различных программных продуктов. Строго рекомендуется прочитать  и  части руководства во избежание непонимания синтаксиса и принципа работы CMake.Ниже приведены примеры использования языка CMake, по которым Вам следует попрактиковаться. Экспериментируйте с исходным кодом, меняя существующие команды и добавляя новые. Чтобы запустить данные примеры, установите CMake с .Как было сказано ранее, CMake поддерживает автоматическое тестирование программ. Данную возможность весьма легко использовать — достаточно лишь написать несколько команд в привычном , а затем запустить тесты посредством  или . В Вашем распоряжении присутствует проверка вывода программ, динамический анализ памяти и многое другое.Мы рассмотрим процесс тестирования программы на конкретном примере. Исходный файл  содержит следующий код:Данный код выводит результат перемножения двух аргументов в консоль. Обратите внимание, что возможна также ситуация возникновения ошибки, если реальное число аргументов не удоволетворяет ожидаемому: в таком случае в поток ошибок будет выведено .В том же каталоге находится файл  с описанием процесса сборки, содержащий приведённый ниже код:Рассмотрим всё по порядку. Первые четыре команды должны быть вам знакомы с , а следующая команда  вызывает ряд вопросов. По существу, данная команда лишь уведомляет CMake о Вашем намерении протестировать программу, попутно генерируя некоторые конфигурационные файлы, о существовании которых Вам знать не обязательно.Следующие три команды  добавляют тесты к текущему проекту. Краткая форма данной команды первым аргументом принимает наименование теста, а последующие аргументы образуют команду оболочки для запуска теста.Череда команд  устанавливает поведение отдельно взятых тестов. После списка наименований тестов следует ключевое слово , сигнализирующее о начале списка свойств, имеющих вид  и задаваемых для выбранных тестов. Полный список доступных свойств находится .Для всех тестов задаётся максимальное время исполнения в одну секунду свойством , а затем для последующих тестов устанавливается ожидаемый вывод свойствами  и  (например, если происходит совпадение с регулярным выражением , то выполнение теста  продолжается, а в случае совпадения с выражением  тест останавливается и считается неудавшимся).Существует аналог команды  — это включение модуля  посредством команды . В общем случае, включение модуля более универсально, однако между ними всё же есть различие.Команда  включает тестирование для текущего каталога, а также для всех последующих. Она должна находится в корневом , так как CTest ожидает файл тестирования в корне сборки.Включение модуля  конфигурирует проект для тестирования посредством CTest/CDash, а также автоматически определяет опцию , принимающую истину при возможности проведения тестирования (по умолчанию — ). Таким образом, при использовании данной команды разумно описывать процесс тестирования подобным образом:Чередой команд  запускаются на выполнение все три теста. Командой  исполняется набор тестов, удоволетворяющих заданному регулярному выражению. Например, команда  запускает лишь третьй тест.Для создания пакета исходных файлов, библиотек и исполняемых файлов Вам осталось лишь описать установку необходимых файлов с помощью команды , а затем включить модуль  командой :В данном случае, команда  уведомляет генератора пакетов о каталоге установки цели . Без написания команд установки генерация пакетов невозможна.Далее перечисляются характеристики пакета заданием нескольких переменных. На самом деле, существует обилие подобных переменных, должным образом оформляющих пакеты. Большинство из них не обязательны, однако некоторые генераторы пакетов требуют их определения. Список переменных, общих для всех генераторов пакетов, доступен .Обязательно определение переменной  — она является списком генераторов пакетов, вызываемых утилитой . В данном случае она принимает значение , следовательно, в корневом каталоге обзорного приложения сгенерируется debian-пакет.Наконец, подключается модуль , конфигурирующий будущий пакет проекта, используя ранее определённые переменные и команду установки исполняемого файла, а также добавляющий две цели сборки —  и  (соответственно бинарная сборка и сборка исходных кодов).Чередой команд  запускается на выполнение выбранный генератор для создания бинарного пакета, а команды  генерируют пакет исходных кодов прямо в корневом каталоге.На этом цикл статей полного руководства по CMake подошёл к концу. Надеюсь, что Вы извлекли много полезного материала, а также повысили своё мастерство в программировании. Удачи!", "url": "https://habr.com/ru/post/433822/"},
{"title": "Qt Everywhere: WebAssembly и WebGL стриминг", "article_text": "Qt Everywhere — так именуются архивы с исходниками Qt. В 5.12.0 завезут WebAssembly и WebGL стриминг и everywhere звучит уже по другому. Так и просилось что-нибудь запрототипировать. Был быстро накидан прототип  на веб-сокетах, что бы протестировать поддержку сети. Под катом будет инструкция по сборке и запуска проекта на WebAssembly, пример вызова JavaScript из С++. Сперва нужно поставить toolchain , которым будем собирать Qt. Не забудьте прописать переменные окружения, что бы qmake нашел emcc. Скрипт  запускался со следующими параметрами:Дальше как и везде:Сборка и запуск проектаЗашивать url на котором висит бэкенд не очень хорошо, т.к. захочется запускать на произвольном порту. В случает работы из браузера нужно взять  и  что бы определить где запущен бэкенд. Для этого придется немного пописать на JavaScript.Для любителей дефайнов есть , я же предпочитаю выносить код в pimpl и отдельные файлы. Pimpl здесь лишний, но код разнесу на разные файлыЗаведем какой-нибудь конфиги две реализацииОсталось прописать в pro файле это магия emscripten позволяющая вызывать JavaScript код из C++. Хотя можно это было сделать и без JavaScriptДесктопные браузеры: запускается и работает в Сhrome, Firefox, Safari, Edge(тут пришлось включить экспериментальные функции JavaScript). В зависимости от железа могут быть существенные задержки на компиляции WebAssembly.В Chrome на Andorid могут пройти минуты на компиляцию WebAssembly. Сразу заметил отсутствия поддержки мобильных браузеров, а именно нет вызова системной клавиатуры, при попытки ввести текст. Safari на iOS 12 тут приложение падает на этапе компиляции WebAssembly и я не стал дебажить. Теоретически можно перейти на asm.js, но это требует отдельного исследования.В блоге позиционировался как VNC на веб-сокетах с отрисовкой на WebGL. Из  Qt WebSockets и Qt собранный с поддержкой OpenGL ES 2 т.е. гонять на железе без GPU будет мучительно. Для её поддержки достаточно поставить  в онлайн установщике и запустить приложение с параметром  или , если нужно указать порт.Но у этой технологии есть свои ограничения:Так же я заметил проседание fps при анимации StackView на переходах между экранами. Достоинство WebGL стриминга:Альтернатива  когда есть готовое приложение на C++ и к нему нужно прикрутить веб-интерфейс. Например web-интерфейс к torrent качалке.Web интерфейс для какого-нибудь умного дома. Не даром в Qt завезли MQTT, а на  пример . Можно иметь общий код UI который работает на планшете и в браузере.Код доступен на , подготовленные бинарники ", "url": "https://habr.com/ru/post/430954/"},
{"title": "﻿Godot: к вопросу о регулярном использовании статических анализаторов кода", "article_text": "Аудитория наших читателей растёт, поэтому мы вновь и вновь пишем статьи, в которых объясняем, как правильно использовать методологию статического анализа кода. Мы считаем очень важным объяснить, что инструменты статического анализа должны использоваться не эпизодически, а регулярно. В очередной раз продемонстрируем это на практическом примере, перепроверив проект Godot.\r\nГотовясь к выступлению на конференции разработчиков игр, я решил обзавестись новыми примерами интересных ошибок, которые способен выявить инструмент . С этой целью были проверены несколько игровых движков, одним из которых был Godot. Никаких особенно интересных ошибок для доклада я в нём не нашел, зато мне захотелось написать статью про обыкновенные ошибки. Эти ошибки очень хорошо демонстрируют актуальность регулярного использования инструментов статического анализа кода.\r\nСледует отметить, что мы уже  этот проект в 2015 году, и автор поработал с выписанными нами ошибками.  можно увидеть соответствующий коммит.\r\nПрошло 3 года. Проект изменился. Анализатор PVS-Studio тоже изменился, и в нём появились новые диагностики. Поэтому нет ничего удивительного, что я легко и быстро смог выписать достаточное количество примеров ошибок для написания этой статьи. При разработке Godot или любого другого проекта постоянно появляются и исправляются новые ошибки. Ненайденные ошибки «оседают» в коде надолго, и затем многие из них могут быть выявлены при запуске статического анализа кода. Из-за этого иногда возникает ложное ощущение, что статические анализаторы находят только какие-то малоинтересные ошибки в редко используемых участках кода. Конечно, так оно и есть, если использовать анализатор неправильно и запускать его только время от времени, например, незадолго до выпуска релиза.\r\nДа, мы сами при написании статей выполняем разовые проверки открытых проектов. Но у нас другая цель. Мы хотим продемонстрировать возможности анализатора кода по выявлению дефектов. Эта задача имеет мало общего с повышением качества кода проекта в целом и сокращением издержек, связанных с правкой ошибок.\r\nЕщё раз о главном. Смысл статического анализа кода не в том, чтобы найти застаревшие ошибки. Эти старые ошибки обычно незначительны, иначе бы они мешали пользователям и их бы уже нашли и исправили. Смысл статического анализа в быстром устранении ошибок в только что написанном или изменённом коде. Это сокращает время отладки, количество жалоб пользователей и, в конечном итоге, сокращает бюджет разрабатываемого проекта.\r\nТеперь перейдём к багам, которые так любят читатели наших публикаций.\r\nДавайте посмотрим, что я заметил, изучая отчёт PVS-Studio. Начну с моей любимой диагностики V501, которая находит , который мы проверяем :).\r\nПредупреждение PVS-Studio: V501 CWE-570 There are identical sub-expressions '!exists_export_template(«uwp_» + platform_infix + \"_debug.zip\", & err)' to the left and to the right of the '||' operator. export.cpp 1135\r\nКлассическая Copy-Paste ошибка. Вызов функции скопирован, но не отредактирован. Имя второго обрабатываемого файла должно заканчиваться на \"_release.zip\".\r\nПредупреждение PVS-Studio: V501 CWE-570 There are identical sub-expressions 'bnode->statements[i]->type == SL::Node::TYPE_CONTROL_FLOW' to the left and to the right of the '||' operator. test_shader_lang.cpp 183\r\nПредупреждение PVS-Studio: V501 CWE-570 There are identical sub-expressions 'p_what == MainLoop::NOTIFICATION_WM_FOCUS_OUT' to the left and to the right of the '||' operator. editor_spin_slider.cpp 157\r\nДумаю, ошибки хорошо видны и не требуют каких-либо пояснений. Точно такой же классический Copy-Paste, как и в первом случае.\r\nПредупреждение PVS-Studio: V501 CWE-570 There are identical sub-expressions to the left and to the right of the '||' operator. soft_body.cpp 399\r\nЗдесь первая строка была скопирована дважды. Но номер оси координат был изменён только во второй строке. А третью строчку отредактировать забыли. Это не что иное, как \"\". На данный момент, помимо «Эффекта последней строки», мною сделаны следующие интересные наблюдения: \"\", \"\". И сейчас я сделаю анонс новой статьи, написанием которой я планирую заняться в ближайшее время. Рабочее название «0, 1, 2». Должно получиться интересно и поучительно. Приглашаю подписываться на один из каналов, чтобы не пропустить: , , ,  и «олдскульный» .\r\nПредупреждение PVS-Studio: V778 CWE-682 Two similar code fragments were found. Perhaps, this is a typo and 'v_scroll' variable should be used instead of 'h_scroll'. scroll_container.cpp 249\r\nПо поводу этого фрагмента кода у меня нет полной уверенности, что здесь есть ошибка. Однако я согласен с анализатором, что второй блок выглядит очень подозрительно. Скорее всего, код писался с помощью Copy-Paste и во втором блоке текста забыли заменить  на .\r\nВероятно, код должен быть таким:\r\nЕщё один случай, когда был скопирован и неудачно изменён достаточно большой фрагмент кода. Строчка с ошибкой помечена мною комментарием \"// <=\".\r\nПредупреждение PVS-Studio: V522 CWE-476 Dereferencing of the null pointer 'E' might take place. shader_gles2.cpp 102\r\nОшибка выявлена косвенным образом. Благодаря анализу  PVS-Studio выявил, что указатель  может быть нулевым в момент его разыменования.\r\nОшибка заключается в том, что в скопированном фрагменте кода забыли заменить в одном месте  на . Из-за этой ошибки функция работает очень странным образом и делает непонятные вещи.\r\nПрограммистам, пишущим не на языке C или C++, сложно представить, что можно допустить опечатку, написав вместо звёздочки '*' запятую ',', и при этом код будет компилироваться. Однако это так.\r\nПредупреждение PVS-Studio: V521 CWE-480 Such expressions using the ',' operator are dangerous. Make sure the expression is correct. os_windows.cpp 776\r\nПеременной  присваивается значение переменной . Далее выполняется оператор запятая ',', чей  ниже, чем у оператора '='. Результат же выражения  никак не используется.\r\nВместо запятой в выражении должен использоваться оператор умножения '*'. Во-первых, такое выражение будет иметь смысл. Во-вторых, ниже есть похожий, но уже корректный вариант инициализации такой же переменной:\r\nПредупреждение PVS-Studio: V547 CWE-571 Expression 'idx >= 0 || idx < 4' is always true. variant_op.cpp 2152\r\nЛюбой индекс будет считаться корректным. Чтобы исправить ошибку, надо заменить оператор  на :\r\nЭта логическая ошибка возникла, скорее всего, по невнимательности, поэтому я склонен отнести её к опечаткам.\r\nТочно такую же ошибку можно наблюдать в этом же файле чуть ниже. Виной размножения ошибки, по всей видимости, является Copy-Paste. \r\nРазмноженная ошибка: V547 CWE-571 Expression 'idx >= 0 || idx < 4' is always true. variant_op.cpp 2527\r\nПример ошибки, от которой так и хочется воскликнуть: WTF?!\r\nПредупреждение PVS-Studio: V621 CWE-835 Consider inspecting the 'for' operator. It's possible that the loop will be executed incorrectly or won't be executed at all. animation_blend_space_1d.cpp 113\r\nОбратите внимание на условие остановки цикла: . Оно всегда истинно, так как переменная  инициализируется значением . При этом из двух более ранних проверок следует, что .\r\nУсловие может стать ложным, только когда возникнет переполнение знаковой переменной , что является неопределённым поведением. Более того, до переполнения не дойдёт, так как намного раньше произойдёт выход за границу массива.\r\nПеред нами, на мой взгляд, красивейшая опечатка, когда вместо '<' написали '>'. Да, у меня извращённое представление о красоте ошибок :).\r\nКорректный цикл:\r\nЕщё один не менее яркий случай опечатки в условии цикла.\r\nПредупреждение PVS-Studio: V693 CWE-835 Consider inspecting conditional expression of the loop. It is possible that 'i < X.size()' should be used instead of 'X.size()'. animation_state_machine_editor.cpp 852\r\nМожет произойти выход за границу массива, так как значение  увеличивается бесконтрольно. Безопасный код:\r\nПредупреждение PVS-Studio: V796 CWE-484 It is possible that 'break' statement is missing in switch statement. gdscript_compiler.cpp 135\r\nСлучайно забыли написать оператор . Поэтому при попадании в  переменным будут присвоены значения, как будто это .\r\nСледующую ошибку можно классифицировать как Copy-Paste. Однако я не уверен, что столь короткая строка была скопирована. Так что будем считать это простой опечаткой при наборе текста.\r\nПредупреждение PVS-Studio: V519 CWE-563 The 'p.velocity.z' variable is assigned values twice successively. Perhaps this is a mistake. Check lines: 664, 665. cpu_particles.cpp 665\r\nДва раза происходит присваивание одной и той же переменной. Ниже можно увидеть вот такой фрагмент кода:\r\nСкорее всего, для первого случая должно было быть написано так же.\r\nПредупреждение PVS-Studio: V751 Parameter 'p_y' is not used inside function body. texture.cpp 1085\r\nФрагмент из описания диагностики :\r\nКак видите, это действительно так, и это очень подозрительно. Переменная  используется дважды, а  не используется. Скорее всего, должно быть написано:\r\nКстати, в исходном коде вызов функции написан в одну строчку. Из-за этого ошибку сложнее заметить. Если бы автор кода написал фактические аргументы в столбик, как я сделал это в статье, то ошибка сразу бросилась бы в глаза. Не забывайте, что табличное форматирование весьма полезно и позволяет избежать множества опечаток. См. главу «Выравнивайте однотипный код „таблицей“ в статье „“.\r\nПредупреждение PVS-Studio: V767 Suspicious access to element of 'files' array by a constant index inside a loop. sprite_frames_editor_plugin.cpp 602\r\nВ цикле обрабатывается один и тот же файл на всех итерациях цикла. Опечатка здесь:\r\nДолжно быть:\r\nАнализатор PVS-Studio выдаёт сразу два срабатывания на этот код:\r\nИ действительно, вот этот тернарный оператор в обоих выражениях выглядит очень странно:\r\nВ одном случае условие всегда истинно, а в другом — ложно. Затрудняюсь сказать, как правильно должен выглядеть этот код. Возможно, он просто избыточен и можно написать так:\r\nЯ могу быть неправ, и код надо исправить совсем другим способом.\r\nОшибок типа V595 почти не нашлось, хотя обычно . Видимо, эти ошибки были исправлены после предыдущей проверки, и затем ошибки этого типа почти не появлялись. Я увидел только несколько ложных срабатываний и одну ошибку.\r\nПредупреждение PVS-Studio: V595 CWE-476 The 'from_node' pointer was utilized before it was verified against nullptr. Check lines: 565, 567. canvas_item_editor_plugin.cpp 565\r\nУказатель вначале разыменовывается для вызова функции  и только затем проверятся на равенство . Проверки следует поменять местами:\r\nПредупреждение PVS-Studio: V557 CWE-125 Array overrun is possible. The value of 'i' index could reach 9. input_default.cpp 1119\r\nМассив  состоит из восьми элементов. При этом константа , задающая количество итераций цикла, равна 10. Получается, что в цикле происходит выход за границу массива.\r\nИ последняя очень странная функция, которая, видимо, предназначена для тестирования чего-то. Функция длинная, поэтому я приведу её в виде картинки (нажмите на картинку для увеличения).\r\nПредупреждение PVS-Studio: V779 CWE-561 Unreachable code detected. It is possible that an error is present. test_math.cpp 457\r\nВ функции встречается несколько безусловных операторов . На картинке я отметил их красными овалами. Такое впечатление, что в эту функцию собрали несколько разных юнит-тестов, но забыли удалить лишние . В результате функция не проверяет то, что должна проверять. Почти всё тело функции состоит из недостижимого кода.\r\nВозможно, конечно, это какая-то хитрая задумка. Но мне кажется, это получилось случайно и код следует исправить.\r\nНа этом давайте закончим. Наверняка, если внимательно всмотреться в отчёт анализатора, можно найти и другие ошибки. Однако даже выписанного с лихвой хватило для написания статьи. Дальше уже станет скучно и мне, и читателю :).\r\nВ статье описаны ошибки, которых бы не существовало, если бы код регулярно анализировался с помощью PVS-Studio. Однако, что ещё более важно, используя анализ регулярно, можно было бы сразу найти и устранить множество других ошибок. Более развернуто эту мысль описал мой коллега в заметке: „“. Очень рекомендую потратить 10 минут на прочтение этой короткой, но очень важной статьи.\r\nСпасибо за внимание. Приглашаю всех скачать и попробовать статический анализ PVS-Studio для проверки ваших собственных проектов.\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: Andrey Karpov. .", "url": "https://habr.com/ru/company/pvs-studio/blog/431200/"},
{"title": "У Интернета могут быть серьёзные проблемы из-за языков, подобных C и C++, которые способствуют появлению уязвимостей", "article_text": "Привет, Хабр! Представляю вашему вниманию перевод статьи \"\" (фр. язык).\r\nОдин баг затрагивает iPhone, другой – Windows, а третий – сервера, работающие на Linux. На первый взгляд эти баги не имеют ничего общего, так как касаются разных платформ: Android, iOS, macOS, Windows, Linux. Однако, на самом деле, всё иначе, по мнению Алекса Гейнора, инженера по безопасности программного обеспечения в Mozilla, ранее работавшего в USDS (United States Digital Service).\r\nВо время третьего «Weakest Link», ежегодного мероприятия, организованного Motherboard Vice,  \r\nна тему компьютерного взлома и кибербезопасности в будущем, Алекс Гейнор поднял серьезную проблему, которая, по его мнению, может угрожать Интернету, но, как ни парадоксально, оставляет разработчиков совершенно равнодушными.\r\nГейнор объяснил, что три ранее упомянутые ошибки существуют, потому что программное обеспечение, которое они затрагивают на разных платформах, было написано с помощью языков программирования, имеющих неприятную тенденцию способствовать возникновению ошибок типа «memory unsafety», разрешая доступ к невыделенным областям памяти.\r\nЭта категория ошибок может привести к багам и уязвимостям безопасности во время получения доступа к памяти.\r\nДавая возможность для возникновения ошибок типа «memory unsafety», языки программирования, такие как C и C++, могут способствовать распространению почти бесконечного потока критических уязвимостей безопасности на протяжении многих лет. В качестве примера этих уязвимостей можно привести: \r\nНесоответствие типов может возникать, когда участок кода не проверяет тип передаваемого ему объекта и использует его вслепую. Такая ситуация может оказаться опасной. Кроме того, вместе с несоответствием типов неправильные указатели на функции или неправильные данные связаны с неправильной частью кода, что в некоторых случаях может привести к его выполнению.\r\nПереполнение буфера (или «buffer overflow» на английском языке) является критической уязвимостью безопасности, которая возникает, когда пользователь вводит строку, которая будет находиться в массиве символов недостаточного размера. Это приводит к записи данных вне области памяти, выделенной для массива. HeartBleed, например, оказавший влияние на 17% защищенных серверов в интернете, был уязвимостью переполнения буфера, позволяющей считывать 60 КБ после конца списка, включая пароли и другие пользовательские данные.\r\nПереполнение целочисленных переменных — трудно обнаружимая уязвимость, которая использует тот факт, что числа не могут превышать определенное значение, которое зависит от количества бит, используемых для их представления, и метода кодирования.\r\nУязвимость «use after free» обычно возникает в случае использования указателя или данных в памяти, когда указатель (или блок памяти) уже освобожден.\r\nВместе эти уязвимости представляют собой эксплойты, наиболее часто встречающиеся в популярном программном обеспечении, к примеру, Firefox, Chrome, Windows, Android или iOS. Гейнор уже насчитал по крайней мере 400 и утверждает: «Я следил за безопасностью этих проектов более года, и почти во всех версиях этих продуктов более половины уязвимостей — это «memory unsafety». И еще более тревожно то, что тяжелые и критические уязвимости [...] почти всегда имеют этот тип».\r\nНесмотря на значительные риски, связанные с безопасностью программного обеспечения, которое они поддерживают, языки программирования «memory unsafety friendly», такие как C или C++, всё ещё используются разработчиками, в то время как проверенные альтернативы, такие как Rust, Swift, которые можно рассматривать как языки «memory safe», редки.\r\nЭто может быть связано с тем, что для нового проекта разработчики, как правило, выбирают язык программирования на основе языков, которые знает их команда, производительности и системы библиотек, которые могут вытекать из этого выбора. При принятии решений компонент безопасности, связанный с этим, почти никогда не рассматривается или же, по крайней мере, рассматривается недостаточно, считает Гейнор.\r\nКроме того, большинство программных проектов, даже самых важных для безопасности Интернета, не являются новыми. Они были запущены десять лет назад, если не больше. Linux, OpenSSL и веб-серверу Apache, например, более двадцати лет. Для масштабных проектов, подобных этим, переписывание всего кода на новом языке не вариант. Они должны быть преобразованы постепенно, что значит, что проекты должны быть написаны и сохранены на двух разных языках вместо одного. Это также предполагает необходимость формирования большой команды, которое занимает много времени и требует больше средств.\r\nСамая большая проблема, наконец, связана с тем, что многие разработчики вообще не верят, что проблема существует. Они считают, что проблема не в том, что такие языки, как C или C++, способствуют возникновению уязвимостей, а в других программистах, которые пишут код с ошибками. Они считают, что проблемы с этими якобы «memory unsafety friendly» языками нет, потому что никакой код не идеален, просто люди не умеют ими пользоваться.\r\nА что Вы думаете по этому поводу?\r\nОтмечу, что здравая критика перевода также приветствуется.\r\nСпасибо за внимание!", "url": "https://habr.com/ru/post/432502/"},
{"title": "Транспайлер-цепь Python → 11l → C++ [для ускорения Python-кода и не только]", "article_text": "\r\nВ данной статье рассматриваются наиболее интересные преобразования, которые выполняет цепочка из двух ов (первый переводит код на языке Python в код на , а второй — код на 11l в C++), а также производится сравнение производительности с другими средствами ускорения/исполнения кода на Python (PyPy, Cython, Nuitka).Явное указание для индексирования от конца массива  вместо просто  нужно для исключения следующих ошибок:\r\nНа первый взгляд выдающаяся черта языка Python, но на практике от неё легко можно отказаться/обойтись посредством оператора  и диапазонов:\r\nАналогично, как оказалось, можно отказаться и от другой интересной фичи Python — list comprehensions.\r\nВ то время как одни , я обнаружил, что:\r\nВ то время как Python не содержит оператора switch, это одна из самых красивых конструкций в языке 11l, и поэтому я решил вставлять switch автоматически:\r\nРассмотрим такую строчку кода на Python:Скорее всего, такая форма записи не очень эффективна , зато очень удобна.\r\nВ 11l же соответствующая данной строчке  запись не только удобная , но и быстрая:\r\nПриведённая строчка странслируется в:\r\nВ том случае, когда производится присваивание переменной, словарь оставляется как есть:\r\nВ Python для указания того, что переменная не является локальной, а должна быть взята снаружи , используется ключевое слово nonlocal .\r\nВ 11l для этого используется префикс @:C++:\r\nАналогично внешним переменным, если забыть объявить глобальную переменную в Python , то получится незаметный баг:Код на 11l  в отличие от Python  выдаст на этапе компиляции ошибку ‘необъявленная переменная ’.\r\nЯ всё время забываю порядок переменных, которые возвращает Python-функция  {сначала идёт значение, а потом индекс или наоборот}. Поведение аналога в Ruby —  — гораздо легче запомнить: with index означает, что index идёт после value, а не перед. Но в 11l логика ещё проще для запоминания:\r\nВ качестве тестировочной используется , а в качестве исходных данных берётся исходник  , и повторяется 10 раз, то есть получается из 48.8 килобайтной статьи файл размером 488Кб.\r\nВот диаграмма, показывающая во сколько раз соответствующий способ исполнения Python-кода быстрее оригинальной реализации :\r\nИсходник на Python и вывод транспайлеров Python → 11l и 11l → C++:", "url": "https://habr.com/ru/post/431318/"},
{"title": "Детерминированные исключения и обработка ошибок в «C++ будущего»", "article_text": "Странно, что на Хабре до сих пор не было упомянуто о наделавшем шуму предложении к стандарту C++ под названием \"Zero-overhead deterministic exceptions\". Исправляю это досадное упущение.Если вас беспокоит оверхед исключений, или вам приходилось компилировать код без поддержки исключений, или просто интересно, что будет с обработкой ошибок в C++2b (отсылка к ), прошу под кат. Вас ждёт выжимка из всего, что сейчас можно найти по теме, и пара опросов.Разговор далее будет вестись не только про статические исключения, но и про связанные предложения к стандарту, и про всякие другие способы обработки ошибок. Если вы зашли сюда поглядеть на синтаксис, то вот он:Если конкретный тип ошибки неважен/неизвестен, то можно использовать просто  и .Пусть мы решили, что ошибка, которая потенциально может возникнуть в функции, недостаточно «фатальная», чтобы бросать из неё исключение. Традиционно информацию об ошибке возвращают с помощью выходного параметра (out parameter). Например,  предлагает ряд подобных функций:(Не бросать же исключение из-за того, что файл не найден?) Тем не менее, обработка кодов ошибок громоздкая и подвержена багам. Код ошибки легко забыть проверить. Современные стили кода  использование выходных параметров, вместо них рекомендуется возвращать структуру, содержащую весь результат.Boost вот уже некоторое время предлагает изящное решение для обработки таких «не-фатальных» ошибок, которые в определённых сценариях могут происходить сотнями в корректной программе:Тип  похож на , но предоставляет удобный интерфейс для работы с «результатом» и «ошибкой». По умолчанию, в  хранится «результат». Реализация  может выглядеть как-то так:Если причина ошибки нам неинтересна, или ошибка может заключаться только в «отсутствии» результата, то можно использовать :В C++17 из Boost в std попал  (без поддержки ); в C++20, возможно, добавят  (это только Proposal, спасибо  за поправку). (не путать с концептами) — новый способ наложить ограничения на параметры функции, добавленный в C++20. Добавлены 3 аннотации:Можно настроить, чтобы нарушение контрактов:Продолжать работу программы после нарушения контракта никак нельзя, потому что компиляторы используют гарантии из контрактов для оптимизации кода функции. Если есть малейшее сомнение в том, что контракт выполнится, стоит добавить дополнительную проверку.Библиотека , добавленная в C++11, позволяет унифицировать обработку кодов ошибок в вашей программе.  состоит из кода ошибки типа  и указателя на объект какого-нибудь класса-наследника . Этот объект, по сути, играет роль таблицы виртуальных функций и определяет поведение данного .Чтобы создавать свои , вы должны определить свой класс-наследник  и реализовать виртуальные методы, самым важным из которых является:Нужно также создать глобальную переменную вашего . Обработка ошибок при помощи error_code + expected выглядит как-то так:Важно, что в  значение 0 означает отсутствие ошибки. Если для ваших кодов ошибок это не так, то перед тем, как конвертировать системный код ошибки в , надо заменить код 0 на код SUCCESS, и наоборот.Все системные коды ошибок описаны в  и . Если на определённом этапе ручной проброс кодов ошибки становится слишком муторным, то всегда можно завернуть код ошибки в исключение  и выбросить.Пусть вам нужно создать очередной класс объектов, владеющих какими-нибудь ресурсами. Скорее всего, вы захотите сделать его некопируемым, но перемещаемым (moveable), потому что с unmoveable объектами неудобно работать (до C++17 их нельзя было вернуть из функции).Но вот беда: перемещённый объект в любом случае нужно удалить. Поэтому необходимо особое состояние \"moved-from\", то есть \"пустого\" объекта, который ничего не удаляет. Получается, каждый класс C++ обязан иметь пустое состояние, то есть невозможно создать класс с инвариантом (гарантией) корректности, от конструктора до деструктора. Например, невозможно создать корректный класс  файла, который открыт на всём протяжении времени жизни. Странно наблюдать это в одном из немногих языков, активно использующих RAII.Другая проблема — зануление старых объектов при перемещении добавляет оверхед: заполнение  может быть до 2 раз медленнее, чем  из-за кучи занулений старых указателей при перемещении, с последующим удалением пустышек.Разработчики C++ давно облизываются на Rust, где у перемещённых объектов не вызываются деструкторы. Эта фича называется Destructive move. К сожалению, Proposal  не предлагает добавить её в C++. Но проблему оверхеда решит.Класс считается Trivially relocatable, если две операции: перемещения и удаления старого объекта — эквивалентны memcpy из старого объекта в новый. Старый объект при этом не удаляется, авторы называют это \"drop it on the floor\".Тип является Trivially relocatable с точки зрения компилятора, если выполняется одно из следующих (рекурсивных) условий:Использовать эту информацию можно с помощью , которая исполняет move init + delete обычным способом, или ускоренным, если это возможно. Предлагается пометить как  большинство типов стандартной библиотеки, включая , , . Оверхед  с учётом этого Proposal исчезнет.Механизм исключений C++ разрабатывался в 1992 году. Были предложены различные варианты реализации. Из них в итоге был выбран механизм таблиц исключений, которые гарантируют отсутствие оверхеда для основного пути выполнения программы. Потому что с самого момента их создания создания предполагалось, что . Недостатки динамических (то есть обычных) исключений:Из-за этих недостатков существенно ограничивается область применения исключений. Когда исключения не могут применяться:По опросам, на местах работы 52% (!) разработчиков исключения запрещены корпоративными правилами.Но исключения — неотъемлемая часть C++! Включая флаг , разработчики теряют возможность использовать значительную часть стандартной библиотеки. Это дополнительно подстрекает компании насаждать собственные \"стандартные библиотеки\" и да, изобретать свой класс строки.Но и это ещё не конец. Исключения — единственный стандартный способ отменить создание объекта в конструкторе и выдать ошибку. Когда они отключены, появляется такая мерзость, как двухфазная инициализация. Операторы тоже не могут использовать коды ошибок, поэтому они заменяются функциями вроде .Герб Саттер (Herb Sutter) в P709 описал новый механизм передачи исключений. Идейно, функция возвращает , однако вместо отдельного дискриминатора типа , который вместе с выравниванием будет занимать до 8 байт на стеке, этот бит информации передаётся каким-то более быстрым способом, например, в Carry Flag.Функции, которые не трогают CF (таких большинство), получат возможность использовать статические исключения бесплатно — и в случае обычного возврата, и в случае проброса исключения! Функции, которые вынуждены будут его сохранять и восстанавливать, получат минимальный оверхед, и это всё равно будет быстрее, чем  и любые обычные коды ошибок.Выглядят статические исключения следующим образом:В альтернативной версии предлагается обязать ставить ключевое слово  в том же выражении, что вызов  функции: . Это сведёт число случаев использования  функций в коде, не безопасном для исключений, практически к нулю. В любом случае, в отличие от динамических исключений, у IDE будет возможность как-то выделять выражения, бросающие исключения.То, что выброшенное исключение не сохраняется отдельно, а кладётся прямо на место возвращаемого значения, накладывает ограничения на тип исключения. Во-первых, он должен быть Trivially relocatable. Во-вторых, его размер должен быть не очень большим (но это может быть что-то вроде ), иначе все функции будут резервировать больше места на стеке.Библиотека , разработанная Найл Дуглас (Niall Douglas), будет содержать  — «новый, лучший» . Основные отличия от :Далее, вводится  — обёртка над  со следующим конструктором:Тип исключения по умолчанию ( без типа), а также базовый тип исключений, к которому приводятся все остальные (вроде ) — это . Он определён примерно так:То есть  — это такой «ошибочный» , у которого значение () помещается в 1 указатель. Так как механизм  обеспечивает корректное удаление, перемещение и копирование, то теоретически в  можно сохранить любую структуру данных. На практике это будет один из следующих вариантов:Проблема в том, что случае 3 не планируется дать возможность привести  обратно к . Единственное, что можно сделать — получить  упакованного . Чтобы иметь возможность достать обратно завёрнутое в  значение, надо выбросить его как динамическое исключение (!), потом поймать и завернуть в . А вообще, Найл считает, что в  должны храниться только коды ошибок и строковые сообщения, чего достаточно для любой программы.Чтобы различать разные виды ошибок, предлагается использовать «виртуальный» оператор сравнения:Использовать несколько catch-блоков или  для выбора типа исключения не получится!Функция может иметь одну из следующих спецификаций: подразумевает . Если динамическое исключение выбрасывается из «статической» функции, то оно заворачивается в . Если статическое исключение выбрасывается из «динамической» функции, то оно заворачивается в исключение . Пример:Предложение предусматривает добавление исключений в один из будущих стандартов C, причём эти исключения будут ABI-совместимы со статическими исключениями C++. Структуру, аналогичную , пользователь должен будет объявлять самостоятельно, хотя избыточность можно убрать с помощью макросов. Синтаксис состоит из (для простоты будем так считать) ключевых слов fails, failure, catch.При этом в C++ тоже можно будет вызывать  функции из C, объявляя их в блоках . Таким образом, в C++ будет целая плеяда ключевых слов по работе с исключениями:Итак, в C++ завезли (точнее, завезут) тележку новых инструментов для обработки ошибок. Далее возникает логичный вопрос:Ошибки разделяются на несколько уровней:В стандартной библиотеке надёжнее всего будет полностью отказаться от использования динамических исключений, чтобы сделать компиляцию «без исключений» легальной.Функции, использующие  для быстрой и минималистичной работы с кодами ошибок C и C++, должны быть заменены на  и , соответственно. Некоторое время старый и новый варианты функций стандартной библиотеки будут сосуществовать, потом старые объявят устаревшими.Ошибки выделения памяти обрабатывает глобальный хук , который может:Сейчас по умолчанию выбрасывается . Предлагается же по умолчанию вызывать . Если вам нужно старое поведение, замените обработчик на тот, который вам нужен, в начале .Все существующие функции стандартной библиотеки станут  и будут крашить программу при . В то же время, будут добавлены новые API вроде , которые допускают ошибки выделения памяти.Исключения , , , , ,  сообщают о нарушении предусловия функции. В новой модели ошибок вместо них должны использоваться контракты. Перечисленные типы исключений  будут объявлены устаревшими, но почти все случаи их использования в стандартной библиотеке будут заменены на .Proposal сейчас находится в состоянии черновика. Он уже довольно сильно поменялся, и ещё может сильно измениться. Некоторые наработки не успели опубликовать, так что предлагаемый API  не совсем актуален.Предложение описывается в 3 документах:На настоящий момент не существует компилятора, который поддерживает статические исключения. Соответственно, сделать их бенчмарки пока невозможно.При наилучшем раскладе детерминированные исключения будут готовы и попадут в C++23. Если не успеют, то, вероятно, попадут в C++26, так как комитет стандартизации, в целом, заинтересован темой.Многие детали предлагаемого подхода к обработке исключений я опустил или умышленно упростил, зато прошёлся по большинству тем, требующихся для понимания статических исключений. Если возникли дополнительные вопросы, то задайте их в комментариях или обратитесь к документам по ссылкам выше. Любые поправки приветствуются.И конечно, обещанные опросы ^^", "url": "https://habr.com/ru/post/430690/"},
{"title": "Текстовая версия доклада «Actors vs CSP vs Tasks...» с C++ CoreHard Autumn 2018", "article_text": "В начале ноября в Минске прошла очередная посвященная языку C++ конференция C++ CoreHard Autumn 2018. На ней был сделан , где речь шла о том, как может выглядеть в C++ применение более высокоуровневых, чем «голая многопоточность», моделей конкурентного программирования. Под катом преобразованная в статью версия этого доклада. Причесанная, местами подправленная, местами дополненная.\r\nПользуясь случаем хочется выразить благодарность сообществу  за организацию очередной большой конференции в Минске и за предоставленную возможность выступить. А также за оперативную публикацию .\r\nИтак, давайте перейдем к основной теме разговора. А именно к тому, какие подходы к упрощению многопоточного программирования в C++ мы можем использовать, как в коде будет выглядеть использование некоторых из этих подходов, какие особенности присущи конкретным подходам, что между ними общего и т.д.\r\nПримечание: в оригинальной презентации к докладу были обнаружены ошибки и опечатки, поэтому в статье будут использованы слайды из обновленной и отредактированной версии, которую можно найти в  или на .\r\nНачать нужно с многократно повторенной банальности, которая, тем не менее, все еще остается актуальной:\r\nХороший пример был недавно описан вот в этой статье здесь, на Хабре: \"\". В ней ребята рассказали о том, как они умудрились собрать, по всей видимости, полный спектр граблей, связанных с разработкой многопоточного кода на C и С++. Там были и «проходы» по памяти в результате гонок, и невысокая производительность из-за неудачного распараллеливания.\r\nВ результате все закончилось вполне закономерно:\r\nЛюди наелись C/С++ при работе над первой версией своего сервера и переписали сервер на другом языке.\r\nОтличная демонстрация того, как в реальном мире, вне нашего уютного C++сообщества, разработчики отказываются от использования С++ даже там, где применение C++ все еще уместно и оправдано.\r\nНо почему же, если многократно говорено, что «голая многопоточность» на C++ — это зло, люди продолжают использовать ее с упорством, достойным лучшего применения? Что тому виной:\r\nВедь существует далеко не один проверенный временем и множеством проектов подход. В частности:\r\nОстается надеяться, что основная причина — это все таки незнание. Вряд ли этому учат в ВУЗах. Значит молодые специалисты, приходя в профессию, используют то немногое, что им уже знакомо. И если затем багаж знаний затем не пополняется, то люди так и продолжают использовать голые threads, mutexes и condition_variables.\r\nСегодня мы поговорим о трех первых подходах из этого списка. Причем поговорим не абстрактно, а на примере одной простенькой задачки. Попробуем показать, как будет выглядеть решающий эту задачу код с использованием Actor-ов, CSP-шных процессов и каналов, а также с применением Task-ов.\r\nТребуется реализовать HTTP-сервер, который:\r\nНапример, такой сервер может потребоваться некому платному сервису, раздающему контент по подписке. Если картинка из этого сервиса затем где-то «всплывет», то по «водяным знакам» на ней можно будет понять, кому нужно «перекрыть кислород».\r\nЗадача абстрактная, она была сформулирована специально для данного доклада под влиянием нашего демо-проекта Shrimp (мы о нем уже рассказывали: , , ).\r\nЭтот наш HTTP-сервер будет работать следующим образом:\r\nПолучив запрос от клиента мы обращаемся к двум внешним сервисам:\r\nОба эти сервиса работают независимо и мы можем обращаться к ним обоим одновременно.\r\nПоскольку обработку запросов можно делать независимо друг от друга, и даже некоторые действия при обработке одного запроса можно делать параллельно, то напрашивается использование конкурентности. Самое простое, что приходит в голову, — это создание отдельной нити на каждый входящий запрос:\r\nНо модель «один-запрос=один-рабочий-поток» слишком дорогостоящая и она плохо масштабируется. Нам это не нужно.\r\nДаже если подойти к количеству рабочих потоков расточительно, то все равно нам потребуется небольшое их количество:\r\nЗдесь нам нужен отдельный поток для приема входящих HTTP-запросов, отдельный поток для собственных исходящих HTTP-запросов, отдельный поток для координации обработки принятых HTTP-запросов. А так же пул рабочих потоков для выполнения операций над изображениями (поскольку манипуляции над изображениями хорошо параллелятся, то обрабатывая картинку сразу не нескольких потоках мы сокращаем время ее обработки).\r\nСледовательно, наша цель в том, чтобы обрабатывать большое количество параллельных входящих запросов на небольшом количестве рабочих нитей. Давайте посмотрим на то, как мы этого достигнем с помощью различных подходов.\r\nПрежде чем перейти к основному рассказу и разбору примеров кода нужно сделать несколько примечаний.\r\nВо-первых, все нижеследующие примеры не привязаны к какому-то конкретному фреймворку или библиотеке. Любые совпадения в именах API-ных вызовов являются случайными и непреднамеренными.\r\nВо-вторых, в приведенных ниже примерах нет обработки ошибок. Сделано это преднамеренно, дабы слайды получились компактными и обозримыми. А также чтобы материал уместился в отведенное на доклад время.\r\nВ-третьих, в примерах используется некая сущность execution_context, которая содержит информацию о том, что еще существует внутри программы. Наполнение этой сущности зависит от подхода. С случае с акторами в execution_context будут ссылки на других акторов. В случае с CSP, в execution_context будут CSP-шные каналы для связи с другими CSP-шными процессами. И т.д.\r\nПри использовании Модели Акторов решение будет строится из отдельных объектов-акторов, каждый из которых обладает собственным приватным состоянием и это состояние недоступно никому, кроме самого актора.\r\nАкторы взаимодействуют друг с другом посредством асинхронных сообщений. У каждого актора есть собственный уникальный почтовый ящик (очередь сообщений), в который отосланные актору сообщения сохраняются и откуда они извлекаются для последующей обработки.\r\nАкторы работают по очень простым принципам:\r\nВнутри приложения акторы могут быть реализованы по-разному:\r\nМы в своем решении будем использовать акторы в виде объектов с коллбэками, а сопрограммы оставим для CSP-подхода.\r\nНа базе акторов общая схема решения нашей задачи будет выглядеть следующим образом:\r\nУ нас будут акторы, которые создаются при старте HTTP-сервера и существуют все время, пока HTTP-сервер работает. Это такие акторы как: HttpSrv, UserChecker, ImageDownloader, ImageMixer.\r\nПри получении нового входящего HTTP-запроса мы создаем новый экземпляр актора RequestHandler, который будет уничтожен после выдачи ответа на входящий HTTP-запрос.\r\nРеализация актора request_handler, который координирует обработку входящего HTTP-запроса может иметь следующий вид:\r\nДавайте разберем этот код.\r\nУ нас есть класс, в атрибутах которого мы храним или собираемся хранить то, что нам потребуется для обработки запроса. Также в этом классе есть набор коллбэков, которые будут вызываться в тот или иной момент.\r\nСперва, когда актор только-только создан, вызывается коллбэк on_start(). В нем мы отсылаем два сообщения другим акторам. Во-первых, это сообщение check_user для проверки ID клиента. Во-вторых, это сообщение download_image для загрузки исходного изображения.\r\nВ каждом из отосланных сообщений мы передаем ссылку на самих себя (вызов метода self() возвращает ссылку на актора, для которого вызвали self()). Это необходимо для того, чтобы нашему актору можно было отослать сообщение в ответ. Если мы ссылку на своего актора не отошлем, например, в сообщении check_user, то актор UserChecker не будет знать, кому же прислать информацию о пользователе.\r\nКогда нам в ответ присылают сообщение user_info с информацией о пользователе, то вызывается коллбэк on_user_info(). А когда нам присылают сообщение image_loaded, то у нашего актора вызывается коллбэк on_image_loaded(). И вот внутри этих двух коллбэков мы видим особенность, присущую Модели Акторов: мы не знаем точно, в каком порядке нам придут ответные сообщения. Поэтому мы должны написать свой код так, чтобы не зависеть от порядка поступления сообщений. Поэтому в каждом из обработчиков сперва сохраняем в соответствующем атрибуте поступившую информацию, а затем проверяем, может у нас уже собрана вся нужная нам информация? Если это так, то мы можем двигаться дальше. Если нет, то будем ждать дальше.\r\nИменно поэтому у нас в on_user_info() и on_image_loaded() есть if-ы, при выполнении которых вызывается send_mix_images_request().\r\nИтак, если вся нужная нам информация от UserChecker и ImageDownloader получена, то вызывается метод send_mix_images_request(), в котором актору ImageMixer отсылается сообщение mix_images. Коллбэк on_mixed_image() вызывается когда нам приходит ответное сообщение с результирующим изображением. Тут мы пересылаем это изображение актору HttpSrv и ждем пока HttpSrv сформирует HTTP-ответ и уничтожит ставшего ненужным RequestHandler-а (хотя, в принципе, ничто не мешает актору RequestHandler-у самоуничтожится в коллбэке on_mixed_image()).\r\nВот, собственно и все.\r\nРеализация актора RequestHandler получилась довольно объемная. Но это за счет того, что нам нужно было описать класс с атрибутами и коллбэками, а затем еще и реализовать коллбэки. Но сама логика работы RequestHandler-а весьма тривиальная и разобраться в ней, не смотря на объем кода класса request_handler, несложно.\r\nТеперь мы можем сказать несколько слов об особенностях Модели Акторов.\r\nКак правило, акторы реагируют только на входящие сообщения. Есть сообщения — актор их обрабатывает. Нет сообщений — актор ничего не делает.\r\nЭто особенно актуально для тех реализаций Модели Акторов, в которых акторы представляются в виде объектов с коллбэками. Фреймворк дергает коллбэк у актора и если актор не возвращает управление из коллбэка, то фреймворк не может обслуживать других акторов на этом же контексте.\r\nНа акторах мы очень легко можем сделать так, что актор-producer будет генерировать сообщения для актора-consumer-а с гораздо более высоким темпом, чем актор-consumer будет способен обработать.\r\nЭто приведет к тому, что очередь входящих сообщений для актора-consumer-а будет постоянно расти. Рост очереди, т.е. рост потребления памяти в приложении, будет снижать скорость работы приложения. Это приведет к еще более быстрому росту очереди и, в итоге, приложение может деградировать до полной неработоспособности.\r\nВсе это является прямым следствием асинхронного взаимодействия акторов. Поскольку операция send, как правило, неблокирующая. А сделать ее блокирующей непросто, т.к. актор может делать send самому себе. И если очередь для актора заполнена, то на send-е самому себе актор будет заблокирован и на этом его работа прекратится.\r\nТак что при работе с акторами нужно уделять серьезное внимание проблеме перегрузки.\r\nКак правило, акторы — это легковесные сущности и существует соблазн создавать их в своем приложении в большом количестве. Можно создать и десять тысяч акторов, и сто тысяч, и миллион. И даже сто миллионов акторов, если железо вам позволяет.\r\nНо проблема в том, что поведение очень большого количества акторов сложно отследить. Т.е. у вас может быть часть акторов, которые явно работают правильно. Часть акторов, которые либо явно работают неправильно, либо вообще не работают и вы об этом точно знаете. Но может быть и большое количество акторов, про которых вы не знаете ничего: работают они вообще, работают ли они правильно или неправильно. А все потому, что когда у вас в программе сто миллионов автономных сущностей с собственной логикой поведения, то следить за этим всем очень непросто.\r\nПоэтому может получиться так, что создавая большое количество акторов в приложении мы не решаем свою прикладную задачу, а получаем еще одну проблему. И, поэтому, нам может быть выгодно отказаться от простых акторов, решающих одну-единственную задачу, в пользу более сложных и тяжеловесных акторов, выполняющих несколько задач. Но зато таких «тяжелых» акторов у нас в приложении будет меньше и нам проще будет за ними следить.\r\nЕсли кто-то захотел попробовать поработать с акторами в C++, то нет смысла строить собственные велосипеды, есть несколько готовых решений, в частности:\r\nВот эти три варианта являются живыми, развивающимися, кросс-платформенными, задокументированными. А еще их можно бесплатно попробовать. Плюс еще несколько вариантов разной степени [не]свежести можно найти .\r\nSObjectizer и CAF предназначены для использования в достаточно высокоуровневых задачах, где можно применять исключения и динамическую память. А фреймворк QP/C++ может быть интересен тем, кто связан с embedded-разработкой, т.к. именно под эту нишу он и «заточен».\r\nМодель CSP очень похожа на Модель Акторов. Мы также строим свое решение из набора автономных сущностей, каждая из которых обладает своим собственным приватным состоянием и взаимодействует с другими сущностями только посредством асинхронных сообщений.\r\nТолько сущности эти в модели CSP называются «процессы».\r\nПроцессы в CSP являются легковесными, без какого либо распараллеливания своей работы внутри. Если нам нужно что-то распараллеливать, то мы просто запускаем несколько CSP-шных процессов, внутри которых уже нет никакого распараллеливания.\r\nВзаимодействуют CSP-шные процессы друг с другом через асинхронные сообщения, но сообщения отсылаются не в почтовые ящики, как в Модели Акторов, а в каналы. Каналы можно рассматривать как очереди сообщений, как правило, фиксированного размера.\r\nВ отличии от Модели Акторов, где для каждого актора автоматически создается почтовый ящик, каналы в CSP должны создаваться явно. И если нам нужно, чтобы два процесса взаимодействовали друг с другом, то мы должны сами создать канал, а потом сказать первому процессу «ты будешь писать сюда», а второму процессу должны сказать: «ты будешь читать вот отсюда».\r\nПри этом у каналов есть, как минимум, две операции, которые нужно вызывать явным образом. Во-первых, это операция write (send) для записи сообщения в канал.\r\nВо-вторых, это операция read (receive) для чтения сообщения из канала. И необходимость явным образом вызывать read/receive отличает CSP от Модели Акторов, т.к. в случае с акторами операция read/receive может быть вообще скрыта от актора. Т.е. акторный фреймворк может извлекать сообщения из очереди актора и вызывать обработчик (коллбэк) для извлеченного сообщения.\r\nТогда как CSP-шный процесс сам должен выбрать момент для вызова read/receive, затем CSP-шный процесс должен определить, что за сообщение он получил и выполнить обработку извлеченного сообщения.\r\nВнутри нашего «большого» приложения CSP-шные процессы могут быть реализованы по-разному:\r\nДалее будем считать, что CSP-шные процессы представлены в виде stackful coroutines (хотя показанный ниже код вполне может быть реализован и на нитях ОС).\r\nСхема решения на базе модели CSP будет очень сильно напоминать аналогичную схему для Модели Акторов (и это неспроста):\r\nЗдесь также будут сущности, которые запускаются при старте HTTP-сервера и работают все время — это CSP-шные процессы HttpSrv, UserChecker, ImageDownloader и ImageMixer. На каждый новый входящий запрос будет создаваться новый CSP-шный процесс RequestHandler. Этот процесс отсылает и принимает те же самые сообщения, что и при использовании Модели Акторов.\r\nВот так может выглядеть код функции, реализующей CSP-шный процесс RequestHandler:\r\nЗдесь все достаточно тривиально и регулярно повторяется один и тот же шаблон:\r\nОчень хорошо это видно на примере общения с CSP-шным процессом ImageMixer:\r\nНо отдельно стоит заострить внимание вот на этом фрагменте:\r\nЗдесь мы видим еще одно серьезное отличие от Модели Акторов. В случае CSP мы можем получать ответные сообщения в том порядке, который нас устраивает.\r\nХотим сперва дождаться user_info? Нет проблем, засыпаем на read-е до тех пор, пока user_info не появится. Если к этому времени image_loaded нам уже прислали, то оно просто будет ждать в своем канале пока мы его не прочитаем.\r\nВот, собственно, все, чем можно сопроводить показанный выше код. Код на базе CSP оказался компактнее, чем его аналог на базе акторов. Что не удивительно, т.к. здесь нам не пришлось описывать отдельный класс с методами-коллбэками. Да и часть состояния нашего CSP-шного процесса RequestHandler присутствует неявным образом в виде аргументов ctx и req.\r\nВ отличии от акторов CSP-шные процессы могут быть и реактивными, и проактивными, и теми и другими. Скажем, CSP-шный процесс проверил свои входящие сообщения, если они были, он их обработал. А потом, видя, что входящих сообщений нет, взялся перемножать матрицы.\r\nСпустя какое-то время CSP-шному процессу матрицы перемножать надоело и он еще раз проверил наличие входящих сообщений. Новых не оказалось? Ну, ладно, пойдем перемножать матрицы дальше.\r\nИ вот эта возможность CSP-ных процессов выполнять какую-то работу даже в отсутствии входящих сообщений сильно отличает модель CSP от Модели Акторов.\r\nПоскольку, как правило, каналы являются очередями сообщений ограниченного размера и попытка записать сообщение в заполненный канал приостанавливает отправителя, то в CSP мы имеем встроенный механизм защиты от перегрузки.\r\nДействительно, если у нас есть шустрый процесс-producer и медленный процесс-consumer, то процесс-producer быстро наполнит канал и его приостановят на очередной операции send. И процесс-producer будет спать до тех пор, пока процесс-consumer не освободит место в канале для новых сообщений. Как только место появится, процесс-producer проснется и накидает в канал новые сообщения.\r\nТем самым, при использовании CSP мы можем меньше переживать о проблеме перегрузки, нежели в случае Модели Акторов. Правда здесь есть свой подводный камень, о котором мы поговорим чуть позже.\r\nМы должны решить, каким образом наши CSP-шные процессы будут реализованы.\r\nМожно сделать так, что каждый CSP-шный процесс будет представлен отдельной нитью ОС. Получается дорогое и не масштабируемое решение. Но зато мы получаем вытесняющую многозадачность: если наш CSP-шный процесс начинает перемножать матрицы или делает какой-то блокирующий вызов, то ОС в конце-концов вытеснит его с вычислительного ядра и даст возможность поработать другим CSP-шным процессам.\r\nМожно сделать так, что каждый CSP-шный процесс будет представлен сопрограммой (stackful coroutine). Это гораздо более дешевое и масштабируемое решение. Но здесь у нас будет только кооперативная многозадачность. Поэтому, если вдруг CSP-шный процесс займется перемножением матриц, то будет заблокирована рабочая нить с этим CSP-шным процессом и другими CSP-шными процессами, которые к ней же привязаны.\r\nТут может быть и еще один фокус. Допустим, мы задействуем стороннюю библиотеку, на внутренности которой мы не можем повлиять. А внутри библиотеки используются TLS-переменные (т.е. thread-local-storage). Мы делаем один вызов библиотечной функции и библиотека устанавливает значение какой-то TLS-переменной. Затем наша сопрограмма «переезжает» на другую рабочую нить, а это возможно, т.к. в принципе, сопрограммы могут мигрировать с одной рабочей нити на другую. Мы делаем следующий вызов библиотечной функции и библиотека пытается прочитать значение TLS-переменной. Но там уже может быть другое значение! И искать такой баг будет очень непросто.\r\nПоэтому нужно тщательно отнестись к выбору способа реализации CSP-шных процессов. В каждом из вариантов есть свои сильные и слабые стороны.\r\nТак же, как и с акторами, возможность создать много CSP-шных процессов в своей программе — это не всегда решение прикладной задачи, а создание себе дополнительных проблем.\r\nПричем, плохая обозримость того, что происходит внутри программы — это только одна часть проблемы. Хочется заострить внимание еще на одном подводном камне.\r\nДело в том, что на CSP-шных каналах запросто можно получить аналог дедлока. Процесс A пытается записать сообщение в полный канал C1 и процесс A приостанавливают. Из канала C1 должен читать процесс B, который попытался записать в канал C2, который полон и, поэтому, процесс B приостановили. А из канала C2 должен был читать процесс A. Все, мы получили дедлок.\r\nЕсли у нас всего два CSP-шных процесса, то подобный дедлок мы можем обнаружить в процессе отладки или даже при процедуре code review. Но если у нас миллионы процессов в программе, они активно общаются друг с другом, то вероятность возникновения подобных дедлоков существенно возрастает.\r\nЕсли кто-то хочет поработать с CSP в C++, то выбор здесь, к сожалению, не такой большой, как для акторов. Ну или я не знаю куда смотреть и как искать. В этом случае, я надеюсь, в комментариях поделятся другими ссылками.\r\nНо, если мы хотим использовать у себя CSP, то в первую очередь нужно смотреть в сторону . Там есть и fiber-ы (т.е. сопрограммы), и каналы, и даже такие низкоуровневые примитивы, как mutex, condition_variable, barrier. Все это можно брать и использовать.\r\nЕсли же вас устраивают CSP-шные процессы в виде нитей, то можно посмотреть и на . Там также есть аналоги CSP-шных каналов и сложные многопоточные приложения на SObjectizer-е можно писать вообще без акторов.\r\nАкторы и CSP-шые процессы очень похожи друг на друга. Неоднократно доводилось встречать утверждение, что эти две модели эквивалентны друг другу. Т.е. то, что можно сделать на акторах, можно чуть ли не 1-в-1 повторить на CSP-шных процессах и наоборот. Говорят, что это даже доказано математически. Но здесь я ничего не понимаю, поэтому не могу ничего утверждать. Но из собственных размышлений где-то на уровне бытового здравого смысла, все это выглядит достаточно правдоподобно. В каких-то случаях, действительно, акторов можно заменить CSP-шыми процессами, а CSP-шные процессы — акторами.\r\nТем не менее, у акторов и CSP есть несколько отличий, которые могут помочь определиться с тем, где выгодно или невыгодно использовать каждую из этий моделей.\r\nУ актора есть единственный «канал» для получения входящих сообщений — это его почтовый ящик, который для каждого актора создается автоматически. И актор извлекает сообщения оттуда последовательно, именно в том порядке, в котором сообщения в почтовый ящик попали.\r\nИ это довольно-таки серьезный вопрос. Допустим, в почтовом ящике актора сейчас три сообщения: M1, M2 и M3. Актор в данный момент заинтересован только в M3. Но прежде чем добраться до M3 актор извлечет сперва M1, затем M2. И что он будет с ними делать?\r\nТогда как CSP-шный процесс имеет возможность выбирать канал, из которого он в данный момент хочет читать сообщения. Так, у CSP-шного процесса может быть три канала: C1, C2 и C3. В данный момент CSP-шный процесс заинтересован только в сообщениях из C3. Именно этот канал процесс и читает. А к содержимому каналов C1 и C2 он вернется тогда, когда будет в этом заинтересован.\r\nКак правило, акторы реактивны и работают только тогда, когда у них есть входящие сообщения.\r\nТогда как CSP-шые процессы могут выполнять какую-то работу даже в отсутствии входящих сообщений. В каких-то сценариях это отличие может играть важную роль.\r\nПо сути акторы являются конечными автоматами (КА). Поэтому если в вашей предметной области конечных автоматов много, да еще и если это сложные, иерархические конечные автоматы, то реализовать их на базе модели акторов вам может быть гораздо проще, чем добавляя реализацию КА в CSP-шный процесс.\r\nОпыт языка Go показывает, насколько легко и удобно пользоваться моделью CSP когда ее поддержка реализована на уровне языка программирования и его стандартной библиотеки.\r\nВ Go легко создавать «CSP-шые процессы» (aka goroutines), легко создавать и работать с каналами, есть встроенный синтаксис для работы сразу с несколькими каналами (Go-шный select, который работает не только на чтение, но и на запись), стандартная библиотека знает про гороутины и может переключать их когда гороутина выполняет блокирующий вызов из stdlib.\r\nВ C++ пока поддержки stackful coroutines нет (на уровне языка). Поэтому работа с CSP в C++ может выглядеть, местами, если не костыльно, то… То уж точно она требует к себе гораздо больше внимания, чем в случае того же Go.\r\nСмысл Task-based подхода в том, что если у нас есть сложная операция, то мы разбиваем эту операцию на отдельные шаги-задачи, где каждая задача (она же task) выполняет какую-то одну подоперацию.\r\nЗапускаем эти задачи специальной операцией async. Операция async возвращает объект-future, в который после выполнения задачи будет помещено значение, возвращенное задачей.\r\nПосле того, как мы запустили N задач и получили N объектов-future, нам нужно все это как-то провязать в цепочку. Вроде того, что когда завершаются задачи №1 и №2, то возвращенные ими значения должны попасть в задачу №3. А когда завершается задача №3, то возвращенное значение должно быть передано в задачи №4, №5 и №6. И т.д., и т.п.\r\nДля такой «провязки» используются специальные средства. Такие, например, как метод .then() у объекта-future, а также функции wait_all(), wait_any().\r\nТакое объяснение «на пальцах» может быть не очень понятно, поэтому давайте перейдем к коду. Может быть в разговоре про конкретный код ситуация прояснится (но не факт).\r\nКод по обработке входящего HTTP-запроса на базе task-ов может выглядеть следующим образом:\r\nДавайте попробуем разобраться с тем, что здесь происходит.\r\nСперва мы создаем задачу, которая должна запуститься на контексте нашего собственного HTTP-клиента и которая запрашивает информацию о пользователе. Возвращенный объект-future мы сохраняем в переменной user_info_ft.\r\nДалее мы создаем похожую задачу, которая также должна запуститься на контексте нашего собственного HTTP-клиента и которая загружает исходное изображение. Возвращенный объект-future сохраняется в переменной original_image_ft.\r\nДалее нам нужно дождаться выполнения двух первых задач. Что мы прямо так и записываем: when_all(user_info_ft, original_image_ft). Когда оба объекта-future получат свои значения, тогда мы запустим еще одну задачу. Эта задача возьмет битовую маску с «водяными знаками» и оригинальное изображение и запустит еще одну задачу на контексте ImageMixer-а. Эта задача смикширует изображения и когда она завершиться, на контексте HTTP-сервера запустится еще одна задача, которая сформирует HTTP-ответ.\r\nНаверное такое объяснение происходящее в коде не сильно прояснило. Поэтому давайте пронумеруем наши задачи:\r\nИ посмотрим на зависимости между ними (из которых проистекает порядок выполнения задач):\r\nА если мы теперь наложим эту картинку на наш исходный код, то, я надеюсь, станет понятнее:\r\nПервая особенность, которая уже должна стать очевидной — это обозримость кода на Task-ах. С ней не все хорошо.\r\nЗдесь же можно упомянуть такую штуку, как callback hell. С ней хорошо знакомы Node.js-программисты. Но и C++ники, которые плотно работают с Task-ами, также окунаются в этот самый callback hell.\r\nЕще одна интересная особенность — это обработка ошибок.\r\nС одной стороны, в случае использования async и future с доставкой информации об ошибки до заинтересованной стороны может быть даже проще, чем в случае акторов или CSP. Ведь если в CSP процесс A отсылает запрос процессу B и ждет ответного сообщения, то при возникновении у B ошибки при выполнении запроса нам нужно решить, как доставлять ошибку процессу A:\r\nА в случае future все проще: мы извлекаем из future либо нормальный результат, либо нам бросают исключение.\r\nНо, с другой стороны, мы можем запросто нарваться на каскад ошибок. Например, в задаче №1 возникло исключение, это исключение попало в объект future, который был передан в задачу №2. В задаче №2 мы попытались взять значение из future, но получили исключение. И, скорее всего, мы это же исключение выбросим наружу. Соответственно, оно попадет в следующий future, который пойдет в задачу №3. Там так же возникнет исключение, которое, вполне возможно, также будет выпущено наружу. И т.д.\r\nЕсли наши исключения будут логироваться, то затем в логе мы сможем увидеть неоднократное повторение одного и того же исключения, которое переходит от одной задачи в цепочке к другой задаче.\r\nИ еще одна очень интересная особенность Task-based похода — это отмена задач если что-то пошло не так. В самом деле, допустим, мы создали 150 задач, выполнили первые 10 из них и поняли, что все, дальше работу продолжать нет смысла. Как нам отменить 140 оставшихся? Это очень и очень хороший вопрос :)\r\nЕще один похожий вопрос — это как подружить задачи с таймерами и таймаутами. Допустим, мы обращаемся к какой-то внешней системе и хотим ограничить время ожидания 50-ью миллисекундами. Как нам взвести таймер, как среагировать на истечение тайм-аута, как прервать цепочку задач, если таймаут истек? Опять же, спросить проще, чем ответить :)\r\nНу и еще к разговору об особенностях Task-based подхода. В показанном примере был применен небольшой читинг:\r\nЗдесь я отправил на контекст нашего собственного HTTP-сервера две задачи, каждая из которых выполняет внутри блокирующую операцию. На самом деле для того, чтобы можно было обрабатывать два запроса к сторонним сервисам в параллель, здесь нужно было создавать свои цепочки асинхронных задач. Но я этого не стал делать для того, чтобы решение получилось более-менее обозримым и поместилось на слайд презентации.\r\nМы рассмотрели три подхода и увидели, что если акторы и CSP-шные процессы похожи друг на друга, то Task-based подход не похож ни на кого из них. И может сложиться впечатление, что Actors/CSP следует противопоставлять Task-ам.\r\nНо лично мне нравится другая точка зрения.\r\nКогда мы говорим про Модель Акторов и CSP, то мы говорим про декомпозицию своей задачи. Мы выделяем в своей задаче отдельные самостоятельные сущности и описываем интерфейсы этих сущностей: какие сообщение они отсылают, какие получают, по каким каналам сообщения ходят.\r\nТ.е. работая с акторами и CSP мы говорим про интерфейсы.\r\nНо, допустим, мы разбили задачу на отдельных акторов и CSP-шные процессы. Как именно они выполняют свою работу?\r\nКогда же мы беремся за Task-based подход, мы начинаем говорить про реализацию. Про то, как выполняется конкретная работа, какие подоперации выполняются, в каком порядке, как эти подоперации связаны по данным и т.д.\r\nТ.е. работая с Task-ами мы говорим про реализацию.\r\nСледовательно, Actors/CSP и Tasks не столько противостоят друг другу, сколько дополняют друг друга. Actors/CSP могут использоваться для декомпозиции задачи и определения интерфейсов между компонентами. А Tasks затем могут использоваться в реализации конкретных компонентов.\r\nНапример, у нас при использовании Actor-ов есть такая сущность, как ImageMixer, которой нужно выполнять манипуляции с изображениями на пуле рабочих нитей. В общем-то ничто не мешает нам в реализации актора ImageMixer использовать Task-based подход.\r\nЕсли захотелось поработать с Task-ами в C++, то смотреть можно в сторону стандартной библиотеки грядущего C++20. Там уже добавили метод .then() к future, а также свободные функции wait_all() и wait_any. За подробностями можно обратиться .\r\nТак же есть уже далеко не новая библиотека . В которой, в принципе, есть все нужное, только чуть-чуть под другим соусом.\r\nИ еще есть еще более старая библиотека . Которая также дает все, что нужно, но под своим соусом.\r\nНедавно здесь, на Хабре, была статья Антона Полухина: \"\".\r\nТам рассказывается об объединении Task-based подхода со stackless coroutines из С++20. И получилось, что код на базе Task-ов по читабельности приблизился к читабельности кода на CSP-шных процессах.\r\nТак что если кто-то заинтересовался Task-based подходом, то имеет смысл ознакомиться с данной статьей.\r\nЧто ж, пора переходит к итогам, благо их не так уж и много.\r\nГлавное, что я хочу сказать, — это то, что в современном мире голая многопоточность вам может потребоваться разве что если вы разрабатываете какой-то фреймворк или решаете какую-то специфическую и низкоуровневую задачу.\r\nА если вы пишете прикладной код, то вряд ли вам нужны голые нити, низкоуровневые примитивы синхронизации или какие-то lock-free алгоритмы вместе с lock-free контейнерами. Уже давно есть подходы, которые проверены временем и отлично себя зарекомендовали:\r\nИ главное, что для них в C++ есть готовые инструменты. Не нужно ничего велосипедить, можно брать, пробовать и, если понравилось, запускать в эксплуатацию.\r\nВот так просто: брать, пробовать и запускать в эксплуатацию.", "url": "https://habr.com/ru/post/430672/"},
{"title": "Асинхронный обмен данными с удалённым приложением через SSH", "article_text": "Доброго времени суток, друзья и коллеги. Меня всё ещё зовут Дмитрий Смирнов, и я всё ещё, к моему вящему удовольствию, являюсь разработчиком ISPsystem. Некоторое время назад я начал работу над совершенно новым проектом, который меня очень вдохновил, поскольку новое — это в нашем случае отсутствие легаси кода и поддержки старых компиляторов. Здравствуй, Boost, C++17 и все прочие радости современной разработки.\r\nТак случилось, что все мои прошлые проекты были многопоточными, соответственно, у меня было крайне мало опыта с асинхронными решениями. Именно это стало самым приятным для меня в этой разработке, помимо современных мощных инструментов. \r\nОдной из последних сопутствующих задач стала необходимость написать обёртку над библиотекой  в реалиях асинхронного приложения, использующего , и способного породить не более двух потоков. Об этом и расскажу.\r\nПримечание: автор предполагает, что читатель знаком с основами асинхронной разработки и boost::asio.\r\nВ общих чертах задача стояла следующим образом: подключиться к удалённому серверу, используя rsa-ключ или логин и пароль; загрузить на удалённую машину некий скрипт и запустить его; вычитывать его ответы и присылать ему команды через то же самое соединение. При этом, разумеется, не блокируя потока (который является половиной всего возможного пула). : я знаю, что в Poco реализована работа с SSH, но я не нашёл способа поженить его с Asio, да и написать что-то своё было интереснее :-).\r\nДля инициализации и сворачивания библиотеки я решил воспользоваться обычным синглтоном:\r\nЕсть в этом решении, разумеется, и подводные камни, согласно моей любимой настольной книге «Тысяча и один способ выстрелить себе в ногу в C++». Если кто-то порождает поток, который забудут поджойнить, и главный завершится раньше, вполне могут возникнуть интересные спецэффекты. Но в данном случае я не буду учитывать подобную возможность.\r\nПосле разбора  становится понятно, что для нашей небольшой библиотеки понадобятся три несложные сущности: сокет, сессия и канал. Поскольку неплохо иметь и синхронные инструменты, мы пока оставим Asio в стороне.\r\nНачнём с простого сокета:\r\nТеперь сессия:\r\nРаз уж мы теперь имеем сокет и сессию, неплохо было бы написать функцию ожидания для сокета в реалиях libssh2:\r\nСобственно, это практически ничем не отличается от приведённого выше примера, кроме того, что там используется select вместо poll.\r\nОстаётся канал. В libssh2 есть несколько видов каналов: простой, SCP, direct tcp. Нас интересует самый простой, базовый канал:\r\nТеперь, когда все основные инструменты готовы, остаётся установить соединение с хостом и производить необходимые нам манипуляции. Асинхронная запись в канал и синхронная, разумеется, будут очень сильно различаться, а вот процесс установления соединения — нет. \r\nПоэтому напишем базовый класс:\r\nВот теперь мы готовы написать простейший класс для соединения с удалённым хостом и выполнения на нем какой-либо команды:\r\nДо сих пор всё, что мы писали, было простым приведением примеров libssh2 к более цивилизованному виду. Но теперь, имея все простые инструменты для синхронной записи данных в канал, мы можем перейти к Asio.\r\nИметь стандартный сокет — это хорошо, но не слишком практично, если нужно асинхронно дождаться его готовности к чтению\\записи, занимаясь в процессе своими делами. Тут на помощь приходит boost::asio::ip::tcp::socket, имеющий замечательный метод:  \r\nОн замечательным образом конструируется из обычного сокета, для которого мы уже заблаговременно установили соединение и boost::asio::io_context — контекста выполнения нашего приложения.\r\nТеперь нам надо начать выполнение какой-либо команды на удалённом хосте и, по мере поступления данных от нее, отдавать их в некоторый коллбэк.\r\nТаким образом, запустив команду, мы передаем управление методу TryRead().\r\nПервым делом мы проверяем, не запущен ли уже процесс чтения каким-то предыдущим вызовом. Если нет, то начинаем ожидать готовности сокета для чтения. В качестве хендлера ожидания используется обычная лямбда с захватом shared_from_this().\r\nОбратите внимание на вызов WantRead(). Async_wait, как оказалось, тоже имеет свои изъяны, и может просто вернуться по таймауту. Чтобы в этом случае не производить лишних действий, я решил проверять сокет через poll без таймаута — действительно ли сокет хочет читать сейчас. Если нет, то мы просто снова запускаем TryRead() и ждём. В противном случае мы сразу приступаем к чтению и передаче данных в коллбэк.\r\nТаким образом, запускается бесконечный асинхронный цикл чтения от запущенного приложения. Следующим шагом для нас станет отправление инструкций приложению:\r\nПереданные в асинхронную запись данные и коллбэк мы сохраним внутри соединения. И запустим очередной цикл, только на этот раз записи:\r\nТаким образом, мы будем записывать в канал данные до тех пор, пока они все не будут успешно переданы. Затем вернём управление вызывающей стороне, чтобы можно было передать новую порцию данных. Так можно не только слать инструкции какому-то приложению на хосте, но и, например, загружать небольшими порциями файлы любого размера, при этом не блокируя тред, что немаловажно.\r\nС помощью этой библиотеки мне удалось успешно запускать на удалённом сервере скрипт, отслеживающий изменения файловой системы, одновременно вычитывая его вывод и посылая различные команды. В целом: очень ценный опыт адаптации си-стайл библиотеки для современного C++ проекта, использующего Boost. \r\nБуду рад прочитать советы более опытных пользователей Boost.Asio, чтобы познать больше и улучшить свое решение :-).", "url": "https://habr.com/ru/company/ispsystem/blog/430488/"},
{"title": "CLion 2018.3: удаленная разработка, профилирование кода, быстродействие и не только", "article_text": "Привет, Хабр!\r\nНа днях мы выпустили CLion 2018.3. Третий в этом году крупный релиз подытоживает нашу работу по двум важным направлениям развития —  и .\r\nКроме того, мы, наконец:\r\nПодробнее об этих и других нововведениях читайте ниже. А чтобы попробовать новые возможности и улучшения, скачивайте бесплатную 30-дневную версию . \r\nПарсер CLion научился понимать две новые возможности стандарта C++17 —  и . С одной стороны, изменения в парсере — это еще не полная поддержка, но, как минимум, подсветка кода будет более правильная, а для случаев  IDE даже правильно выведет тип и его можно будет увидеть, например, при вызове информации о параметрах функции. мы писали о том, что CLion теперь использует не только собственный языковой движок для работы с кодом на C/C++, но и еще один дополнительный, экспериментальный, сделанный на основе Clangd. Включив его для показа ошибок и предупреждений в редакторе, мы двинулись дальше и в CLion 2018.3 реализовали на его основе некоторые действия навигации по коду и поиска в коде.\r\nЯзыковой движок на базе Clangd предоставляет результаты, которые впоследствии все равно объединяются с результатами, полученными из собственного движка CLion. Типичный пример — Find Usages (): по открытым в редакторе файлам поиск осуществляет Clangd, а по остальным — наш собственный движок.\r\nПримеры других действий, где дополнительно используется языковой движок на Clangd:\r\nClangd включен по умолчанию и настраивается в Settings/Preferences | Languages & Frameworks | C/C++ | Clangd:\r\nТо есть можно независимо включать/выключать необходимую функциональность поверх Clangd — например, только показ ошибок или только навигацию. Если нужно полностью отключить использование Clangd, снимите все галочки в этом диалоге.\r\nИ, кстати, Clang-Tidy вполне можно запускать и без Clangd, но запуск через Clangd существенно улучшает производительность, так как использует AST-дерево, закешированное в Clangd.\r\nВ  появилась возможность на Windows работать с подсистемой Windows Subsystem for Linux (WSL). Это Linux-окружение, встроенное в Windows, позволяет собирать, запускать и отлаживать Linux-приложения на Windows. Мы тогда говорили, что специально реализовали поддержку WSL через ssh, то есть как удаленной подсистемы. Это был первый шаг к работе с полностью удаленными конфигурациями.\r\nИ вот в CLion 2018.3 мы объявили о поддержке первого большого варианта удаленной разработки:\r\nНастроить такую удаленную конфигурацию очень легко — надо просто создать удаленный тулчейн в Settings/Preferences | Build, Execution, Deployment | Toolchains и использовать его в каком-нибудь CMake Profile. Подробная инструкция есть в  и в . Прогресс синхронизации с удаленным хостом отображается в окне File Transfer (View | Tool Windows | File Transfer), а изменить параметры соединения и пути к директориям на удаленной машине — в настройках Settings/Preferences | Build, Execution, Deployment | Deployment.\r\nВ этом направлении ожидается еще очень много работы. Сейчас, как видно, не поддерживаются варианты расположения кода сразу на удаленной машине, нет поддержки удаленной системы контроля версий, нет интеграции с удаленным терминалом, и есть множество мелких недочетов по установке самого соединения. Но главное есть — \r\nCLion 2018.3 дает возможность анализировать производительность кода. На Linux — предоставляется интеграция с , на macOS — с . Новое действие доступно в меню Run, на панели навигации и в контекстном меню иконок запуска приложения. Результаты профилирования кода доступны в окне CPU Profiler (View | Tool Windows | CPU Profiler).\r\nПодробно о том, что необходимо установить на компьютер, чтобы заработало профилирование кода, читайте в  или . \r\nСтоит отметить, что UI/UX пока несколько экспериментальный. Его планируется существенно улучшать в версиях 2019.x. Но уже есть полезные штуки, вроде возможности посмотреть все треды вместе или по одному, возможность навигации на исходный код и др.\r\nКоличество разнообразных комбинаций команд сборки так выросло, что мы решили вынести их все в отдельный пункт меню — Build. Там и сборка/пересборка всего проекта, и таргета  из всех или из выбранного CMake профайла, и выбранной конфигурации, и одного конкретного файла:\r\nЭто, понятное дело, для CMake. Для compilation database там будет только команда пересборки конкретного файла.\r\nС диалогом Search Everywhere () пользователи CLion знакомы давно, как и с диалогом Find Action ( / ) для поиска команды или настройки по имени, и с диалогами навигации на файл, символ или класс по их имени. И вот теперь это, на самом деле, один и тот же диалог!\r\nОтдельные диалоги превратились в отдельные вкладки, переключение работает через . Заодно мы устранили ряд проблем, связанных с этими диалогами, в т. ч. потери фокуса и некорректные размеры.\r\nДругой новый универсальный диалог — Run Anything (). Из него можно запустить приложение в обычном режиме или из-под отладчика, а также открыть любой проект:\r\nCompilation database — альтернативная проектная модель, которую уже некоторое время поддерживает CLion. Она очень удобна тем, что  фактически из любой другой проектной модели, популярной или вообще кастомной. CLion умеет открывать проекты из compilation database, парсить правильно код и предоставлять все умные средства работы с кодом. Единственный минус — это отсутствие в данном формате информации о сборке всего проекта, так что собрать из IDE пока получится только отдельные файлы.\r\nВ этом релизе мы добавили в CLion схему для файлов сompilation_database.json, а на основе уже этой схемы реализовали проверки в самом файле. Например, некорректный тип значения проперти или вообще отсутствующая проперть:\r\nПроверки могут быть очень полезны, если вы-таки решили написать такой файл руками или подправить имеющийся файл.\r\nВо многих дампах от наших пользователей было видно, что существенные проблемы с производительностью IDE связаны с тем, как IDE определяет список имеющихся в проекте тестов. В версии 2018.3 мы сделали этот процесс ленивым, и теперь, если вы не открыли ни одного файла с тестами в редакторе, они не будут индексироваться. Кроме того, были произведены улучшения производительности при навигации на результаты тестов, автодополнении тестовых макросов и пр.\r\nКак известно, в окне Quick Documentation ( / ) CLion умеет показывать не только документацию и комментарии к коду, но и выведенные типы для переменных и финальную подстановку в макросах. Эта финальная подстановка теперь отформатирована, и в ней подсвечиваются ключевые слова. Очень удобно для сложных макросов с несколькими уровнями вложения, например для Boost:\r\nКомментарии TODO теперь можно делать многострочными, главное соблюсти отступ для второй и последующих строк — CLion автоматически поймет, что это часть комментария TODO:\r\nЕсть пользователи, для которых стандартные темы не удобны, так как не обладают достаточной контрастностью. Для них мы добавили специальную High-contrast Theme. Ее можно включить только в редакторе кода (Ctrl+`) или же для всей IDE (Settings/Preferences | Appearance & Behavior | Appearance | Theme).\r\nВместе с IntelliJ Platform мы переработали меню настроек плагинов в IDE (Settings/Preferences | Plugins). Теперь гораздо проще поддерживать установленные плагины в актуальном состоянии, а также сортировать и фильтровать огромный репозиторий существующих плагинов для IDE.\r\nЕще одно важное платформенное изменение — это долгожданная поддержка . Теперь все операции для работы с VCS в CLion учитывают и подмодули: клонирование проекта, его обновление, сравнения версий (diff) и пр.\r\nДобавилось окно , в котором можно не только просмотреть все pull requests, но и искать/фильтровать их по автору или состоянию. А еще можно создать новую ветку из любого pull request буквально в один клик.\r\nТрадиционное видео о новых возможностях CLion 2018.3 на английском языке:\r\nВ следующем году мы планируем продолжать работу над вторым дополнительным языковым движком на базе Clangd — посмотрим, какие еще возможности IDE мы сможем на нем реализовать. Будем улучшать производительность редактора, доделывать и улучшать имеющиеся фичи; особенно разнообразной выглядит работа по поддержке удаленной разработки в CLion. Из интеграций планируем clang-format и, вероятно, тот или иной отладчик для Windows/MSVC.\r\nА ключевым направлением для нас станет . Совсем недавно к нашей команде присоединился , автор очень популярного плагина для поддержки в CLion . Илья будет продолжать интегрировать эту функциональность в IDE, мы же планируем в самое ближайшее время доделать memory view и переделать hex view.\r\nВопросы, пожелания, баг-репорты и просто мысли высказывайте в комментариях! Мы будем рады ответить.", "url": "https://habr.com/ru/company/JetBrains/blog/431384/"},
{"title": "C++20 и Modules, Networking, Coroutines, Ranges, Graphics. Итоги встречи в Сан-Диего", "article_text": "До C++20 осталась пара лет, а значит, не за горами feature freeze. В скором времени международный комитет сосредоточится на причёсывании черновика C++20, а нововведения будут добавляться уже в C++23.\r\nНоябрьская встреча в Сан-Диего — предпоследняя перед feature freeze. Какие новинки появятся в C++20, что из крупных вещей приняли, а что отклонили — всё это ждёт вас под катом.\r\nДобавили новый тип данных . Массив этих символов представляет собой UTF-8 строку:\r\nНа первый взгляд кажется, что нововведение незначительное. Но это не так.\r\nchar8_t — первый шаг к тому, чтобы стандартная библиотека C++ из коробки поддерживала UTF-8. Впереди ещё много работы, к C++20 она явно не завершится.\r\nОднако уже теперь char8_t многим превосходит char/unsigned char. Программы, использующие char8_t, могут работать быстрее за счёт того, что char8_t  с другими типами данных. Иными словами, модификация строки или любой переменной не приведёт к тому, что значения переменных будут перечитываться из памяти:\r\nЕсли бы мы в примере взяли char (std::string_view), то получили бы код, . В случае char8_t .\r\nУчтите, что теперь u8«hello» — это массив chat8_t, а не массив char. Данное изменение в стандарте ломает обратную совместимость с C++11/14/17! Полный список изменений связанных с char8_t доступен в документе . В этом же документе есть список примеров, когда валидный до C++20 код становится невалидным из-за char8_t.\r\nК C++20 многие (и я в их числе) хотят увидеть в стандарте контейнеры, которыми можно пользоваться на этапе компиляции. Это позволит делать меньше вычислений на runtime, а значит, при работе приложения будет тратиться меньше процессорного времени. При этом, зачастую, вам не придётся ничего менять в исходниках — всё просто начнёт работать быстрее, инициализироваться на этапе компиляции, лучше оптимизироваться компилятором…\r\nВ Сан-Диего сильно расширили возможности компилятора и стандартной библиотеки по вычислению выражений на этапе компиляции:\r\nНа следующем заседании, которое пройдёт в США 18–23 февраля 2019 года, планируется добавить контейнерам std::string, std::vector (и возможно std::map) возможность работать на этапе компиляции.\r\nВсе добавления и правки жизненно важны для готовящейся к C++23/26 рефлексии.\r\nНачиная с C++20 можно будет дополнительно настраивать unordered контейнеры и обязывать их не конструировать временные объекты при операциях поиска:\r\nВещь весьма полезная, детали можно найти в документе .\r\nУже давно считается, что std::bind — достаточно опасная вещь, из-за которой легко пораниться. Поэтому в C++20 добавили более простую функцию .\r\nОна не поддерживает placeholders, правильно работает с ref-qualifiers и компилируется немного быстрее. Пользоваться ей можно будет приблизительно вот так:\r\nВсеобъемлющее описание есть в документе .\r\nУра, теперь можно подсказывать компилятору, что данные у нас выравнены:\r\nЭто поможет компилятору автоматически векторизовать циклы и генерировать более производительный код. Дополнительные примеры можно найти в документе .\r\nВ  приняли сокращённый синтаксис для записи шаблонных функций и классов, аргументы которых должны соответствовать концепту. Например,  значит, что sort — это  функция, и что тип переменной `c` соответствует концепту Sortable.\r\nКлассы std::optional и std::variant теперь обязаны иметь тривиальные деструкторы, copy/move конструкторы и copy/move операторы присваивания, если шаблонные параметры классов обладают свойствами тривиальности. Это немного поможет компилятору и стандартной библиотеке генерировать более производительный и компактный код ().\r\nMove-конструктор std::function теперь обязан быть noexcept. Если у вас есть std::vector<std::function> и конструкторы std::function раньше не были noexcept, то работа с таким вектором станет в несколько раз производительнее ().\r\nЕсли вы имели дело с большими массивами чисел и иcпользовали make_unique/make_shared, то иногда производительность слегка проседала за счёт того, что каждый элемент массива инициализировался нулём. Некоторые специально писали , чтобы не инициализировать каждое значение. Так вот, в C++20 добавили  и . Эти две функции приехали из Boost и они не делают лишней инициализации ().\r\nЕщё добавили  функции, принимающие rvalue. Это помогает избегать лишних инкрементов и декрементов атомарного счётчика при работе с std::shared_ptr ().\r\nВ великолепном документе  убрали боль при использовании std::variant:\r\nЕщё один великолепный документ  того же автора избавляет от граблей, на которые очень многие наступали:\r\nНаконец, решили, что в контрактах автор класса имеет право использовать приватные члены класса в условиях контракта ():\r\nИтак, приступим к крупным нововведениям. И начнём с плохого: в C++20 нам  видать работы с сетью из коробки. Отложили на неопределённый срок.\r\nК хорошим новостям — подгруппа EWG одобрила дизайн модулей, так что есть все шансы увидеть их в C++20. Финальная битва за модули предстоит на следующем заседании.\r\nRanges в C++20 приняли. На голосовании в последний день авторы предложения  сорвали долгие овации. Весь зал аплодировал стоя. Начало оваций даже успели сфотографировать, счастливый автор предложения — в шапке этого поста.\r\nВот пара примеров того, что можно делать с ranges:\r\nВозвращаемся к тому, что не приняли. Coroutines не вошли в стандарт на голосовании. Возможно, это случится на следующем заседании, но шансов маловато.\r\nПредложение о двухмерной графике воскресили, над ним продолжают работать. Автор планирует закинуть прототип в общедоступное место (например, в Boost), обкатать, собрать отзывы экспертов по 2D графике из другого комитета по стандартизации.\r\nНа заседании мы в основном дотаскивали stacktrace (который мы в Яндекс.Такси очень любим) до стандарта C++. Сейчас черновик документа выглядит . Надеюсь, что осталось совсем чуть-чуть, и к C++20 успеем.\r\nЕщё мы пытались привнести в стандарт плагины (динамическую загрузку библиотек, ). Тут нас ждал провал — предложение отклонили. Учтём ошибки и попробуем позже.\r\nНаше старое предложение добавить , внезапно подхватил другой разработчик в документе . Всячески поддерживали документ на голосованиях, первую подгруппу прошли, надеемся на успех.\r\nИдею упростить работу с std::variant, а именно , так же отклонили. Основные возражения — пока боязно менять std::variant, учитывая его проблемы с конструкторами (хотя после ) они исчезнут. Попробуем ещё раз.\r\nС конкурентным unordered map () наоборот, всё было достаточно гладко: нам порекомендовали проверить пару альтернативных интерфейсов и сказали, что предложение почти готово для принятия в Concurrent Data Structures TS (правда, он пока только планируется).\r\nВ подгруппе SG6 Numerics мы прошлись по большинству имеющихся идей, предложили и немного обсудили механизм взаимодействия различных классов чисел (). Ждём, когда начнут создавать Numbers TS, куда должны попасть все новые и вкусные классы чисел.\r\nВ подгруппе по ядру языка мы презентовали идеи о , а именно . Люди очень хотят нечто подобное, но не в том виде, что было изложено. Нас отправили напрямую к разработчикам компиляторов за консультацией.\r\nНу и, как упоминалось выше, нашу бумагу , приняли в C++20. Теперь можно будет использовать на этапе компиляции array, tuple, pair, всё что нужно для копировании std::string, back_insert_iterator, front_insert_iterator, insert_iterator.\r\nC++20 обещает быть весьма занятным: Concepts, Contracts, Ranges, Modules, работа с временными зонами и множество constexpr нововведений.\r\nВ скором времени  отправим комментарии к черновику стандарта C++20. Поэтому, если у вас есть какая-то боль, или вы не согласны с каким-то нововведением, пожалуйста, оставляйте свои мысли .\r\nТакже приглашаем вас на наши ближайшие встречи по C++:  в Москве и Санкт-Петербурге и  в Новосибирске.", "url": "https://habr.com/ru/company/yandex/blog/430406/"},
{"title": "«Не надо скромничать. Пробуй!». Интервью о жизни, компиляторах и жизни в компиляторах с Alexandre Mutel из Unity", "article_text": "Как добиться успеха в системном программировании, что нужно знать и понимать, особенно если ты работаешь уже третий десяток лет? C# и перформанс — cтоит ли переписывать на C# всё что видишь? Какое будущее в смысле низкоуровневых компиляторных технологий нас ждёт?\r\nСегодня в нашей виртуальной студии на вопросы отвечает . Alexandre Mutel работает на должности Lead Software Architect в Unity Technologies. Кроме того, он известный в опенсорсе разработчик, контрибутящий в SharpDX, Markdig, Zio и другие проекты, а с 2014 года — MVP в категории «Visual Studio and Development Technologies». \r\nAlexandre работает над разными низкоуровневыми и высокоуровневыми вопросами в областях рендеринга графики в реальном времени, GPGPU, синтеза звука, эффективного использования и архитектуры управляемых языков, кодогенерации и документации.\r\nКак всегда, интервью ведут Евгений Трифонов () и Олег Чирухин () из JUG.ru Group.\r\nВсё началось в детстве — у меня появился Amstrad PC 464. Когда я начал программировать на этом компьютере, мне было то ли 11, то ли 12, точно не помню. Я быстро освоил программирование на BASIC и накупил книжек по разработке игр: тогда это казалось очень интересным. Я совсем мало играл в игры, куда интересней было разрабатывать, писать код. Потом я продолжил писать код на ассемблере для Amstrad. \r\nВ 16 лет у меня появилась Amiga 500. Встретил ребят, которые занимались написанием демок — это было совсем не то, что сейчас. Сейчас это WebGL, и это уже совсем другая демосцена. Я начал писать много демок, которые я не всегда показывал, но мне просто нравилось писать на ассемблере. И это было так просто. \r\nПотом пошёл в технологический колледж, где изучал компьютерную инженерию. Это уже было нечто совсем другое по сравнению с играми и ассемблером. Я обожал изучать вещи, про существование которых раньше даже не знал: операционные системы, UNIX, работа с языком C (до этого я пользовался только BASIC или ассемблером, потому что у меня не было денег, чтобы купить компилятор C/C++). \r\nКогда окончил колледж, начал работать в индустрии валютного рынка. Эта была работа на французскую компанию в Нью-Йорке. Через два года я вернулся и попал в банк. Вообще, я не хотел работать в банке, я хотел работать в геймдеве. Но в результате залип там — новая область, много чему можно научиться. Так и провёл там лет 8-9, в основном имея дело с Java и немного с C++. Множество распределённых серверов и SQL БД, копирование баз данных… Совсем не то, чем я занимаюсь сейчас. \r\nПотом я взял некий творческий отпуск и поехал в туристическую поездку по миру: был в Африке, в Южной Америке, целый год в Азии. Путешествие меня поменяло и встряхнуло. Когда я вернулся, то не мог уже работать с компьютерами, в IT-сфере, не мог работать на банк. Я уволился и провёл 4 года на курсах социальных работников, чтобы работать с детьми, с бездомными, инвалидами, пожилыми людьми. Три года я учился этому, и это было очень интересно, потому что большую часть жизни я работал в области точных наук: математики, проектов, абстракций. А потом вдруг взял и перешёл в очень гуманитарную область. Пытался даже работать в этой области после обучения, но как раз в этот период один друг, с которым я делал демки в детстве, намекнул, что можно снова этим заняться. \r\nЯ начал заниматься демками всё своё свободное время, и очень быстро это стало занимать больше, чем работа с детьми на улице. Это было плохо. Люди говорили: «Нужно попробовать найти работу в геймдеве, почему нет? Ты же можешь». Но я думал, что это невозможно, ведь я давно не работал с компьютерами, и с моим резюме сложно было отыскать работу в IT. \r\nЯ начал работать над опенсорсными приложениями и выпустил пару проектов, которыми стали пользоваться компании. Однажды со мной вышла на связь одна из этих компаний, они пользовалась одним из последних проектов, который называется SharpDX. Я поехал в Японию вместе с семьёй — ведь у меня уже было двое детей. Мы прожили 5 лет в Японии. В это время я работал над созданием игрового движка с нуля на C#.\r\nГода два назад я вернулся во Францию и начал работать в Unity. Это мешало тому, чем я занимался раньше, но они предложили работу над очень сложной и интересной задачей, настоящим испытанием: сделать нативный компилятор, генерирующий нативный код из IL .NET-кода. Это было именно то, чем я всегда хотел заниматься, но не мог, потому что мне бы за такое не заплатили. И вот появился шанс, прекрасная возможность. Я проработал над этим проектом 2 года. \r\nДа, похоже, рассказ получился не очень коротким.\r\nЯ придерживаюсь в этом вопросе золотой середины.  Я верю, что многие, если не большинство приложений, которые мы разрабатываем, адаптируются к требованиям производительности с самого начала, в результате обеспечивая наилучшее качество. \r\nПосмотрите, что происходило в IT-индустрии на наших глазах. Например, когда Windows на протяжении нескольких лет становилась немного медленнее — Windows Vista и т.п. По сути велась естественная работа по улучшению перформанса, ведь годами об этом особо не беспокоились. Когда вышла Windows 8, она была уже немного лучше. Потом вышла Windows 10 и она стала ещё немного лучше. В результате, у нас есть система, которая работает весьма неплохо по сравнению с тем, что было раньше. Действительно важно для них было сделать эти оптимизации, ведь однажды люди обязательно стали бы «жить не по средствам» и начали бы говорить: «О! Этот софт больше не работает, мы переходим на Linux, потому, что он быстрее и меньше тупит». \r\nТо же самое можно сказать про весь софт, который мы разрабатываем. И вот что удивительно: всегда была тенденция работать с нативным кодом, в какой-то момент даже в Windows решили вернуться к C++, они говорили: «C++ — это решение, .NET очень медленный, тут Garbage Collector и бла-бла-бла…». И вот снова стали актуальны нативные языки. \r\nВ то же самое время V8 в Chrome вернул в обиход JavaScript благодаря JIT.  JS — скриптовый язык, не супербыстрый, но иногда он отрабатывает в два раза быстрее C++. Этого было достаточно, чтобы он выжил и чтобы мы использовали его прямо сейчас для вещей вроде написания кода в Visual Studio Code. Но если присмотреться, это всё потому, что требования по производительности закладывались туда с самого начала. Даже в VSCode, даже несмотря на то, как много там JavaScript и скриптового кода вообще, всё остальное — V8, стек рендеринга, JIT — всё это написано на языке, предназначенном для максимальной производительности, то есть на C++. Всё могло быть написано на другом языке, не обязательно C++, но факт в том, что весь этот софт развивался с учётом перформанса с самого начала. \r\nТак что да, мы можем использовать менее эффективные и производительные языки, но только потому, что всё нижележащие технологии разрабатываются с целью получить фантастический . Например, Visual Studio Code — изумительное программное обеспечение, очень хорошо работающее для разработчиков, решающее их задачи. Многие говорят: «Хотя нам нравится пользоваться более нативными редакторами кода, прямо сейчас мы переходим на Visual Studio Code» — потому что они считают его вполне эффективным. Перформанс повсюду, но иногда мы не видим его, потому что он уже заложен во всё, что мы используем.\r\nМы думаем: это написано на JavaScript, потому что он достаточно быстрый. Но JavaScript такой быстрый только потому, что сотни сотен инженеров-разработчиков годами работали, чтобы оптимизировать JIT. Сейчас мы можем пользоваться скриптовыми языками даже для написания очень сложных приложений. Скриптовыми языками, которые без всей этой подготовительной работы оказались бы гораздо медленнее. Мы живём в странное время. У нас есть выбор, но всё равно есть эта история с перформансом, которая повторяется для каждого языка снова и снова. \r\nТак что .NET — типичный пример. За последние три-четыре года там проведена громадная работа. Если вы посмотрите когда-нибудь на ASP.NET Core, если вы посмотрите на всю работу, проделанную с CoreCLR… Перформанс — это хорошо продаваемая штука, он стоит денег и позволяет достигать большего. Пытаясь уложиться в жесткие требования, можно попробовать стать более производительным, можно сэкономить мощности, сэкономить немного денег в конце месяца — перформанс влияет на всё. Когда я слышу, как люди говорят: «Всё в порядке, я разрабатываю своё приложение, у него средняя производительность, сойдёт…», о чём они думают? Нужно уделять немного времени, чтобы проверять, можешь ли ты сделать своё приложение чуть более производительным. Если ты сможешь сэкономить ресурсы или время работы приложения хотя бы на десятую долю, это уже хорошо.\r\nНет, я так не думаю. Сейчас я работаю удалённо. На работе, в Unity, мы можем работать удалённо, поэтому я постоянно использую Slack для общения с коллегами. Это лучший способ для меня и быть на связи, и оставаться продуктивным. Это отнимает много времени от работы, потому что нужно проверять каналы и так далее, но я могу временно выключить Slack и сфокусироваться на работе. Пока я работал в компании в опенспейсе, у меня не было выбора: если кто-то хочет задать вопрос, приходится сразу отвечать, это куда сложней.\r\nЧто касается Twitter и электронной почты, я не проверяю их так часто. Один-два раза в день я читаю Twitter, это зависит от разных факторов: участвую ли я в каких-то обсуждениях и что обсуждаю. Если используешь что-то типа Slack, можно присоединяться к разным каналам в компании, можно следить за многими темами, за которыми ты бы не мог следить, если бы работал один. Нужно найти золотую середину: все мы беспокоимся о множестве вещей, которые происходят в компании, но нужно быть избирательным, ведь нельзя участвовать во всех обсуждениях одновременно. Некоторые люди могут читать так много каналов, что я просто поражаюсь их способностям, сам я не такой. На сегодняшний день я читаю около 30 каналов, это не так много.\r\nНе уверен, что существует заготовленный путь для такого перехода. Если ты интересуешься такими технологиями, то делаешь некую обычную домашку. Дома ты пишешь парсеры и штуки, связанные с компиляторами. Не обязательно писать полностью компилятор от начала до конца, до самой генерации машинного кода. Ты начинаешь интересоваться написанием компиляторной инфраструктуры. Это то, что я делаю последние годы, работая в Unity. Если ты увлечён низкоуровневыми вещами, то это одно из тех мест, где можно понять, как это всё устроено на самом деле. Как можно улучшить работу, где стоит улучшить перформанс, и где этого ещё не сделали. Если ты беспокоишься о перформансе, то очень важно быть в курсе, на чём будет выполняться приложение в конце концов. \r\nПерформанс — это моя тема, и всё это стало для меня отличной возможностью. Хочется подходить к решению проблемы в её основе, то есть на уровне компилятора. Именно здесь мы можем в десятки раз увеличивать производительность в тех местах, где это нужно для наших пользователей. Если мы запускаем игры, приложения, фильмы или что-то в этом роде, иногда можно сравнительно легко достичь таких результатов. \r\nУвлечённость низкоуровневыми штуками и составными частями компилятора привели меня к текущей работе. Но это не было чем-то, чем я специально хотел заниматься. Иногда, когда ты получаешь много опыта с разными языками, пишешь приложения — появляется желание даже придумать свой собственный язык. Я начинал этим заниматься, но прекратил, потому что это слишком много работы, а у меня очень мало свободного времени. Но у тебя появляется подсознательное желание вернуться «к корням», попытаться сделать что-то самому, чтобы всё понять. Конечно, я понимал, как работают компиляторы и всё такое, но не понимал сложности требований. Сложных трейдоффов, с которыми придется разбираться, например, в области управления памятью. Очень сложно выбрать то, что одновременно даст и большую продуктивность работы прикладного разработчика и будет эффективным. Эта проблема всё ещё не решена до конца. Rust или .NET никогда не решат этого. Rust — прекрасный, изумительный, но он сложен в работе, особенно если ты переходишь на него с чего-то типа JavaScript. Тем не менее, имеются примеры разработчиков на Python или JavaScript, которые переходят на Rust, хотя это и несколько удивительно. \r\nЕсли честно, я ненавижу C++, ненавижу C, но работаю с ними. Я искренне верю, что они приводят к куче багов, к огромной неэффективности разработки. Многие думают, что раз ты программируешь на C, то ты уже де-факто пишешь быстрый код, что твоя программа будет перформанс-ориентированной. Это неправда. Если ты лепишь кучи malloc и всякого такого, оно будет медленным даже по сравнению с тем, что написано на .NET. Хорошие разработчики на C/C++ вынуждены использовать ухищрения вроде . Ты должен зарываться в кучу странных вещей, о которых никто не слышал. Хотя вот разработчики игр обычно о таких вещах знают. Как минимум, разработчики AAA или люди, которые делают игры на C/C++-фреймворках. Часть проблем происходит от сложности самого языка. Раньше я вообще не читал книг по C++ и только три-четыре года назад начал читать книги только по C++, чтобы просто прочувствовать язык. Я программировал на нём, но у меня не было систематического, формального подхода, и меня поразила его сложность, количество вещей, которые ты можешь испортить, если не напишешь всё правильно. \r\nНе далее, как пару месяцев назад в Unity был баг, кто-то допустил ошибку в куске кода на C++, это было в конструкторе, что-то передавалось по значению и в итоге мы брали от этого значения адрес и искали в кэше. Фактически мы ссылались на значение, которого уже не было в памяти. И всё это потому, что там перепутали указатели с неуказателями, и тот, кто сделал этот рефакторинг, не проверил все места использования. Совершенно другой код, который отлично работал, внезапно работать перестал. Вроде бы, ошибка маленькая, но она поломала всё целиком. По сути, это ошибка в работе с памятью. Так что да, когда я вижу подобные вещи, то убеждаюсь, что мы должны ограничить доступ к работе на C и C++, максимально сократить их использование. В .NET-части я действительно ограничил их применение только платформозависимыми вещами. Но писать всё на C# довольно муторно. Для того, чтобы получать доступ к API, нужно делать кучу dlopen. Хотя, например, можно попробовать инкапсулировать всё это в обёртку на C и организовать доступ через всего одну функцию. Такие вещи я предпочёл бы изолировать и разрабатывать их дальше на C и C++. Но это такая узкая тема про интероп, а дальше ты остаёшься с нормальным управляемым языком, используешь его большую часть времени, наслаждаешься более быстрой компиляцией. \r\nЯ ненавижу ошибки компилятора C++ и линкера, ненавижу необходимость работать с разными платформами, всё это очень-очень сложно. Ты начинаешь компилировать на MSVC, потом должен переключиться на Clang, потом на GCC. На Linux, на Mac, на Windows, на Android, на iOS и так далее и тому подобное. Работа с C++ — это кошмар! \r\nЯ ненавижу разделение между файлами в редакторе, .h-файлами и cpp.-файлами. Люди окончательно запутываются в языке и начинают программировать на макросах. Я люблю метапрограммирование, но в современном C++ мы можем делать просто полное безумие. Сами по себе эти штуки изумляют, но вообще-то это уже слишком. \r\nПодводя итог: да, думаю, мы можем разрабатывать эффективный софт на C#. Может быть, не такой быстрый, как на C++, но можем. Именно это мы пытаемся делать в Unity — например, мы делаем burst compiler, чтобы компилировать особое подмножество C#, добиваясь максимального перформанса, местами даже большего, чем это получилось бы на C++ — но оставаясь в C#. Это вполне безопасно. Для указателей нужно объявлять unsafe, не генерить исключений, делать всё эксплицитно. И это горький опыт. Но всё-таки ты можешь написать код, который будет так же быстр, как на C++. Думаю, это как раз то направление, в которое стоит идти .NET и куда должны идти мы.\r\nДа! Я общаюсь с людьми, которые работают над JIT и в Microsoft, и в сообществе. Есть кое-что, во что я искренне верю. Я верю, что существует момент, когда твой язык становится более зрелым и основополагающим, и тогда ты должен бросить вызов, проверить его на прочность. Тебе нужно уметь использовать его в качестве фундамента. Доказать, что можешь применить его даже для создания чего-то очень требовательного к перформансу. И это история про Garbage Collector и JIT. Очень-очень большой процент подсистем рантайма .NET, в том числе JIT и GC, может быть сделан на C#. Если взять за правило, что на C++ можно описывать только абстракции базовой платформы, это сделает большую часть рантайма платформонезависимой. Я бы очень порадовался, если бы это произошло. Но это огромная работа. \r\nЕсть одна причина, почему мне эта идея особенно нравится. Я уже говорил об этом, рефакторинг и улучшение кодобазы на C/C++ настолько сложны, что в какой-то момент ты перестаёшь этим рефакторингом заниматься. Это настолько больно, что ты просто к этому больше не притронешься. Придётся переносить и менять какие-то файлы руками, ибо рефакторинги в IDE будут работать плохо, например, потому что слишком много шаблонов — и так далее и тому подобное. Разрабатывая на C#, можно было бы быть амбициознее насчёт своих желаний. Добавлять новые оптимизации оказалось бы возможным гораздо быстрее и проще, просто потому, что время компиляции уменьшилось. Уменьшилось бы время итераций для тестирования и так далее. Приятно, что, например, в CoreRT стараются максимально использовать C# вместо C++. Ситуация меняется. \r\nНо мы всё ещё на полпути от того, чтобы переписать .NET GC на C#. Но мы могли бы. Например, я знаю, что могу переписать .NET GC, причём переписать по-другому. Несколько лет назад я сильно заинтересовался GC, читал книжки про это, написал что-то вроде прототипа реализации GC. Я был поражён работой Java-комьюнити над Jikes RVM — они проделали эту работу на Java. Позже я обнаружил, что в Golang компилятор вначале был написан на C, а потом на Golang. Когда стал читать исходный код Golang-компилятора, был удивлён организацией кодобазы и тем, как структурированы оптимизации. Например, есть огромный файл, где описываются разрешённые оптимизации, которые можно применять к некоторым инструкциям. Инструкции могут мапиться в более быстрые нативные инструкции, и это всё описано в огромном текстовом файле. Я не видел такого ни в LLVM, ни в .NET JIT. \r\nПодводя итоги, да, использование управляемого языка должно дать нам больше возможностей для написания более качественного рантайма. \r\nХа, вы говорите, как будто бы для любой вещи есть заранее заготовленные правила! Компиляторы более требовательны к коду, чем обычные приложения. Первое: нужно быть предельно внимательным при проектировании базовой архитектуры. Нужно внимательно следить за переиспользованием и изоляцией: если ты изменяешь что-то, то в других местах ничего не должно посыпаться и испортить весь остальной код. \r\nВторое: я убеждён, что мы обязаны сопровождать код большим количеством комментариев, чтобы объяснять внутренние зависимости, которые не очевидны, когда просто смотришь на код. Мне очень не нравится, когда говорят: «Код должен сам описывать себя! Он должен быть очевиден!». Это совершенно неверно и вводит в заблуждение. Инженеры любят рассказывать такие сказки молодым разработчикам, и так делать не стоит. \r\nКогда я вижу кодобазу вроде LLVM, например — она может быть несовершенна, но там полно комментариев. Например, когда есть структура в заголовочном файле, комментарии могут объяснить, где эта структура объявляется, почему она так объявляется, почему здесь такие поля. Для всех этих вещей есть причина. Если ты не объяснишь эту причину, никто и не поймёт, почему ты сделал это именно так. Если ты просто прочитаешь код, ничего понятно не станет. Например, выравнивая данные для эффективного кэширования, если ты не объяснишь это в комментарии, как другие поймут, что всё это делалось ради эффективности? Возможно, впоследствии даже тебе самому придётся перечитать весь код, восстановить всю структуру приложения и раскладку данных в памяти, и тогда придёт озарение. Но если ты не добавишь комментарии в код и не объяснишь этого, то кто-то другой посмотрит на всё это и скажет: «Вау, тут прибитое гвоздями поле, это не очень реюзабельно, поставлю-ка я здесь другой класс и добавлю указатель» — и тем самым поломает вообще всё, потому, что не понял, почему здесь было сделано именно так. \r\nИ я говорю так не только о хорошей, но и о плохой работе. Не раз мне приходилось вставлять комментарий в код, чтобы сказать, что вот эту часть я сделал не очень хорошо, не очень горжусь этим, это место нужно исправлять, пока что мы его оставим в текущем виде, но когда-нибудь нужно будет к нему вернуться и починить. Объяснял причину, почему это сделано так: например, не хватило времени, чтобы сделать хорошо. Ты задокументировал, что сделал лишь небольшую часть необходимого, и это нормально. Ты применил вот такой костыль, и если бы попытался сделать более правильно, то сломал бы всё. Но ты должен это объяснить даже для тех участков кода, которые работают не очень хорошо. Итак, комментарии — это второе. \r\nИ третье для меня — тестирование. Нужно делать больше юнит-тестов. Не больших интеграционных тестов, а именно мелких юнит-тестов, проверяя части своего API, начиная с нижних уровней. Так твое приложение будет совершенствоваться со временем. Например, я написал SharpDX вообще без тестов. И в момент написания он был неплох. Но дело в том, что я создавал его не для людей, а для себя, в своё свободное время. Я хотел иметь доступ к DirectX C++ API, которое уже было доступно на C++. На протяжении многих лет я проверял, что всё работает. Но каждый раз, когда я вносил какие-либо изменения, приходилось проверять функциональность заново. Последние несколько лет я переключился на другие проекты: времени нет, да и не пользуюсь я им больше. А потом пришел один разработчик из опенсорсного сообщества, выделил компилятор в отдельный пакет и попробовал на этом сделать нечто отдельное от SharpDX. Штука в том, что я полностью не проверил этот PR, поскольку мы не сделали ни одного теста. Просто замерджил его pull request (он казался идеальным). Он начал делать мини-тесты на своём репозитории на своём отдельном приложении. Но мы кое-чего не учли, и сам SharpDX оказался совершенно сломан в какой-то из версий. Тут же нарисовались люди с проблемами вида: «А чего это вот этот метод вызывает исключение?» На последующих проектах (и опенсорсных, и рабочих) я старался быть очень осознанным в плане тестирования, периодически даже пытаясь увеличить покрытие. Но попытка достичь 90-процентного покрытия — это очень муторно. Иногда реальные тесты получаются слишком странными, ты написал их просто для отладки и не можешь внести их под покрытие, не хочешь тащить такое в свой код.\r\nВ общем, да, я считаю, что это вот эти три вещи, к которым нужно подходить очень внимательно: архитектура, комментарии, тестирование.\r\nЯ думаю, что сегодня главный челлендж — создать компилятор, который будет эффективен в работе с SIMD. И это действительно вызов, ответить на который компиляторы немного затрудняются, потому что SIMD и подобные оптимизации обычно добавляются позже, не обязательно с самого начала создания компилятора. (В случае с LLVM, наверное, они были с самого начала). Дело в том, что это приносит множество новых проблем оптимизатору, он должен уметь выполнять их корректно. Как можно заметить, компиляторы сейчас затрудняются, например, автоматически векторизовывать код. В каком-то виде они могут это делать, но иногда это проще сделать вручную. Компиляторы неспособны определять все места для оптимизации, и в результате генерится неэффективный код. Это сложная тема. Кое-кто из Intel работает над добавлением технологии векторизации в LLVM. Проект разрабатывается уже несколько лет, и в целом это только подготовка, чтобы внести эти изменения в апстрим LLVM. Их ещё пока там нет, это очень сложно, и потребуются годы. LLVM — это очень хорошая система, хотя бы потому, в ней есть вещи, отсутствующие в .NET. Использование преимуществ SIMD, CPU и разных ядер — вот это будет наибольшим современным челленджем. Вот почему, например, в .NET языки добавляют векторные интринсики — можно использовать векторизатор и SIMD-инструкции эксплицитно. Но во многих случаях, вроде циклов, можно было бы ожидать и автовекторизации. \r\nРаньше я бы сказал: «Нам нужны компиляторы как сервисы и компиляторы как библиотеки». Сегодня это больше не проблема. Люди убедились в полезности этих идей. Поэтому LLVM и стала такой известной штукой: она разрабатывалась с самого начала как компилятор-библиотека, в которой можно пользоваться любым языком, каким захочется. То же самое, например, с Roslyn на C#, там тоже есть компилятор. Конечно, это компилятор не того же типа, но тем не менее его можно использовать в собственном коде. Думаю, сейчас все уже в курсе этих штук, люди осознают, что компилятор приносит пользу. Так что для меня совместимый с SIMD код — более важная штука. Программировать с прицелом на GPU, CPU, на количество используемых ядер — это только начало. У нас есть 6, 8, 16, 42 ядра. В какой-то момент начнётся их увеличение, мы должны быть готовы к этому, чтобы использовать всю эту мощь максимально эффективно.\r\nДа, для меня Markdown — это такой способ написания документации, который нравится разработчикам. Скорее всего, это не для простых обывателей, которым всё ещё проще использовать Word или что-то такое. Но для разработчиков он хорош. Разработчики на протяжении многих лет пользовались чем? Текстовыми файлами, разными способами размечали в них заголовки, и так далее. И это было нормально. Ты знаешь, это как читать RFC в интернете — есть куча текстовых форматов файлов, очень ограниченных, очень хорошо сделанных, но не формализованных. Их не всегда было просто читать, там не было картинок, и это было сумасшествие. Но у нас не было выбора, и приходилось использовать даже ASCII-art. А потом появился Word, PDF и тому подобное. В двухтысячном году куча документации была в Word. Разработчиков было не очень-то просто уговорить работать с такими документами — это было не модно. Было неудобно смотреть изменения в документации, когда вносишь правки в связанный код и наоборот. Когда появился Markdown, это было изумительно, стало возможным производить из него что-то очень приятное — например, HTML. И это всё ещё текстовый формат, который легко читать и добавлять в свою кодобазу. Даже если у тебя не сгенерировано HTML, Markdown можно удобно читать в текстовом редакторе. Сейчас, когда ты открываешь проект на Github, он определяет Markdown-файлы и самостоятельно красиво их отображает. И всё это лежит рядом с твоим кодом. Документация среди кода — лучшая форма технической документации. Например, в Microsoft перевели всю техническую документацию на Markdown, и теперь документацию можно читать прямо на GitHub, они принимают PR — вот такой прекрасный способ дать доступ к документации и организовать процесс внесения правок, воспользоваться которым может каждый. \r\nВ плане нормализации Markdown, есть проект под названием CommonMark, который запущен несколько лет назад, целью которого является стандартизация Markdown. Думаю, что сегодня CommonMark — это и есть стандарт. Люди начинают уважать его, следовать ему, но есть и множество других реализаций. Например,  в прошлом году. Никто этого не заметил — и это хорошо. Но они смогли перейти на него. И Microsoft тоже перевёл документацию на CommonMark, потому что они использовали мой Markdig. Они начали работать над тем, чтобы использовать Markdig много лет назад, а до этого они взяли самописный Markdown-движок, использующий внутри регулярки. Это неплохо, но, насколько знаю, они не очень следовали в этом движке спецификации CommonMark, поэтому в результате перешли на Markdig. Они связались со мной, и это было круто. Я написал Markdig для того, чтобы им пользовались, и хотел использовать в своём собственном проекте, но потом надолго отложил его в сторону. Очень рад, что такая компания как Microsoft решила его подхватить.\r\nЭто применимо не только к программированию, но и к любой сфере. Главное — делать свою домашку, изучать вещи самостоятельно. Важно задавать вопросы. Не обязательно принимать язык программирования таким, какой он есть. Не то чтобы надо его менять, но важно понимать, почему разные вещи работают так, как они работают. Ты должен быть любознателен и открыт к изучению причин, должен задавать хорошие вопросы. «Я не понимаю, как это устроено, но я хочу понять это». Что бы ты сделал, чтобы улучшить язык? Чем больше вопросов ты задаёшь языку, которым пользуешься, тем больше у тебя будет возможностей помогать, улучшать его, узнавать новые вещи и открывать, почему что-то в программном обеспечении сделано определенным образом. Так ты сможешь узнать гораздо больше, чем просто вбивая в Google «я хочу сделать X» и находить на гитхабе готовые проекты из одной функции «сделать хорошо». Когда мы пишем реальное приложение, слишком сложно было бы вдаваться в детали каждой использованной зависимости — это была бы огромная работа по ковырянию в деталях. Но в той части, которая тебя заботит, которая интересна для тебя лично, стоит глубже погружаться и задавать вопросы. Как это работает, можно ли это сделать быстрее, почему какая-то вещь работает не очень хорошо — ты обязательно должен понять, почему. «Может быть, я могу написать что-то лучшее?» \r\nМногие проекты, с которыми я работал, по большей части были законченными. Иногда хозяева проекта не хотели его менять. Это грустно, ведь ожидаешь, что в опенсорсе все друг с другом будут сотрудничать. Реальность опенсорса такова, что иногда тебе нужно заняться чем-то другим. Иногда то, что ты предлагаешь, хорошо, но ведёт к слишком большим изменениям. Людям бывает тяжело принимать такие предложения — возможно, это принесёт только больше багов и больше поддержки, и кто будет всё это поддерживать? Тот, кто пришёл с этим предложением? Наверное, нет. \r\nИногда я тоже забываю о том, что нужно задавать разные вопросы. Простые вопросы. Можем ли бы сделать это быстрее? Да ли нет? Нужно действовать вместо того, чтобы просто пользоваться и ругаться на медленно работающие вещи, и ничего не делать по этому поводу. Нужно копать, исправлять… Делать что-то дома, справляться с болью. С каждым разом ты становишься всё более готов понимать вызовы и разрабатывать более сложные программы. И, может быть, в конце концов ты будешь чуть менее разочарован реакцией других людей, потому что начнёшь лучше понимать их ограничения. \r\nИ ещё одна важная вещь. Не надо скромничать. Пробуй! Пробуй делать то, тебе хочется. Если у тебя появилась идея — попытайся воплотить её. Даже если эта идея безумная, и иногда ты можешь получить немного безумные результаты — в этом тоже что-то есть. Пока ты занимаешься такими вещами, можно встретить множество странных и сумасшедших людей, от которых можно получить крутые инсайты о том, как можно заниматься разработкой. Тебе нужно быть очень внимательным к тому, что они говорят, как они работают, что они думают. Не копируй их, потому что у тебя есть свой собственный путь и своё будущее. Это круто, когда ты можешь встретить таких людей на своем карьерном пути. У меня было несколько таких людей. Я не всегда это осознавал, но спустя какое-то время понимал: «Да ведь этот парень был крутым!». Я научился у них чему-то, но, может быть, мог бы научиться большему. Это золотая середина между тем, чтобы пытаться думать самостоятельно и брать лучшее от лучших умов вокруг себя. Они могут повлиять на тебя в хорошем смысле и могут помочь разработать более крутые вещи. \r\nЭто история про то, чтобы быть развиваться самостоятельно, задавать как можно больше вопросов, пытаться быть открытым людям, которых встречаешь, к событиям, которые можно использовать, и принимать участие в чём-то большем, чем мы сами.", "url": "https://habr.com/ru/company/jugru/blog/429242/"},
{"title": "Современный C++ != (Самый)Новый Стандарт", "article_text": "\r\nТермин «современный C++» часто используется как синоним выражения «код, использующий новый стандарт C++». Здесь «новый» может означать что угодно от C++11 до C++17, или даже то, что уже сейчас доступно из C++20. Я думаю, что современный C++ — это нечто большее, не ограничивающееся добавлением флага .\r\nЕсли поискать значение слова «современный» в сети, одним из первых мы найдем определение из словаря . Вот две части, относящиеся к C++:\r\nТехники, методы и идеи имеют отношение к чему-то большему, чем просто новые возможности языка. Часто эти новые возможности поддерживают или включают новые техники, но многие из них существовали уже достаточно долгое время. Что касается характеристик развития языка, в их основе лежит то, как мы используем язык. Это относится к тому, как мы комбинируем старые и новые возможности, и это нечто большее, чем просто рабочая программа на C++, или то, что включено в стандартную библиотеку. \r\nМожно поспорить, что возможности, существовавшие со времен C++98, не входят в современный C++, потому что они существуют слишком давно. Однако, нужно помнить, что самые активные люди в сообществе, которые говорят или пишут о «современном C++», это чаще всего первопроходцы. Большинство использует, изучает и даже преподает старый добрый «C с классами» из 90-х, что делает многие методы, которые там не используются, частью современного C++.\r\nЧто же из доступного в C++98 я считаю принадлежащим к категории «современный C++»? Вот неполный список некоторых важных возможностей и идей:\r\nRAII расшифровывается как «получение ресурса есть инициализация», или «получение ответственности есть инициализация». Хотя название делает упор на «инициализацию», ключевая часть здесь, на самом деле — это деструктор. Детерминированное освобождение ресурсов — одна из основных характеристик C++, которая отличает его от большинства других языков. Для многих — это  характеристика.\r\nRAII может использоваться для надежного управления многими вещами, такими как память (например, ), дескрипторы файлов (), сетевые соединения, мьютексы, соединения с базами данных, а также сущности, которые имеют отдаленное отношение к ресурсам. Если вам нужен надежный способ сделать некоторое действие, а потом отменить его на выходе из некоторой области видимости или при уничтожении объекта, RAII — то, что вам нужно.\r\nЯ видел много кода, в котором ручная чистка при завершении функций превращалась в кошмар. В случае исключений такая очистка не происходит, так что в этой ситуации . Даже если вы не используете исключения,  может существенно улучшить ваш код, но только если вам не нужно проводить чистку.\r\nОпределенно, техника RAII входит в современный C++, хотя она и была доступна с самого начала.\r\nИдея  очень популярна в последнее время. В прошлом любые идентификаторы, размеры, почтовые индексы, цены и так далее представлялись через int или double, или другой арифметический тип. То, что они были совместимы, совершенно несвязанные друг с другом значения, которые по чистой случайности имеют один тип, было источником багов, но что поделать? По крайней мере, компилятор молча не !\r\nНа деле получается, что система типов C++ и абстракции с нулевой стоимостью*, которые предоставляет нам компилятор, позволяют сделать многое. Просто создайте разные типы для идентификаторов, почтовых индексов, размеров (нет, без typedef, спасибо) и так далее. Если вам интересно, посмотрите один из докладов ,  или .\r\n*(Даже если стоимость абстракции ненулевая,  прежде чем отказываться от нее)\r\nЕсли не считать некоторых недавних дополнений, <algorithm> был в стандартной библиотеке с самого начала. Но если взглянуть на код, выходит, что люди часто предпочитают писать циклы вручную. Причины разнятся от незнания того, какие стандартные алгоритмы доступны, до веры в то, что «шаблоны слишком медленные» (часто без объяснения, по сравнению с чем).\r\nВещи вроде метапрограммирования с использованием шаблонов применялись со времен C++98. Логика, выполняемая на этапе компиляции, может существенно уменьшить сложность на этапе выполнения. В прошлом ее было неудобно использовать. Синтаксис шаблонов отличается в сторону усложнения от возможностей, которые есть в последних стандартах. Это что-то вроде отдельного языка, который нам приходится учить. Однако, такие вещи как диспетчеризация тегов или типажи не слишком сложны для использования и написания.\r\nДа, большинство типажей в стандартной библиотеке появилось с приходом C++11, но писать их под свои нужды  сложно, и некоторые наиболее общие из них были в Boost до C++11. Я считаю использование логики этапа компиляции частью современного C++, потому что оно отделяет C++ от вездесущего «C с классами». \r\nСовременный C++ имеет отношение не к новым стандартам, а к тому, как мы пишем наши программы. Во-первых, на C++98 можно писать в более или менее современном стиле. Во-вторых, «C с классами и range-based for циклами» — это еще не современный C++. Новые возможности языка и библиотек помогают нам писать в стиле современного C++, но не они делают наш код современным C++.", "url": "https://habr.com/ru/company/pvs-studio/blog/429780/"},
{"title": "Полное руководство по CMake. Часть первая: Синтаксис", "article_text": " — это открытый и кросс-платформенный набор утилит, предназначенных для автоматизации тестирования, компиляции и создания пакетов проектов на C/C++. Написав однажды небольшой и понятный всем скрипт, Вы тем самым обеспечите одинаковую сборку Вашего проекта на любых платформах, где доступен CMake., будучи транслированным в нативный файл сборки (например, Makefile или Ninja), определяет процесс всего управления проектом. В Вашем распоряжении, с функциональной стороны, есть лишь команды, которые могут образовываться в довольно сложные конструкции. С них мы и начнём.Ниже приведены примеры использования языка CMake, по которым Вам следует попрактиковаться. Экспериментируйте с исходным кодом, меняя существующие команды и добавляя новые. Чтобы запустить данные примеры, установите CMake с .Команды в CMake подобны функциям во многих языках программирования. Чтобы вызвать команду, необходимо написать её имя, а затем передать ей обрамлённые в круглые скобки аргументы, отделённые символами пробелов. В приведённом примере команде  передаются шесть аргументов для вывода в консоль:Аргументы, обрамлённые в двойные кавычки, позволяют внутри себя совершать экранирование и подстановку переменных. Необрамлённые аргументы не позволяют производить подобных вещей и не могут включать в себя символы  и пробелы, однако более удобны для использования. Пример:Стоит отметить, что аргумент  расширится до списка , так как любой необрамлённый аргумент автоматически расширяется до списка значений (при условии, что значения изначального аргумента разделены символами точки с запятой), но с обрамлённым в двойные кавычки аргументом такая трансформация не происходит (символы точки с запятой просто исчезают). Об этой особенности  в комментариях.Комментарии начинаются с символа решётки и заканчиваются в конце той строки, где они были напечатаны. Текст, заключённый в комментариях, игнорируется системой сборки и не оказывает никакого эффекта на её работу. Примеры выше также демонстрируют использование комментариев.Переменные можно определить путём вызова команды , а удалить вызовом . Получить значение переменной можно по конструкции . Если переменная ещё не определена и где-то потребовалось получить её значение, то данная переменная обратится в пустую строку. Пример:CMake поддерживает задание опций, подлежащих модицификациям пользователей. Опции похожи на переменные и задаются командой , принимающей всего три аргумента: имя переменной, строковое описание переменной и значение переменной по умолчанию ( или ):Прежде чем приступать к изучению условных операторов и циклических конструкций, необходимо понимать работу логических выражений. Логические выражения используются при проверки условий и могут принимать одно из двух значений: правда или ложь. Например, выражение  обратится в правду, так как 52 < 58. Выражение  обратится в правду,  обратится в ложь. Сравнивать можно не только числа, но и строки, версии, файлы, принадлежность к списку и регулярные выражения. Полный список логических выражений можно посмотреть .Условные операторы в CMake работают в точности как в других языках программирования. В данном примере сработает лишь первый условный оператор, который проверяет, что 5 > 1. Второе и третье условия ложны, так как 5 не может быть меньше или равняться одному. Блоки команд  и  необязательны, а  обязательна и сигнализирует о завершении предыдущих проверок.Циклы в CMake подобны циклам других языков программирования. В приведённом примере устанавливается значение переменной  в , а затем четыре вложенные команды последовательно исполняются пока значение переменной  будет равняться . Последняя четвёртая команда  устанавливает значение проверяемой переменной в , поэтому цикл сразу остановится, не дойдя до второй итерации. Команда  сигнализирует о завершении списка вложенных в цикл команд.Данный пример цикла  работает следующим образом: на каждой итерации данного цикла переменной  присваивается следующее значение из списка , а затем исполняется команда , которая выводит текущее значение переменной . Когда значений в списке не остаётся, то цикл завершает своё выполнение. Команда  сигнализирует о завершении списка вложенных в цикл команд.Существуют ещё 3 формы записи цикла . Первый цикл в данном примере на место списка генерирует целые числа от 0 до 10, второй цикл генерирует в диапазоне от 3 до 15, а третий цикл работает в сегменте от 50 до 90, но с шагом 10.Синтаксис CMake позволяет определять собственные команды, которые можно будет вызывать в точности как встроенные. Приведённый ниже пример демонстрирует использование функций и макросов: сначала определяются функция и макрос со своими собственными командами, а при их вызове их команды исполняются последовательно.Команда  первым аргументов принимает имя будущей функции, а остальные аргументы — это имена параметров, с которыми можно работать как с обычными переменными. Параметры видимы лишь определяемой функции, значит вне функции доступ к её параметрам мы получить не можем. Более того, все другие переменные, определяемые и переопределяемые внутри функции, видны лишь ей самой.Макросы аналогичны функциям за тем исключением, что они не имеют собственной области видимости: все переменные внутри макросов рассматриваются как глобальные. Более подробно о различиях макросов и функций Вы можете почитать .Как  в комментариях, макросы в CMake подобны макросам в препроцессоре языка Си: если в тело макроса поместить команду , то произойдёт выход из вызвавшей функции (или из всего скрипта), что демонстрирует данный пример:В приведённом выше примере функция  не успеет напечатать сообщение , так как прежде, на место вызова макроса  будет подставлена и выполнена команда выхода.Как  в комментариях, Мощный механизм  позволяет производить разбор аргументов, переданных в функцию или макрос.Данная команда принимает префикс, используемый в определении переменных (смотреть следующий абзац), список опций, используемых без последующих значений, список ключевых слов, после которых следует одно значение, список ключевых слов, после которых следуют множества значений и список всех значений, переданных в функцию или макрос.Работа механизма разбора аргументов заключается в преобразовании полученных аргументов в значения переменных. Таким образом, рассмотренная команда для каждой опции и ключевого слова определяет собственную переменную вида , инкапсулирующую некоторое значение. Для опций — это булевы значения (истина — опция указана, иначе — ложь), а для ключевых слов — все переданные значения, расположенные после них.Функция  содержит вызов команды , а затем команды печати значений определённых переменных. Далее, функция вызывается с аргументами , после чего производится печать на экран:В предыдущем разделе Вы узнали о том, что некоторые конструкции в CMake могут определять собственные области видимости. На самом деле, все переменные по умолчанию считаются глобальными (доступ к ним есть везде), за исключением тех, которые были определены и переопределены в функциях. Также имеются , у которых своя собственная область видимости, но они применяются не столь часто.Как  в комментариях, переменные можно определять в \"родительской\" области видимости с помощью команды . Данный пример демонстрирует эту особенность:Если из определения переменной  убрать , то переменная будет доступна лишь функции , а в глобальной области видимости она примет пустое значение.На этом синтаксис языка CMake заканчивается.  выйдет примерно через пару дней и будет вводить в использование системы сборки CMake. До скорых встреч!", "url": "https://habr.com/ru/post/431428/"},
{"title": "В трёх статьях о наименьших квадратах: ликбез по теории вероятностей", "article_text": "Полтора года назад я опубликовал статью , которая получила весьма приличный отклик, который, в том числе, заключался в том, что я предложил нарисовать сову. Ну, раз сова, значит, нужно объяснять ещё раз. Через неделю ровно на эту тему я начну читать несколько лекций студентам-геологам; пользуюсь случаем, излагаю тут (адаптированные) основные тезисы в качестве черновика. Моей основной целью не является дать готовый рецепт из книги о вкусной и здоровой пищи, но рассказать, почему он таков и что ещё находится в соответствующем разделе, ведь связи между разными разделами математики — это самое интересное!\r\nНа данный момент я предполагаю разбить текст на три статьи:\r\nЯ зайду к наименьшим квадратам чуть сбоку, через принцип максимума правдоподобия, а он требует минимального ориентирования в теории вероятностей. Данный текст рассчитан на третий курс нашего факультета геологии, что означает, (с точки зрения задействованного матаппарата!) что заинтересованный старшеклассник при соответствующем усердии должен суметь в нём разобраться.\r\nОднажды мне задали вопрос, верю ли я в теорию эволюции. Прямо сейчас сделайте паузу, подумайте, как вы на него ответите.\r\nЛично я, опешив, ответил, что нахожу её правдоподобной, и что вопрос веры тут вообще не встаёт. Научная теория имеет мало общего с верой. Если кратко, то теория лишь строит модель окружающего нас мира, нет необходимости в неё верить. Более того,  требует от научной теории иметь возможность опровержения. А ещё состоятельная теория должна обладать, в первую очередь, предсказательной силой. Например, если вы генетически модифицируете сельскохозяйственные культуры таким образом, что они сами будут производить пестициды, то вполне логично, что будут появляться устойчивые к ним насекомые. Однако существенно менее очевидно, что этот процесс может быть замедлен благодаря выращиванию обычных растений бок о бок с генномодифицированными. Основываясь на теории эволюции, соответствующее моделирование сделало , и он, похоже, .\r\nКак я упомянул ранее, я зайду к наименьшим квадратам через принцип максимального правдоподобия. Давайте проиллюстрируем на примере. Предположим, что нам интересны данные о росте пингвинов, но мы можем измерить лишь несколько этих прекрасных птиц. Вполне логично ввести в задачу модель распределения роста — чаще всего она нормальная. Нормальное распределение характеризуется двумя параметрами — средним значением и среднеквадратичным отклонением. Для каждого фиксированного значения параметров мы можем посчитать вероятность того, что будут сгенерированы именно те измерения, что мы произвели. Дальше, варьируя параметры, найдём те, что максимизируют вероятность.\r\nТаким образом, для работы с максимальным правдоподобием нам нужно оперировать в понятиях теории вероятностей. Чуть ниже мы «на пальцах» определим понятие вероятности и правдоподобия, но сначала я хотел бы заострить внимание на другом аспекте. Я на удивление редко вижу людей, которые задумываются над словом «теория» в словосочетании «теория вероятностей».\r\nПо поводу того, каковы истоки, значения и область применимости вероятностных оценок, уже не первую сотню лет идут яростные споры. Например,  заявил, что вероятность есть не что иное, как субъективный анализ вероятности того, что что-то произойдёт, и что эта вероятность не существует вне ума. Это готовность человека делать ставки на что-то происходящее. Это мнение прямо противоположно взгляду  на вероятность конкретного результата события, в котором предполагается, что одно и то же событие может повторяться многократно, а «вероятность» конкретного результата связана с частотой выпадения конкретного результата во время повторных испытаний. Помимо субъективистов и фреквентистов есть ещё и объективисты, утверждающие, что вероятности — это реальные аспекты универсума, а не просто описания степени уверенности наблюдателя.\r\nКак бы то ни было, но все три научные школы на практике используют один и тот же аппарат, основанный на аксиомах Колмогорова. Давайте приведём косвенный аргумент, с субъективистской точки зрения, в пользу теории вероятностей, построенной на аксиомах Колмогорова. Приведём сами аксиомы чуть позже, а для начала предположим, что у нас есть букмекер, который принимает ставки на следующий чемпионат мира по футболу. Пусть у нас будут два события: a = чемпионом станет команда Уругвая, b = чемпионом станет команда Германии. Букмекер оценивает шансы команды Уругвая победить в 40%, шансы команды Германии в 30%. Очевидно, что и Германия, и Уругвай победить одновременно не могут, поэтому шанс a∧b нулевой. Ну и заодно букмекер считает, что вероятность того, что победит либо Уругвай, либо Германия (а не Аргентина или Австралия) составляет 80%. Давайте это запишем в следующем виде:\r\nЕсли букмекер утверждает, что его степень уверенности в событии  равняется 0.4, то есть,  = 0.4, то игрок может выбрать, будет ли он делать ставку за или против высказывания , ставя суммы, которые совместимы со степенью уверенности букмекера. Это значит, что игрок может сделать ставку на то, что событие  произойдёт, поставив четыре рубля против шести рублей букмекера. Или же игрок может поставить шесть рублей вместо четырёх рублей букмекера на то, что событие  не произойдёт. \r\nЕсли степень уверенности букмекера неточно отражает состояние мира, то можно рассчитывать на то, что в долговременной перспективе он будет проигрывать деньги игрокам, чьи убеждения более точны. Более того, в данном конкретном примере у игрока есть стратегия, при которой букмекер  теряет деньги. Давайте её проиллюстрируем:\r\nИгрок делает три ставки, и какой бы ни был исход чемпионата, он всегда в выигрыше. Обратите внимание, что в рассмотрение суммы выигрыша в принципе не входит то, являются ли Уругвай или Германия фаворитами чемпионата, проигрыш букмекера обеспечен! К этой ситуации привело то, что букмекер не руководствовался азами теории вероятностей, нарушив третью аксиому Колмогорова, давайте приведём их все три:\r\nВ текстовом виде они выглядят так:\r\nВ 1931 году де Финетти  очень сильное утверждение:\r\nАксиомы вероятностей могут рассматриваться как ограничивающее множество вероятностных убеждений, которых может придерживаться некоторый агент. Обратите внимание, что из следования букмекера аксиомам Колмогорова не вытекает то, что он будет выигрывать (оставим в стороне вопросы комиссионных), но если им не следовать, то он будет гарантированно проигрывать. Отметим, что в пользу применения вероятностей были выдвинуты и другие аргументы; но именно  успех систем формирования рассуждений, основанных на теории вероятностей, оказался привлекательным стимулом, вызвавшим пересмотр многих взглядов.\r\nИтак, мы чуть-чуть приоткрыли завесу того,  теорвер может иметь смысл, но какими именно объектами он манипулирует? Весь теорвер построен лишь на трёх аксиомах; во всех трёх участвует некая магическая функция . Более того, глядя на эти аксиомы, мне это очень напоминает функцию площади фигуры. Давайте попробуем посмотреть, работает ли площадь для определения вероятности. \r\nОпределим слово «событие» как «подмножество единичного квадрата». Определим слово «вероятность события» как «площадь соответствующего подмножества». Грубо говоря, у нас есть большая картонная мишень, и мы, закрыв глаза, в неё стреляем. Шансы того, что пуля попадёт в данное множество, прямо пропорциональны площади множества. Достоверное событие в данном случае — весь квадрат, а заведомо ложное, например, любая точка квадрата. Из нашего определения вероятности следует, что идеально попасть в точку невозможно (наша пуля — это материальная точка). Я очень люблю картинки, и рисую их много, и теорвер не является исключением! Давайте проиллюстрируем все три аксиомы:\r\nИтак, первая аксиома выполнена: площадь неотрицательна, и не может превысить единицы. Достоверное событие — это весь квадрат, а заведомо ложное — любое множество нулевой площади. И с дизъюнкицей работает отлично!\r\nДавайте рассмотрим простейший пример с подбрасыванием монеты, он же . Проводится  опытов, в каждом из которых может произойти одно из двух событий («успех» или «неудача»), одно с вероятностью , второе с вероятностью . Наша задача состоит в том, чтобы найти вероятность получения ровно  успехов в этих  опытах. Эту вероятность нам даёт формула Бернулли:\r\nВозьмём обычную монету (), подбрасываем её десять раз (), и считаем, сколько раз выпадает решка:\r\nВот так выглядит график плотности вероятности:\r\nТаким образом, если мы зафиксировали вероятность наступления «успеха» (0.5), и также зафиксировали количество экспериментов (10), то возможное количество «успехов» может быть любым целым числом между 0 и 10, однако эти исходы не являются равновероятными. Вполне очевидно, что получить пять «успехов» гораздо вероятнее, нежели ни одного. Например, вероятность насчитать семь решек составляет примерно 12%.\r\nА теперь давайте посмотрим на эту же задачу с другой стороны. У нас есть реальная монетка, но её распределение априорной вероятности «успех»/«неудача» мы не знаем. Однако мы можем её подкинуть десять раз и посчитать количество «успехов». Например, у нас выпало семь решек. Как нам это поможет оценить ?\r\nМы можем попробовать зафиксировать в формуле Бернулли =10 и =7, оставив  свободным параметром:\r\nТогда формула Бернулли может быть интерпретирована как  оцениваемого параметра, (в данном случае ). Я даже буковку сменил у функции, теперь это  (от англ. likehood). То есть, правдоподобие — это вероятность сгенерировать данные наблюдения (7 решек из 10 опытов) для заданного значения параметра(-ов).\r\nНапример, правдоподобие сбалансированной монеты (=0.5) при условии выпадения семи решек из десяти бросков примерно равняется 12%. Можно построить график функции :\r\nИтак, мы ищем такое значение параметров, которое максимизирует правдоподобие получения тех наблюдений, что у нас есть. В данном конкретном случае у нас функция одной переменной, мы ищем её максимум. Для того, чтобы было проще искать, я буду искать максимум не , а . Логарифм — функция строго монотонная, так что максимизация одного и другого — это строго одно и то же. А логарифм нам разбивает произведение на сумму, которую сильно удобнее дифференцировать. Итак, мы ищем максимум вот этой функции:\r\nДля этого приравняем нулю её производную:\r\nПроизводная log x = 1/x, получаем:\r\nТо есть, максимум правдоподобия (примерно 27%) достигается в точке\r\nНа всякий случай посчитаем вторую производную:\r\nВ точке p=0.7 она отрицательна, так что эта точка действительно является максимумом функции L.\r\nА вот так выглядит плотность вероятности для схемы Бернулли с  = 0.7:\r\nДавайте представим, что у нас есть некая постоянная физическая величина, которую мы хотим измерить, будь то длину линейкой или напряжение вольтметром. Любое измерение даёт  этой величины, но не саму величину. Методы, которые я тут описываю, разработаны Гауссом в конце 18го века, когда он измерял орбиты небесных тел.\r\nНапример, если мы измерим напряжение на батарейке N раз, то получим N разных измерений. Какое из них брать? Все! Итак, пусть у нас будет N величин Uj:\r\nПредположим, что каждое измерение Uj равно идеальной величине, плюс гауссов шум, который характеризуется двумя параметрами — положение гауссова колокола и его «ширина». Вот так выглядит плотность вероятности:\r\nТо есть, имея N заданных величин Uj, наша задача найти такой параметр, U который максимизирует значение правдоподобия. Правдоподобие (я сразу беру от него логарифм) можно записать следующим образом:\r\nНу а дальше всё строго как раньше, приравняем нулю частные производные по параметрам, которые мы ищем:\r\nПолучим, что наиболее вероятная оценка неизвестной величины U может быть найдена как среднее от всех измерений:\r\nНу а наиболее вероятный параметр сигма это обычное среднеквадратичное отклонение:\r\nСтоило ли заморачиваться, чтобы получить в ответе простое среднее от всех измерений? На мой вкус, стоило. Кстати, усреднение многократных измерений постоянной величины с целью увеличения точности измерений — это вполне стандартная практика. Например, . К слову сказать, для этого гауссовости шума не нужно, достаточно того, что шум несмещённый.\r\nПродолжаем разговор, давайте возьмём тот же самый пример, но чуть его усложним. Мы хотим измерить сопротивление некоего резистора. При помощи лабораторного блока питания мы умеем пропустить через него некоторое эталонное количество ампер, и измерить напряжение, которое для этого понадобится. То есть, у нас на вход нашего оценщика сопротивления будет N пар чисел (Ij, Uj).\r\nНарисуем эти точки на графике; закон Ома нам говорит о том, что мы ищем наклон синей прямой.\r\nЗапишем выражение для правдоподобия параметра R:\r\nИ опять приравняем нулю соответствующую частную производную:\r\nТогда наиболее правдоподобное сопротивление R может быть найдено по следующей формуле:\r\nЭтот результат уже несколько менее очевидный, нежели простое среднее всех измерений. Обратите внимание, что если мы сделаем сто измерений в районе одного ампера, и одно измерение в районе килоампера, то предыдущие сто измерений практически не повлияют на результат. Давайте запомним этот факт, он нам пригодится в следующей статье.\r\nНаверняка вы уже обратили внимание, что в последних двух примерах максимизация логарифма правдоподобия эквивалентна минимизации суммы квадратов ошибки оценивания. Давайте рассмотрим ещё один пример. Возьмём калибровку безмена при помощи эталонных грузов. Пусть у нас есть N эталонных грузов массой xj, повесим их на безмен и измерим длину пружины, получим N длин пружины yj:\r\nЗакон Гука нам говорит, что растяжение пружины линейно зависит от приложенной силы, а в эту силу у нас входит вес грузов и вес самой пружины. Пусть жёсткость пружины — это параметр , ну а растяжение пружины под собственным весом — это параметр b. Тогда мы можем вот таким образом записать выражение правдоподобия наших измерений (по-прежнему под гипотезой гауссового шума измерений):\r\nМаксимизация правдоподобия L эквивалентна минимизации суммы квадратов ошибок оценивания, то есть, мы можем искать минимум функции S, определённой следующим образом:\r\nИными словами, мы ищем такую прямую, которая минимизирует сумму квадратов длин зелёных отрезков:\r\nНу а дальше никаких сюрпризов, приравниваем к нулю частные производные:\r\nПолучаем систему из двух линейных уравнений с двумя неизвестными:\r\nВспоминаем седьмой класс школы и выписываем решение:\r\nМетоды наименьших квадратов являются частным случаем максимизации правдоподобия для тех случаев, когда плотность вероятности является гауссовой. В случае же когда плотность (совсем) не гауссова, МНК дают оценку, отличающуюся от оценки MLE (maximum likehood estimation). Кстати, в своё время Гаусс выдвигал гипотезу, что распределение не играет роли, важна только независимость испытаний. \r\nКак видно из этой статьи, чем дальше в лес, тем более громоздкими становятся аналитические решения этой проблемы. Ну да мы не в восемнадцатом веке, у нас есть компьютеры! В следующий раз мы увидим геометрический и, затем, программистский подход к проблеме МНК, оставайтесь на линии.", "url": "https://habr.com/ru/post/428768/"},
{"title": "C++: сеанс спонтанной археологии и почему не стоит использовать вариативные функции в стиле C", "article_text": "Началось все, как водится, с ошибки. Я первый раз работал с  и делал в C++ части обертку над функцией, создающей Java объект. Эта функция —  — вариативна, т.е. помимо указателя на среду , указателя на тип создаваемого объекта и идентификатора вызываемого метода (в данном случае конструктора), она принимает произвольное число других аргументов. Что логично, т.к. эти другие аргументы передаются вызываемому методу на стороне Java, а методы могут быть разные, с разным числом аргументов любых типов.\r\nСоответственно и свою обертку я тоже сделал вариативной. Для передачи произвольного числа аргументов в  использовал , потому что по-другому в данном случае никак. Да, так и отправил  в . И уронил JVM банальным segmentation fault.\r\nЗа 2 часа я успел перепробовать несколько версий JVM, от 8-ой до 11-ой, потому что: во-первых это мой первый опыт с , и в этом вопросе я StackOverflow доверял больше, чем себе, а во-вторых кто-то на StackOverflow посоветовал в таком случае использовать не OpenJDK, а OracleJDK, и не 8, а 10. И лишь потом я наконец заметил, что помимо вариативной  есть , которая произвольное число аргументов принимает через .\r\nЧто мне больше всего не понравилось в этой истории, так это то, что я не сразу заметил разницу между эллипсисом (многоточием) и . А заметив, не смог объяснить себе, в чем принципиальное отличие. Значит, надо разобраться и с эллипсисом, и с , и (поскольку речь все-таки о C++) с вариативными шаблонами.\r\nСтандарт C++ описывает только отличия своих требований от требований Стандарта С. О самих отличиях позже, а пока кратко перескажу, что говорит Стандарт С (начиная с C89).\r\nВ C не так уж много типов. Почему  заявлен в Стандарте, но ничего не сказано о его внутреннем устройстве? \r\nЗачем нужен эллипсис, если произвольное число аргументов в функцию можно передать через ? Это сейчас можно было бы сказать: «в качестве синтаксического сахара», но 40 лет назад, я уверен, было не до сахара.\r\nФилип Джеймс Плаугер () в книге «Стандартная библиотека Си» () — 1992 год — рассказывает, что изначально C создавался исключительно для компьютеров PDP-11. А там перебрать все аргументы функции можно было с помощью простой арифметики указателей. Проблема появилась с ростом популярности C и переноса компилятора на другие архитектуры. В первом издании «Языка программирования Си» () Брайана Кернигана () и Денниса Ритчи () — 1978 год — прямо сказано:  В этой книге описывается , но еще нет , и не упоминаются тип и макросы . Они появляются во втором издании «Языка программирования Си» (1988 год), и это — заслуга комитета по разработке первого Стандарта Си (C89, он же ANSI C). Комитет добавил в Стандарт заголовок , взяв за основу , созданный Эндрю Кёнигом () с целью повысить переносимость ОС UNIX. Макросы  было решено оставить макросами, чтобы существующим компиляторам было проще поддержать новый Стандарт.\r\nТеперь, с появлением С89 и семейства , стало возможным создавать переносимые вариативные функции. И хотя внутреннее устройство этого семейства по-прежнему никак не описывается, и никаких требований к нему не предъявляется, но уже понятно, почему.\r\nИз чистого любопытства можно найти примеры реализации . Например, в той же «Стандартной библиотеке Си» приводится пример для :\r\nГораздо более новый  использует такой тип для :\r\nВ целом можно сказать, что тип и макросы  предоставляют стандартный интерфейс обхода аргументов вариативной функции, а их реализация по историческим причинам зависит от компилятора, целевых платформы и архитектуры. Причем эллипсис (т.е. вариативные функции вообще) появился в C раньше, чем  (т.е. заголовок ). И  создавался не для замены эллипсиса, а для возможности разработчикам писать свои переносимые вариативные функции.\r\nС++ во многом сохраняет обратную совместимость с C, поэтому все вышесказанное относится и к нему. Но есть и свои особенности.\r\nРазработкой Стандарта C++ занималась и занимается рабочая группа . За основу еще в 1989 году был взял только что созданный Стандарт С89, который постепенно менялся, чтобы описывать собственно C++. В 1995 году поступило предложение  от Джона Микко (), в котором автор предлагал изменить ограничения для макросов :Последний пункт я даже переводить не стал, чтобы поделиться своей болью. Во-первых, «» в Стандарте C++ осталось . И во-вторых, я долго ломал голову над смыслом этой фразы, сравнивал со Стандартом С, где все понятно. Только после прочтения N0695 я наконец понял: тут имеется в виду то же самое.\r\nТем не менее, все 3 изменения были приняты . Еще в C++ исчезло требование вариативной функции иметь хотя бы один именованный параметр (в таком случае нельзя получить доступ и к остальным, но об этом позже), и список допустимых типов неименованных аргументов дополнился указателями на члены класса и  типами.\r\nСтандарт C++03 не принес вариативным функциям никаких изменений. С++11 стал конвертировать неименованный аргумент типа  в  и разрешил компиляторам на свое усмотрение поддерживать типы с нетривиальными конструкторами и деструкторами . C++14 разрешил использовать в качестве последнего именованного параметра функции и массивы , а C++17 запретил — раскрытия пакета параметров () и захваченные лямбдой переменные .\r\nВ итоге C++ добавил вариативным функциям своих подводных камней. Одна только неуточняемая () поддержка типов с нетривиальными конструкторами/деструкторами чего стоит. Ниже я постараюсь свести все неочевидные особенности вариативных функций в один список и дополнить его конкретными примерами.\r\nС одной стороны все просто: сопоставление с эллипсисом проигрывает сопоставлению с обычным именованным аргументом, даже в случае стандартного или определенного пользователем приведения типа.\r\nНо это работает только до тех пор, пока вызов  без аргументов не надо рассматривать отдельно.\r\nВсе по Стандарту: нет аргументов — нет сопоставления с эллипсисом, и при разрешении перегрузки вариативная функция становится ничем не хуже обычной.\r\nНу хорошо, вариативные функции местами не очень очевидно себя ведут и в контексте C++ легко могут оказаться плохо переносимыми. В Интернете есть множество советов вида «Не создавайте и не используйте вариативные С функции», но из Стандарта C++ их поддержку убирать не собираются. Значит, есть какая-то польза от этих функций? Ну есть.\r\nИдея вариативных шаблонов была предложена Дугласом Грегором (), Яакко Ярви () и Гэри Пауэллом () еще в 2004 году, т.е. за 7 лет до принятия стандарта C++11, в котором эти вариативные шаблоны и были официально поддержаны. В Стандарт вошла третья ревизия их предложения за номером .\r\nС самого начала вариативные шаблоны создавались, чтобы у программистов была возможность создавать типобезопасные (и переносимые!) функции от произвольного числа аргументов. Другая цель — упростить поддержку шаблонов классов с переменным числом параметров, но сейчас речь идет только о вариативных функциях.\r\nВариативные шаблоны принесли в C++ три новых понятия : \r\nПолный список того, где и как можно раскрывать пакеты параметров, приводится в самом Стандарте . А в контексте обсуждения вариативных функций достаточно сказать, что:\r\nПри раскрытии пакета явный эллипсис необходим, чтобы поддержать различные шаблоны () раскрытия и избежать при этом неоднозначности. \r\nКак я уже упоминал, вариативные шаблоны создавались в том числе и как непосредственная замена вариативным функциям C. Сами авторы этих шаблонов предложили свою, очень простую, но типобезопасную версию  – одной из первых вариативных функций в C.\r\nПодозреваю, тогда и появился этот шаблон перебора вариативных аргументов — через рекурсивный вызов перегруженных функций. Но мне все-таки больше нравится вариант без рекурсии.\r\nПри разрешении и эти вариативные функции рассматриваются после прочих — как шаблонные и как наименее специализированные. Но нет проблем в случае вызова без аргументов.\r\nПри разрешении перегрузки вариативная шаблонная функция может обойти только вариативную C функцию (хотя зачем их смешивать?). Кроме — конечно же! — вызова без аргументов.\r\nЕсть сопоставление с эллипсисом — соответствующая функция проигрывает, нет сопоставления с эллипсисом — и шаблонная функция уступает нешаблонной.\r\nВ 2008 году Лоик Жоли () подал в комитет по стандартизации C++ своё предложение , в котором на практике показал, что вариативные шаблонные функции работают медленнее аналогичных функций, аргументом которых является список инициализации (). И хотя это противоречило теоретическим обоснованиям самого автора, Жоли предложил реализовать ,  и  именно с помощью списков инициализации, а не вариативных шаблонов.\r\nНо уже в 2009 году появилось опровержение. В тестах Жоли была обнаружена «серьезная ошибка» (кажется, даже им самим). Новые тесты (см.  и ) показали, что вариативные шаблонные функции все-таки быстрее, и иногда значительно. Что не удивительно, т.к. список инициализации делает копии своих элементов, а для вариативных шаблонов можно многое посчитать еще на этапе компиляции.\r\nТем не менее в C++11 и последующих стандартах ,  и  – это обычные шаблонные функции, произвольное число аргументов в которые передается через список инициализации.\r\nИтак, вариативные функции в стиле C:\r\nЕдинственное допустимое использование вариативных функций — взаимодействие с C API в C++ коде. Для всего остального, включая , есть вариативные шаблонные функции, которые:\r\nВариативные шаблонные функции могут быть более многословными по сравнению со своими аналогами в стиле C и иногда даже требовать своей перегруженной нешаблонной версии (рекурсивный обход аргументов). Их сложнее читать и писать. Но все это с лихвой окупается отсутствием перечисленных недостатков и наличием перечисленных же достоинств. \r\nНу и вывод получается простой: вариативные функции в C стиле остаются в C++ только из-за обратной совместимости, и они предлагают широкой выбор возможностей прострелить себе ногу. В современном C++ очень желательно не писать новые и по возможности не использовать уже существующие вариативные C функции. Вариативные же шаблонные функции принадлежат миру современного C++ и гораздо более безопасны. Используйте их.\r\nВ сети легко найти и скачать электронные версии упомянутых книг. Но я не уверен, что это будет легально, поэтому ссылок не даю.", "url": "https://habr.com/ru/post/430064/"},
{"title": "Стример из MiniDV-видеокамеры", "article_text": "Иногда может захотеться странного. Вот вроде бы лежит себе видеокамера стандарта MiniDV и лежит. Есть не просит. А что если взять и записать на её кассеты вовсе даже не видео, а, скажем, файлы. Запись-то всё равно цифровая. Пусть объём кассеты всего лишь около 13 ГБ (под данные получилось занять около 9.5 ГБ), пусть скорость чтения 3.5 МБ в секунду, но ведь получится простой домашний стример. Так сказать, “стример для бедных”. Почему бы не отправить на несколько кассет, скажем, какие-либо важные файлы. Просто так, на всякий случай. Попробуем!\r\nНа чём основана запись данных на MiniDV видеокамеру? Да просто можно вместо аудиоданных и части видеоданных подсунуть данные файлов — формат-то цифровой с отдельным сжатием каждого кадра по одинаковому алгоритму. Осталось дело за программой, которая это сможет сделать.\r\nПоискав по интернету, как использовать бытовую видеокамеру как стример, я нашёл на форумах и в статьях десятилетней давности упоминания нескольких программ. Для Windows, например, это были DVStreamer Pro и DVStreamer Lite. За первую лет десять назад авторы просили примерно 60$. Вторая бесплатная, но с массой ограничений (256 файлов не более 8 Мб каждый или один файл не более гигабайта). Плюс многочисленные жалобы на нестабильную работу обеих версий. Скачав со странички производителя данное ПО (версии Lite там почему-то больше нет – похоже, программа теперь одна), обнаружился ещё 30-дневный срок на, так сказать, пробу. И да, эта программа так же, как и десятилетие назад, нестабильно работает и запросто вылетает от перемены погоды на Марсе. Зато она умеет непосредственно управлять камерой и автоматически выполнять перемотку к требуемому файлу.\r\nНу что ж, а что же у нас доступно для Linux? Оказывается, кое-что доступно, а именно dvbackup-0.0.4. Эта программа способна переданный ей поток данных упаковать в RAW DV формат и передать для записи другой программе dvcontrol, входящей в комплект. Ну и в обратном порядке, он может так же извлечь файлы из RAW DV.\r\nК сожалению, завести dvcontrol мне не удалось – она стабильно не видела данных по ieee1394 от видеокамеры. А что если разобраться с dvbackup и самому сформировать RAW DV файл со своими собственными прибамбасами? Например, вместо статичного логотипа, показываемого видеокамерой во время воспроизведения видео от dvbackup, сделать свой логотип, добавив полоску прогресса и имя записываемого файла, а также добавить поддержку папок.\r\nОсталось решить, чем бы такой RAW файл считать и записать на камеру. А впрочем, всё это давно умеет видеоредактор Kino. Вот его-то мы и будем использовать для работы с видеокамерой. Сказано – сделано. Разобрав dvbackup на части, и довольно быстро сформировав файл данных, я убедился, что Kino может записать этот файл на камеру (при этом ругаясь на невозможную частоту). А вот считать не может. Нет, говорит, видеопотока. Камера меж тем этот самый видеопоток на экранчике прекрасно отображает. \r\nВот тут-то и пришлось очень внимательно пройтись по формату DV, постепенно заменяя части из dvbackup (часто, с комментариями автора про “магические числа” и неизвестные назначения) на корректные и соответствующие описанию DV-формата. Ряд данных пришлось расшифровывать прямо с реального потока от видеокамеры, так как в моём описании DV-формата такие идентификаторы блоков не описаны. В результате, после очередной доработки напильником, выяснилось, что Kino полученный видеофайл вполне удовлетворяет и он способен производить и запись и чтение данного файла без проблем. Правда, судя по всему, причина изначального неприятия была в том, что я отключил аудио, когда создавал RAW DV файл первый раз. Только ли в этом было дело, я сейчас даже проверять не стал\r\nИтак, в результате экспериментов получилась вот такая вот программа для Windows:\r\nОна умеет собирать файлы в RAW DV видеофайл и извлекать файлы из такого видеофайла. Так же можно очистить отчёт и прервать обработку, если вы передумали. В начале видеоданных и перед каждым файлом можно задать префикс — это такой пустой блок, облегчающий позиционирование на начало файла (между файлами (локальный префикс) можно и не делать вовсе, а вот в самом начале (глобальный префикс) стоит чаще всего задать — это облегчит поиск начала блока файлов). Всё это настраивается в диалогах программы. Так же есть режим проверки данных в DV-видеофайле. В этом режиме файлы извлекаются, но не сохраняются.\r\nПолученный видеофайл вы можете записать на ленту любым редактором, который позволяет записывать файлы RAW DV. В одном из вариантов программы я сделал сборку RAW DV внутрь AVI файла, но оказалось, что использованные мной видеоредакторы при экспорте теряют данные, помещённые в DV-формат. Поэтому от этого варианта пришлось отказаться.\r\nЗапись данных на видеокамеру в Kino выглядит вот так:\r\nА так выглядит процесс записи на видеокамере:\r\nНасколько надёжен такой стример? Я записал на кассету часть фотоальбома 9.5 ГБ как набор файлов фотографий в формате jpg примерно по 1-3 МБ. При считывании сбой был зафиксирован у трёх файлов.\r\nКонечно, хотелось бы управлять камерой напрямую, но я пока ещё не нашёл внятного описания работы с камерой по ieee1394. Единственная книжка, где хоть что-то было написано – это “Программирование аппаратных средств Windows”, но указанный там пример, во-первых, содержит ошибки, а во-вторых, просто отыскал мне устройство платы ieee1394, установленную в компьютере, а вовсе не видеокамеру. Попытка отправить и принять данные с платы не увенчалась успехом. Поэтому, если кто-нибудь может рассказать о работе с камерой по ieee1394 с использованием WinAPI и на Си/Си++, то буду очень ему благодарен.", "url": "https://habr.com/ru/post/429762/"},
{"title": "Как мы перевели 10 миллионов строк кода C++ на стандарт C++14 (а потом и на C++17)", "article_text": "Некоторое время назад (осенью 2016), при разработке очередной версии технологической платформы 1С:Предприятие внутри команды разработки встал вопрос о поддержке нового стандарта  в нашем коде. Переход на новый стандарт, как мы предполагали, позволил бы нам писать многие вещи элегантней, проще и надежней, упрощал поддержку и сопровождение кода. И в переводе вроде бы нет ничего экстраординарного, если бы не масштабы кодовой базы и специфические особенности нашего кода.\r\nДля тех кто не знает, 1С:Предприятие – это среда для быстрой разработки кросс-платформенных бизнес-приложений и runtime для их выполнения в разных ОС и СУБД. В общих чертах в состав продукта входят:\r\nМы стараемся по максимуму писать один код для разных ОС — кодовая база сервера общая на 99%, клиента — примерно на 95%. Технологическая платформа 1С:Предприятие преимущественно написана на C++ и ниже приведены приблизительные характеристики кода:\r\nИ все это хозяйство надо было перевести на C++14. О том, как мы это делали и с чем столкнулись в процессе, мы сегодня и расскажем.\r\nВсе написанное ниже о медленной/быстрой работе, (не)большом потреблении памяти реализациями стандартных классов в различных библиотеках означает одно: это справедливо ДЛЯ НАС. Вполне возможно, для ваших задач стандартные реализации подойдут наилучшим образом. Мы же отталкивались от своих задач: брали типичные для наших клиентов данные, прогоняли на них типичные сценарии, смотрели на быстродействие, объем потребляемой памяти и т.п., и анализировали – устраивают ли нас и наших клиентов такие результаты или нет. И поступали в зависимости от.\r\nИзначально мы писали код платформы 1С:Предприятие 8 на Microsoft Visual Studio. Проект начался в начале 2000-х и у нас была версия только под Windows. Естественно, с тех пор код активно развивался, многие механизмы были полностью переписаны. Но код писался по стандарту 1998 года, и, например, правые угловые скобки у нас были разделены пробелами, чтобы успешно проходила компиляция, вот так:\r\nВ 2006 году, с выходом версии платформы 8.1, мы начали поддерживать Linux и перешли на стороннюю стандартную библиотеку . Одной из причин перехода была работа с широкими строками. В нашем коде мы повсеместно используем std::wstring, основанный на типе wchar_t. Его размер в Windows 2 байта, а в Linux по умолчанию 4 байта. Это приводило к несовместимости наших бинарных протоколов между клиентом и сервером, а также различных персистентных данных. Опциями gcc можно указать, чтобы размер wchar_t при компиляции был тоже 2 байта, но тогда об использовании стандартной библиотеки от компилятора можно позабыть, т.к. она использует glibc, а та в свою очередь скомпилирована под 4-байтный wchar_t. Другими причинами были более качественная реализация стандартных классов, поддержка хеш-таблиц и даже эмуляция семантики перемещения внутри контейнеров, которой мы активно пользовались. И еще одной причиной, как говорится last but not least, была производительность строк. У нас был свой класс для строк, т.к. у нас в силу специфики нашего софта строковые операции используются очень широко и для нас это критично. \r\nНаша строка основана на идеях оптимизации строк, высказанных ещё в начале 2000-х . Позднее, когда Александреску работал в Facebook, с его подачи в движке Facebook была использована строка, работающая на схожих принципах (см. библиотеку ).\r\nВ нашей строке использовались две основные технологии оптимизации:\r\nЧтобы ускорить компиляцию платформы, мы исключили из своего варианта STLPort реализацию stream (который мы не использовали), это дало нам ускорение компиляции примерно на 20%. Впоследствии нам пришлось ограниченно использовать . Boost активно использует stream, в частности, в своих сервисных API (например, для логирования), поэтому нам приходилось модифицировать его, исключая из него использование stream. Это, в свою очередь, затрудняло нам переход на новые версии Boost. \r\nПри переходе на стандарт C++14 мы рассматривали такие варианты: \r\nПервый вариант был отвергнут сразу из-за слишком большого объема работ.\r\nМы некоторое время думали над вторым вариантом; в качестве кандидата рассматривали , но он на тот момент не работал под Windows. Чтобы портировать libc++ на Windows, пришлось бы проделать немало работы — например, писать самим всё, что связано с потоками, синхронизацией потоков и атомарностью, поскольку в libc++ в этих областях использовалось .\r\nИ мы выбрали третий путь.\r\nИтак, нам предстояло заменить использование STLPort на библиотеки соответствующих компиляторов (Visual Studio 2015 для Windows, gcc 7 для Linux, clang 8 для macOS). \r\nК счастью, наш код писался в основном по гайдлайнам и не использовал всяческие хитрые трюки, так что миграция на новые библиотеки протекала сравнительно гладко, с помощью скриптов, заменяющих в исходных файлах имена типов, классов, неймспейсов и инклюдов. Миграция затронула 10 000 исходных файлов (из 14 000). wchar_t заменялся на char16_t; мы решили отказаться от использования wchar_t, т.к. char16_t на всех ОС занимает 2 байта и не портит совместимость кода между Windows и Linux.\r\nНе обошлось без небольших приключений. Например, в STLPort итератор можно было неявно скастить к указателю на элемент, и в некоторых местах нашего кода это использовалось. В новых библиотеках так делать было уже нельзя, и эти места приходилось анализировать и переписывать вручную. \r\nИтак, миграция кода закончена, код компилируется для всех ОС. Настало время тестов. \r\nТесты после перехода показали проседание производительности (местами до 20-30%) и увеличение потребляемой памяти (до 10-15%) по сравнению со старой версией кода. Это было, в частности, связано с неоптимальной работой стандартных строк. Поэтому строку нам опять пришлось использовать свою, слегка доработанную. \r\nТакже вскрылась интересная особенность реализации контейнеров во встраиваемых библиотеках: пустые (без элементов) std::map и std::set из встроенных библиотек аллоцируют память. А у нас в силу особенностей реализации в некоторых местах кода создается довольно много пустых контейнеров этого типа. Аллоцируют стандартные контейнеры памяти немного, для одного корневого элемента, но для нас это оказалось критичным – на ряде сценариев у нас ощутимо упала производительность и выросло потребление памяти (по сравнению с STLPort). Поэтому мы заменили в нашем коде эти два типа контейнеров из встроенных библиотек на их реализацию от Boost, где эти контейнеры не имели такой особенности, и это решило проблему с замедлением и повышенным потреблением памяти.\r\nКак часто бывает после масштабных изменений в больших проектах, первая итерация исходников работала не без проблем, и тут нам сильно пригодились, в частности, поддержка отладочных итераторов в Windows-реализации. Шаг за шагом мы двигались вперед, и к весне 2017 (версия 8.3.11 1С:Предприятия) миграция была завершена. \r\nПереход на стандарт С++14 занял у нас около 6 месяцев. БОльшую часть времени над проектом работал один (но очень высококвалифицированный) разработчик, а на финальной стадии подключились представители команд, ответственных за конкретные области — UI, кластер серверов, средства разработки и администрирования и т.д.\r\nПереход сильно упростил нам работу по миграции на новейшие версии стандарта. Так, версия 1С:Предприятие 8.3.14 (в разработке, релиз запланирован на начало следующего года) уже переведена на стандарт . \r\nПосле миграции у разработчиков появилось больше возможностей. Если раньше у нас была своя доработанная версия STL и один неймспейс std, то теперь у нас в неймспейсе std находятся стандартные классы из встроенных библиотек компилятора, в неймспейсе stdx – наши, оптимизированные для наших задач строки и контейнеры, в boost – свежая версия boost. И разработчик использует те классы, которые оптимально подходят для решения его задач. \r\nПомогает в разработке также и «родная» реализация конструкторов перемещения () для ряда классов. Если у класса есть конструктор перемещения и этот класс помещается в контейнер, то STL оптимизирует копирование элементов внутри контейнера (например, когда контейнер расширяется и надо изменить capacity и реаллоцировать память). \r\nСамое, пожалуй, неприятное (но не критичное) последствие миграции — мы столкнулись с увеличением объема , и полный результат билда со всеми промежуточными файлами стал занимать по 60 – 70 Гб. Такое поведение связано с особенностями современных стандартных библиотек, ставших менее критично относиться к объему генерируемых служебных файлов. Это не влияет на работу скомпилированного приложения, но доставляет ряд неудобств в разработке, в частности, увеличивает время компиляции. Повышаются также требования к свободному месту на диске на билдовых серверах и на машинах разработчиков. Наши разработчики параллельно работают над несколькими версиями платформы, и сотни гигабайт промежуточных файлов иногда создают трудности в работе. Проблема неприятная, но не критичная, ее решение мы пока отложили. Как один из вариантов ее решения рассматриваем технику  (ее, в частности, использует Google при разработке браузера Chrome).", "url": "https://habr.com/ru/company/1c/blog/429678/"},
{"title": "Learn OpenGL. Урок 6.4 – IBL. Зеркальная облученность", "article_text": "\r\nВ  мы подготовили нашу модель PBR для работы вместе с методом IBL – для этого нам потребовалось заранее подготовить карту облученности, которая описывает диффузную часть непрямого освещения. В этом уроке мы обратим внимание на вторую часть выражения отражающей способности – зеркальную:\r\nМожно заметить, что зеркальная составляющая Кука-Торренса (подвыражение с множителем ) не является постоянной и зависит от направления падающего света,  от направления наблюдения. Решение этого интеграла для всех возможных направлений падения света вкупе со всеми возможными направлениями наблюдения в реальном времени просто неосуществимо. Поэтому исследователи Epic Games предложили подход, названый (), позволяющий заранее частично подготовить данные для зеркальной компоненты, при соблюдении некоторых условий.\r\nВ этом подходе зеркальная компонента выражения отражающей способности разделяется на две части, которые можно подвергнуть предварительной свертке по отдельности, а затем объединить в PBR шейдере, для использования в качестве источника непрямого зеркального излучения. Также как и в случае с формированием карты облученности, процесс свертки принимает HDR карту окружения на своем входе. \r\nДля понимания метода приближения раздельной суммой взглянем еще раз на выражение отражающей способности, оставив в нем только подвыражение для зеркальной компоненты (диффузная часть была рассмотрена отдельно в ):\r\nКак и в случае с подготовкой карты облученности данный интеграл нет никакой возможности решать в реальном времени. Потому желательно аналогичным образом предрассчитать карту для зеркальной составляющей выражения отражающей способности, а в основном цикле рендера обойтись простой выборкой из этой карты на основе нормали к поверхности. Однако, все не так просто: карта облученности получалась относительно легко за счет того, что интеграл зависел лишь от , а постоянное подвыражение для Ламбертовской диффузной составляющей можно было вынести за знак интеграла. В данном же случае интеграл зависит не только от , что легко понять из формулы BRDF:\r\nВыражение под интегралом зависит также и от  – по двум векторам направления осуществить выборку из предварительно подготовленной кубической карты практически невозможно. Положение точки  в данном случае можно не учитывать – почему это так было рассмотрено в предыдущем уроке. Предварительный расчет интеграла для всех возможных сочетаний  и  невозможен в задачах реального времени.\r\nМетод раздельной суммы от Epic Games решает эту проблему путем разбиения задачи предварительного расчета на две независимые части, результаты которых можно объединить позже для получения итогового предрассчитанного значения. Метод раздельной суммы выделяет два интеграла из исходного выражения для зеркальной компоненты:\r\nРезультат расчета первой части обычно называется  (), и является картой окружения, подвергнутой процессу свертки, заданному этим выражением. Все это схоже с процессом получения карты облученности, однако в этом случае свертка ведется с учетом значения шероховатости. Высокие значения шероховатости приводят к использованию более разрозненных векторов выборки в процессе свертки, что порождает более размытые результаты. Результат свертки для каждого следующего выбранного уровня шероховатости сохраняется в очередном мип-уровне подготавливаемой карты окружения. Например, карта окружения, подвергнутая свертке для пяти различных уровней шероховатости, содержит пять мип-уровней и выглядит примерно так:\r\nВектора выборки и их величина разброса определяются на основе функции нормального распределения () модели BRDF Кука-Торренса. Данная функция принимает вектор нормали и направление наблюдения как входные параметры. Поскольку направление наблюдения заранее неизвестно в момент предварительного расчета, то разработчикам Epic Games пришлось сделать еще одно допущение: направление взгляда (а значит, и направление зеркального отражения) всегда идентично выходному направлению выборки . В виде кода:\r\nВ таких условиях направление взгляда не потребуется в процессе свертки карты окружения, что делает расчет выполнимым в реальном времени. Но с другой стороны мы лишаемся характерного искажения зеркальных отражений при наблюдении под острым углом к отражающей поверхности, что видно на изображении ниже (из публикации ). В общем и целом, такой компромисс считается допустимым.\r\nВторая часть выражения раздельной суммы содержит BRDF исходного выражения для зеркальной компоненты. Если допустить, что входящая энергетическая яркость спектрально представлена белым светом для всех направлений (т.е., ), то возможно предварительно рассчитать значение для BRDF при следующих входных параметрах: шероховатость материала и угол меду нормалью  и направлением света  (или же ). Подход Epic Games предполагает хранение результатов вычисления BRDF для каждого сочетания шероховатости и значения угла между нормалью и направлением света в виде двухмерной текстуры, известной как (), которая позже используется как справочная таблица (, ). Данная справочная текстура использует красный и зеленый выходные каналы для хранения масштаба и смещения для расчета коэффициента Френеля поверхности, что в итоге позволяет решить и вторую часть выражения раздельной суммы:\r\nДанная вспомогательная текстура создается следующим образом: текстурные координаты по горизонтали (в пределах от [0., 1.]) рассматриваются как значения входного параметра  функции BRDF; текстурные координаты по вертикали рассматриваются как входные значения шероховатости. \r\nВ итоге, имея такую карту комплексирования и предварительно обработанную карту окружения, можно скомбинировать выборки из них для получения итогового значения интегрального выражения зеркальной компоненты:\r\nДанный обзор метода раздельной суммы от Epic Games должен помочь составить впечатление о процессе приближенного вычисления части выражения отражающей способности, отвечающей за зеркальную компоненту. Теперь же попробуем подготовить данные карты самостоятельно.\r\nПредварительная фильтрация карты окружения идет схожим образом с тем, что было сделано для получения карты облученности. Разница заключается лишь в том, что сейчас мы учитываем шероховатость и сохраняем результат для каждого уровня шероховатости в новом мип-уровне кубической карты.\r\nДля начала придется создать новую кубическую карту, которая будет содержать результат предварительной фильтрации. Для того, чтобы создать необходимое число мип-уровней мы попросту вызовем  – необходимый запас памяти будет выделен для текущей текстуры:\r\nОбратите внимание: поскольку выборка из будет вестись с учетом существования мип-уровней, то необходимо установить режим фильтра уменьшения в режим , чтобы включить трилинейную фильтрацию. Предварительно обработанные образы зеркальных отражений хранятся в отдельных гранях кубической карты с разрешением на базовом мип-уровне всего 128х128 пикселей. Для большинства материалов этого вполне хватает, однако, если в вашей сцене повышенное количество гладких, блестящих поверхностей (например, новенькая машина), вам может потребоваться увеличение этого разрешения.\r\nВ предыдущем уроке мы провели свертку карты окружения путем создания векторов выборки, которые равномерно распределены в полусфере , используя сферические координаты. Для получения облученности этот метод вполне эффективен, чего не скажешь о расчетах зеркальных отражений. Физика зеркальных бликов подсказывает нам, что направление зеркально отраженного света прилегает к вектору отражения  для поверхности с нормалью , даже если шероховатость не равна нулю:\r\nОбобщенная форма возможных исходящих направлений отражения называется (; «лепесток зеркальной диаграммы направленности» – пожалуй, слишком многословно, ). С ростом шероховатости лепесток увеличивается, расширяется. Также его форма меняется в зависимости от направления падения света. Таком образом, форма лепестка сильно зависит от свойств материала.\r\nВозвращаясь к модели микроповерхностей, можно себе представить форму зеркального лепестка как описывающую ориентацию отражения относительно медианного вектора микро-поверхностей, с учетом некоторого заданного направления падения света. Понимая, что большая часть лучей отраженного света лежит внутри зеркального лепестка, сориентированного на основе медианного вектора, имеет смысл создавать вектора выборки, сориентированные сходным образом. Иначе многие из них окажутся бесполезными. Такой подход называется ().\r\nДля полного понимания сути выборки по значимости придется сначала ознакомиться с таким математическим аппаратом, как метод интегрирования Монте-Карло. Данный метод основывается на сочетании статистики и теории вероятности и помогает провести численное решение некоторой статистической задачи на большой выборке без необходимости рассмотрения элемента этой выборки.\r\nНапример, вы хотите подсчитать средний рост населения страны. Для получения точного и достоверного результата пришлось бы измерить рост гражданина и усреднить результат. Однако, поскольку население большей части стран довольно велико данный подход практически нереализуем, поскольку требует слишком много ресурсов на исполнение.\r\nДругой подход заключается в создании меньшей подвыборки, наполненной истинно случайными (несмещенными) элементами исходной выборки. Далее вы также измеряете рост и усредняете результат для этой подвыборки. Можно взять хоть всего сотню людей и получить результат, пусть и не абсолютно точный, но все же достаточно близкий к реальной ситуации. Объяснение этому методу лежит в рассмотрении закона больших чисел. И суть его описывается таким образом: результат некоторого измерения в меньшей подвыборке размера , составленной из истинно случайных элементов исходного множества, будет приближен к контрольному результату измерения, проведенного на всем исходном множестве. Причем приблизительный результат стремится к истинному с ростом .\r\nИнтегрирование методом Монте-Карло является приложением закона больших чисел для решения интегралов. Вместо решения интеграла с учетом всего (возможно бесконечного) множества значений , мы используем  случайных точек выборки и усредняем результат. С ростом  приблизительный результат гарантированно будет приближаться к точному решению интеграла.\r\nДля решения интеграла получается значение подынтегральной функции для  случайных точек из выборки в пределах [a, b], результаты суммируются и делятся на общее число взятых точек для усреднения. Элемент  описывает (), которая показывает с какой вероятностью каждое выбранное значение встречается в исходной выборке. Например, данная функция для роста граждан выглядела бы примерно так:\r\nВидно, что при использовании случайных точек выборки у нас гораздо выше шанс встретить значение роста в 170см, чем кого-то с ростом 150см.\r\nЯсно, что при проведении интегрирования методом Монте-Карло некоторые точки выборки имеют больше шансов появиться в последовательности, нежели другие. Поэтому в любом выражении для оценки методом Монте-Карло мы делим или умножаем отобранную величину на вероятность её появления, используя функцию плотности вероятности. На данный момент при оценке интеграла мы создавали множество равномерно распределенных точек выборки: шанс получения любой из них был одинаков. Таким образом наша оценка была (), что означает, что при росте количества точек выборки наша оценка будет сходиться к точному решению интеграла.\r\nОднако, есть оценочные функции, являющиеся (), т.е. подразумевающими создание точек выборки не в истинно случайной манере, а с преобладанием некоторой величины или направления. Такие функции оценки позволяют оценке методом Монте-Карло сходиться к точному решению . С другой стороны, из-за смещенности функции оценки, решение может и не сойтись никогда. В общем случае это считается приемлемым компромиссом, особенно в задачах компьютерной графики, поскольку оценка очень близкая к аналитическому результату и не требуется, если визуально его эффект выглядит достаточно достоверно. Как мы скоро увидим выборка по значимости (использующая смещенную функцию оценки) позволяет создавать точки выборки, смещенные в сторону определенного направления, что учитывается с помощью умножения или деления каждого выбранного значения на соответствующее значение функции плотности вероятности.\r\nИнтегрирование Монте-Карло довольно часто встречается в задачах компьютерной графики, поскольку является достаточно интуитивным методом оценки значения непрерывных интегралов численным методом, который достаточно эффективен. Достаточно взять некоторую площадь или объем в которой ведется выборка (например, наша полусфера ), создать  случайных точек выборки, лежащих внутри, и провести взвешенное суммирование полученных значений.\r\nМетод Монте-Карло – весьма обширная тема для обсуждения и здесь мы более не будем углубляться в детали, однако остается еще одна важная деталь: существует отнюдь не один способ создания . По умолчанию, каждая точка выборки является полностью (псведо)случайной – чего мы и ожидаем. Но, используя определенные свойства квазислучайных последовательностей есть возможность создать наборы векторов, которые хоть и случайны, но обладают интересными свойствами. Например, при создании случайных выборок для процесса интегрировании можно использовать так называемые (), которые обеспечивают случайность созданных точек выборки, но в общем наборе они более равномерно :\r\nИспользование последовательностей низкого несоответствия для создания набора векторов выборки для процесса интеграции является (). Квази-методы Монте-Карло сходятся гораздо быстрее общего подхода, что весьма заманчивое свойство для приложений с высокими требованиями к производительности.\r\nИтак, мы знаем об общем и квази-методе Монте-Карло, но есть еще одна деталь, которая обеспечит еще бОльшую скорость сходимости: выборка по значимости. \r\nКак уже было отмечено в уроке, для зеркальных отражений направление отраженного света заключено в зеркальном лепестке, размер и форма которого зависит от шероховатости отражающей поверхности. Понимая, что любые (квази)случайные векторы выборки, оказавшиеся вне зеркального лепестка не окажут влияния на интегральное выражение зеркальной компоненты, т.е. бесполезны. Имеет смысл генерацию векторов выборки сфокусировать в области зеркального лепестка, используя смещенную функцию оценки для метода Монте-Карло.\r\nВ этом и заключается суть выборки по значимости: создание векторов выборки заключено в некоторой области, сориентированной вдоль медианного вектора микро-поверхностей, и форма которой определенна шероховатостью материала. Используя сочетание квази-метода Монте-Карло, последовательностей низкого несоответствия и смещения процесса создания векторов выборки за счет выборки по значимости, мы достигает очень высоких скоростей сходимости. Поскольку схождение к решению достаточно быстрое, то мы можем использовать меньшее количество векторов выборки при достижении все еще достаточно приемлемой оценки. Описанная комбинация методов, в принципе, позволяет графическим приложениям даже решать интеграл зеркальной компоненты в реальном времени, хотя предварительный расчет все еще остается значительно более выгодным подходом.\r\nВ этом уроке мы все же используем предварительный расчет зеркальной компоненты выражения отражающей способности для непрямого излучения. И использовать будем выборку по значимости с применением случайной последовательности низкого несоответствия и квази-метод Монте-Карло. Используемая последовательность известна как (), подробное описание которой дано . Данная последовательность, в свою очередь, основана на (), которая использует специальное преобразование двоичной записи десятичной дроби относительно десятичной точки.\r\nИспользуя хитрые трюки побитовой арифметики можно довольно эффективным образом задать последовательность ван дер Корпута прямо в шейдере и на её основе создавать i-ый элемент последовательности Хаммерсли из выборки в  элементов:\r\nФункция возвращает i-ый элемент последовательности низкого несоответствия из множества выборок размера .\r\nВместо равномерного или случайного (по Монте-Карло) распределения генерируемых векторов выборки внутри полусферы , фигурирующей в решаемом нами интеграле, мы попробуем создавать вектора так, чтобы они тяготели к основному направлению отражения света, характеризуемого медианным вектором микроповерхностей и зависящего от шероховатости поверхности. Сам процесс выборки будет схож с ранее рассмотренным: откроем цикл с достаточно большим количеством итераций, создадим элемент последовательности низкого несоответствия, на его основе создадим вектор выборки в касательном пространстве, перенесем этот вектор в мировые координаты и используем для выборки значения энергетической яркости сцены. В принципе, изменения касаются лишь того, что теперь применяется элемент последовательности низкого несоответствия для задания нового вектора выборки:\r\nКроме того, для полного формирования вектора выборки потребуется каким-то образом его сориентировать в направлении зеркального лепестка, соответствующего заданному уровню шероховатости. Можно взять NDF (функция нормального распределения) из , посвящённого теории и скомбинировать с GGX NDF для метода задания вектора выборки в сфере за авторством Epic Games:\r\nВ результате получится вектор выборки, приблизительно сориентированный вдоль медианного вектора микроповерхностей, для заданной шероховатости и элемента последовательности низкого несоответствия . Обратите внимание, что Epic Games использует квадрат величины шероховатости для большего визуального качества, что основано на оригинальной работе Disney о методе PBR.\r\nЗакончив реализацию последовательности Хаммерсли и кода генерации вектора выборки, мы можем привести код шейдера предварительной фильтрации и свертки:\r\nМы осуществляем предварительную фильтрацию карты окружения на основе некоторой заданной шероховатости, уровень которой изменяется для каждого мип-уровня результирующей кубической карты (от 0.0 до 1.0), а результат фильтра сохраняем в переменной . Далее переменная делится на суммарный вес для всей выборки, причем сэмплы с меньшим вкладом в итоговый результат (имеющие меньшее значение ) также меньше увеличивают и итоговый вес.\r\nОстается написать код, непосредственно поручающий OpenGL фильтрацию карты окружения с различными уровнями шероховатости и последующим сохранением результатов в череде мип-уровней целевой кубической карты. Здесь как нельзя кстати пригодится уже подготовленный код из уроке об расчете карты :\r\nПроцесс похож на свертку карты облученности, однако в этот раз следует на каждом шаге уточнить размер кадрового буфера, уменьшая его в два раза для соответствия мип-уровням. Также мип-уровень, в который будет вестись рендер в данный момент необходимо указать в качестве параметра функции .\r\nРезультатом выполнения данного кода должна стать кубическая карта, содержащая все более размытые изображения отражений на каждом последующем мип-уровне. Можно использовать такую кубическую карту как источник данных для скайбокса и взять выборку из любого мип-уровня далее нулевого:\r\nРезультатом такого действия будет следующая картина:\r\nВыглядит как сильно размытая исходная карта окружения. Если у вас результат схож, то, верней всего, процесс предварительной фильтрации HDR карты окружения выполнен верно. Попробуйте поэкспериментировать с выборкой из разных мип-уровней и понаблюдать постепенный рост размытости с каждым следующим уровнем.\r\nДля большинства задач описанный подход работает достаточно хорошо, но рано или поздно придется встретиться с различными артефактами, которые порождает процесс предварительной фильтрации. Здесь перечислены самые распространенные и методы борьбы с ними.\r\nВыборка значений из обработанной предварительным фильтром кубической карты для поверхностей с высокой шероховатостью приводит к считыванию данных из мип-уровня где-то ближе к концу их цепочки. При выборке из кубических карты OpenGL по умолчанию не осуществляет линейной интерполяции между гранями кубической карты. Поскольку высокие мип-уровни обладают меньшим разрешением, а карта окружения была подвергнута свертке с учетом сильно бОльшего зеркального лепестка, становится очевидным:\r\nК счастью, в OpenGL встроена возможность активации такой фильтрации простым флагом:\r\nДостаточно установить флаг где-то в коде инициализации приложения и с этим артефактом покончено.\r\nПоскольку зеркальные отражения в общем случае содержат высокочастотные детали, а также области с сильно отличающимися яркостями, то их свертка требует использования большого числа точек выборки для корректного учета большого разброса значений внутри HDR отражений от окружения. В примере мы и так берем достаточно большое число сэмплов, но для определенных сцен и высоких уровней шероховатости материала этого все равно не будет достаточно, и вы станете свидетелем появлению множества пятен вокруг ярких областей:\r\nМожно и дальше увеличивать количество сэмплов, но это не будет универсальным решением и в каких-то условиях все равно допустит артефакт. Но можно обратиться к методу , который позволяет уменьшить проявление артефакта. Для этого на стадии предварительной свертки выборку из карты окружения осуществлять не напрямую, а с одного из её мип-уровней, на основе величины, полученной из функции распределения вероятности подынтегрального выражения и шероховатости:\r\nТолько не забудьте включить трилинейную фильтрацию для карты окружения, чтобы успешно осуществлять выборку из мип-уровней:\r\nТакже не забудьте создать непосредственно мип-уровни для текстуры силами OpenGL, но только после того, как основной мип-уровень полностью сформирован:\r\nДанный способ работает на удивление хорошо, убирая практически все (а зачастую и все) пятнав отфильтрованной карте, даже на высоких уровнях шероховатости.\r\nИтак, мы успешно обработали фильтром карту окружения и теперь можем сконцентироваться на второй части аппроксимации в виде раздельной суммы, представляющей собой BRDF. Для освежения памяти снова взглянем на полную запись приближенного решения:\r\nЛевую часть суммы мы предварительно рассчитали и результаты для различных уровней шероховатости записали в отдельную кубическую карту. Правая часть потребует свертки выражения BDRF вместе со следующими параметрами: углом , шероховатостью поверхности и коэффициентом Френеля . Процесс похожий на интегрирование зеркальной BRDF для полностью белого окружения или с постоянной энергетической яркостью . Свертка BRDF для трех переменных является нетривиальной задачей, но в данном случае  можно вынести из выражения, описывающего зеркальную BRDF:\r\nЗдесь  – функция, описывающая расчет к-та Френеля. Перенеся делитель в выражение для BRDF можно перейти к следующей эквивалентной записи:\r\nЗаменяя правое вхождение  на аппроксимацию Френеля-Шлика, получим:\r\nОбозначим выражение  как  для упрощения решения относительно :\r\nДалее функцию  мы разобьем на два интеграла:\r\nТаким образом  будет постоянной под интегралом, и мы ее можем вынести за знак интеграла. Далее, мы раскроем  в исходное выражение и получим итоговую запись для BRDF в виде раздельной суммы:\r\nПолученные два интеграла представляют собой масштаб и смещение для значения  соответственно. Заметьте, что  содержит в себе вхождение , потому эти вхождения взаимно сокращаются и исчезают из выражения.\r\nИспользуя уже отработанный подход свертку BRDF мы можем провести вместе с входными данными: шероховатостью и углом между векторами  и . Результат запишем в 2D текстуру — (), которая будет служить вспомогательной таблицей значений для использования в итоговом шейдере, где будет формироваться окончательный результат непрямого зеркального освещения.\r\nШейдер свертки BRDF работает на плоскости, прямо используя двухмерные текстурные координаты как входные параметры процесса свертки (и ). Код заметно похож на свертку предварительной фильтрации, но здесь вектор выборки обрабатывается с учетом геометрической функции BRDF и выражения аппроксимации Френеля-Шлика:\r\nКак видно, свертка BRDF реализована в виде практически буквального переложения вышеизложенных математических выкладок. Берутся входные параметры шероховатости и угла , формируется вектор выборки на основе выборки по значимости, обрабатывается с использованием функции геометрии и преобразованного выражения Френеля для BRDF. В результате для каждого сэмпла получается величина масштабирования и смещения величины , которые в конце усредняются и возвращаются в виде .\r\nВ уроке упоминалось, что геометрическая компонента BRDF немного отличается в случае расчета IBL, поскольку коэффициент  задается иначе: \r\nПоскольку свертка BRDF является частью решения интеграла в случае расчета IBL, то мы будем использовать коэффициент  для расчета функции геометрии в модели Schlick-GGX:\r\nОбратите внимание на то, что коэффициент  рассчитывается на основе параметра . При этом в данном случае параметр не возводится в квадрат при описании параметра , что делалось в других местах, где применялся данный параметр. Не уверен, где здесь кроется неувязка: в работе Epic Games или в первоначальном труде от Disney, но стоит сказать, что именно такое прямое присвоение величины параметру  приводит к созданию карты интегрирования BRDF идентичной, представленной в публикации Epic Games.\r\nДалее, сохранение результатов свертки BRDF обеспечим в виде 2D текстуры размера 512х512:\r\nПо рекомендациям Epic Games здесь используется 16-битный формат текстуры с плавающей точкой. Обязательно установите режим повтора в дабы избежать артефактов сэмплинга с края.\r\nДалее, мы используем тот же объект буфера кадра и выполняем шейдер на поверхности полноэкранного квада:\r\nВ итоге получаем текстурную карту, хранящую результат свертки части выражения раздельной суммы, отвечающей за BRDF:\r\nИмея на руках результаты предварительной фильтрации карты окружения и текстуру с результатами свертки BRDF, мы сможем восстановить результат вычисления интеграла для непрямого зеркального освещения на основе аппроксимации раздельной суммой. Восстановленной значение впоследствии будет использовано как непрямое или фоновое зеркальное излучение.\r\nИтак, чтобы получить величину, описывающую непрямую зеркальную компоненту в общем выражении отражающей способности, необходимо «склеить» в единое целое вычисленные компоненты аппроксимации раздельной суммой. Для начала добавим в итоговый шейдер соответствующие сэмплеры для заранее рассчитанных данных:\r\nСперва мы получаем значение непрямого зеркального отражения на поверхности за счет выборки из предварительно обработанной карты окружения на основе вектора отражения. Обратите внимание, что здесь выбор мип-уровня для сэмплинга основывается на величине шероховатости поверхности. Для более шероховатых поверхностей отражение будет :\r\nНа этапе предварительной свертки мы подготовили лишь 5 мип-уровней (с нулевого по четвертый), константа служит для ограничения выборки из сформированных мип-уровней.\r\nДалее делаем выборку из карты интегрирования BRDF на основе шероховатости и угла между нормалью и направлением взгляда:\r\nПолученное из карты значение содержит коэффициенты масштабирования и смещения для величины  (здесь берется величина  – френелевский коэффициент). Преобразованная величина  далее комбинируется с величиной, полученной из карты предварительной фильтрации, для получения приближенного решения исходного интегрального выражения – .\r\nТаким образом мы получаем решение для части выражения отражающей способности, отвечающей за зеркальное отражение. Для получения полного решения модели PBR IBL необходимо скомбинировать эту величину с решением для диффузной части выражения отражающей способности, которое мы получили в  уроке:\r\nОтмечу, что величина не умножается на , поскольку она и так содержит в себе френелевский коэффициент.\r\nЗапустим же наше тестовое приложение со знакомым набором сфер с меняющимися характеристиками металличности и шероховатости и взглянем на их вид в полном великолепии PBR:\r\nМожно пойти еще дальше и скачать набор текстур, соответствующих модели PBR и получить сферы из :\r\nИли даже загрузить шикарную модель вместе с подготовленными PBR текстурами от :\r\nДумаю, что никого особо убеждать не придется в том, что нынешняя модель освещения выглядит намного более убедительно. И более того, освещение выглядит физически корректным вне зависимости от карты окружения. Ниже использованы несколько совершенно различных HDR карт окружения, целиком меняющих характер освещения – но все изображения выглядят физически достоверно, при том, что никаких параметров в модели подгонять не пришлось! (В принципе, в этом упрощении работы с материалами и кроется основной плюс PBR пайплайна, а более качественная картинка — можно сказать, приятное следствие. )\r\nФух, наше путешествие в суть PBR рендера вышло довольно объемным. К результату мы шли через целую череду шажков и, конечно, многое может пойти не так при первых подходах. Потому при любых проблемах советую тщательно разобраться в коде примеров для  и сфер (и в коде шейдеров, конечно!). Либо спрашивайте совета в комментариях.\r\nЯ надеюсь, что читая эти строки вы уже оформили для себя понимание работы PBR модели рендера, а также разобрались и успешно запустили тестовое приложение. В этих уроках все необходимые вспомогательные текстурные карты для модели PBR мы рассчитывали в нашем приложении заранее, перед основным циклом рендера. Для задач обучения этот подход годится, но не для практического применения. Во-первых, такая предварительная подготовка должна происходить один раз, а не каждый запуск приложения. Во-вторых, если вы решите добавить еще несколько карт окружения, то и их тоже придется обработать при запуске. А если добавится еще несколько карт? Настоящий снежный ком.\r\nИменно поэтому в общем случае карта облученности и предварительно обработанная карта окружения подготавливаются единожды, а затем сохраняются на диске (карта комплексирования BRDF не зависит от карты окружения, так что её вообще можно рассчитать или загрузить один раз). Отсюда следует, что вам понадобится формат для хранения HDR кубических карт, включая их мип-уровни. Ну, или можно хранить и загружать их, используя один из широко распространенных форматов (так  поддерживает сохранение мип-уровней).\r\nЕще важный момент: с целью дать глубокое понимание PBR пайплайна в этих уроках я привел описание полного процесса подготовки к PBR рендеру, включая предварительные расчеты вспомогательных карт для IBL. Однако, в своей практике вы с тем же успехом можете воспользоваться одной из великолепных утилит, которые подготовят эти карты для вас: например  или .\r\nТакже мы не рассмотрели процесс подготовки кубических карт () и связанные с ним процессы интерполяции кубических карт и коррекции параллакса. Кратко данную технику можно описать следующим образом: мы размещаем в нашей сцене множество объектов проб отражения, которые формируют локальный снимок окружения в виде кубической карты, а далее на его основе формируются все необходимые вспомогательные карты для IBL модели. Путем интерполяции данных от нескольких проб на основе удаления от камеры можно получить высокодетализированное освещение на основе изображения, качество которого по сути ограничено лишь количеством проб, которые мы готовы разместить в сцене. Такой подход позволяет корректно меняться освещению, например, при перемещении с ярко освещенной улицы в сумрак некоего помещения. Вероятно, я напишу урок о пробах отражения в будущем, однако на данный момент могу лишь порекомендовать для ознакомления статью за авторством Chetan Jags, приведенную ниже.\r\n(Реализацию проб, да и многого другого можно посмотреть в сырцах движка автора туториалов , )", "url": "https://habr.com/ru/post/429744/"},
{"title": "﻿NCBI Genome Workbench: научные исследования под угрозой", "article_text": "Современные компьютерные технологии, технические и программные решения — всё это сильно облегчает и ускоряет проведение различных научных исследований. Зачастую компьютерное моделирование — единственный способ проверки многих теорий. Научный софт имеет свои особенности. Например, такой софт зачастую подвергается очень тщательному тестированию, но слабо документирован. Тем не менее программное обеспечение пишется людьми, а люди допускают ошибки. Ошибки в научных программах могут ставить под сомнение целые исследования. В этой статье будут приведены десятки проблем, обнаруженных в коде пакета программ NCBI Genome Workbench. предлагает исследователям большой набор инструментов для изучения и анализа генетических данных. Пользователи могут исследовать и сравнивать данные из нескольких источников, включая базы данных NCBI (National Center for Biotechnology Information) или собственных личных данных.\r\nКак уже говорилось ранее, научный софт обычно хорошо покрыт unit-тестами. При проверке этого проекта из анализа было исключено 85 каталогов с файлами тестов. Это около тысячи файлов. Наверное, это обусловлено требованиями к тестированию разных сложных алгоритмов, которые изобретаются для тех или иных исследований. Но качество остального кода (не тестового) находится не на таком высоком уровне, как хотелось бы. Впрочем, как и в любом проекте, в котором ещё не позаботились о внедрении инструментов статического анализа кода :).\r\nДанные для обзора (или даже исследования) кода были предоставлены статическим анализатором кода для C/C++/C#/Java — .\r\nНа основе нашей базы ошибок, которая на данный момент составляет более 12 тысяч отборных примеров, мы замечаем и описываем особые паттерны написания кода, которые приводят к многочисленным ошибкам. Например, мы проводили следующие исследования:\r\nЭтот проект положил начало описанию нового паттерна. Речь идёт о цифрах  и  в названиях переменных, например,  и  и т.п. Очень легко перепутать две таких переменных. Это частный случай опечаток в коде, но к появлению таких ошибок приводит одно — желание работать с одноимёнными переменными, различающихся только цифрами 1 и 2 в конце имени.\r\nНемного забегая вперёд, скажу, что все перечисленные исследования нашли своё подтверждение в коде этого проекта :D.\r\nРассмотрим первый пример из проекта Genome Workbench: There are identical sub-expressions '(!loc1.IsInt() &&!loc1.IsWhole())' to the left and to the right of the '||' operator. nw_aligner.cpp 480\r\nМы видим две переменные с именами  и . А также ошибку в коде: переменная  не используется, потому что вместо неё лишний раз используется .\r\nДругой пример: A part of conditional expression is always false: s1.IsSet(). valid_biosource.cpp 3073\r\nВ первой же строке кода перепутали переменные  и . Исходя из названия, это функция сравнения. Но такая ошибка может быть где угодно, потому что, назвав переменные  и , программист почти наверняка сделает ошибку в будущем. И чем больше использований таких имен в функции, тем выше вероятность совершить ошибку. There are identical sub-expressions to the left and to the right of the '!=' operator: bd.bit_.bits[i] != bd.bit_.bits[i] bm.h 296\r\nЯ полагаю, что после всех проверок размеры массивов  у объектов  и  равны. Поэтому автор кода написал один цикл для поэлементного сравнения массивов , но сделал опечатку в имени одного из сравниваемых объектов. В итоге сравниваемые объекты ошибочно могут быть признаны равными в некоторых ситуациях.\r\nЭтот пример достоин статьи \"\". There are identical sub-expressions 'CFieldHandler::QualifierNamesAreEquivalent(field, kFieldTypeSeqId)' to the left and to the right of the '||' operator. field_handler.cpp 152\r\nСкорее всего, одна из проверок является лишней. Я не нашёл в коде переменных, похожих на . Тем не менее тут возможен лишний вызов функции из-за оператора \"||\", что ухудшает производительность.\r\nЕщё пара однотипных мест с предупреждением анализатора, требующих проверки: An item with the same key 'kArgRemote' has already been added. blast_args.cpp 3262\r\nАнализатор обнаружил добавление 2-х одинаковых значений в контейнер . Напомним, что данный контейнер хранит только уникальные значения, поэтому дубликаты в него не добавляются. \r\nКод, подобный приведенному выше, часто пишется методом copy-paste. Тут может быть просто лишнее значение, или, возможно, автор забыл переименовать одну из переменных, когда скопировал. При удалении лишнего вызова  код немного оптимизируется, что, впрочем, не существенно. Намного важнее, что здесь может скрываться серьезная ошибка из-за пропущенного элемента в множестве. The 'then' statement is equivalent to the subsequent code fragment. vcf_reader.cpp 1105\r\nФункция содержит крупные и полностью идентичные фрагменты кода. При этом они содержат разные сопроводительные комментарии. Код написан не оптимально, запутанно и, возможно, содержит ошибку.\r\nВесь список подозрительных мест с оператором if-else выглядит так: The compiler could delete the 'memset' function call, which is used to flush 'passwd_buf' buffer. The memset_s() function should be used to erase the private data. challenge.c 366\r\nКак вы уже, наверное, догадались, в названии раздела использован забавный комментарий про безопасность из кода.\r\nЕсли вкратце, то функция  будет удалена компилятором, потому что очищаемые буферы больше не используются. И такие данные, как  или , на самом деле не будут затёрты нулями. Более подробно об этом неочевидном механизме компилятора можно узнать из статьи \"\". The compiler could delete the 'memset' function call, which is used to flush 'answer' object. The memset_s() function should be used to erase the private data. challenge.c 561\r\nТо был не единственный пример с комментариями про «безопасность». Судя по комментариям, можно предположить, что безопасность действительно важна для проекта. Поэтому прилагаю весь не маленький список выявленных проблем: It is likely that a wrong variable is being compared inside the 'for' operator. Consider reviewing 'i'. taxFormat.cpp 569\r\nЯ думаю, в условие внутреннего цикла переменная  затесалась случайно. Вместо неё должна использоваться переменная . The variable 'i' is being used for this loop and for the outer loop. Check lines: 302, 309. sls_alp.cpp 309\r\nДва вложенных одинаковых цикла, в которых ещё и обнуляется глобальный счётчик — выглядят ну очень подозрительно. Разработчикам следует проверить, что тут вообще происходит. The comma operator ',' in array index expression '[-- i2, — k]'. nw_spliced_aligner16.cpp 564\r\nСразу скажу, что ошибки тут вроде нет (пока, lol). Рассмотрим следующую строку:\r\nСлово 'matrix' и двойная индексация могут навести на мысль, что массив двумерный, но это не так. Это обычный указатель на массив целых чисел. Но диагностика  не просто так появилась. Программисты действительно путаются в способах индексации двумерных массивов.\r\nВ данном случае автор просто решил сэкономить на одной строке кода, хотя мог написать так: A suspicious expression 'A[B == C]'. Probably meant 'A[B] == C'. ncbi_service_connector.c 180\r\nЕщё один пример кода, в котором я долго пытался понять, что происходит :D. Функцией  проверяется символ с индексом , но если этот символ '$', то в функцию передаётся символ с индексом . При этом сравнение с '$' уже было заранее. Возможно, ошибки тут нет, но код точно можно переписать понятнее. Array overrun is possible. The 'row' index is pointing beyond array bound. aln_reader.cpp 412\r\nВот тут присутствует серьёзная ошибка. Правильная проверка индекса  должна быть такой:\r\nИначе возможно обращение к данным за пределами вектора .\r\nЕщё много таких мест: The 'm_onClickFunction' variable is assigned to itself. alngraphic.hpp 103\r\nВот тут даже прокомментировать нечего. Можно только посочувствовать человеку, который на что-то кликал, кликал, но ничего не менялось.\r\nЕщё два случая присваивания переменных самим себе приведу списком: Parameter 'w1' is always rewritten in function body before being used. bmfunc.h 5363\r\nФункция, в которой перетирается аргумент сразу при входе в функцию, может вводить в заблуждение использующих её разработчиков. Код следует перепроверить. The 'm_qsrc' function argument possesses the same name as one of the class members, which can result in a confusion. compart_matching.cpp 873\r\nСразу 3 функции класса содержат аргументы, имена которых совпадают с полем класса. Это может приводить к ошибкам в телах функций: программист может думать, что работает с членом класса, на самом деле изменяя значение локальной переменной. Uninitialized variable 'm_BitSet' used. SnpBitAttributes.hpp 187\r\nОдин из конструкторов неаккуратно работает с переменной . Дело в том, что переменная неинициализированная. Её «мусорное» значение используется на первой итерации цикла, после чего происходит инициализация. Это очень серьёзная ошибка, приводящая к неопределённому поведению программы. The object was created but it is not being used. If you wish to call constructor, 'this->SIntervalComparisonResult::SIntervalComparisonResult(....)' should be used. compare_feats.hpp 100\r\nОчень давно я не встречал таких ошибок при проверке проектов. Но проблема всё ещё актуальна. Ошибка в том, что вызов параметризированного конструктора таким образом приводит к созданию и удалению временного объекта. А поля класса остаются неинициализированными. Вызывать другой конструктор следует через список инициализации (см. ). Non-void function should return a value. bio_tree.hpp 266\r\nАнализатор считает, что в перегруженном операторе не хватает строки: The uninitialized class member 'm_OutBlobIdOrData' is used to initialize the 'm_StdOut' member. Remember that members are initialized in the order of their declarations inside a class. remote_app.hpp 215\r\nНа этот фрагмент кода выдаётся сразу 3 предупреждения анализатора. Поля класса инициализируются не в том порядке, в котором перечислены в списке инициализации, а в том, как объявлены в классе. Классическая причина ошибки в том, что не все программисты помнят или знают об этом правиле. Здесь и в списке инициализации как раз неверный порядок. Складывается ощущение, что список полей вводили в случайном порядке.  Object slicing. An exception should be caught by reference rather than by value. cobalt.cpp 247\r\nПерехват исключений по значению может приводить к потере части информации об исключении из-за создания нового объекта. Намного лучше и безопасней перехватывать исключение по ссылке.\r\nАналогичные места: Unreachable code detected. It is possible that an error is present. merge_tree_core.cpp 627\r\nКод условного оператора написан так, что абсолютно все ветви кода заканчиваются оператором . Это привело к тому, что в цикле  образовались несколько строк недостижимого кода. Выглядят эти строки очень подозрительно. Скорее всего, такая проблема возникла после рефакторинга кода, и теперь тут требуется внимательный code-review. The 'interval_width' variable is assigned values twice successively. Perhaps this is a mistake. Check lines: 454, 456. aln_writer.cpp 456\r\nПеременная  перезаписывается несколько раз, т.к. в ветках  отсутствуют операторы . Хоть и классическая, но очень нехорошая ошибка.\r\nЕщё несколько подозрительных мест: Recurring check. The 'if (m_QueryOpts->filtering_options)' condition was already verified in line 703. blast_options_local_priv.hpp 713\r\nОчевидно, ветвь  требует переписывания. У меня есть несколько идей, что хотели сделать с указателем , но код всё равно какой-то запутанный. Взываю к авторам кода.\r\nНу и проблема не приходит одна: EOF should not be compared with a value of the 'char' type. The 'linestring[0]' should be of the 'int' type. alnread.c 3509\r\nСимволы, которые планируется сравнивать с EOF, не должны храниться в переменных типа . Иначе есть риск, что символ со значением 0xFF (255) превратится в -1 и будет интерпретироваться точно так же, как конец файла (EOF). Также (на всякий случай) стоит проверить реализацию функции . Infinite loop is possible. The 'cin.eof()' condition is insufficient to break from the loop. Consider adding the 'cin.fail()' function call to the conditional expression. ncbicgi.cpp 1564\r\nАнализатор обнаружил потенциальную ошибку, из-за которой может возникнуть бесконечный цикл. В случае возникновения сбоя при чтении данных вызов функции  будет всегда возвращать значение . Для завершения цикла в этом случае необходима дополнительная проверка значения, возвращаемого функцией . Perhaps the '?:' operator works in a different way than it was expected. The '?:' operator has a lower priority than the '&&' operator. ncbi_connutil.c 1135\r\nОбратите внимание на выражение:\r\nОно не вычисляется так, как ожидал программист, потому что всё выражение выглядит так:\r\nПриоритет оператора  выше, чем у . По этой причине код выполняется не так, как задумывалось. It's probably better to assign value to 'seq' variable than to declare it anew. Previous declaration: validator.cpp, line 490. validator.cpp 492\r\nИз-за того, что программист объявил новую переменную  внутри секции try/catch, другая переменная  остаётся неинициализированной и используется ниже по коду. It's odd to compare a bool type value with a value of 0: (((status) & 0x7f) == 0) != 0. ncbi_process.cpp 111\r\nНичего не предвещало беды, но WIFEXITED оказался макросом, раскрывающимся таким образом:\r\nПолучается так, что функция возвращает противоположное значение.\r\nВ коде нашлась еще одна такая функция, на которую выдалось предупреждение: The 'dst_len' pointer was utilized before it was verified against nullptr. Check lines: 309, 315. zlib.cpp 309\r\nУказатель  разыменовывается в самом начале функции, при этом далее по коду проверяется на равенство нулю. В коде допущена ошибка, которая приводит к неопределённому поведению, если указатель  окажется равен . Consider inspecting the 'ch != '\\0' && ch == ' '' expression. The expression is excessive or contains a misprint. cleanup_utils.cpp 580\r\nУсловие остановки цикла зависит только от того, является символ  пробелом или нет. Выражение можно упростить до такого:\r\nИспользование компьютерных программ в научных исследованиях помогает и будет помогать делать открытия. Будем надеяться, что особо важные из них не будут пропущены из-за какой-нибудь опечатки.\r\nПриглашаю разработчиков проекта NCBI Genome Workbench связаться с нами, и мы предоставим полный отчёт, выданный анализатором PVS-Studio.\r\nНадеюсь, что это небольшое исследование кода поможет исправить многие ошибки и в целом улучшить надёжность проекта. Попробуйте запустить PVS-Studio на коде своих проектов, если ещё не делали этого. Вам может это понравиться :).\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: Svyatoslav Razmyslov. ", "url": "https://habr.com/ru/company/pvs-studio/blog/430476/"},
{"title": "Методы наименьших квадратов без слёз и боли", "article_text": "Итак, очередная статья из цикла ». Сегодня мы  разговор о методах наименьших квадратов, но на сей раз с точки зрения программиста. Это очередная статья в серии, но она стоит особняком, так как вообще не требует никаких знаний математики. Статья задумывалась как введение в теорию, поэтому из базовых навыков она требует умения включить компьютер и написать пять строк кода. Разумеется, на этой статье я не остановлюсь, и в ближайшее же время опубликую продолжение. Если сумею найти достаточно времени, то напишу книгу из этого материала. Целевая публика — программисты, так что хабр подходящее место для обкатки. Я в целом не люблю писать формулы, и я очень люблю учиться на примерах, мне кажется, что это очень важно — не просто смотреть на закорючки на школьной доске, но всё пробовать на зуб.\r\nИтак, начнём. Давайте представим, что у меня есть триангулированная поверхность со сканом моего лица (на картинке слева). Что мне нужно сделать, чтобы усилить характерные черты, превратив эту поверхность в гротескную маску?\r\nВ данном конкретном случае я решаю эллиптическое дифференциальное уравнение, носящее имя . Товарищи программисты, давайте сыграем в игру: прикиньте, сколько строк в C++ коде, его решающем? Сторонние библиотеки вызывать нельзя, у нас в распоряжении только голый компилятор. Ответ под катом.\r\nНа самом деле, двадцати строк кода достаточно для солвера. Если считать со всем-всем, включая парсер файла 3Д модели, то в двести строк уложиться — раз плюнуть.\r\nДавайте расскажу, как это работает. Начнём издалека, представьте, что у нас есть обычный массив f, например, из 32 элементов, инициализированный следующим образом:\r\nА затем мы тысячу раз выполним следующую процедуру: для каждой ячейки f[i] мы запишем в неё среднее значение соседних ячеек: f[i] = ( f[i-1] + f[i+1] )/2. Чтобы было понятнее, вот полный код:\r\nКаждая итерация будет сглаживать данные нашего массива, и через тысячу итераций мы получим постоянное значение во всех ячейках. Вот анимация первых ста пятидесяти итераций:\r\nЕсли вам неясно, почему происходит сглаживание, прямо сейчас остановитесь, возьмите ручку и попробуйте порисовать примеры, иначе дальше читать не имеет смысла. Триангулированная поверхность ничем принципиально от этого примера не отличается. Представьте, что для каждой вершины мы найдём соседние с ней, посчитаем их центр масс, и передвинем нашу вершину в этот центр масс, и так десять раз. Результат будет вот таким:\r\nРазумеется, если не остановиться на десяти итерациях, то через некоторое время вся поверхность сожмётся в одну точку ровно так же, как и в предыдущем примере весь массив стал заполнен одним и тем же значением.\r\nПолный код , а здесь я приведу самую важную часть, опустив лишь чтение и запись 3Д моделей. Итак, триангулированная модель у меня представлена двумя массивами: verts и faces. Массив verts — это просто набор трёхмерных точек, они же вершины полигональной сетки. Массив faces — это набор треугольников (количество треугольников равно faces.size()), для каждого треугольника в массиве хранятся индексы из массива вершин. Формат данных и работу с ним я подробно описывал в  по компьютерной графике. Есть ещё третий массив, который я пересчитываю из первых двух (точнее, только из массива faces) — vvadj. Это массив, который для каждой вершины (первый индекс двумерного массива) хранит индексы соседних с ней вершин (второй индекс).\r\nПервое, что я делаю, это для каждой вершины моей поверхности считаю вектор кривизны. Давайте проиллюстрируем: для текущей вершины v я перебираю всех её соседей n1-n4; затем я считаю их центр масс b = (n1+n2+n3+n4)/4. Ну и финальный вектор кривизны может быть посчитан как c=v-b, это не что иное, как .\r\nНепосредственно в коде это выглядит следующим образом:\r\nНу а дальше мы много раз делаем следующую вещь (смотрите предыдущую картинку): мы вершину v двигаем v := b + const * c. Обратите внимание, что если константа равна единице, то наша вершина никуда не сдвинется! Если константа равна нулю, то вершина заменяется на центр масс соседних вершин, что будет сглаживать нашу поверхность. Если константа больше единицы (заглавная картинка сделана при помощи const=2.1), то вершина будет сдвигаться в направлении вектора кривизны поверхности, усиливая детали. Вот так это выглядит в коде:\r\nКстати, если меньше единицы, то детали будут наоборот ослабляться (const=0.5), но это не будет эквивалентно простому сглаживанию, «контраст картинки» останется:\r\nОбратите внимание, что мой код генерирует файл 3Д модели в формате , рендерил я в сторонней программе. Посмотреть получившуюся модель можно, например, в . Если вам интересны именно методы отрисовки, а не генерирование модели, то читайте мой .\r\nДавайте вернёмся к самому первому примеру, и сделаем ровно то же самое, но только не будем переписывать элементы массива под номерами 0, 18 и 31:\r\nОстальные, «свободные» элементы массива я инициализировал нулями, и по-прежнему итеративно заменяю их на среднее значение соседних элементов. Вот так выглядит эволюция массива на первых ста пятидесяти итерациях:\r\nВполне очевидно, что на сей раз решение сойдётся не к постоянному элементу, заполняющему массив, а к двум линейным рампам. Кстати, действительно ли всем очевидно? Если нет, то экспериментируйте с этим кодом, я специально привожу примеры с очень коротким кодом, чтобы можно было досконально разобраться с происходящим.\r\nПусть нам дана обычная система линейных уравнений:\r\nЕё можно переписать, оставив в каждом из уравнений с одной стороны знака равенства x_i:\r\nПусть нам дан произвольный вектор , приближающий решение системы уравнений (например, нулевой).\r\nТогда, воткнув его в правую часть нашей системы, мы можем получить обновлённый вектор приближения решения .\r\nЧтобы было понятнее, x1 получается из x0 следующим образом:\r\nПовторив процесс k раз, решение будет приближено вектором \r\nДавайте на всякий случай запишем рекурретную формулу:\r\nПри некоторых предположениях о коэффициентах системы (например, вполне очевидно, что диагональные элементы не должны быть нулевыми, т.к. мы на них делим), данная процедура сходится к истинному решению. Эта гимнастика известна в литературе под названием . Конечно же, существуют и другие методы численного решения систем линейных уравнений, причём значительно более мощные, например, , но, пожалуй, метод Якоби является одним из самых простых.\r\nА теперь давайте ещё раз внимательно посмотрим на основной цикл из примера 3:\r\nЯ стартовал с какого-то начального вектора x, и тысячу раз его обновляю, причём процедура обновления подозрительно похожа на метод Якоби! Давайте выпишем эту систему уравнений в явном виде:\r\nПотратьте немного времени, убедитесь, что каждая итерация в моём питоновском коде — это строго одно обновление метода Якоби для этой системы уравнений. Значения x[0], x[18] и x[31] у меня зафиксированы, соответственно, в набор переменных они не входят, поэтому они перенесены в правую часть.\r\nИтого, все уравнения в нашей системе выглядят как — x[i-1] + 2 x[i] — x[i+1] = 0. Это выражение не что иное, как . То есть, наша система уравнений нам просто-напросто предписывает, что вторая производная должна быть везде равна нулю (ну, кроме как в точке x[18]). Помните, я говорил, что вполне очевидно, что итерации должны сойтись к линейным рампам? Так именно поэтому, у линейной функции вторая производная нулевая.\r\nА вы знаете, что мы с вами только что решили ?\r\nКстати, внимательный читатель должен был бы заметить, что, строго говоря, у меня в коде системы линейных уравнений решаются не методом Якоби, но , который является своебразной оптимизацией метода Якоби:\r\nА давайте мы самую малость изменим третий пример: каждая ячейка помещается не просто в центр масс соседних ячеек, но в центр масс \r\nВ прошлом примере мы выяснили, что помещение в центр масс — это дискретизация оператора Лапласа (в нашем случае второй производной). То есть, теперь мы решаем систему уравнений, которая говорит, что наш сигнал должен иметь некую постоянную вторую производную. Вторая производная — это кривизна поверхности; таким образом, решением нашей системы должна стать кусочно-квадратичная функция. Проверим на дискретизации в 32 сэмпла:\r\nПри длине массива в 32 элемента наша система сходится к решению за пару сотен итераций. А что будет, если мы попробуем массив в 128 элементов? Тут всё гораздо печальнее, количество итераций нужно уже исчислять тысячами:\r\nМетод Гаусса-Зейделя крайне прост в программировании, но малоприменим для больших систем уравнений. Можно попытаться его ускорить, применяя, например, . На словах это может звучать громоздко, но идея крайне примитивная: если мы хотим решение с разрешением в тысячу элементов, то можно для начала решить с десятью элементами, получив грубую аппроксимацию, затем удвоить разрешение, решить ещё раз, и так далее, пока не достигнем нужного результата. На практике это выглядит следующим образом:\r\nА можно не выпендриваться, и использовать настоящие солверы систем уравнений. Вот я решаю этот же пример, построив матрицу A и столбец b, затем решив матричное уравнение Ax=b:\r\nА вот так выглядит результат работы этой программы, заметим, что решение получилось мгновенно:\r\nТаким образом, действительно, наша функция кусочно-квадратичная (вторая производная равна константе). В первом примере мы задали нулевую вторую производную, в третьем ненулевую, но везде одинаковую. А что было во втором примере? Мы решили , задав кривизну поверхности. Напоминаю, что произошло: мы посчитали кривизну входящей поверхности. Если мы решим задачу Пуассона, задав кривизну поверхности на выходе равной кривизне поверхности на входе (const=1), то ничего не изменится. Усиление характеристических черт лица происходит, когда мы просто увеличиваем кривизну (const=2.1). А если const<1, то кривизна результирующей поверхности уменьшается.\r\nРазвиваю идею, предложенную , поиграйте с этим кодом:\r\nЭто результат по умолчанию, рыжий Ленин — это начальные данные, голубая кривая — это их эволюция, в бесконечности результат сойдётся в точку:\r\nА вот результат с коэффицентом 2.:\r\nДомашнее задание: почему во втором случае Ленин сначала превращается в Дзержинского, а затем снова сходится к Ленину же, но большего размера?\r\nОчень много задач обработки данных, в частности, геометрии, могут формулироваться как решение системы линейных уравнений. В данной статье я не рассказал,  строить эти системы, моей целью было лишь показать, что это возможно. Темой следующей статьи будет уже не «почему», но «как», и какие солверы потом использовать. \r\nКстати, а ведь в названии статьи присутствуют наименьшие квадраты. Увидели ли вы их в тексте? Если нет, то это абсолютно не страшно, это именно ответ на вопрос «как?». Oставайтесь на линии, в следующей статье я покажу, где именно они прячутся, и как их модифицировать, чтобы получить доступ к крайне мощному инструменту обработки данных. Например, в десяток строк кода можно получить вот такое:\r\nStay tuned for more!", "url": "https://habr.com/ru/post/429980/"},
{"title": "3 книги по C++ 17 (на английском)", "article_text": "Сегодня мы рассказываем вам о трех книгах, написанных нашими Microsoft MVP, по C++ 17. Они могут быть хорошими отправными точками в пути ознакомления с новой версией этого языка программирования. Все они продаются в электронном и бумажном виде на онлайн площадках (от €8.64 до $42.99 за электронные версии).“Professional C++” — это продвинутое руководство по программированию на C++. Созданная для того, чтобы помочь опытным программистам с последним обновлением, эта книга проходится по основам и погружается прямо в описание всех возможностей C++17. Каждая фича дополняется примером и фрагментом кода, который вы можете использовать в своих проектах.\r\nДемонстрируемые примеры включают протестированный на Windows и Linux код, а также авторские советы и секреты, которые могут помочь вам улучшить свой рабочий процесс. Даже многие опытные разработчики никогда полностью не изучали границы возможностей языка; эта книга рассказывает о функциях, о которых вы никогда не знали. Её главная цель — показать вам, как превратить эти функции в реальные решения.C++ является одним из наиболее широко используемых языков программирования и имеет примеры использования в различных областях, таких как игры, графическое программирование и операционные системы. На протяжении многих лет C++ остается одним из лучших решений для разработчиков программного обеспечения во всем мире. \r\nЭта книга покажет вам некоторые важные возможности C++ и расскажет о том, как их реализовать для удовлетворения ваших потребностей. Каждая проблема уникальна и не просто проверяет ваши знания языка; она тестирует ваши способности стратегического мышления и умение находить лучший выход из любой ситуации. Но существуют разные проблемы, которые, порой, ставят разработчиков в тупик. Эта книга приходит на выручку именно в таких ситуациях.\r\nЭта книга понравится разработчикам C ++ всех уровней.Хотя C++ 17 не такой большой, как C++ 11, он больше C++ 14. \r\nМногие ожидали модули, совместные подпрограммы, концепты и другие мощные функции, но разработчики не смогли подготовить все вовремя. Является ли C++ 17 из-за этого плохим? Отнюдь нет. И эта книга покажет, почему.\r\nКнига дает вам эксклюзивные познания о C++ 17 и опирается на опыт многих статей, появившихся на bfilipek.com. Главы были написаны с нуля и обновлены в соответствии с последней информацией. Также вы найдете много примеров и практических советов по использования. Кроме того, книга дает представление о текущем статусе реализации, поддержке компилятора, проблемах с производительностью и других сопутствующих знаниях, которые помогут вам улучшить текущие проекты.\r\nЕсли вы имеете представление о C++ 11/14 и хотите перейти к новейшим методам C++, то эта книга для вас.", "url": "https://habr.com/ru/company/microsoft/blog/427623/"},
{"title": "Четыре года развития SObjectizer-5.5. Как SObjectizer изменился за это время?", "article_text": "Первая версия SObjectizer-а в рамках ветки 5.5 вышла чуть больше четырех лет назад — в начале октября 2014-го года. А сегодня , которая, вполне возможно, закроет историю развития SObjectizer-5.5. По-моему, это отличный повод оглянуться назад и посмотреть, что же было сделано за минувшие четыре года.\r\nВ этой статье я попробую тезисно разобрать наиболее важные и знаковые изменения и нововведения: что было добавлено, зачем, как это повлияло на сам SObjectizer или его использование.\r\nВозможно, кому-то такой рассказ будет интересен с точки зрения археологии. А кого-то, возможно, удержит от такого сомнительного приключения, как разработка собственного акторного фреймворка для C++ ;)\r\nИстория SObjectizer-5 началась в середине 2010-го года. При этом мы сразу ориентировались на C++0x. Уже в 2011-ом первые версии SObjectizer-5 стали использоваться для написания production-кода. Понятное дело, что компиляторов с нормальной поддержкой C++11 у нас тогда не было.\r\nДолгое время мы не могли использовать в полной мере все возможности «современного C++»: variadic templates, noexcept, constexpr и пр. Это не могло не сказаться на API SObjectizer-а. И сказывалось еще очень и очень долго. Поэтому, если при чтении описания какой-то фичи у вас возникает вопрос «А почему так не было сделано раньше?», то ответ на такой вопрос скорее всего: «Потому, что раньше не было возможности».\r\nВ данном разделе мы пройдемся по ряду фич, которые оказали существенное влияние на SObjectizer. Порядок следования в этом списке случаен и не имеет отношения к «значимости» или «весу» описываемых фич.\r\nИзначально в пятом SObjectizer-е все, что относилось к рантайму SObjectizer-а, определялось внутри пространства имен so_5::rt. Например, у нас были so_5::rt::environment_t, so_5::rt::agent_t, so_5::rt::message_t и т.д. Что можно увидеть, например, в традиционном примере HelloWorld из SO-5.5.0:\r\nСамо сокращение «rt» расшифровывается как «run-time». И нам казалось, что запись «so_5::rt» гораздо лучше и практичнее, чем «so_5::runtime».\r\nНо оказалось, что у многих людей «rt» — это только «real-time» и никак иначе. А использование «rt» как сокращение для «runtime» нарушает их чувства настолько сильно, что иногда анонсы версий SObjectizer-а в Рунете превращались в холивар на тему [не]допустимости трактовки «rt» иначе, нежели «real-time».\r\nВ конце-концов нам это надоело. И мы просто задеприкейтили пространство имен «so_5::rt».\r\nВсе, что было определено внутри «so_5::rt» перехало просто в «so_5». В результате тот же самый HelloWorld сейчас выглядит следующим образом:\r\nНо старые имена из «so_5::rt» остались доступны все равно, через обычные using-и (typedef-ы). Так что код, написанный для первых версий SO-5.5 оказывается работоспособным и в свежих версиях SO-5.5.\r\nОкончательно пространство имен «so_5::rt» будет удалено в версии 5.6.\r\nНаверное, код на SObjectizer-е теперь оказывается более читабельным. Все-таки «so_5::send()» воспринимается лучше, чем «so_5::rt::send()».\r\nНу а у нас, как у разработчиков SObjectizer-а, головной боли поубавилось. Вокруг анонсов SObjectizer-а в свое время и так было слишком много пустой болтовни и ненужных рассуждений (начиная от вопросов «Зачем нужны акторы в C++ вообще» и заканчивая «Почему вы не используете PascalCase для именования сущностей»). Одной флеймоопасной темой стало меньше и это было хорошо :)\r\nЕще в самых первых версиях SObjectizer-5.5 отсылка обычного сообщения выполнялась посредством метода deliver_message, который нужно было вызвать у mbox-а получателя. Для отсылки отложенного или периодического сообщения нужно было вызывать single_timer/schedule_timer у объекта типа environment_t. А уже отсылка синхронного запроса другому агенту вообще требовала целой цепочки операций. Вот, например, как это все могло выглядеть четыре года назад (здесь уже используется std::make_unique(), который в C++11 еще не был доступен):\r\nКроме того, формат обработчиков сообщений в SObjectizer к версии 5.5 эволюционировал. Если первоначально в SObjectizer-5 все обработчики должны были иметь формат:\r\nто со временем к разрешенным форматам добавились еще несколько:\r\nНовые форматы обработчиков стали широко использоваться, т.к. постоянно расписывать «const so_5::event_data_t<Msg>&» — это то еще удовольствие. Но, с другой стороны, более простые форматы оказались не дружественными агентам-шаблонам. Например:\r\nТакой шаблонный агент будет работать только если Msg_To_Process — это тип сообщения, а не сигнала.\r\nВ ветке 5.5 появилось и существенно эволюционировало семейство send-функций. Для этого пришлось, во-первых, получить в свое распоряжение компиляторы с поддержкой variadic templates. И, во-вторых, накопить достаточный опыт работы, как с variadic templates вообще, так и с первыми версиями send-функций. Причем в разных контекстах: и в обычных агентах, и в ad-hoc-агентах, и в агентах, которые реализуются шаблонными классами, и вне агентов вообще. В том числе и при использовании send-функций с mchain-ами (о них речь пойдет ниже).\r\nВ дополнение к send-функциям появились и функции request_future/request_value, которые предназначены для синхронного взаимодействия между агентами.\r\nВ результате сейчас отсылка сообщений выглядит следующим образом:\r\nДобавился еще один возможный формат для обработчиков сообщений. Причем, именно этот формат и будет оставлен в следующих мажорных релизах SObjectizer-а как основной (и, возможно, единственный). Это следующий формат:\r\nГде Msg может быть как типом сообщения, так и типом сигнала.\r\nТакой формат не только стирает грань между агентами в виде обычных классов и агентов в виде шаблонных классов. Но еще и упрощает перепосылку сообщения/сигнала (спасибо семейству функций send):\r\nПоявление send-функций и обработчиков сообщений, получающих mhood_t<Msg>, можно сказать, принципиально изменило код, в котором сообщения отсылаются и обрабатываются. Это как раз тот случай, когда остается только пожалеть, что в самом начале работ над SObjectizer-5 у нас не было ни компиляторов с поддержкой variadic templates, ни опыта их использования. Семейство send-функций и mhood_t следовало бы иметь с самого начала. Но история сложилась так, как сложилась…\r\nПервоначально все отсылаемые сообщения должны были быть классами-наследниками класса so_5::message_t. Например:\r\nПока пятым SObjectizer-ом пользовались только мы сами, это не вызывало никаких вопросов. Ну вот так и вот так.\r\nНо как только SObjectizer-ом начали интересоваться сторонние пользователи, мы сразу же столкнулись с регулярно повторяющимся вопросом: «А я обязательно должен наследовать сообщение от so_5::message_t?» Особенно актуальным этот вопрос был в ситуациях, когда нужно было отсылать в качестве сообщений объекты типов, на которые пользователь повлиять вообще не мог. Скажем, пользователь использует SObjectizer и еще какую-то внешнюю библиотеку. И в этой внешней библиотеке есть некий тип M, объекты которых пользователь хотел бы отсылать в качестве сообщений. Ну и как в таких условиях подружить тип M и so_5::message_t? Только дополнительными обертками, которые пользователь должен был писать вручную.\r\nМы добавили в SObjectizer-5.5 возможность отсылать сообщения даже в случае, если тип сообщения не наследуется от so_5::message_t. Т.е. сейчас пользователь может запросто написать:\r\nПод капотом все равно остается so_5::message_t, просто за счет шаблонной магии send() понимает, что std::string не наследуется от so_5::message_t и внутри send-а конструируется не простой std::string, а специальный наследник от so_5::message_t, внутри которого уже находится нужный пользователю std::string.\r\nПохожая шаблонная магия применяется и при подписке. Когда SObjectizer видит обработчик сообщения вида:\r\nто SObjectizer понимает, что на самом деле придет специальное сообщение с объектом std::string внутри. И что нужно вызвать обработчик с передачей в него ссылки на std::string из этого специального сообщения.\r\nИспользовать SObjectizer стало проще, особенно когда в качестве сообщений нужно отсылать не только объекты своих собственных типы, но и объекты типов из внешних библиотек. Несколько человек даже нашли время сказать отдельное спасибо именно за эту фичу.\r\nИзначально в SObjectizer-5 использовалась только модель взаимодействия 1:N. Т.е. у отосланного сообщения могло быть более одного получателя (а могло быть и не одного). Даже если агентам нужно было взаимодействовать в режиме 1:1, то они все равно общались через multi-producer/multi-consumer почтовый ящик. Т.е. в режиме 1:N, просто N в этом случае было строго единица.\r\nВ условиях, когда сообщение может быть получено более чем одним агентом-получателем, отсылаемые сообщения должны быть иммутабельными. Именно поэтому обработчики сообщений имели следующие форматы:\r\nВ общем-то, простой и понятный подход. Однако, не очень удобный, когда агентам нужно общаться друг с другом в режиме 1:1 и, например, передавать друг-другу владение какими-то данными. Скажем, вот такое простое сообщение не сделать, если все сообщения — это строго иммутабельные объекты:\r\nТочнее говоря, отослать-то такое сообщение можно было бы. Но вот получив его как константный объект, изъять к себе содержимое process_image::image_ уже просто так не получилось бы. Пришлось бы помечать такой атрибут как mutable. Но тогда мы бы теряли контроль со стороны компилятора в случае, когда process_image почему-то отсылается в режиме 1:N.\r\nВ SObjectizer-5.5 была добавлена возможность отсылать и получать мутабельные сообщения. При этом пользователь должен специальным образом помечать сообщение и при отсылке, и при подписке на него.\r\nНапример:\r\nДля SObjectizer-а my_message и mutable_msg<my_message> — это два разных типа сообщений.\r\nКогда send-функция видит, что ее просят отослать мутабельное сообщение, то send-функция проверяет, а в какой почтовый ящик это сообщение пытаются отослать. Если это multi-consumer ящик, то отсылка не выполняется, а выбрасывается исключение с соответствующим кодом ошибки. Т.е. SObjectizer гарантирует, что мутабельные сообщение могут использоваться только при взаимодействии в режиме 1:1 (через single-consumer ящики или mchain-ы, которые являются разновидностью single-consumer ящиков). Для обеспечения этой гарантии, кстати говоря, SObjectizer запрещает отсылку мутабельных сообщений в виде периодических сообщений.\r\nС мутабельными сообщениями оказалось неожиданно. Мы их добавили в SObjectizer в результате обсуждения в кулуарах . С ощущением «ну раз просят, значит кому-то нужно, поэтому стоит попробовать». Ну и сделали без особых надежд на широкую востребованность. Хотя для этого пришлось очень долго «курить бамбук» прежде чем придумалось как мутабельные сообщения добавить в SO-5.5 не поломав совместимость.\r\nНо вот когда мутабельные сообщения в SObjectizer появились, то оказалось, что применений для них не так уж и мало. И что мутабельные сообщения используются на удивление часто (упоминания об этом можно найти ). Так что на практике эта фича оказалась более чем полезна, т.к. она позволяет решить проблемы, которые без поддержки мутабельных сообщений на уровне SObjectizer-а, нормального решения не имели.\r\nАгенты в SObjectizer изначально были конечными автоматами. У агентов нужно было явным образом описывать состояния и делать подписки на сообщения в конкретных состояниях. \r\nНапример:\r\nНо это были простые конечные автоматы. Состояния не могли быть вложены друг в друга. Не было поддержки обработчиков входа в состояния и выхода из него. Не было ограничений на время пребывания в состоянии.\r\nДаже такая ограниченная поддержка конечных автоматов была удобной и мы пользовались ей не один год. Но в один прекрасный момент нам захотелось большего.\r\nВ SObjectizer появилась поддержка иерархических конечных автоматов.\r\nТеперь состояния могут быть вложены друг в друга. Обработчики событий из родительских состояний автоматически «наследуются» дочерними состояниями.\r\nПоддерживаются обработчики входа в состояние и выхода из него.\r\nЕсть возможность задать ограничение на время пребывания агента в состоянии.\r\nЕсть возможность хранить историю для состояния.\r\nДабы не быть голословным, вот пример агента, который является не сложным иерархическим конечным автоматом (код из штатного примера blinking_led):\r\nВсе это мы уже описывали , нет необходимости повторяться.\r\nВ настоящий момент нет поддержки ортогональных состояний. Но у этого факта есть два объяснения. Во-первых, мы пробовали сделать эту поддержку и столкнулись с рядом сложностей, преодоление которых нам показалось слишком дорогостоящим. И, во-вторых, пока еще ортогональные состояния никто у нас не просил. Когда попросят, тогда вновь вернемся к этой теме.\r\nЕсть ощущение, что очень серьезное (хотя мы здесь, конечно же, субъективны и пристрастны). Ведь одно дело, когда сталкиваясь со сложными конечными автоматами в предметной области ты начинаешь искать обходные пути, что-то упрощать, на что-то тратить дополнительные силы. И совсем другое дело, когда ты можешь объекты из своей прикладной задачи отобразить на свой C++ный код чуть ли не 1-в-1.\r\nКроме того, судя по вопросам, которые задают, например, по поведению обработчиков входа/выхода в/из состояния, этой функциональностью пользуются.\r\nБыла интересная ситуация. SObjectizer нередко использовался так, что только часть приложения была написана на SObjectizer-е. Остальной код в приложении мог не иметь никакого отношения ни к акторам вообще, ни к SObjectizer-у в частности. Например, GUI-приложение, в котором SObjectizer применяется для каких-то фоновых задач, тогда как основная работа выполняется на главном потоке приложения.\r\nИ вот в таких случаях оказалось, что из не-SObjectizer-части внутрь SObjectizer-части отсылать информацию проще простого: достаточно вызывать обычные send-функции. А вот с распространением информации в обратную сторону не все так просто. Нам показалось, что это не есть хорошо и что следует иметь какие-то удобные каналы общения SObjectizer-частей приложения с не-SObjectizer-частями прямо «из коробки».\r\nТак в SObjectizer появились message chains или, в более привычной нотации, mchains.\r\nMchain — это такой специфический вариант single-consumer почтового ящика, в который сообщения отсылаются обычными send-функциями. Но вот для извлечения сообщений из mchain не нужно создавать агентов и подписывать их. Есть две специальные функции, которые можно вызывать хоть внутри агентов, хоть вне агентов: receive() и select(). Первая читает сообщения только из одного канала, тогда как вторая может читать сообщения сразу из нескольких каналов:\r\nПро mchain-ы мы уже несколько раз здесь рассказывали:  и . Поэтому особо на тему того, как выглядит работа с mchain-ами углубляться здесь не будем.\r\nПосле появления mchain-ов в SObjectizer-5.5 оказалось, что SObjectizer, по факту, стал еще менее «акторным» фреймворком, чем он был до этого. К поддержке Actor Model и Pub/Sub, в SObjectizer-е добавилась еще и поддержка модели CSP (communicating sequential processes). Mchain-ы позволяют разрабатывать достаточно сложные многопоточные приложения на SObjectizer вообще без акторов. И для каких-то задач это оказывается более чем удобно. Чем мы сами и пользуемся время от времени.\r\nОдним из самых серьезных недостатков Модели Акторов является предрасположенность к возникновению перегрузок. Очень легко оказаться в ситуации, когда актор-отправитель отсылает сообщения актору-получателю с более высоким темпом, чем актор-получатель может обрабатывать сообщения.\r\nКак правило, отсылка сообщений в акторных фреймворках — это неблокирующая операция. Поэтому при возникновении пары «шустрый-producer и тормозной-consumer» очередь у актора-получателя будет увеличиваться пока остается хоть какая-то свободная память.\r\nГлавная сложность этой проблемы в том, что хороший механизм защиты от перегрузки должен быть заточен под прикладную задачу и особенности предметной области. Например, чтобы понимать, какие сообщения могут дублироваться (и, следовательно, иметь возможность безопасно отбрасывать дубликаты). Чтобы понимать, какие сообщения нельзя выбрасывать в любом случае. Кого можно приостанавливать и на сколько, а кого вообще нельзя. И т.д., и т.п.\r\nЕще одна сложность в том, что не всегда нужен именно хороший механизм защиты. Временами достаточно иметь что-то примитивное, но действенное, доступное «из коробки» и простое в использовании. Чтобы не заставлять пользователя делать свой overload control там, где достаточно просто выбрасывать «лишние» сообщения или пересылать эти сообщения какому-то другому агенту.\r\nКак раз для того, чтобы в простых сценариях можно было воспользоваться готовыми средствами защиты от перегрузки, в SObjectizer-5.5 были добавлены т.н. message limits. Этот механизм позволяет отбрасывать лишние сообщения, или пересылать их другим получателям, либо вообще просто прерывать работу приложения, если лимиты превышены. Например:\r\nБолее подробно эта тема раскрывается .\r\nНельзя сказать, что появление message limits стало чем-то, что кардинально изменило SObjectizer, принципы его работы или работу с ним. Скорее это можно сравнить с запасным парашютом, который используется лишь в крайнем случае. Но когда приходится его использовать, то оказываешься рад, что он вообще есть.\r\nSObjectizer-5 был для разработчиков «черным ящиком». В который сообщение отсылается и… И оно либо приходит к получателю, либо не приходит.\r\nЕсли сообщение до получателя не доходит, то пользователь оказывался перед необходимостью пройти увлекательный квест в поисках причины. В большинстве случаев причины тривиальны: либо сообщение отослано не в тот mbox, либо не была сделана подписка (например, пользователь сделал подписку в одном состоянии агента, но забыл сделать ее в другом). Но могут быть и более сложные случаи, когда сообщение, скажем, отвергается механизмом защиты от перегрузки.\r\nПроблема была в том, что механизм доставки сообщений упрятан глубоко в потрохах SObjectizer Run-Time и, поэтому, протрассировать процесс доставки сообщения до получателя было сложно даже разработчикам SObjectizer-а, не говоря уже про пользователей. Особенно про начинающих пользователей, которые и совершали наибольшее количество таких тривиальных ошибок.\r\nВ SObjectizer-5.5 был добавлен, а затем и доработан, специальный механизм трассировки процесса доставки сообщений под названием message delivery tracing (или просто msg_tracing). Подробнее этот механизм и его возможности описывался в .\r\nТак что теперь, если сообщения теряются при доставке, можно просто включить msg_tracing и посмотреть, почему это происходит.\r\nОтладка написанных на SObjectizer приложений стала гораздо более простым и приятным делом. Даже .\r\nНами SObjectizer всегда рассматривался как инструмент для упрощения разработки многопоточного кода. Поэтому первые версии SObjectizer-5 были написаны так, чтобы работать только в многопоточной среде.\r\nЭто выражалось как в использовании примитивов синхронизации внутри SObjectizer-а для защиты внутренностей SObjectizer-а при работе в многопоточной среде. Так и в создании нескольких вспомогательных рабочих нитей внутри самого SObjectizer-а (для выполнения таких важных операций, как обслуживание таймера и завершение дерегистрации коопераций агентов).\r\nТ.е. SObjectizer был создан для многопоточного программирования и для использования в многопоточной среде. И нас это вполне устраивало.\r\nОднако, по мере использования SObjectizer-а «в дикой природе» обнаруживались ситуации, когда задача была достаточно сложной для того, чтобы в ее решении использовались акторы. Но, при этом, всю работу можно и, более того, нужно было выполнять на одном единственном рабочем потоке.\r\nИ мы встали перед весьма интересной проблемой: а можно ли научить SObjectizer работать на одной-единственной рабочей нити?\r\nОказалось, что можно.\r\nОбошлось нам это недешево, было потрачено много времени и сил на то, чтобы придумать решение. Но решение было придумано.\r\nБыло введено такое понятие, как environment infrastructure (или env_infrastructure в немного сокращенном виде). Env_infrastructure брал на себя задачи управления внутренней кухней SObjectizer-а. В частности, решал такие вопросы, как обслуживание таймеров, выполнение операций регистрации и дерегистрации коопераций.\r\nДля SObjectizer-а было сделано несколько вариантов однопоточных env_infrastructures. Что позволило разрабатывать на SObjectizer однопоточные приложения, внутри которых существуют нормальные агенты, обменивающиеся друг с другом обычными сообщениями.\r\nПодробнее об этой функциональности мы рассказывали .\r\nПожалуй, самое важное, что произошло при внедрении данной фичи — это разрыв наших собственных шаблонов. Взгляд на SObjectizer уже никогда не будет прежним. Столько лет рассматривать SObjectizer  как инструмент для разработки многопоточного кода. А потом раз! И обнаружить, что однопоточный код на SObjectizer-е также может разрабатываться. Жизнь полна неожиданностей.\r\nSObjectizer-5 был черным ящиком не только в отношении механизма доставки сообщений. Но так же не было средств узнать, сколько агентов сейчас работает внутри приложения, сколько и каких диспетчеров создано, сколько у них рабочих нитей задействовано, сколько сообщений ждут в очередях диспетчеров и т.д.\r\nВся эта информация весьма полезна для контроля за приложениями, работающими в режиме 24/7. Но и для отладки так же временами хотелось бы понимать, растут ли очереди или увеличивается/уменьшается ли количество агентов.\r\nК сожалению, до поры, до времени у нас просто руки не доходили до того, чтобы добавить в SObjectizer средства для сбора и распространения подобной информации.\r\nВ один прекрасный момент . По умолчанию run-time мониторинг отключен, но если его включить, то в специальный mbox регулярно будут отсылаться сообщения, внутри которых будет информация о количестве агентов и коопераций, о количестве таймеров, о рабочих нитях, которыми владеют диспетчеры (а там уже будет информация о количестве сообщений в очередях, количестве агентов, привязанных к этим нитям).\r\nПлюс со временем появилась возможность дополнительно включить сбор информации о том, сколько времени агенты проводят внутри обработчиков событий. Что позволяет обнаруживать ситуации, когда какой-то агент работает слишком медленно (либо тратит время на блокирующих вызовах).\r\nВ нашей практике run-time мониторинг используется не часто. Но, когда он нужен, то тогда осознаешь его важность. Ведь без такого механизма бывает невозможно (ну или очень сложно) разобраться с тем, что и как [не]работает.\r\nТак что это фича из категории «можно и обойтись», но ее наличие, на наш взгляд, сразу же переводит инструмент в другую весовую категорию. Т.к. сделать прототип акторного фреймворка «на коленке» не так уж и сложно. Многие делали это и еще многие будут это делать. Но вот снабдить затем свою разработку такой штукой, как run-time мониторинг… До этого доживают далеко не все наколенные наброски.\r\nЗа четыре года в SObjectizer-5.5 попало немало нововведений и изменений, описание которых, даже в конспективном виде, займет слишком много места. Поэтому обозначим часть из них буквально одной строкой. В случайном порядке, без каких-либо приоритетов.\r\nВ SObjectizer-5.5 добавлена поддержка системы сборки CMake.\r\nТеперь SObjectizer-5 можно собирать и как динамическую, и как статическую библиотеку.\r\nSObjectizer-5.5 теперь собирается и работает под Android (как посредством , так и посредством свежих Android NDK).\r\nПоявились приватные диспетчеры. Теперь можно создавать и использовать диспетчеры, которые никто кроме вас не видит.\r\nРеализован механизм delivery filters. Теперь при подписке на сообщения из MPMC-mbox-ов можно запретить доставку сообщений, чье содержимое вам не интересно.\r\nСущественно упрощены средства создания и регистрации коопераций: методы introduce_coop/introduce_child_coop, make_agent/make_agent_with_binder и вот это вот все.\r\nПоявилось понятие фабрики lock-объектов и теперь можно выбирать какие lock-объекты вам нужны (на базе mutex-ов, spinlock-ов, комбинированных или каких-то еще).\r\nПоявился класс wrapped_env_t и теперь запускать SObjectizer в своем приложении можно не только посредством so_5::launch().\r\nПоявилось понятие stop_guard-ов и теперь можно влиять на процесс завершения работы SObjectizer-а. Например, можно запретить SObjectizer-у останавливаться пока какие-то агенты не завершили свою прикладную работу.\r\nПоявилась возможность перехватывать сообщения, которые были доставлены до агента, но не были агентом обработаны (т.н. dead_letter_handlers).\r\nПоявилась возможность оборачивать сообщения в специальные «конверты». Конверты могут нести дополнительную информацию о сообщении и могут выполнять какие-то действия когда сообщение доставлено до получателя.\r\nЛюбопытно также взглянуть на проделанный путь с точки зрения объема кода/тестов/примеров. Вот что нам говорит утилита cloc про объем кода ядра SObjectizer-5.5.0:\r\nА вот тоже самое, но уже для v.5.5.23 (из них 1147 строк — это код библиотеки optional-lite):\r\nОбъем тестов для v.5.5.0:\r\nТесты для v.5.5.23:\r\nНу и примеры для v.5.5.0:\r\nОни же, но уже для v.5.5.23:\r\nПрактически везде увеличение почти в три раза.\r\nА объем документации для SObjectizer-а, наверное, увеличился даже еще больше.\r\nПредварительные планы развития SObjectizer-а после релиза версии 5.5.23 были описаны  около месяца назад. Принципиально они не поменялись. Но появилось ощущение, что версию 5.6.0, релиз которой запланирован на начало 2019-го года, нужно будет позиционировать как начало очередной стабильной ветки SObjectizer-а. С прицелом на то, что в течении 2019-го года SObjectizer будет развиваться в рамках ветки 5.6 без каких-либо существенных ломающих изменений.\r\nЭто даст возможность тем, кто сейчас использует SO-5.5 в своих проектах, постепенно перейти на SO-5.6 без опасения о том, что следом придется еще и переходить на SO-5.7.\r\nВерсия же 5.7, в которой мы хотим себе позволить отойти где-то от базовых принципов SO-5.5 и SO-5.6, в 2019-ом году будет рассматриваться как экспериментальная. Со стабилизацией и релизом, если все будет хорошо, уже в 2020-ом году.\r\nВ заключении хотелось бы поблагодарить всех, кто помогал нам с развитием SObjectizer-а все это время. И отдельно хочется сказать спасибо всем тем, кто рискнул попробовать поработать с SObjectizer-ом. Ваш фидбэк всегда был нам очень полезен.\r\nТем же, кто еще не пользовался SObjectizer-ом хотим сказать: попробуйте. Это не так страшно, как может показаться.\r\nЕсли вам что-то не понравилось или не хватило в SObjectizer — скажите нам. Мы всегда прислушиваемся к конструктивной критике. И, если это в наших силах, воплощаем пожелания пользователей в жизнь.", "url": "https://habr.com/ru/post/429046/"},
{"title": "Портирование COM на Linux", "article_text": "Мне нравится технология COM. Но речь пойдет не о технологии, восхвалении или недостатках COM, а опыте переноса и реализации на Linux. Велосипед? Целесообразность? Давайте не будем на этом заострять внимание. Создает объект класса по clsuid, увеличивает количество ссылок на so, каждый раз при успешном создании объекта. Вызов IUnknown::AddRef, так же должен увеличивать счетчик ссылок на so, а IUnknown::Release должен уменьшать. \r\nЕсли количество ссылок на SO равно 0, то можно выгружать библиотеку. \r\nРегистрирует в “реестре” все clsuid сервера. Вызывается единожды при инсталляции COM-сервера. \r\nУдаляет из “реестра” записи о зарегистрированных clsuid сервера. Вызывается единожды при деинсталляции COM-сервера.   \r\nСпасибо.", "url": "https://habr.com/ru/post/427919/"},
{"title": "Работа со строками на этапе компиляции в современном C++", "article_text": "Если вы программируете на C++, то наверняка задавались вопросом почему нельзя сравнить два строковых литерала или выполнить их конкатенацию:Впрочем, как говорится, \"нельзя, но если очень хочется, то можно\". Ломать стереотипы будем под катом, причем прямо на этапе компиляции.В одном из проектов, над которым я работал, было принято использовать std::string в качестве строковых констант. В проекте было несколько модулей, в которых были определены глобальные строковые константы:Думаю, вы уже догадались, что случилось в один прекрасный день.  приняла значение , несмотря на то, что  имела значение , как и ожидалось. Как это могло произойти? Все очень просто, порядок инициализации глобальных объектов не определен, в момент инициализации  переменная  была пуста.Кроме того, такой подход имеет еще ряд недостатков. Во-первых, брошенное при создании глобального объекта исключение не отлавливается. Во-вторых, инициализация происходит при выполнении программы, что тратит драгоценное процессорное время.Именно тогда у меня возникла идея о работе со строками на этапе компиляции, которая в итоге и привела к написанию этой статьи.В этой статье рассмотрим строки, операции над которыми можно проводить на этапе компиляции. Назовем такие строки статическими.Все реализованные операции были включены в библиотеку для работы со статическими строками. Исходные коды библиотеки доступны на github, ссылка в конце статьи.Для использования библиотеки требуется как минимум C++14.Определим статическую строку как массив символов, для удобства будем считать, что строка всегда оканчивается нулевым символом:Здесь можно пойти по другому пути, и определить строку как кортеж символов. Мне этот вариант показался более трудоемким и менее удобным. Поэтому здесь он рассмотрен не будет.Посмотрите на определение строки hello выше, оно просто ужасно. Во-первых, нам нужно заранее вычислять длину массива. Во-вторых, нужно не забыть записать нулевой символ в конец. В-третьих, все эти запятые, скобки и кавычки. Определенно, с этим нужно что-то делать. Хотелось бы написать как-нибудь так:Здесь нам поможет одна из форм вариативного шаблона, которая позволяет развернуть шаблонные аргументы как индексы для агрегатной инициализации нашей статической строки из строкового литерала:Уже лучше, но индексы все же приходится писать руками. Здесь также отметим, что если указывать не все индексы, то можно получить подстроку строкового литерала, а если записать их в обратном порядке, то и его инверсию:Это соображение очень пригодится нам в дальнейшем.Теперь нам нужно как-то сгенерировать последовательность индексов строки. Для этого применим трюк с наследованием. Определим пустую структуру (нужно же что-то наследовать) с набором искомых индексов в качестве шаблонных параметров:Определим структуру-генератор, которая будет генерировать индексы по одному, храня счетчик в первом параметре:Позаботимся и о конечной точке рекурсии, когда все индексы сгенерированы (счетчик равен нулю), мы отбрасываем счетчик и генератор превращается в нужную нам последовательность:В итоге, функция создания статической строки будет выглядеть так:Напишем аналогичную функцию для статической строки, она пригодится нам далее:В дальнейшем, для каждой функции, принимающей строковый литерал  будем писать аналогичную функцию, принимающую статическую строку . Но я, для краткости, упоминать об этом не буду.Поскольку длина строкового литерала нам известна, мы можем автоматически сгенерировать последовательность индексов, напишем обертку для функции выше:Эта функция позволяет сделать ровно то, что мы хотели в начале главы.В случае отсутствия аргументов будем возвращать пустую статическую строку, которая состоит только из нулевого символа:Также нам понадобится создавать строку из кортежа символов:К слову, все, что далее будет описано в этой статье, опирается на приемы, которые описаны в данной главе. Поэтому, если что-то осталось непонятным, лучше перечитать главу еще раз.Здесь все просто. Так как наша строка оканчивается нулевым символом, достаточно вывести в поток данные массива:Здесь тоже ничего сложного. Инициализируем строку данными массива:Будем сравнивать строки посимвольно, пока не выявим различия, либо не достигнем конца хотя бы одной из строк. Поскольку constexpr for еще не изобрели, воспользуемся рекурсией и тернарным оператором:В дальнейшем, нам понадобится расширенная версия компаратора, введем индивидуальный индекс для каждой их строк, также ограничим количество сравниваемых символов:Такая версия компаратора позволит нам сравнивать не только строки целиком, но и отдельные подстроки.Для конкатенации используем тот же вариативный шаблон, что и в главе про создание статической строки. Инициализируем массив сначала символами первой строки (без учета нулевого символа), затем второй, и наконец добавляем нулевой символ в конец:Реализуем также вариативный шаблон для конкатенации произвольного количества строк или строковых литералов:Рассмотрим операции поиска символа и подстроки в статической строке.Поиск символа не представляет особенной сложности, рекурсивно проверяем символы по всем индексам и возвращаем первый индекс в случае совпадения. Также дадим возможность задавать начальную позицию поиска и порядковый номер совпадения:Константа  указывает на то, что поиск не увенчался успехом. Определим ее следующим образом:Аналогично реализуем поиск в обратном направлении:Для определения вхождения символа достаточно попробовать поискать его:Подсчет количества вхождений реализуется тривиально:Так как предполагается, что статические строки будут относительно небольшими, не будем здесь реализовывать , реализуем простейший квадратичный алгоритм:Аналогично реализуем поиск в обратном направлении:Для определения вхождения подстроки достаточно попробовать поискать ее:Применив ранее описанный компаратор мы можем определить, начинается ли статическая строка с заданной подстроки:Аналогично для окончания статической строки:Здесь рассмотрим операции, связанные с подстроками статической строки.Как мы отметили ранее, для получения подстроки нужно сгенерировать последовательность индексов, с заданным начальным и конечным индексами:Реализуем получение подстроки с проверкой начала и конца подстроки с помощью :Префикс — это подстрока, начало которой совпадает с началом исходной статической строки:Аналогично для суффикса, только совпадает конец:Чтобы разделить статическую строку по заданному индексу, достаточно вернуть префикс и суффикс:Для реверсирования статической строки напишем генератор индексов, который генерирует индексы в обратном порядке:Теперь реализуем функцию, которая реверсирует статическую строку:Вычислять хэш будем по следующей формуле:H(s) = (s + 1) ⋅ 33 + (s + 1) ⋅ 33 +… + (s + 1) ⋅ 33 + 5381 ⋅ 33 mod 2В этой главе рассмотрим преобразование статической строки в целое число, а также обратное преобразование. Для простоты будем считать, что числа представлены типами  и , это типы большой разрядности, то есть подходят для большинства случаев.Для преобразования числа в статическую строку нам нужно получить все цифры числа, преобразовать их в соответствующие символы и составить из этих символов строку.Для получения всех цифр числа будем использовать генератор, аналогичный генератору последовательности индексов. Определим последовательность символов:Реализуем генератор символов цифр, храня текущее число в первом параметре, а цифры в следующих, очередная цифра добавляется в начало последовательности, а число делится на десять:Если текущее число равно 0, то отбрасываем его, возвращая последовательность цифр, больше преобразовывать нечего:Следует также учесть случай, когда первоначальное число равно нулю, в этом случае нужно вернуть нулевой символ, иначе нуль будет преобразован в пустую последовательность символов, а потом и в пустую строку:Реализованный генератор прекрасно работает для положительных чисел, но не пригоден для отрицательных. Определим новый генератор, добавив в начало еще один шаблонный параметр — знак преобразуемого числа:Будем обрабатывать число также, как показано выше, но с учетом знака:Здесь есть один тонкий момент, обратите внимание на . Здесь нельзя , так как диапазон отрицательных чисел на одно число шире диапазона положительных и модуль минимального числа выпадает из множества допустимых значений.Отбрасываем число после обработки, если оно отрицательно, добавим символ знака минуса:Отдельно позаботимся о преобразовании нуля:Наконец, реализуем функции преобразования:Для преобразования статической строки в число нужно преобразовать символы в цифры, а затем сложить их, предварительно домножив на соответствующую степень десятки. Выполняем все действия рекурсивно, для пустой строки возвращаем нуль:Для преобразования знаковых чисел, нужно учесть, что отрицательные числа начинаются с символа знака минуса:К этому моменту библиотеку уже возможно полноценно использовать, но некоторые моменты вызывают неудобство. В этой главе рассмотрим как можно сделать использование библиотеки более удобным.Упакуем строку и реализованные методы в объект. Это позволит использовать более короткие имена методов, а также реализовать операторы сравнения:Использование компаратора в виде функции неудобно и нечитаемо. Определим глобальные операторы сравнения:Аналогично реализуем остальные операторы > <= >= == !=, для всех вариаций аргументов статических строк и строковых литералов. Здесь приводить их нет смысла из-за тривиальности.Для удобства преобразования числа в статическую строку и обратно определим соотвествующие макросы:Ниже приведены примеры реального использования реализованной библиотеки.Конкатенация статических строк и строковых литералов:Конкатенация статических строк, строковых литералов и чисел:Парсинг URL:Итерация по символам в обоих направлениях:Библиотеку, реализующую все вышеперечисленное, можно взять в моем Спасибо за внимание, замечания и дополнения приветствуются.Реализовал пользовательский литерал _ss для создания статических строк из строковых литералов:Функцию make_static_string() запрятал во внутренний немспейс, все стало выглядеть приятнее:Добавил шаблонный параметр Char вместо char:Сделал специализации для char и whar_t, нижние используются в качестве неймспейсов, чтобы дергать статическую concat, которую внес в структуру статической строки:Теперь все работает и для \"широких\" литералов:Поправил метод size(), теперь size() и length() возвращают длину строки без учета нулевого символа, для получения размера массива нужно использовать sizeof():Обновленная версия лежит на \r\nСпасибо всем за полезные комментарии.В ходе обсуждения с  появился еще один способ реализации статических строк, где символы передаются как шаблонные параметры:Детальное рассмотрение этого варианта выходит за рамки статьи, буду рад, если кто-то из читателей займется доведением его до ума.", "url": "https://habr.com/ru/post/428846/"},
{"title": "Интересная задачка на С", "article_text": "Просматривая протоколы собеседований на позицию разработчика, обнаружил такую задачу: \"Предложите код, который бы выводил на печать числа в убывающем порядке от n до 0, не используя (скрыто или явно) операторы сравнения (реализация функции вывода на печать не в счет)\". Несмотря на то, что ко мне эта задача не имела отношения, она меня заняла и я решил подумать над способами ее решения (хотя, кому и при решении какой задачи может понадобиться такой метод оптимизации кода, мне осталось неизвестно, но тем не менее ).Первое, что пришло на ум, — попытаться использовать шаблоны. Например такПроблема в том, что программирование это инженерная дисциплина, а не оккультная, и если \"что-то\" должно в системе происходить, то \"оно\" должно быть описано и под это должны быть выделены ресурсы, и в данном случае, поскольку отработка шаблонов происходит на этапе компиляции, есть ограницения на вложенность подобного рода конструкций (и это хорошо и правильно, и Слава Богу, что так есть), и компилятор совершенно справедливо выдал \"fatal error C1202: recursive type or function dependency context too complex\" при размере N больше 2000.Следующее, что пришло в голову, использовать классический метод с указателями на функции.Но и тут ограничения, накладываемые на нас законом природы, дали о себе знать, и поскольку вложенность вызовов функций ограничена размерами стека, то при значении N > 4630 был получен законный \"Stack overflow\".На этом месте разочарование и злоба полностью завладели мной и я понял, что для полноценного решения этой задачи не стоит гнушаться ни чем, в том числе самыми грязными трюками. Проблема в том, что при определенных значениях N нам нужно передавать управление на нужные участки кода. И в этом нет никаких проблем, когда у нас в распоряжении есть условные операторы, но когда их нет, приходиться прибегать к колдовству. В стародавние времена это можно было решить методом goto, но с тех пор охотники на ведьм и другие драконоборцы сильно ограничили его функциональность (и это также хорошо и правильно) и мы бы хотели написать что то типа этогоно не можем.\r\nПоэтому, хотя мне и запретили заниматься черной магией, в этом случае я решил сделать исключение, добавив к предыдущему примеру чуточку волшебства.И это полностью решило проблему (при любых N).P.S.: Буду рад услышать о других методах решения этой задачи", "url": "https://habr.com/ru/post/428343/"},
{"title": "JsonWriterSax — библиотека для создания JSON", "article_text": "Некоторое время назад я писал приложение на c++/Qt, которое отправляло по сети большие объемы данных в формате . Использовался стандартный . При внедрении столкнулся с низкой производительностью, а также неудобным дизайном классов, который не позволял нормально детектировать ошибки при работе. В результат появилась библиотека , позволяющая писать JSON документы в SAX стиле с высокой скоростью, которую и публикую на  под лицензией MIT. Кому интересно — прошу под кат.  — структуированный текстовый формат данных, разработанный Дугласом Крокфордом и являющийся подмножеством языка ECMAScript (на его основе созданы JavaScript, JScript и др.). JSON пришел на смену XML, расширяя возможности вложенности и добавляя типы данных. В настоящее время является активно применяется в интернете.Но в JSON имеются и недостатки. На мой взгляд среди стандартных типов явно не хватает типа DateTime — приходится передавать значение в виде числа или строки, а при разборе принимать решение уже в зависимости от контекста. Но стоит отметить, что и в ECMAScript тип Date создавался давно, не был продуман, и в мире js для работы с датами используют сторонние библиотеки.так жеДля парсинга и создания структуированных документов имеется 2 основных подхода — SAX и DOM. Они появились еще для XML, но могут использоваться как паттерны и для создания обработчиков других форматов. Используется для последовательной обработки данных и позволяет обрабатывать большие документы в потоке. При чтении возвращает приложению информацию о найденном элементе или ошибке, но сохранение информации и контроль вложенности лежит на самом приложении. При записи обычно указываются шаги в стиле: начать элемент, начать суб-элемент, записать число, записать строку, закрыть суб-элемент, закрыть элемент. К недостаткам можно отнести то, что от программиста требуется тщательнее писать код, лучше понимать структуру документа и отсутствие или крайняя ограниченность по редактированию существующего документа. При данном способе в памяти строится дерево документа, которое может сериализоваться, десериализоваться и изменяться. Основной недостаток — это высокий расход память и увеличение времени обработки. Под капотом обычно используется SAX обработчик.Стандартный QJsonDocument использует DOM подход. При создании документа скорость невысока — можно посмотреть бенчмарки в конце статьи. Но самой большой проблемой для меня оказался непродуманный дизайн возврата ошибки. В данном примере при нехватке памяти запишется в поток ошибок сообщение\r\nи данные перестанут добавляться. В случае с массивом можно проверять условиеНо что делать при работе с объектом? Постоянно проверять, что новый ключ добавился? Парсить лог в поисках ошибки?Библиотека  позволяет писать JSON документ в  в SAX стиле и доступна на github по лицензии MIT. Контроль за памятью возлагается на приложение. Библиотека контролирует целостность JSON — при некорректном добавлении элемента функция записи вернет ошибку. Для контроля используется КС-грамматика. Были написаны , но возможно какой-то кейс остался без внимания. Если кто-то зафиксирует некорректную работу проверки и сообщит для исправления ошибки — буду очень благодарен.Считаю, что лучшее описание библиотеки для программиста — пример кода =)В результате получимВ результате получимИспользовался QBENCHMARK при release-сборке. Функциональность реализована в классе .В последующих версиях планирую добавить возможность описывать формат пользовательских данных через lambda-функции с помощью с QVariant, добавить возможность использовать разделители для форматирования документа (pretty document) и возможно, если сообщество заинтересуется, добавлю SAX парсер.Кстати для нахождения ошибки переполнения мне помогла моя библиотека, позволяющая для qInfo(), qDebug(), qWarning() задавать формат и выводить в стиле модуля Python . Данную библиотеку так же планирую выложить в opensource — если кто заинтересовался — пишите в комментариях.", "url": "https://habr.com/ru/post/427899/"},
{"title": "Полёт свиньи, или Оптимизация интерпретаторов байт-кода", "article_text": "Всем известен тот факт, что свиньи не летают. Не менее популярно мнение о том, что интерпретаторы байт-кодов как техника исполнения языков высокого уровня не поддаются ускорению без применения трудоёмкой динамической компиляции.Во второй части серии статей об интерпретаторах байт-кодов я на примере небольшой стековой виртуальной машины ПВМ («Поросячья Виртуальная Машина») постараюсь показать, что не всё потеряно для трудолюбивых поросят с амбициями и что в рамках (в основном) стандартного C вполне возможно ускорить работу таких интерпретаторов по меньшей мере в полтора раза.Давайте знакомиться. — заурядная стековая машина, основанная на  из  серии статей. Наша свинка знает только один тип данных — 64-битное машинное слово, а все (целочисленные) вычисления производит на стеке максимальной глубиной в 256 машинных слов. Помимо стека, у этого поросёнка имеется рабочая память объёмом 65 536 машинных слов. Результат выполнения программы — одно машинное слово — можно либо поместить в регистр-результат, либо просто вывести в стандартный вывод (stdout).Всё состояние в машине «ПоросёнокВМ» хранится в единственной структуре:Вышеперечисленное позволяет отнести эту машину к низкоуровневым виртуальным машинам, почти все накладные расходы в которых приходятся на обслуживание главного цикла программы:Из кода видно, что на каждый опкод поросёнок должен:Полезная нагрузка здесь только в пятом пункте, всё остальное — накладные расходы: декодирование или извлечение из стека аргументов инструкции (пункт 4), проверка значения опкода (пункт 2), многократное возвращение в начало главного цикла и последующий труднопредсказуемый условный переход (пункт 3).Словом, у хрюшки явно превышен рекомендованный индекс массы тела, и если мы хотим привести её в форму, то придётся со всеми этими излишествами бороться.Для начала определимся с правилами игры.Писать программы для виртуальной машины прямо в C — моветон, но и создавать язык программирования — долго, поэтому мы с поросёнком решили ограничиться свинским языком ассемблера.Программа, вычисляющая сумму чисел от 1 до 65 536, на этом ассемблере выглядит примерно так:Не Python, конечно, но всё необходимое для поросячьего счастья тут есть: комментарии, метки, условные и безусловные переходы по ним, мнемоники для инструкций и возможность указывать непосредственные аргументы инструкций.В комплекте с машиной «ПоросёнокВМ» идут ассемблер и дизассемблер, которые смелые духом и имеющие много свободного времени читатели могут самостоятельно опробовать в бою.Числа суммируются очень быстро, поэтому для тестирования производительности я написал другую программу — наивную реализацию .На самом деле поросёнок и так бегает довольно быстро (его инструкции близки к машинным), поэтому для получения внятных результатов каждый замер я буду делать для ста запусков программы.Первая версия нашей неоптимизированной свиньи бегает примерно так:Полсекунды! Сравнение, безусловно, нечестное, но тот же алгоритм на Python сто пробежек делает чуть медленнее:4,5 секунды, или в девять раз медленнее. Надо отдать должное поросёнку — способности у него есть! Ну а теперь давайте посмотрим, может ли наша свинья накачать пресс.Первое правило быстрого кода — не делать лишней работы. Второе правило быстрого кода — не делать лишней работы никогда. Так какую лишнюю работу делает «ПоросёнокВМ»?Наблюдение первое: профилирование нашей программы показывает, что есть последовательности инструкций, встречающиеся чаще других. Не будем сильно мучить нашу свинью и ограничимся только парами инструкций:В машине «ПоросёнокВМ» чуть больше 20 инструкций, а для кодирования используется целый байт — 256 значений. Внесение новых инструкций не проблема. Что мы и сделаем:Ничего сложного. Давайте посмотрим, что из этого получилось:Ого! Кода всего-то на три новых инструкции, а выиграли мы полторы сотни миллисекунд!Выигрыш здесь достигается благодаря тому, что наш поросёнок при выполнении таких инструкций не делает лишних движений: поток исполнения не вываливается в главный цикл, ничего дополнительно не декодируется, а аргументы инструкций не проходят лишний раз через стек.Это называется статическими суперинструкциями, поскольку дополнительные инструкции определяются статически, то есть программистом виртуальной машины на этапе разработки. Это простая и эффективная техника, которую в той или иной форме используют все виртуальные машины языков программирования.Главная проблема статических суперинструкций заключается в том, что без конкретной программы невозможно определить, какие именно инструкции стоит объединить. Разные программы пользуются разными последовательностями инструкций, и узнать эти последовательности можно только на этапе запуска конкретного кода.Следующим шагом могла бы стать динамическая компиляция суперинструкций в контексте конкретной программы, то есть динамические суперинструкции (в 90-е и в начале 2000-х этот приём играл роль примитивной JIT-компиляции).В рамках обычного С создавать инструкции на лету невозможно, и наш поросёнок совершенно справедливо не считает это честным соревнованием. К счастью, у меня для него есть пара упражнений получше.Следуя нашим правилам быстрого кода, ещё раз зададимся вечным вопросом: что можно не делать?Когда мы знакомились с устройством машины «ПоросёнокВМ», я перечислял все действия, которые виртуальная машина выполняет для каждого опкода. И пункт 2 (проверка значения опкода на вхождение в допустимый интервал значений switch) вызывает больше всего подозрений.Присмотримся к тому, как GCC компилирует конструкцию switch:Но зачем делать проверку интервала значений на каждую инструкцию? Мы считаем, что опкод бывает либо правильный — завершающий исполнение инструкцией OP_DONE, либо неправильный — вышедший за пределы байт-кода. Хвост потока опкодов отмечен нулём, а ноль — опкод инструкции OP_ABORT, завершающей исполнение байт-кода с ошибкой.Выходит, эта проверка вообще не нужна! И поросёнок должен уметь доносить эту мысль до компилятора. Попробуем немного поправить главный switch:Зная, что инструкций у нас всего 26, мы накладываем битовую маску (восьмеричное значение 0x1f — это двоичное 0b11111, покрывающее интервал значений от 0 до 31) на опкод и добавляем обработчики на неиспользованные значения в интервале от 26 до 31.Битовые инструкции — одни из самых дешёвых в архитектуре x86, и они уж точно дешевле проблемных условных переходов вроде того, который использует проверка на интервал значений. Теоретически мы должны выигрывать несколько циклов на каждой исполняемой инструкции, если компилятор поймёт наш намёк.Кстати, способ указания интервала значений в case — не стандартный C, а расширение GCC. Но для наших целей этот код подходит, тем более что переделать его на несколько обработчиков для каждого из ненужных значений несложно.Пробуем:Ещё 50 миллисекунд! Поросёнок, ты будто бы в плечах раздался!..Какие ещё упражнения могут помочь нашему поросёнку? Самую большую экономию времени мы получили благодаря суперинструкциям. А они уменьшают количество выходов в главный цикл и позволяют избавиться от соответствующих накладных расходов.Центральный switch — главное проблемное место для любого процессора с внеочередным выполнением инструкций. Современные предсказатели ветвлений научились неплохо прогнозировать даже такие сложные непрямые переходы, но «размазывание» точек ветвлений по коду может помочь процессору быстро переходить от инструкции к инструкции.Другая проблема — это побайтовое чтение опкодов инструкций и непосредственных аргументов из байт-кода. Физические машины оперируют 64-битным машинным словом и не очень любят, когда код оперирует меньшими значениями.Компиляторы часто оперируют , то есть последовательностями инструкций без ветвлений и меток внутри. Базовый блок начинается либо с начала программы, либо с метки, а заканчивается концом программы, условным ветвлением или прямым переходом к метке, начинающей следующий базовый блок.У работы с базовыми блоками много преимуществ, но нашу свинью интересует именно её ключевая особенность: инструкции в пределах базового блока выполняются последовательно. Было бы здорово как-нибудь выделять эти базовые блоки и выполнять инструкции в них, не теряя времени на выход в главный цикл.В нашем случае можно даже расширить определение базового блока до трассы. Трасса в терминах машины «ПоросёнокВМ» будет включать в себя все последовательно связанные (то есть при помощи безусловных переходов) базовые блоки.Помимо последовательного выполнения инструкций, неплохо было бы ещё заранее декодировать непосредственные аргументы инструкций.Звучит всё это довольно страшно и напоминает динамическую компиляцию, которую мы решили не использовать. Поросёнок даже немного засомневался в своих силах, но на практике всё оказалось не так плохо.Давайте сначала подумаем, как можно представить входящую в трассу инструкцию:Здесь arg — заранее декодированный аргумент инструкции, а handler — указатель на функцию, выполняющую логику инструкции.Теперь представление каждой трассы выглядит так:То есть трасса — это последовательность s-кодов ограниченной длины. Сам кеш трасс внутри виртуальной машины выглядит так:Это просто массив из трасс длиной, не превышающей возможную длину байт-кода. Решение ленивое, практически для экономии памяти имеет смысл использовать хеш-таблицу.В начале работы интерпретатора первый обработчик каждой из трасс будет сам себя компилировать:Главный цикл интерпретатора теперь выглядит так:Компилирующий трассу обработчик чуть сложнее, и, помимо сборки трассы, начинающейся от текущей инструкции, он делает следующее:Нормальный обработчик инструкции:Завершает работу каждой трассы обработчик, не делающий никаких вызовов в хвосте функции:Всё это, конечно, сложнее, чем добавление суперинструкций, но давайте посмотрим, дало ли это нам что-нибудь:Ура, ещё 30 миллисекунд!Как же так? Вместо простых переходов по меткам мы делаем цепочки вызовов обработчиков инструкций, тратим время на вызовы и передачу аргументов, но наш поросёнок всё равно бегает по трассам быстрее простого switch с его метками.Такой выигрыш в производительности трасс достигается благодаря трём факторам:Прежде чем подвести итоги наших тренировок, мы с поросёнком решили испробовать ещё одну древнюю технику интерпретации программ — шитый код.Любая интересующаяся историей интерпретаторов свинья слышала про  (англ. threaded code). Вариантов этого приёма множество, но все они сводятся к тому, чтобы вместо массива опкодов идти по массиву, например, указателей на функции или метки, переходя по ним непосредственно, без промежуточного опкода.Вызовы функций — дело дорогое и особого смысла в наши дни не имеющее; большая часть других версий шитого кода нереализуема в рамках стандартного C. Даже техника, о которой речь пойдёт ниже, использует широко распространённое, но всё же нестандартное расширение C — указатели на метки.В версии шитого кода (англ. token threaded code), которую я выбрал для достижения наших свинских целей, мы сохраняем байт-код, но перед началом интерпретации создаём таблицу, отображающую опкоды инструкций на адреса меток обработчиков инструкций:Обратите внимание на символы && — это указатели на метки с телами инструкций, то самое нестандартное расширение GCC.Для начала выполнения кода достаточно прыгнуть по указателю на метку, соответствующую первому опкоду программы:Никакого цикла здесь нет и не будет, каждая из инструкций сама делает прыжок к следующему обработчику:Отсутствие switch «размазывает» точки ветвлений по телам инструкций, что в теории должно помочь предсказателю ветвлений при внеочередном выполнении инструкций. Мы как бы встроили switch прямо в инструкции и вручную сформировали таблицу переходов.Вот и вся техника. Поросёнку она понравилась своей простотой. Посмотрим, что получается на практике:Упс! Это самая медленная из всех наших техник! Что же случилось? Выполним те же тесты, выключив все оптимизации GCC:Здесь шитый код показывает себя лучше.Тут играют роль три фактора:По старой памяти эту технику ещё используют в коде, например, интерпретатора Python VM, но, честно говоря, в наши дни это уже архаизм.Давайте, наконец, подведём итоги и оценим успехи, которых добилась наша свинья.\r\nНе уверен, что это можно назвать полётом, но, давайте признаем, наш поросёнок прошёл большой путь от 550 миллисекунд на сто пробежек по «решету» до финальных 370 миллисекунд. Мы использовали разные техники: суперинструкции, избавление от проверки интервалов значений, сложную механику трасс и, наконец, даже шитый код. При этом мы, в общем-то, действовали в рамках вещей, реализованных во всех популярных компиляторах C. Ускорение в полтора раза, как мне кажется, это неплохой результат, и поросёнок заслужил лишнюю порцию отрубей в корыте.Одно из неявных условий, которое мы со свиньёй себе поставили, — сохранение стековой архитектуры машины «ПоросёнокВМ». Переход к регистровой архитектуре, как правило, уменьшает количество необходимых для логики программ инструкций и, соответственно, может помочь избавиться от лишних выходов в диспетчер инструкций. Думаю, ещё 10—20% времени на этом можно было бы срезать.Основное же наше условие — отсутствие динамической компиляции — тоже не закон природы. Накачать свинью стероидами в виде JIT-компиляции в наши дни очень даже несложно: в библиотеках вроде  или  вся грязная работа уже сделана. Но время на разработку и общий объём кода даже с использованием библиотек здорово увеличиваются.Существуют, конечно, и другие приёмы, до которых у нашего поросёнка не дошли копытца. Но пределов совершенству нет, и наше свинское путешествие — вторая часть серии статей про интерпрепретаторы байт-кодов — всё же должно где-то закончиться. Если читателям придут в голову интересные способы разогнать свинью, мы с поросёнком будем рады их испробовать. Отдельная благодарность моей сестре, Ренате Казановой, за эскизы иллюстраций, и нашему иллюстратору, Владимиру Шопотову (), за финальные рисунки. Оригинальный поросенок не очень разговорчив в целом, и понимает только примитивный ассемблер. Но  каким-то волшебным образом за несколько часов сделал для него небольшой язык — . Теперь можно хрюкать без ограничений! Читатель  предложил еще одну оптимизацию: кеширование вершины стека в отдельной переменной. Удивительным образом это изменение делает шитый код самым быстрым вариантом из всех; для него решето Эратосфена работает в два раза быстрее оригинальной наивной версии интерпретатора. Всех любопытствующих прошу смотреть в .", "url": "https://habr.com/ru/company/badoo/blog/428878/"},
{"title": "The Kernel-Bridge Framework: мостик в Ring0", "article_text": "Хотели ли Вы когда-нибудь заглянуть под капот операционной системы, посмотреть на внутреннее устройство её механизмов, покрутить винтики и посмотреть на открывшиеся возможности? Возможно, даже хотели поработать напрямую с железом, но считали, что драйвера — rocketscience?\r\nПредлагаю вместе пройтись по мостику в ядро и посмотреть, насколько глубока кроличья нора.\r\nИтак, представляю драйвер-фреймворк для kernel-хакинга, написанный на C++17, и призванный, по возможности, снять барьеры между ядром и юзермодом или максимально сгладить их присутствие. А также, набор юзермодных и ядерных API и обёрток для быстрой и удобной разработки в Ring0 как для новичков, так и для продвинутых программистов.\r\nОсновные возможности:\r\n… и многое другое.\r\nА начнём мы с загрузки и подключения фреймворка в наш проект на C++.\r\nДля сборки очень желательно пользоваться новейшей версией Visual Studio и последним доступным пакетом WDK (Windows Driver Kit), скачать который можно с .\r\nДля тестирования прекрасно подойдёт бесплатный VMware Player с установленной Windows, не ниже Windows 7, любой разрядности.\r\nСборка тривиальная и вопросов не вызовет:\r\nВ результате мы получим драйвер, юзермодную библиотеку, а также сопутствующие служебные файлы ( для ручной установки,  для подписи драйвера на Microsoft Hardware Certification Publisher и т.д.).\r\nДля установки драйвера (если нет необходимой для х64 цифровой подписи кода — соответствующего EV-сертификата) нужно перевести систему в тестовый режим, игнорирующий наличие цифровой подписи у драйверов. Для этого выполним в командной строке от имени администратора:\r\n… и перезагрузим машину. Если всё сделано правильно, в нижнем правом углу появится надпись, что Windows находится в тестовом режиме.\r\nНастройка тестовой среды завершена, приступим к использованию API в нашем проекте.\r\nФреймворк имеет следующую иерархию: — набор функций для использования в драйверах и ядерных модулях, не имеют внешних зависимостей и могут быть свободно использованы в сторонних проектах — набор юзермодных обёрток над драйвером и служебные функции для работы с PE-файлами, PDB-символами и т.д. — одновременно и юзермодные, и ядерные хедеры, содержащие необходимые общие типы\r\nДрайвер можно загрузить двумя способами: как обычный драйвер и как минифильтр. Второй способ предпочтительный, т.к. открывает доступ к расширенному функционалу фильтров и юзермодных каллбэков на системные события.\r\nИтак, создадим консольный проект на C++, подключим необходимые заголовочные файлы и загрузим драйвер:\r\nОтлично! Теперь мы можем использовать API и взаимодействовать с ядром.\r\nНачнём с наиболее востребованного функционала в среде разработчиков читов — чтение и запись памяти чужого процесса:\r\nНичего сложного! Опустимся на уровень ниже — чтение и запись ядерной памяти:\r\nА что насчёт функций для взаимодействия с железом? Например, I/O-порты.\r\nПробросим их в юзермод, взведя 2 бита IOPL в регистре EFlags, отвечающие за уровень привилегий, на котором доступны инструкции ///. \r\nТаким образом, мы сможем выполнять их в юзермоде без ошибки Privileged Instruction:\r\nНо что насчёт настоящей свободы? Ведь зачастую хочется выполнить произвольный код с привилегиями ядра. Напишем весь ядерный код в юзермоде и передадим на него управление из ядра (SMEP отключается автоматически, перед вызовом драйвер сохраняет FPU-контекст и сам вызов происходит внутри -блока):\r\nНо кроме баловства с шеллами, есть и серьёзный функционал, позволяющий создавать простейшие DLP на основе подсистемы файловых, объектных и процессных фильтров.\r\nФреймворк позволяет фильтровать ///, а также события открытия\\дуплицирования хэндлов () и события запуска процессов\\потоков и подгрузки модулей (). Это позволит, к примеру, блокировать доступ к произвольным файлам или подменять информацию о серийных номерах жёсткого диска.\r\nПринцип работы:\r\nПример подписки на  и урезание доступа к текущему процессу:\r\nИтак, мы вкратце пробежались по основным моментам юзермодной части фреймворка, но за кадром остался ядерный API.\r\nВесь API и обёртки расположены в соответствующей папке: \r\nОни включают работу с памятью, с процессами, со строками и блокировками, и много с чем ещё, существенно упрощая разработку своих собственных драйверов. API и обёртки зависят только от самих себя и не зависят от внешнего окружения: Вы можете свободно использовать их в своём собственном драйвере.\r\nПример работы со строками в ядре — камень преткновения всех новичков:\r\nЕсли же Вы хотите реализовать свой собственный обработчик для своего IOCTL-кода, вы очень легко можете сделать это по следующей схеме:\r\nПоддерживаются все три вида ввода-вывода (METHOD_BUFFERED, METHOD_NEITHER и METHOD_IN_DIRECT/METHOD_OUT_DIRECT), по-умолчанию используется METHOD_NEITHER.\r\nВот и всё! В статье охвачена лишь малая толика всех возможностей. Надеюсь, фреймворк будет полезен начинающим разработчикам компонентов ядра, реверс-инженерам, разработчикам читов, античитов и защит. \r\nА также, принять участие в разработке приглашаются все желающие. В дальнейших планах:\r\nБлагодарю за внимание!", "url": "https://habr.com/ru/post/429198/"},
{"title": "«Lock-free, or not lock-free, that is the question» или «Здоровый сон хуже горькой редьки»", "article_text": "На написание данной статьи меня подвигли комментарии к статье \"\". Речь в данной статье пойдёт о разработке многопоточных приложений, применимости lock-free к некоторым кейсам возникшим в процессе работы над , о функции  и насилии над планировщиком задач.Вобщем всё довольно сумбурно, надеюсь ход мысли в изложении будет понятен. Если интересно то прошу под кат.Событийно- ориентированное ПО всегда чего-то ждёт. Будь то GUI или сетевой сервер, они ждут каких-либо событий: поступления ввода с клавиатуры, события мыши, поступление пакета данных по сети. Но всякое ПО ждёт по разному. Lock-free системы вообще не должны ждать. По крайней мере использование lock-free алгоритмов, должно происходить там где ждать не нужно, и даже вредно. Но ведь мы говорим о конкурентных (много-поточных) системах, и как ни странно lock-free алгоритмы тоже ждут. Да они не блокируют исполнение параллельных потоков, но сами при этом ждут возможности сделать что-либо без блокировки. LAppS очень активно использует мьютексы и семафоры. При этом в стандарте C++ семафоры отсутствуют. Механизм очень важный и удобный, однако C++ должен работать в системах, в которых нет поддержки семафоров, и поэтому в стандарт семафоры не включены. При этом если семафоры, я использую потому, что они удобны, то мьютексы потому, что вынужден. Поведение мьютекса в случае конкурентного lock() также как и sem_wait() в Linux, помещает ожидающий поток в конец очереди планировщика задач, и когда она оказывается в топ-е, проверка повторяется и без возврата в userland, поток помещается опять в очередь, если ожидаемое событие ещё не произошло. Это очень важный момент. И я решил проверить, могу-ли я отказаться от std::mutex и POSIX-семафоров, эмулируя их с помощью std::atomic, перенеся нагрузку по большей части в userland. На самом деле не удалось, но обо всём по порядку. Во первых у меня есть несколько секций в которых эти эксперименты могли-бы оказаться полезными:Начнём с \"неблокирующих-блокировок\". Давайте напишем свой мьютекс с использованием атомиков, как это показано в некоторых выступлениях Х. Саттера (оригинального кода нет, поэтому по памяти и поэтому код на 100% с оригиналом не совпадает, да и у Саттера этот код относился к прогрессу C++20, поэтому есть отличия). И несмотря на простоту этого кода, в нём есть подводные камни.В отличии от std::mutex::unlock(), поведение test::mutex:unlock() при попытке разблокировать из другого потока, — детерминированное. Будет выброшено исключение. Это хорошо, хоть и не соответствует поведению стандарта. А что в этом классе плохо? Плохо то, что метод test::mutex:lock() будет безбожно жрать ресурсы ЦП в выделенных потоку квотах времени, в попытках завладеть мьютексом, которым уже владеет другой поток. Т.е. цикл в test::mutex:lock() приведёт к бесполезной трате ресурсов ЦП. Каковы наши варианты выхода из этой ситуации? Мы можем воспользоваться sched_yield() (как предлагается в одном из коментариев к вышеупомянутой статье). Так-ли это просто? Во первых для того что-бы использовать sched_yield() необходимо что-бы потоки исполнения использовали политики SCHED_RR, SCHED_FIFO, для своей приоритезации в планировщике задач. В противном случае вызов sched_yield() будет бесполезной тратой ресурсов ЦП. Во вторых, очень частый вызов sched_yield() всё равно повышает расход ресурсов ЦП. Более того, использование real-time политик в вашем приложении, и при условии, что в системе нет других real-time приложений, ограничит очередь планировщика с выбранной политикой только вашими потоками. Казалось-бы, — это хорошо! Нет не хорошо. Вся система станет менее отзывчива, т.к. занята задачей с приоритетом. CFQ окажется в загоне. А ведь в приложении есть и другие потоки, и очень часто возникает ситуация, когда захвативший мьютекс поток, ставится в конец очереди (истекла квота), а поток который ждёт освобождения мьютекса прямо перед ним. В моих экспериментах (case 2) этот метод дал примерно те-же результаты (на 3.8% хуже), что и std::mutex, но система при этом менее отзывчива и расход ресурсов ЦП повышается на 5%-7%. Можно попытаться изменить test::mutex::lock() так (тоже плохо):Тут можно экспериментировать с длительностью сна в наносекундах, 4нс задержки оказались оптимальными для моего ЦП и падение производительности относительно std::mutex в том-же case 2, составило 1.2%. Не факт что nanosleep спал 4нс. На самом деле или больше (в общем случае) или меньше (если прерывался). Падение (!) потребления ресурсов ЦП составило 12%-20%. Т.е. это был такой здоровый сон. В OpenSSL и LibreSSL есть две функции устанавливающие коллбэки для блокирования при использовании этих библиотек в многопоточной среде. Выглядит это так:А теперь самое страшное, использование вышеприведённого мьютекса test::mutex в LibreSSL снижает производительность LAppS почти в 2 раза. Причём независимо от варианта (пустой цикл ожидания, sched_yield(), nanosleep()).Вобщем case 2 и case 1 вычёркиваем, и остаёмся с std::mutex. Перейдём к семафорам. Есть множество примеров того как реализовать семафоры с помощью std::condition_variable. Все они используют std::mutex в том числе. И такие симуляторы семафоров медленнее (по моим тестам), чем системные POSIX семафоры. Поэтому сделаем семафор на атомиках:О, этот семафор оказывается многократно более быстрым чем системный семафор. Результат отдельного тестирования этого семафора с одним провайдером и 20 консамерами:T.e. этот семафор с почти бесплатным post(), который в 29 раз быстрее системного, ещё и очень быстр в пробуждении ждущих его потоков: 29325 пробуждений¹ в милисeкунду, против 1007 пробуждений в милисeкунду у системного. У него детерминированное поведение при разрушенном семафоре или разрушаемом семафоре. И естественно segfault при попытке использовать уже уничтоженный. (¹) На самом деле столько раз в милисeкунду поток не может быть отложен и пробужен планировщиком. Т.к. post() не блокирующий, при данном синтетическом тесте, wait() очень часто оказывается в ситуации когда и спать не нужно. При этом как минимум 7-мь потоков параллельно читают значение семафора.Но использование его в case 3 в LAppS приводит к потерям производительности независимо от времени сна. Он слишком часто просыпается для проверки, а события в LAppS поступают гораздо медленнее (латентность сети, латентность клиентской части генерирующей нагрузку, и т.д.). А проверять реже, — значит также потерять в производительности. Более того использование сна в подобных случаях и подобным образом совсем вредно, т.к. на другом железе результаты могут оказаться совсем другими (как и в случае ассемблерной инструкции pause), и для каждой модели ЦПУ ещё и придётся подбирать время задержки. Преимущество системных мьютекса и семафора, в том что поток исполнения не просыпается до тех пор пока событие (разблокировка мьютекса или инкремент семафора) не произойдёт. Лишние циклы ЦП не тратятся, — профит. Вобщем, всё от это лукавого, отключение iptables на моей системе даёт от 12% (с TLS) до 30% (без TLS) прироста производительности...", "url": "https://habr.com/ru/post/428087/"},
{"title": "Проблемные аспекты программирования на С++", "article_text": "\r\nЭтот код компилируется, даже, если в точке вызова  не доступно полное объявление класса . Visual Studio выдает следующее предупреждение:", "url": "https://habr.com/ru/post/428898/"},
{"title": "Бесполезный отложенный неблокирующий обмен сообщениями в MPI: лайт-аналитика и туториал для тех, кто немножечко «в теме»", "article_text": "Совсем недавно мне пришлось решать очередную тривиальную учебную задачу от своего преподавателя. Однако, решая ее, мне удалось обратить внимание на вещи о коих я ранее вовсе не задумывался, возможно, не задумывались и Вы. Эта статья скорее будет полезна студентам да и всем, кто начинает свой путь в мир параллельного программирования с использованием MPI.\r\nИтак, суть нашей, в сущности вычислительной задачи, заключается в том, чтобы сравнить во сколько раз программа, использующая неблокирующие отложенные двухточечные передачи быстрее той, что использует блокирующие двухточечные передачи. Измерения будем проводить для входных массивов размерностью 64, 256, 1024, 4096, 8192, 16384, 65536, 262144, 1048576, 4194304, 16777216, 33554432 элементов. По умолчанию предлагается решать ее четырьмя процессами. А вот, собственно, и то, что мы будем считать:\r\nНа выходе у нас должно получиться три вектора: Y1, Y2 и Y3, которые соберет у себя нулевой процесс. Все это дело я буду тестировать на своей системе на базе  с 16 ГБ ОЗУ. Для разработки программ будем использовать реализацию стандарта  (на момент написания статьи она актуальна), Visual Studio Community 2017 и не Fortran.\r\nЯ бы не хотел подробно описывать то, как работают функции MPI, которые будут использованы, за этим всегда можно сходить и , поэтому проведу лишь краткий обзор того, что мы будем использовать. — осуществляет блокирующую отправку сообщения, т.е. после вызова функции процесс блокируется до тех пор пока отправляемые им данные не будут записаны из его памяти в внутрисистемный буфер среды MPI, после процесс продолжает работать дальше; — осуществляет блокирующий прием сообщения, т.е. после вызова функции процесс блокируется до тех пор пока не поступят данные от процесса-отправителя и пока эти данные не будут полностью записаны в буфер процесса-приемника средой MPI. — в фоновом режиме подготавливает среду к посылке данных, которая произойдет в некотором будущем и никаких блокировок; — эта функция работает аналогично предыдущей, только на этот раз для приема данных; — запускает сам процесс приема или передачи сообщения, он так же проходит в фоновом режиме а.к.а. без блокировки; — используется для проверки и, при необходимости, ожидания завершения посылки или приема сообщения, а вот она как раз и блочит процесс при необходимости (если данные «недоотправлены» или «недоприняты»). Например, процесс хочет использовать данные, которые к нему еще не дошли — не хорошо, поэтому вставляем MPI_Wait перед тем местом, где ему эти данные понадобятся (вставляем её даже если просто есть риск повреждения данных). Еще пример, процесс запустил фоновую передачу данных, а после запуска передачи данных сразу же стал эти данные как-то изменять — не хорошо, поэтому вставляем MPI_Wait перед тем местом в программе, где он начинает эти данные изменять (тут так же вставляем её даже если просто есть риск повреждения данных).\r\nТаким образом  последовательность вызовов при отложенном неблокирующем обмене такая:\r\nТак же я использовал в своих тестовых программах , , смысл их в принципе аналогичен MPI_Start и MPI_Wait соответственно, только они оперируют несколькими посылками и/или передачами. Но это еще далеко не весь список функций старта и ожидания, есть еще несколько функций проверки завершенности операций.\r\nДля наглядности построим граф выполнения вычислений четырьмя процессами. При этом надо постараться относительно равномерно распределить все векторные арифметические операции по процессам. Вот что у меня получилось:\r\nВидите эти массивы T0-T2? Это буферы для хранения промежуточных результатов операций. Так же на графе при передаче сообщений от одного процесса к другому в начале стрелки стоит название массива, данные которого передаются, а в конце стрелки — массив, принимающий эти данные.\r\nНу что же, когда мы наконец ответили на вопросы:\r\nОсталось только ее решить…\r\nДалее я представлю коды двух программ о которых шла речь выше, но для начала дам еще немного пояснений что да как.\r\nВсе векторные арифметические операции я вынес в отдельные процедуры (add, sub, mul, div) дабы увеличить читаемость кода. Все входные массивы инициализируются в соответствии с формулами, которые я указал  наобум. Так как нулевой процесс осуществляет сборку результатов работы со всех остальных процессов, следовательно, он работает дольше всех, поэтому время его работы логично считать равным времени выполнения программы (как мы помним, нас интересует: арифметика + меседжинг) и в первом и во втором случае. Измерение интервалов времени будем осуществлять с помощью функции  и заодно я решил вывести какое у меня там разрешение часиков с помощью  (где-то в душе я надеюсь, что они подвяжутся к моему инвариантному TSC, в этом случае, я даже готов простить им погрешность, связанную с временем вызова функции MPI_Wtime). Так вот, соберем воедино все о чем я писал выше и в соответствии с графом разработаем наконец эти программы (и отладим конечно же тоже).\r\nКому интересно посмотреть код:\r\nДавайте запустим наши программы для массивов разных размеров и посмотрим что из этого выйдет. Результаты тестов сведем в таблицу, в последнем столбце которой рассчитаем и запишем коэффициент ускорения, который определим так: К = T / T\r\nЕсли посмотреть на эту таблицу чуть внимательнее чем обычно, то можно заметить, что при увеличении числа обрабатываемых элементов коэффициент ускорения убывает как-то так:\r\nДавайте попробуем определить в чем же дело? Для этого я предлагаю написать маленькую тестовую программку, которая будет измерять время каждой векторной арифметической операции и бережно сводить результаты в обыкновенный текстовый файл.\r\nВот, собственно, сама программа:\r\nПри запуске она просит ввести число циклов измерений, я тестировал для 10000 циклов. На выходе получаем усредненный результат по каждой операции:\r\nДля измерения времени я использовал высокоуровненую . Настойчиво рекомендую почитать  чтобы большинство вопросов по измерению времени этой функцией отпали сами собой. Она по моим наблюдениям цепляется за TSC (но теоретически может и не за него), а возвращает, согласно справке, текущее число тиков счетчика. Но дело в том, что мой счетчик физически не может измерить интервал времени 32 нс (см. первую строку таблицы результатов). Такой результат получается из-за того, что между двумя вызовами QueryPerformanceCounter проходит то 0 тиков, то 1. Для первой строки в таблице можно лишь заключить, что примерно треть результатов из 10000 равны 1 тик.  Теперь, давайте откроем любую из программ и посчитаем сколько всего операций каждого типа в ней встречается, традиционно все «размажем» по очередной таблице:\r\nНаконец-то мы знаем время каждой векторной арифметической операции и сколько её в нашей программе, попробуем узнать сколько времени тратится на эти операции в параллельных программах и сколько времени уходит на блокирующий и отложенный неблокирующий обмен данными между процессами и снова, для наглядности, сведем это в таблицу:\r\nПо результатам полученных данных построим график трех функций: первая — описывает изменение времени, тратящегося на блокирующие передачи между процессами, от числа элементов массивов, вторая — изменение времени, тратящегося на отложенные неблокирующие передачи между процессами, от числа элементов массивов и третья — изменение времени, тратящегося на арифметические операции, от числа элементов массивов:\r\nКак вы уже обратили внимание, вертикальная шкала графика — логарифмическая, это вынужденная мера, т.к. разброс времен слишком большой и на обычном графике не было бы видно ровным счетом ничего. Обратите внимание на функцию зависимости времени, затрачиваемого на арифметику, от количества элементов, она благополучно обгоняет две другие функции уже на приблизительно на 1 млн. элементов. Все дело в том, что она растет на бесконечности быстрее, чем два ее оппонента. Поэтому, с увеличением числа обрабатываемых элементов, время работы программ все более определяется арифметикой, а не передачами. Предположим, что вы увеличили число передач между процессами, концептуально вы увидите лишь то, что момент, когда функция арифметики обгонит две другие произойдет попозже.\r\nТаким образом, продолжая увеличивать длину массивов вы придете к тому, что программа с отложенными неблокирующими передачами будет лишь совсем немного быстрее той, что использует блокирующий обмен. А если устремить длину массивов в бесконечность (ну или просто брать очень уж длинные массивы), то время работы вашей программы будет прочти на 100% определяться вычислениями, а коэффициент ускорения будет благополучно стремиться к 1.", "url": "https://habr.com/ru/post/427219/"},
{"title": "Learn OpenGL. Урок 6.3 – Image Based Lighting. Диффузная облученность", "article_text": " Освещение на основе изображения или () – является категорией методов освещения, основанных не на учете аналитических источников света (рассмотренных в ), но рассматривающих все окружение освещаемых объектов как один непрерывный источник света. В общем случае техническая основа таких методов лежит в обработке кубической карты окружения (подготовленной в реальном мире или созданная на основе трехмерной сцены) таким образом, чтобы хранимые в карте данные могли быть напрямую использованы в расчетах освещения: фактически каждый тексель кубической карты рассматривается как источник света. В общем и целом, это позволяет запечатлеть эффект глобального освещения в сцене, что является важной компонентой, передающей общий «тон» текущей сцены и помогающей освещаемым объектам быть лучше «встроенными» в нее.\r\nПоскольку алгоритмы IBL учитывают освещение от некоего «глобального» окружения, то их результат считается более точной имитацией фонового освещения или даже очень грубой аппроксимацией глобального освещения. Этот аспект делает методы IBL интересными в плане включения в модель PBR, поскольку задействование освещения от окружения в модели освещения позволяет объектам выглядеть гораздо более физически корректно.\r\nДля включения влияния IBL в уже описанную систему PBR вернемся к знакомому уравнению отражательной способности:\r\nКак было описано ранее основной целью является вычисление интеграла для всех входящих направлений излучения  по полусфере . В  вычисление интеграла было необременительным, поскольку мы заранее знали число источников света, а, значит, и все те несколько направлений падения света, что им соответствуют. В этот же раз интеграл с наскока не решить:  падающий вектор  от окружающей среды может нести с собой ненулевую энергетическую яркость. В итоге для практической применимости метода требуется удовлетворить следующие требования:\r\nНу, первый пункт разрешается сам собой. Здесь уже проскочил намек на решение: один из методов представления облученности сцены или окружения – это кубическая карта, прошедшая специальную обработку. Каждый тексель в такой карте можно рассматривать как отдельный излучающий источник. Осуществляя выборку из такой карты по произвольному вектору  мы легко получаем энергетическую яркость сцены в этом направлении.\r\nИтак, получаем энергетическую яркость сцены для произвольного вектора : \r\nЗамечательно, однако решение интеграла требует от нас осуществления выборок из карты окружения не с одного направления, а со всех возможных в полусфере. И так – на каждый затеняемый фрагмент. Очевидно, для задач реального времени это практически неосуществимо. Более эффективным методом было бы часть подынтегральных операций просчитать заранее, еще вне нашего приложения. Но для этого придется закатать рукава и поглубже погрузиться в суть выражения отражающей способности:\r\nВидно, что части выражения, связанные с рассеянной  и зеркальной  компонентами BRDF, являются независимыми. Можно разделить интеграл на две части:\r\nТакое разделение на части позволит нам разобраться с каждой из них по отдельности и в этом уроке мы расправимся с частью, отвечающей за рассеянное освещение.\r\nПроанализировав вид интеграла по диффузной составляющей можно сделать вывод, что диффузная составляющая Ламберта по сути есть постоянная (цвет , коэффициент преломления  и  являются постоянными в условиях подынтегрального выражения) и не зависит от прочих переменных. С учетом этого факта можно вынести постоянные за знак интеграла:\r\nТак мы получим интеграл, зависящий только от  (предполагается, что  соответствует центру кубической карты окружения). Основываясь на этой формуле можно рассчитывать или, еще лучше, пред-рассчитать новую кубическую карту, хранящую результат вычисления интеграла диффузной составляющей для каждого направления выборки (или текселя карты)  с использованием операции свертки.\r\nСверткой называют операцию применения некоторого вычисления к каждому элементу в наборе данных, с учетом данных всех остальных элементов набора. В данном случае такими данными является энергетическая яркость сцены или карты окружения. Таким образом, для вычисления одного значения на каждом направлении выборки в кубической карте мы вынуждены будем принять во внимание значения, взятые со всех прочих возможных направлений выборки на полусфере, лежащей вокруг точки выборки.\r\nДля свертки карты окружения нужно решить интеграл для каждого результирующего направления выборки  путем осуществления множественных дискретных выборок вдоль направлений , принадлежащих полусфере , и усредняя итоговую энергетическую яркость. Полусфера, на основе которой берутся направления выборки  ориентирована вдоль вектора , представляющего целевое направление, для которого вычисляется свертка в текущий момент. Посмотрите на картинку для лучшего понимания:\r\nТакая пред-рассчитанная кубическая карта, хранящая результат интегрирования для каждого направления выборки , может быть рассмотрена и как хранящая результат суммирования всего непрямого диффузного освещения в сцене, падающего на некоторую поверхность, сориентированную вдоль направления . Другими словами, такие кубические карты называют картами облученности (irradiance map), поскольку подвергнутая предварительной свертке кубическая карта окружения позволяет осуществлять непосредственную выборку величины облученности сцены, исходящую с произвольного направления , без дополнительных вычислений. Ниже представлен пример кубической карты окружения и полученная на её основе карта облученности (за авторством ), усредняющая энергетическую яркость окружения для каждого выходного направления .\r\nИтак, данная карта хранит результат свертки в каждом текселе (соответствующем направлению ), и внешне такая карта выглядит будто хранящей усредненный цвет карты окружения. Выборка в любом направлении из такой карты вернет значение облученности, исходящей с этого направления.\r\nВ  уже был кратко отмечен тот факт, что для корректной работы PBR модели освещения чрезвычайно важен учет HDR диапазона яркостей присутствующих источников света. Поскольку модель PBR на входе принимает параметры так или иначе основанные на вполне конкретных физических величинах и характеристиках, то логично потребовать соответствия энергетической яркости источников света их реальным прототипам. Неважно как мы обоснуем конкретную величину потока излучения для каждого источника: сделаем грубую инженерную оценку или же обратимся к – разница в характеристиках между комнатной лампой и солнцем будет громадной в любом случае. Без использования  диапазона будет просто невозможно достаточно точно установить относительные яркости разнообразных источников света.\r\nИтак, PBR и HDR – друзья на век, это понятно, только как относится этот факт к методам освещения на основе изображений? В прошлом уроке было показано, что перевести PBR в HDR диапазон рендеринга дело несложное. Остается одно «но»: поскольку непрямое освещение от окружения основывается на кубической карте окружения, необходим способ сохранить HDR характеристики этого фонового освещения в карте окружения.\r\nДо сего момента мы применяли карты окружения, созданные в LDR формате (как, например, ). Выборку цвета из них мы использовали в рендеринге как есть и это вполне приемлемо для непосредственного шейдинга объектов. И совершенно не годится при использовании карт окружения как источников физически достоверных измерений.\r\nПознакомитесь с форматом файлов изображений RGBE. Файлы с расширением \"\" используются для хранения изображений с широким динамическим диапазоном, отводя по одному байту под каждый элемент цветовой триады и еще один байт под общую экспоненту. В том числе формат позволяет хранить и кубические карты окружения с диапазоном цветовой интенсивности, выходящим за LDR диапазон [0., 1.]. А значит источники света могут сохранить свою реальную интенсивность, будучи представленными такой картой окружения.\r\nВ сети водится достаточно бесплатных карты окружения в формате RGBE, снятых в различных реальных условиях. Вот, например, пример с сайта :\r\nВозможно, вы удивитесь увиденному: ведь это искаженное изображение совсем не похоже на обычную кубическую карту с её выраженной разбивкой на 6 граней. Объясняется то просто: данная карта окружения была спроецирована со сферы на плоскость – применена . Сделано это для возможности хранения в формате, не поддерживающем режим хранения кубических карт как есть. Безусловно, такой метод проецирования несет с собой недостатки: разрешение по горизонтали гораздо выше, нежели по вертикали. В большинстве случаев применения в рендеринге это допустимое соотношение, поскольку обычно интересные детали окружения и освещения как раз-таки располагаются в горизонтальной плоскости, а не в вертикальной. Ну и плюс ко всему нам нужен код преобразования обратно в кубическую карту.\r\nЗагрузка данного формата изображений своими силами требует знания , что пусть и не сложно, но все равно трудоемко. На наше счастье библиотека загрузки изображений , реализованная в один заголовочный файл, поддерживает загрузку RGBE файлов, возвращая массив чисел с плавающей точкой – то что надо для наших целей! Добавив библиотеку в свой проект загрузка данных изображений реализуется предельно просто:\r\nБиблиотека автоматически преобразует значения из внутреннего HDR формата в обычные вещественные 32-битные числа, по умолчанию с тремя цветовыми каналами. Вполне достаточно для сохранения данных исходного HDR изображения в обычной 2D текстуре с плавающей точкой.\r\nРавнопрямоугольную развертку вполне можно использовать для непосредственного осуществления выборок из карты окружения, однако это потребовало бы затратных математических операций, в то время как выборка из нормальной кубической карты было бы практически бесплатным по производительности. Именно из этих соображений в данном уроке мы займемся преобразованием равнопрямоугольного изображения в кубическую карту, которая и будет использоваться далее. Однако, здесь также будет показан и метод прямой выборки из равнопрямоугольной карты с использованием трехмерного вектора, чтобы вы могли выбрать подходящий именно вам метод работы.\r\nДля преобразования понадобится отрисовать куб единичного размера, наблюдая его изнутри, спроецировать на его грани равнопрямоугольную карту и затем извлечь шесть изображений с граней в качестве граней кубической карты. Вершинный шейдер этого этапа довольно прост: он просто обрабатывает вершины куба как есть, а также передает их непреобразованные позиции во фрагментный шейдер для использования в качестве трехмерного вектора выборки:\r\nВо фрагментном шейдере мы затеняем каждую грань кубика так, как если бы попытались аккуратно обернуть кубик листом с равнопрямоугольной картой. Для этого берется переданное во фрагментный шейдер направление выборки, обрабатывается особой тригонометрической магией и, в конечном счете, осуществляется выборка из равнопрямоугольной карты так, будто это на сам деле кубическая карты. Результат выборки непосредственно сохраняется как цвет фрагмента грани кубика:\r\nЕсли на самом деле отрисовать куб с этим шейдером и привязанной HDR картой окружения, то получится нечто подобное: \r\nТ.е. видно, что фактически мы спроецировали прямоугольную текстуру на куб. Замечательно, но как это нам поможет в формировании настоящей кубической карты? Чтобы покончить с этой задачей необходимо отрендерить такой же кубик 6 раз с камерой, смотрящей на каждую из граней, при том записывая вывод в отдельный объект :\r\nБезусловно, не забудем организовать и память под хранение каждой из шести граней будущей кубической карты:\r\nПосле этой подготовки останется только непосредственно осуществить перенос частей равнопрямоугольной карты на грани кубической карты.\r\nНе будем сильно вдаваться в детали, тем более что код во много повторяет виденный в уроках по и . В принципе, все сводится к подготовке шести отдельных видовых матриц, ориентирующих камеру строго на каждую из граней кубика, а также специальной матрицы проекции с углом зрения в 90°, чтобы запечатлеть грань куба целиком. Затем просто шесть раз осуществляется рендер, а результат сохраняется во фреймбуфер с плавающей точкой:\r\nЗдесь используется прикрепление цвета кадрового буфера, и поочередная смена подключенной грани кубической карты, что приводит к непосредственному выводу рендера на одну из граней карты окружения. Данный код необходимо выполнить всего один раз, после чего у нас на руках останется полноценная карта окружения , содержащая результат преобразования исходной равнопрямоугольной версии HDR карты окружения.\r\nПротестируем полученную кубическую карту, набросав простейший шейдер для скайбокса:\r\nОбратите внимание на трюк с компонентами вектора : мы используем тетраду при записи преобразованной координаты вершины, чтобы обеспечить всем фрагментам скайбокса максимальную глубину, равную 1.0 (подход уже использовался в ). Не забудем поменять функцию сравнения на :\r\nФрагментный шейдер просто осуществляет выборку из кубической карты:\r\nВыборка из карты осуществляется на основе интерполированных локальных координат вершин куба, что является корректным направлением выборки в данном случае (опять же, обсуждалось в уроке по скайбоксам, ). Поскольку компоненты переноса в видовой матрице были проигнорированы, то рендер скайбокса не будет зависеть от положения наблюдателя, создавая иллюзию бесконечно далекого фона. Поскольку здесь мы напрямую выводим данные из HDR карты в фреймбуфер по умолчанию, являющийся LDR приемником, то необходимо вспомнить и о тональной компрессии. И, последнее: практически все HDR карты сохраняются в линейном пространстве, а, значит, необходимо применить и как финальный аккорд обработки.\r\nИтак, при выводе полученного скайбокса вместе с уже знакомым массивом сфер получается нечто подобное:\r\nЧто ж, потрачено немало усилий, но в итоге мы успешно освоились со считыванием HDR карты окружения, с преобразованием её из равнопрямоугольной в кубическую карту, с выводом HDR кубической карты в виде скайбокса в сцене. Более того, код преобразования в кубическую карту посредством рендера на шесть граней кубической карты пригодится нам и далее – в задаче . Код всего процесса преобразования – .\r\nКак было сказано в начале урока, главная наша цель – решить интеграл для всех возможных направлений непрямого диффузного освещения с учетом заданной облученности сцены в виде кубической карты окружения. Известно, что мы можем получить значение энергетической яркости сцены  для произвольного направления , осуществляя выборку из HDR кубической карты окружения в этом направлении. Для решения интеграла потребуется осуществить выборку энергетической яркости сцены со всех возможных направлений в полусфере  каждого рассматриваемого фрагмента.\r\nОчевидно, что задача выборки освещения от окружения со всех возможных направлений в полусфере  является вычислительно невыполнимой – таких направлений бесконечное число. Однако, можно применить аппроксимацию, взяв конечное количество направлений, выбранных случайно или расположенных равномерно внутри полусферы. Это позволит получить достаточно хорошее приближение к истинной облученности, по сути решая интересующий нас интеграл в виде конечной суммы.\r\nНо для задач реального времени даже такой подход все еще невероятно накладен, ведь выборки осуществляются для каждого фрагмента, и число выборок должно быть достаточно высоким для приемлемого результата. Таким образом неплохо было бы данные для этого шага, вне процесса рендеринга. Поскольку ориентация полусферы определяет из какой области пространства мы запечатлеваем облученность, то можно заранее рассчитать облученность для каждой возможной ориентации полусферы на основе всех возможных исходящих направлений :\r\nВ итоге, при заданном произвольном векторе , мы сможем осуществить выборку из предрассчитанной карты облученности, дабы получить величину диффузной облученности на этом направлении. Для определения величины непрямого диффузного излучения в точке текущего фрагмента мы берем величину суммарной облученности из полусферы, сориентированной по нормали к поверхности фрагмента. Другими словами, получение облученности сцены сводится к простой выборке:\r\nДалее, для создания карты облученности необходимо осуществить свертку карты окружения, преобразованной к кубической карте. Нам известно, что для каждого фрагмента его полусфера считается сориентированной вдоль нормали к поверхности . В этом случае свертка кубической карты сводится к расчету усредненной суммы энергетической яркости со всех направлений  внутри полусферы , сориентированной вдоль нормали :\r\nК счастью, та трудоемкая предварительная работа, что мы совершили в начале урока теперь позволит довольно просто преобразовать карту окружения в виде кубической карты в специальном фрагментном шейдере, вывод которого будет использован для формирования новой кубической карты. Для этого пригодится тот самый кусочек кода, который был использован для перевода равнопрямоугольной карты окружения в кубическую карту. \r\nОстанется только взять другой шейдер обработки:\r\nЗдесь сэмплер представляет собой HDR кубическую карту окружения, ранее полученную из равнопрямоугольной.\r\nСпособов осуществить свертку карты окружения существует немало, в данном случае для каждого текселя кубической карты мы сформируем несколько векторов выборки из полусферы , сориентированной вдоль направления выборки, и усредним результаты. Количество векторов выборки будет фиксированным, а сами вектора – равномерно распределены внутри полусферы. Отмечу, что подынтегральное выражение является непрерывной функцией, а дискретная оценка этой функции будет лишь приближением. И чем больше векторов выборки мы возьмем, тем ближе к аналитическому решению интеграла мы будем.\r\nПодынтегральная часть выражения для отражающей способности зависит от телесного угла  – величины с которой не очень удобно работать. Вместо интегрирования по телесному углу  мы изменим выражение, приведя к интегрированию по сферическим координатам  и :\r\nУгол Фи будет представлять азимут в плоскости основания полусферы, изменяясь от 0 до . Угол  будет представлять угол места, изменяясь в пределах от 0 до . Измененное выражение для отражающей способности в таких терминах выглядит следующим образом:\r\nРешение такого интеграла потребует взятия конечного числа выборок в полусфере  и усреднения результатов. Зная число выборок  и  по каждой из сферических координат можно перевести интеграл к :\r\nПоскольку обе сферические координаты изменяются дискретно, то в каждый момент выборка осуществляется с некой усредненной площади на полусфере, как видно на рисунке выше. Из-за природы сферической поверхности размер площадки дискретной выборки неизбежно уменьшается с увеличением угла места  и приближением к зениту. Для компенсации этого эффекта уменьшения площади мы добавили в выражение весовой коэффициент .\r\nВ итоге осуществление дискретной выборки в полусфере на основе сферических координат для каждого фрагмента в виде кода выглядит следующим образом:\r\nПеременная определяет размер дискретного шага по поверхности полусферы. Меняя эту величину можно добиться увеличения или уменьшения точности результата.\r\nВнутри обоих циклов из сферических координат формируется обычный 3хмерный вектор выборки, переводится из касательного в мировое пространство и далее используется для выборки из HDR кубической карты окружения. Результат выборок накапливается в переменной , которая в финале обработки будет поделена на число сделанных выборок, дабы получить усредненное значение облученности. Обратите внимание, что результат выборки из текстуры модулируется двумя величинами:  – для учета ослабления света на больших углах, и  – для компенсации уменьшения площади выборки при приближении к зениту.\r\nОстается только разобраться с кодом, осуществляющим рендер и захват результатов свертки карты окружения . Сперва создадим кубическую карту, для хранения облученности (потребуется осуществить однократно, до входа в основной цикл рендера):\r\nПоскольку карта облученности получается на основе усреднения равномерно распределенных выборок энергетической яркости карты окружения, то она практически не содержит высокочастотных деталей и элементов – для её хранения будет достаточно текстуры довольно малого разрешения (здесь – 32х32) и включенной линейной фильтрации.\r\nДалее, настроим фреймбуфер захвата на данное разрешение:\r\nКод захвата результатов свертки похож на код перевода карты окружения из равнопрямоугольной в кубическую, только используется шейдер свертки:\r\nПосле выполнения этого этапа у нас на руках будет предрассчитанная карта облученности, которую можно непосредственно использовать для расчетов непрямого диффузного освещения. Для проверки того, как прошла свертка – попробуем заменить текстуру скайбокса с карты окружения на карту облученности:\r\nЕсли в результате вы увидели нечто, похожее на сильно размытую карту окружения, то, верней всего, свертка прошла успешно.\r\nПолученная карта облученности используется в диффузной части разделенного выражения отражающей способности и представляет собой накопленный вклад со всех возможных направлений непрямого освещения. Поскольку в данном случае свет приходит не от конкретных источников, а от окружения в целом, то диффузное и зеркальное непрямое освещение мы рассматриваем как фоновое (), заменяя ранее использовавшуюся постоянной величину.\r\nДля начала, не забудем добавить новый сэмплер с картой облученности:\r\nИмея карту облученности, хранящей всю информацию об непрямом диффузном излучении сцены, и нормаль к поверхности, получить данные об облученности конкретного фрагмента так же просто, как сделать одну выборку из текстуры:\r\nОднако, поскольку непрямое излучение содержит данные и для диффузной и для зеркальной компоненты (что мы увидели в разделенной на компоненты версии выражения отражающей способности), нам потребуется промодулировать диффузную составляющую особым образом. Так же, как и в предыдущем уроке, мы используем выражение Френеля для определения степени отражения света для данной поверхности, откуда получим степень преломления света или диффузный коэффициент:\r\nПоскольку фоновое освещение падает со всех направлений в полусфере на основе нормали к поверхности , то невозможно определить единственный медианный () вектор для вычисления коэффициента Френеля. Дабы сымитировать эффект Френеля в таких условиях, приходится рассчитывать коэффициент на основе угла между нормальною и вектором наблюдения. Однако, ранее в качестве параметра для вычисления коэффициента Френеля мы использовали медианный вектор, полученный на основе модели микроповерхностей и зависящий от шероховатости поверхности. Поскольку в данном случае шероховатость не входит в параметры вычисления, то степень отражения света поверхностью будет всегда завышенным. Непрямое освещение в целом должно вести себя так же, как и непосредственное, т.е. от шероховатых поверхностей мы ожидаем меньшей степень отражения по краям. Но поскольку шероховатость не учитывается, то степень зеркального отражения по Френелю для непрямого освещения выглядит нереалистично на шероховатых неметаллических поверхностях (на изображении ниже описываемый эффект преувеличен для большей наглядности):\r\nОбойти эту неприятность можно внесением шероховатости в выражение Фременля-Шлика, процесс описанный :\r\nС учетом шероховатости поверхности при вычислении к-та Френеля, код вычисления фоновой составляющей принимает следующий вид:\r\nКак оказалось, использование освещения на основе изображения по своей сути сводится к одной выборке из кубической карты. Все трудности, в основном, связаны с предварительной подготовкой и переводом карты окружения в карту облученности.\r\nВзяв знакомую сцену из урока об света, содержащую массив сфер с меняющейся металличностью и шероховатостью, и добавив диффузное фоновое освещение от окружения, то получится нечто подобное:\r\nВыглядит все еще странно, поскольку материалы с высокой степенью металличности все еще наличия отражения для того, чтобы по-настоящему выглядеть, хм, металлическими (металлы ведь не отражают диффузное освещение). А в данном случае единственные отражения получены от точечных аналитических источников света. И все же, уже сейчас можно сказать, что сферы выглядят более погруженными в окружение (особенно заметно при переключении карт окружения), поскольку поверхности теперь корректно реагируют на фоновое освещение от окружения сцены.\r\nПолный исходный код урока – . В следующем уроке мы, наконец, разберемся со второй половиной выражения отражающей способности, отвечающей за непрямое зеркальное освещение. После этого шага вы по-настоящему почувствуете мощь подхода PBR в освещении.: У нас есть для координации переводов. Если есть серьезное желание помогать с переводом, то милости просим!", "url": "https://habr.com/ru/post/426987/"},
{"title": "﻿В PVS-Studio появилась поддержка GNU Arm Embedded Toolchain", "article_text": "\r\nВстраиваемые системы давно и прочно вошли в нашу жизнь. Требования к их стабильности и надежности очень высоки, а исправление ошибок обходится дорого. Поэтому для embedded разработчиков особенно актуально регулярное использование специализированных инструментов для обеспечения качества исходного кода. Эта статья расскажет о появлении поддержки GNU Arm Embedded Toolchain в анализаторе PVS-Studio и дефектах кода, найденных в проекте Mbed OS.\r\nАнализатор PVS-Studio уже поддерживает несколько коммерческих компиляторов для встраиваемых систем, например:\r\nТеперь к поддержке добавлен еще один инструмент разработчика — GNU Embedded Toolchain. — коллекция компиляторов от компании Arm, основанная на GNU Compiler Collection. Первый официальный релиз состоялся в 2012 году, и с тех пор проект развивается вместе с GCC.\r\nОсновное предназначение GNU Embedded Toolchain — генерация кода, работающего на «голом железе» (bare metal), то есть напрямую на процессоре без прослойки в виде операционной системы. В комплект поставки входят компиляторы для C и C++, ассемблер, набор утилит GNU Binutils и библиотека . Исходный код всех компонентов полностью открыт и распространяется по лицензии GNU GPL. С официального сайта можно скачать версии под Windows, Linux и macOS.\r\nЧтобы протестировать анализатор, нужно как можно больше исходного кода. Обычно проблем с этим нет, но, когда мы имеем дело с embedded разработкой, нацеленной в первую очередь на устройства, входящие в IoT, найти достаточное количество больших проектов может быть сложно. К счастью, эту проблему удалось решить за счет специализированных операционных систем, исходный код которых в большинстве случаев открыт. Дальше речь пойдет об одной из них.\r\nХотя основной целью статьи является рассказать о поддержке GNU Embedded Toolchain, много про это написать сложно. Тем более, что читатели наших статей наверняка ждут описания каких-то интересных ошибок. Что же, не будем обманывать их ожидания и запустим анализатор на проекте Mbed OS. Это операционная система с открытым исходным кодом, которая разрабатывается при участии компании Arm.\r\nОфициальный сайт: \r\nИсходный код: \r\nВыбор на Mbed OS пал не случайно, вот как описывают проект его авторы:\r\nArm Mbed OS is an open source embedded operating system designed specifically for the «things» in the Internet of Things. It includes all the features you need to develop a connected product based on an Arm Cortex-M microcontroller, including security, connectivity, an RTOS and drivers for sensors and I/O devices.\r\nЭто идеальный проект для сборки с помощью GNU Embedded Toolchain, особенно с учетом участия Arm в его разработке. Сразу оговорюсь, что цели найти и показать как можно больше ошибок в конкретном проекте у меня не было, поэтому результаты проверки рассмотрены кратко.\r\nВ ходе проверки кода Mbed OS анализатор PVS-Studio выдал 693 предупреждения, 86 из них — с приоритетом high. Я не буду подробно рассматривать их все, тем более что многие из них повторяются или не представляют особого интереса. Например, анализатор выдал много предупреждений  (Expression is always true/false), относящихся к однотипным фрагментам кода. Анализатор можно настроить, чтобы существенно сократить количество ложных и неинтересных срабатываний, но такой задачи при написании статьи не ставилось. Желающие могут посмотреть пример подобной настройки, описанной в статье \"\".\r\nДля статьи я отобрал несколько интересных ошибок, чтобы продемонстрировать работу анализатора.\r\nНачнем с распространенного класса ошибок в C и C++ — утечек памяти.\r\nПредупреждение анализатора:  CWE-401 The function was exited without releasing the 'read_buf' pointer. A memory leak is possible. cfstore_test.c 565\r\nКлассическая ситуация при работе с динамической памятью. Выделенный с помощью  буфер используется только внутри функции и освобождается перед выходом. Проблема в том, что этого не происходит, если функция прекращает работу досрочно. Обратите внимание на одинаковый код в блоках . Скорее всего, автор скопировал верхний фрагмент и забыл добавить вызов .\r\nЕще пример, аналогичный предыдущему.\r\nПредупреждение анализатора:  CWE-401 The function was exited without releasing the 'interface' pointer. A memory leak is possible. nanostackemacinterface.cpp 204\r\nУказатель на выделенную память возвращается через выходной параметр, но только если вызов  прошел успешно, а в случае ошибки происходит утечка, потому что локальная переменная  выходит из области видимости, и указатель попросту теряется. Здесь следовало бы либо вызвать , либо хотя бы отдать хранящийся в переменной  адрес наружу в любом случае, чтобы об этом мог позаботиться вызывающий код.\r\nИспользование функции  часто приводит к ошибкам, примеры связанных с ней проблем можно посмотреть в статье \"\".\r\nРассмотрим такое предупреждение анализатора: CWE-628 The 'memset' function processes '0' elements. Inspect the third argument. mbed_error.c 282\r\nПрограммист намеревался обнулить память, занимаемую структурой , но перепутал местами второй и третий аргумент. В результате  байт заполняется значением .\r\nТочно такая же ошибка присутствует сотней строк выше: CWE-628 The 'memset' function processes '0' elements. Inspect the third argument. mbed_error.c 123\r\nПредупреждение анализатора:  CWE-670 An unconditional 'return' within a loop. thread_network_data_storage.c 2348\r\nВ этом фрагменте  — это макрос, который раскрывается в оператор . Внутренний цикл выполняет не больше одной итерации из-за вызова  сразу после строки, в которой инициализируется выходной параметр функции. Возможно, этот код работает так, как задумано, но использование внутреннего цикла выглядит в этом контексте довольно странно. Скорее всего, инициализация  и выход из функции должны выполняться по условию, или от внутреннего цикла можно избавиться.\r\nКак я говорил выше, анализатор выдал довольно большое количество неинтересных предупреждений , поэтому я изучал их бегло и выписал для статьи только два случая. CWE-570 Expression 'pcb->state == LISTEN' is always false. lwip_tcp.c 689\r\nАнализатор считает, что условие  всегда ложно, давайте разберемся, почему. \r\nПеред оператором  используется макрос , который по логике своей работы напоминает . Его объявление выглядит так:\r\nЕсли условие ложно, макрос сообщает об ошибке и выполняет код, переданный через параметр , в этом фрагменте кода — безусловный переход с использованием .\r\nВ данном примере проверяется условие 'pcb->state == CLOSED', то есть переход на метку  происходит в случае, когда  имеет любое другое значение. Оператор , следующий за вызовом , проверяет  на равенство , но это условие никогда не выполняется, потому что  в этой строке может содержать только значение .\r\nРассмотрим еще одно предупреждение, связанное с условиями:  CWE-570 The use of 'if (A) {...} else if (A) {...}' pattern was detected. There is a probability of logical error presence. Check lines: 62, 65. libdhcpv6_server.c 62\r\nЗдесь  и  проверяют одно и то же условие, в результате чего код в теле  никогда не выполняется. Такие ошибки часто возникают при написании кода методом ''.\r\nПосмотрим напоследок на забавный фрагмент кода.\r\nПредупреждение анализатора:  Ownerless expression '& discover_response_tlv'. thread_discovery.c 562\r\nА теперь давайте взглянем на объявление макроса :\r\nМакрос раскрывается в аргумент data, то есть его вызов внутри функции  после препроцессирования превращается в выражение .\r\nУ меня комментариев нет. Наверное, это не ошибка, но такой код всегда вводит меня в состояние, подобному изображению на картинке :).\r\nСписок поддерживаемых в PVS-Studio компиляторов пополнился. Если у вас есть проект, предназначенный для сборки с помощью GNU Arm Embedded Toolchain, предлагаю попробовать проверить его с помощью нашего анализатора. Скачать демонстрационную версию можно . Обратите также внимание на вариант с , который подходит для некоторых небольших проектов.\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: Yuri Minaev. .", "url": "https://habr.com/ru/company/pvs-studio/blog/427447/"},
{"title": "﻿Почему перенос при целочисленном переполнении — не очень хорошая идея", "article_text": " в русском языке нет четкого соответствия в употребляемом контексте слова «wrap»/«wrapping». Существует математический термин \"\", который близок к описываемому явлению, а термин \"\" (carry flag) — механизм выставления флага в процессорах при целочисленном переполнении. Другим вариантом перевода может быть фраза «вращение/переворот/оборот вокруг нуля». Она лучше отображает смысл «wrap» по сравнению с «перенос», т.к. показывает переход чисел при переполнении из положительного в отрицательный диапазон. Однако, как оказалось, эти слова смотрятся в тексте непривычно для тестовых читателей. Для упрощения в дальнейшем примем в качестве перевода термина «wrap» слово «перенос».\r\nКомпиляторы языка C (и C++) в своей работе всё чаще руководствуются понятием  — представлением о том, что поведение программы при некоторых операциях не регламентировано стандартом и что, генерируя объектный код, компилятор вправе исходить из предположения, что программа таких операций не производит. Немало программистов возражало против такого подхода, поскольку сгенерированный код в этом случае может вести себя не так, как задумывал автор программы. Эта проблема становится всё острее, так как компиляторы применяют всё более хитроумные методы оптимизации, которые наверняка будут опираться на понятие неопределённого поведения.\r\nВ этом контексте показателен пример со знаковым целочисленным переполнением. Большинство разработчиков на C пишут код для машин, в которых для представления целых чисел используется , а сложение и вычитание в таком представлении реализованы точно так же, в беззнаковой арифметике. Если сумма двух положительных целых чисел со знаком переполнится — то есть станет больше, чем вмещает тип, — процессор выдаст значение, которое, будучи интерпретировано как двоичное дополнение знакового числа, будет считаться отрицательным. Это явление называется «переносом», поскольку результат, дойдя до верхней границы диапазона значений, «переносится» и начинается с нижней границы.\r\nПо этой причине можно иногда увидеть вот такой код на C:\r\nЗадача оператора  — обнаружить состояние переполнения (в данном случае оно возникает после прибавления 1000 к значению переменной ) и сообщить об ошибке. Проблема в том, что в C знаковое целочисленное переполнение является одним из случаев неопределённого поведения. Компиляторы с некоторых пор считают такие условия всегда ложными: если прибавить 1000 (или любое другое положительное число) к другому числу, результат не может быть меньше начального значения. Если же происходит переполнение, значит, возникает неопределённое поведение, и не допускать этого — уже (по-видимому) забота самого программиста. Поэтому компилятор может решить, что условный оператор можно целиком удалить в целях оптимизации (ведь условие всегда ложно, оно ни на что не влияет, значит, можно обойтись без него).\r\nПроблема в том, что этой оптимизацией компилятор убрал проверку, которую программист добавил специально, чтобы выявить неопределённое поведение и обработать его. Вот  можно посмотреть, как это происходит на практике. (Примечание: сайт godbolt.org, на котором размещён пример, очень классный! Можно редактировать код и сразу же смотреть, как его обрабатывают разные компиляторы, а их там представлено множество. Поэкспериментируйте!). Обратите внимание, что компилятор не убирает проверку на переполнение, если изменить тип на беззнаковый, поскольку поведение при беззнаковом переполнении в языке С определено (точнее, при беззнаковой арифметике результат переносится, поэтому переполнения на самом деле не происходит).\r\nТак что же, это неправильно? Кто-то говорит, что да, хотя очевидно, что многие разработчики компиляторов считают такое решение законным. Если я правильно понимаю, основные доводы сторонников (правка: зависящего от реализации) переноса при переполнении сводятся к следующему:\r\nРазберём каждый пункт по очереди:\r\nПеренос полезен в основном тогда, когда надо отследить уже возникшее переполнение. (Если и существуют другие задачи, которые решаются переносом и не могут быть решены с помощью беззнаковых целочисленных переменных, я не могу сходу припомнить таких примеров, и подозреваю, что их немного). При том, что перенос действительно упрощает проблему использования некорректно переполненных переменных, оно определённо не является панацеей (вспомним умножение или сложение двух неизвестных величин с неизвестным знаком).\r\nВ тривиальных же случаях, когда перенос просто позволяет отследить возникшее переполнение, так же не составит труда заранее узнать, возникнет ли оно вообще. Наш пример можно переписать в следующем виде:\r\nТо есть, вместо того чтобы вычислять сумму и затем выяснять, произошло переполнение или нет, проверяя результат на математическую непротиворечивость, можно проверить, превысит ли сумма максимальное вмещаемое типом число. (Если знак обоих операндов неизвестен, проверку придётся сильно усложнить, но то же касается и проверки при переносе).\r\nУчитывая всё это, я нахожу неубедительным аргумент, будто перенос полезен в большинстве случаев.\r\nС этим доводом сложнее спорить, поскольку очевидно, что код по крайней мере программистов на C предполагает семантику переноса при знаковом целочисленном переполнении. Но одного только этого факта недостаточно, чтобы считать такую семантику предпочтительной (заметьте, что некоторые компиляторы позволяют включить её, если необходимо).\r\nОчевидное решение проблемы (ожидание программистами именно этого поведения) — сделать так, чтобы компилятор выдавал предупреждение, когда он оптимизирует код, предполагая отсутствие неопределённого поведения. К сожалению, как мы видели в примере на сайте godbolt.org по ссылке выше, компиляторы не всегда поступают таким образом (Gcc версии 7.3 — да, а версии 8.1 — нет, так что налицо шаг назад).\r\nЕсли это замечание справедливо для всех случаев, то оно послужило бы сильным аргументом в пользу того, что компиляторы должны по умолчанию придерживаться семантики переноса, так как, пожалуй, будет лучше разрешить проверки на переполнение, пусть даже этот механизм некорректен с технической точки зрения — хотя бы уже потому, что он может использоваться в потенциально сломанном коде.\r\nЯ допускаю, что конкретно этой оптимизацией (удаление проверок математически противоречивых условий) в обычных программах на C зачастую можно пренебречь, так как их авторы стремятся к наилучшей производительности и всё равно оптимизируют код вручную: то есть, если очевидно, что данный оператор содержит условие, которое никогда не будет истинным, программист, скорее всего, уберёт его сам. В самом деле, я выяснил, что в нескольких исследованиях эффективность такой оптимизации была поставлена под вопрос, протестирована и признана практически несущественной в рамках контрольных тестов. Однако, хотя эта оптимизация почти никогда не даёт преимущества в языке C, генераторы кода и оптимизации компиляторов в большинстве своём универсальны и могут использоваться в других языках — и для них данный вывод может быть неверен. Возьмём язык C++ с его, скажем так, традицией полагаться на оптимизатор, чтобы тот убирал избыточные конструкции в коде шаблонов, а не делать это вручную. А ведь существуют и языки, которые преобразуются транспайлером в C, и при этом избыточный код в них также оптимизируется C-компиляторами.\r\nКроме того, даже если сохранить проверки на переполнение, вовсе не факт, что стоимость переноса целочисленных переменных будет минимальной даже на машинах, использующих дополнительный код. Архитектура Mips, например, может выполнять арифметические операции только в регистрах фиксированного размера (32 бита). Тип , как правило, имеет размер 16 бит, а  — 8 бит; при хранении в регистре переменной одного из этих типов её размер расширится, и, чтобы корректно перенести её, потребуется выполнить по крайней мере одну дополнительную операцию и, возможно, задействовать дополнительный регистр (чтобы вместить соответствующую битовую маску). Должен признать, что я уже давно не имел дела с кодом для Mips, так что я не уверен насчёт точной стоимости этих операций, но я уверен, что она ненулевая и что на других архитектурах RISC могут возникнуть такие же проблемы.\r\nЕсли разобраться, этот аргумент особенно слаб. Его суть в том, что стандарт якобы позволяет реализации (компилятору) трактовать «неопределённое поведение» лишь в ограниченных пределах. В самом же тексте стандарта — в том его фрагменте, к которому апеллируют сторонники переноса, — сказано следующее (это часть определения понятия «неопределённое поведение»):\r\nПРИМЕЧАНИЕ: \r\nИдея в том, что слова «полное игнорирование ситуации» не позволяют предполагать, что событие, приводящее к неопределённому поведению, — например, переполнение при сложении — не может произойти, а скорее, что если оно случается, то компилятор должен продолжить работу как ни в чем не бывало, но при этом также учитывать результат, который получится, если он пошлёт процессору запрос на выполнение такой операции (другими словами, как если бы исходный код транслировался в машинный прямолинейно и наивно).\r\nПрежде всего, следует заметить, что этот текст дан как «примечание», а потому не является нормативным (т.е. не может что-то предписывать), согласно директиве ISO, упомянутой в предисловии к стандарту:\r\nПоскольку этот фрагмент о «неопределённом поведении» является примечанием, он ничего не предписывает. Обратите внимание, что настоящее определение понятия «неопределённое поведение» звучит так:\r\nЯ выделил главную мысль: к неопределённому поведению не предъявляется никаких требований; список «возможных видов неопределённого поведения» в примечании содержит лишь примеры и не может быть окончательным предписанием. Фразу «не предъявляет никаких требований» невозможно истолковать как-то иначе.\r\nНекоторые, развивая данный аргумент, утверждают, что независимо от текста комитет по языку, когда он формулировал эти слова, , что поведение в целом должно соответствовать архитектуре аппаратного обеспечения, на котором выполняется программа, настолько, насколько это возможно, подразумевая наивную трансляцию в машинный код. Это может быть правдой, хотя я не видел никаких свидетельств (например, исторических документов) в защиту этого довода. Однако, даже если бы это было так, не факт, что это утверждение применимо к текущей редакции текста.\r\nДоводы в защиту переноса по большей части несостоятельны. Пожалуй, самый сильный аргумент получается, если их объединить: на перенос иногда рассчитывают менее опытные программисты (которые не знают тонкостей языка C и неопределённого поведения в нем), и оно не снижает производительность — хотя последнее верно не во всех случаях, а первая часть неубедительна, если рассматривать её отдельно.\r\nЛично я предпочёл бы, чтобы переполнения блокировались (trapping), а не переносились. То есть, чтобы программа падала, а не продолжала работать — с неопределённым ли поведением или потенциально некорректным результатом, ведь и в том, и в другом случае появляется уязвимость. Такое решение, конечно, немного снизит производительность на большинстве (?) архитектур, особенно на x86, но, с другой стороны, ошибки, связанные с переполнением, будут сразу выявлены и ими не получится воспользоваться или получить с их помощью некорректные результаты дальше по ходу выполнения программы. Кроме того, в теории компиляторы при таком подходе могли бы безопасно удалять избыточные проверки на переполнение, поскольку оно  не случится, хотя, как я вижу, ни Clang, ни GСС этой возможностью не пользуются.\r\nК счастью, и прерывание, и перенос реализованы в компиляторе, которым я пользуюсь чаще всего, — GCC. Для переключения между режимами используются аргументы командной строки  и  соответственно.\r\nДействий, приводящих к неопределённому поведению, конечно же, много — целочисленное переполнение лишь одно из них. Я вовсе не считаю, что все эти случаи полезно трактовать как неопределённое поведение, и я уверен, что существует немало специфических ситуаций, когда семантика должна определяться языком или, по крайней мере, оставаться на усмотрение реализаций. И я опасаюсь излишне вольных трактовок этого понятия производителями компиляторов: если поведение компилятора не отвечает интуитивным представлениям разработчиков, особенно тех, кто лично читал текст стандарта, это может привести к реальным ошибкам; если прирост производительности в этом случае пренебрежимо мал, то лучше от таких трактовок отказаться. В одном из следующих постов я, возможно, разберу некоторые из этих проблем.\r\nДополнение (от 24 августа 2018 года)\r\nЯ понял, что многое из сказанного выше можно было бы написать лучше. Ниже я кратко резюмирую и поясню свои слова и добавлю несколько мелких замечаний: Перевод статьи публикуется в блоге с разрешения автора. Оригинальный текст: Davin McCall \"\".\r\nДополнительные ссылки по теме от команды PVS-Studio:", "url": "https://habr.com/ru/company/pvs-studio/blog/427683/"},
{"title": "﻿Как PVS-Studio оказался внимательнее, чем три с половиной программиста", "article_text": "\r\nPVS-Studio, как и другие статические анализаторы кода, часто выдаёт ложные срабатывания. Но не стоит спешить считать странные срабатывания ложными. Это короткая история о том, как PVS-Studio вновь оказался внимательнее нескольких человек.\r\nНам в поддержку написал пользователь, утверждая, что анализатор выдаёт сразу четыре ложных срабатывания на одну строчку кода. Письмо, написанное в поддержку, изначально попало к Евгению Рыжкову, который, бегло прочитав его и не заметив аномального в фидбеке, сразу переслал его ведущему разработчику Святославу Размыслову. Евгений не всматривался в код, так что будет честно посчитать его только за половину программиста :).\r\nСвятослав прочитал письмо и засомневался, что анализатор мог так грубо ошибиться. Поэтому он пришёл ко мне на консультацию. У Святослава была надежда, что мой глаз намётан и я замечу что-то такое, что подскажет, почему анализатор выдал все эти странные сообщения. К сожалению, я только подтвердил, что сообщения действительно очень странные и их не должно быть. Однако что же послужило причиной их возникновения, я заметить не смог. Было решено открыть задачу в багтрекере и начать разбираться, что же не так.\r\nИ только когда Святослав начал делать синтетические примеры, чтобы подробно расписать проблему в багтрекере, на него снизошло озарение. Давайте теперь посмотрим, сможете ли вы быстро найти причину, почему анализатор выдаёт 4 сообщения.\r\nВот текст письма, публикуемый с разрешения автора. И поясняющая картинка, которая была прикреплена к письму.\r\nV560 warnings here are all false. Running with most recent version of PVS-Studio for personal use. Basically, «IF» statement is correct. Outer one is done for speed — inner ones are still needed and non are always true or false.\r\nТеперь, уважаемый читатель, ваше время проверить себя! Видите ошибку?\r\nВаше время проявить внимательность. А единорог пока немного подождёт.\r\nПосле вводной части статьи, скорее всего многие нашли ошибку. Когда настроен найти ошибку, она находится. Намного сложнее заметить ляп после прочтения письма, где это называется «ложными срабатываниями» :).\r\nТеперь пояснение для тех, кто поленился искать баг. Ещё раз рассмотрим условие:\r\nАвтор кода планировал проверить, что символ не входит ни в один из трёх диапазонов.\r\nОшибка в том, что оператор логический NOT (!) применяется только к первому подвыражению. \r\nЕсли выполнилось условие:\r\nто вычисление выражения прерывается согласно . Если условие не выполняется, то значение переменной  лежит в диапазоне [0xFF10..0xFF19]. Соответственно, четыре дальнейших сравнения не имеют смысла. Все они будут ложными или истинными.\r\nЕщё раз. Смотрите, если  лежит в диапазоне  и продолжается вычисление выражения, то:\r\nОб этом и предупреждает анализатор PVS-Studio.\r\nВот так, статический анализатор оказался внимательнее пользователя и двух с половиной программистов из нашей команды.\r\nЧтобы исправить ситуацию, надо добавить дополнительные скобки:\r\nИли переписать условие:\r\nВпрочем, я не могу рекомендовать к использованию ни один из этих вариантов. Я бы для упрощения чтения кода написал так:\r\nОбратите внимание, что я убрал часть скобок. Как только что мы видели, большое количество скобок вовсе не помогло избежать ошибки. Скобки должны облегчать чтение кода, а не усложнять. Программисты хорошо помнят, что приоритет сравнений =<, => выше, чем у оператора &&. Поэтому здесь скобки не нужны. А вот если спросить, что приоритетней — && или ||, многие растеряются. Поэтому для задания последовательности вычислений &&, || скобки лучше поставить.\r\nПочему лучше писать || в начале я описывал в статье \"\" (см. главу: Выравнивайте однотипный код «таблицей»).\r\nВсем спасибо за внимание. Скачивайте и начинайте использовать . Он поможет выявлять многие ошибки и потенциальные уязвимости на самых ранних этапах.\r\nЕсли хотите поделиться этой статьей с англоязычной аудиторией, то прошу использовать ссылку на перевод: Andrey Karpov. .", "url": "https://habr.com/ru/company/pvs-studio/blog/427309/"},
{"title": "Новое в SObjectizer-5.5.23: исполнение желаний или ящик Пандоры?", "article_text": "\r\nДанная статья является продолжением опубликованной месяц назад статьи-размышлении \"\". В той статье описывалась задача, которую мы хотели решить в очередной версии SObjectizer-а, рассматривались два подхода к ее решению и перечислялись достоинства и недостатки каждого из подходов.\r\nПрошло время, один из подходов был воплощен в жизнь и новые версии , а также сопутствующего ему , уже, что называется «задышали полной грудью». Можно в буквальном смысле брать и пробовать.\r\nСегодня же мы поговорим о том, что было сделано, зачем это было сделано, к чему это привело. Если кому-то интересно следить за тем, как развивается один из немногих живых, кросс-платформенных и открытых акторных фреймворков для C++, милости прошу под кат.\r\nНачиналось все с попытки решить проблему гарантированной отмены таймеров. Суть проблемы в том, что когда отсылается отложенное или периодическое сообщение, то программист может отменить доставку сообщения. Например:\r\nПосле вызова  таймер больше не будет отсылать новые экземпляры сообщения my_message. Но те экземпляры, которые уже были отосланы и попали в очереди получателей, никуда не денутся. Со временем они будут извлечены из этих самых очередей и будут переданы агентам-получателям для обработки.\r\nПроблема эта является следствием базовых принципов работы SObjectizer-5 и не имеет простого решения из-за того, что SObjectizer не может изымать сообщения из очередей. Не может потому, что в SObjectizer очереди принадлежат диспетчерам, диспетчеры бывают разные, очереди у них также организованы по разному. В том числе  и SObjectizer в принципе не может знать, как эти диспетчеры работают.\r\nВ общем, есть вот такая особенность у родных таймеров SObjectizer-а. Не то, чтобы она слишком уж портила жизнь разработчикам. Но некоторую дополнительную внимательность нужно проявлять. Особенно новичкам, которые только знакомятся с фреймворком.\r\nИ вот, наконец, руки дошли до того, чтобы предложить решение для этой проблемы.\r\nВ  рассматривалось два возможных варианта. Первый вариант не требовал модификаций механизма доставки сообщений в SObjectizer-е, но зато требовал от программиста явным образом изменять тип отсылаемого/получаемого сообщения.\r\nВторой вариант требовал модификации механизма доставки сообщений SObjectizer-а. Именно этот путь и был выбран, поскольку он позволял прятать от получателя сообщения тот факт, что сообщение было отослано каким-то специфическим образом.\r\nПервая составляющая реализованного решения — это добавление в SObjectizer такого понятия, как конверт (envelope). Конверт — это специальное сообщение, внутри которого лежит актуальное сообщение (payload). SObjectizer доставляет конверт с сообщением до получателя почти что обычным способом. Принципиальная разница в обработке конверта обнаруживается лишь на самом последнем этапе доставки:\r\nЗдесь есть два ключевых момента, которые оказывают серьезнейшее влияние на то, для чего и как могут использоваться конверты с сообщениями.\r\nПервый ключевой момент в том, что у конверта сообщение запрашивается только тогда, когда у получателя найден обработчик для сообщения. Т.е. только тогда, когда сообщение действительно доставлено до получателя и получатель вот прямо здесь и сейчас будет это сообщение обрабатывать.\r\nВторой ключевой момент здесь в том, что конверт может не отдать находящееся в нем сообщение. Т.е., например, конверт может проверить текущее время и решить, что все сроки доставки были пропущены и, поэтому, сообщение перестало быть актуальным и обрабатывать его нельзя. Посему конверт не отдаст сообщение наружу. Соответственно, SObjectizer просто проигнорирует этот конверт и никаких дополнительных действий предпринимать не будет.\r\nКонверт — это реализация интерфейса envelope_t, который определен следующим образом:\r\nТ.е. конверт — это, по сути такое же сообщение, как и все остальные. Но со специальным признаком, который и возвращается методом so5_message_kind().\r\nПрограммист может разрабатывать свои конверты наследуясь от envelope_t (или, что более удобно, от ) и переопределяя методы-хуки handler_found_hook() и transformation_hook().\r\nВнутри методов-хуков разработчик конверта решает, хочет ли он отдать находящееся внутри конверта сообщение для обработки/трансформации или не хочет. Если хочет, то разработчик должен вызвать метод invoke() и объекта invoker. Если не хочет, то не вызывает, в этом случае конверт и его содержимое будет проигнорированно.\r\nРешение, которое сейчас реализовано в so_5_extra в виде пространства имен so_5::extra::revocable_timer, очень простое: при особой отсылке отложенного или периодического сообщения создается специальный конверт, внутри которого находится не только само сообщение, но и атомарный флаг revoked. Если этот флаг сброшен, то сообщение считается актуальным. Если выставлен, то сообщение считается отозванным.\r\nКогда у конверта вызывается метод-хук, то конверт проверяет значение флага revoked. Если флаг выставлен, то конверт не отдает сообщение наружу. Тем самым, обработка сообщения не выполняется даже если таймер уже успел поместить сообщение в очередь получателя.\r\nДобавление интерфейса envelope_t — это только одна часть реализации конвертов в SObjectizer. Вторая часть — это учет факта существования конвертов в механизме доставки сообщений внутри SObjectizer-а.\r\nТут, к сожалению, не обошлось без внесения видимых для пользователя изменений. В частности, в класс abstract_message_box_t, который определяет интерфейс всех почтовых ящиков в SObjectizer-е, потребовалось добавить еще один виртуальный метод:\r\nЭтот метод отвечает за доставку до получателя конверта message с сообщением типа msg_type внутри. Такая доставка может отличаться в деталях реализации в зависимости от того, что это за mbox.\r\nПри добавлении do_deliver_enveloped_msg() в abstract_message_box_t у нас был выбор: сделать его чистым виртуальным методом или же предложить какую-то реализацию по умолчанию.\r\nЕсли бы мы сделали do_deliver_enveloped_msg() чистым виртуальным методом, то мы бы поломали совместимость между версиями SObjectizer в ветке 5.5. Ведь тогда тем пользователям, которые написали собственные реализации mbox-ов, пришлось бы при переходе на SObjectizer-5.5.23 модифицировать собственные mbox-ы, иначе бы не удалось пройти компиляцию с новой версией SObjectizer-а.\r\nНам этого не хотелось, поэтому мы не стали делать do_deliver_enveloped_msg() чистым виртуальным методом в v.5.5.23. Он имеет реализацию по умолчанию, которая просто бросает исключение. Т.о., кастомные пользовательские mbox-ы смогут нормально продолжать работу с обычными сообщениями, но будут автоматически отказываться принимать конверты. Мы сочли такое поведение более приемлемым. Тем более, что на начальном этапе вряд ли конверты с сообщениями будут применяться широко, да и маловероятно что в «дикой природе» часто встречаются кастомные реализации SObjectizer-овских mbox-ов ;)\r\nКроме того, существует далеко не нулевая вероятность, что в последующих мажорных версиях SObjectizer-а, где мы не будем оглядываться на совместимость с веткой 5.5, интерфейс abstract_message_box_t претерпит серьезные изменения. Но это мы уже забегаем далеко вперед…\r\nСам SObjectizer-5.5.23 не предоставляет простых средств отсылки конвертов. Предполагается, что под конкретную задачу разрабатывается конкретный тип конверта и соответствующие инструменты для удобной отсылки конвертов конкретного типа. Пример этого можно увидеть в , где нужно не только отослать конверт, но и отдать пользователю специальный timer_id.\r\nДля более простых ситуаций можно воспользоваться средствами из . Например, вот так выглядит отсылка сообщения с заданным ограничением на время его доставки:\r\nКонверты предназначены для переноса внутри себя каких-то сообщений. Но каких?\r\nЛюбых.\r\nИ это подводит нас к интересному вопросу: а можно ли вложить конверт внутрь другого конверта?\r\nДа, можно. Сколько угодно. Глубина вложенности ограничена только здравым смыслом разработчика и глубиной стека для рекурсивного вызова handler_found_hook/transformation_hook.\r\nПри этом SObjectizer идет навстречу разработчикам собственных конвертов: конверт не должен думать о том, что у него внутри — конкретное сообщение или другой конверт. Когда у конверта вызывают метод-хук и конверт решает, что он может отдать свое содержимое, то конверт просто вызывает invoke() у handler_invoker_t и передает в invoke() ссылку на свое содержимое. А уже invoke() внутри сам разберется, с чем он имеет дело. И если это еще один конверт, то invoke() сам вызовет у этого конверта нужный метод-хук.\r\nС помощью уже показанного выше инструментария из so_5::extra::enveloped_msg пользователь может сделать несколько вложенных конвертов вот таким образом:\r\nТеперь, после того, как мы прошлись по внутренностям SObjectizer-5.5.23 пора бы уже перейти к более полезной для пользователей, прикладной части. Ниже рассматривается несколько примеров, которые либо базируются на том, что уже реализовано в so_5_extra, либо используют инструменты из so_5_extra.\r\nПоскольку вся эта кухня с конвертами затевалась ради решения проблемы гарантированного отзыва таймерых сообщений, то давайте посмотрим, что в итоге получилось. Будем использовать пример из so_5_extra-1.2.0, который задействует инструменты из нового пространства имен so_5::extra::revocable_timer:\r\nЧто мы здесь имеем?\r\nУ нас есть агент, который сперва инициирует несколько таймерных сообщений, а потом блокирует свою рабочую нить на некоторое время. За это время таймер успевает поставить в очередь агента несколько заявок в результате сработавших таймеров: несколько экземпляров periodic, по одному экземпляру first_delayed и second_delayed.\r\nСоответственно, когда агент разблокирует свою нить, он должен получить первый periodic и first_delayed. При обработке first_delayed агент отменяет доставку periodic-а и second_delayed. Поэтому эти сигналы до агента доходить не должны вне зависимости от того, есть ли они уже в очереди агента или нет (а они есть).\r\nСмотрим на результат работы примера:\r\nДа, так и есть. Получили первый periodic и first_delayed. Затем нет ни periodic-а, ни second_delayed.\r\nА вот если в примере заменить «таймеры» из so_5::extra::revocable_timer на штатные таймеры из SObjectizer, то результат будет другой: до агента все-таки дойдут те экземпляры сигналов periodic и second_delayed, которые уже попали к агенту в очередь.\r\nЕще одна полезная, временами, штука, которая станет доступной в so_5_extra-1.2.0 — это доставка сообщения с ограничением по времени. Например, агент request_handler отсылает сообщение verify_signature агенту crypto_master. При этом request_handler хочет, чтобы verify_signature был доставлен в течении 5 секунд. Если это не произошло, то смысла в обработке verity_signature уже не будет, агент request_handler уже прекратит свою работу.\r\nА агент crypto_master — это такой товарищ, который любит оказываться «бутылочным горлышком»: временами начинает притормаживать. В такие момент у него в очереди скапливаются сообщения, вроде вышеуказанного verify_signature, которые могут ждать до тех пор, пока crypto_master-у не полегчает.\r\nПредположим, что request_handler отослал сообщение verify_signature агенту crypto_master, но тут crypto_master-у поплохело о он «залип» на 10 секунд. Агент request_handler уже «отвалился», т.е. уже отослал всем отказ в обслуживании и завершил свою работу. Но ведь сообщение verify_signature в очереди crypto_master-а осталось! Значит, когда crypto_master «отлипнет», то он возьмет данное сообщение и будет это сообщение обрабатывать. Хотя это уже не нужно.\r\nС помощью нового конверта so_5::extra::enveloped_msg::time_limited_delivery_t мы можем решить данную проблему: агент request_handler отошлет verify_signature вложенное в конверт time_limited_delivery_t с ограничением на время доставки:\r\nТеперь если crypto_master «залипнет» и не успеет добраться до verify_signature за 5 секунд, то конверт просто не отдаст это сообщение на обработку. И crypto_master не будет делать работу, которая уже никому не нужна.\r\nНу и напоследок пример любопытной штуки, которая не реализована штатно ни в SObjectizer, ни в so_5_extra, но которую можно сделать самостоятельно.\r\nИногда хочется получать от SObjectizer-а что-то вроде «отчета о доставке» сообщения до получателя. Ведь одно дело, когда сообщение до получателя дошло, но получатель по каким-то своим причинам на него не среагировал. Другое дело, когда сообщение вообще до получателя не дошло. Например, было заблокировано . В первом случае сообщение, на которое мы не дождались ответа, можно не перепосылать. А вот во втором случае может иметь смысл перепослать сообщение спустя некоторое время.\r\nСейчас мы рассмотрим, как посредством конвертов можно реализовать простейший механизм «отчетов о доставке».\r\nИтак, сначала сделаем необходимые подготовительные действия:\r\nТеперь мы можем определить сообщения, которые будут использоваться в примере. Первое сообщение — это запрос для выполнения каких-то нужных нам действий. А второе сообщение — это подтверждение того, что первое сообщение дошло до получателя:\r\nДалее мы можем определить агента processor_t, который будет обрабатывать сообщения типа request_t. Но обрабатывать будет с имитацией «залипания». Т.е. он обрабатывает request_t, после чего меняет свое состояние с st_normal на st_busy. В состоянии st_busy он ничего не делает и игнорирует все сообщения, которые к нему прилетают.\r\nЭто означает, что если агенту processor_t отослать подряд три сообщения request_t, то первое он обработает, а два других будут выброшены, т.к. при обработке первого сообщения агент уйдет в st_busy и проигнорирует то, что к нему будет приходить пока он находится в st_busy.\r\nВ st_busy агент processor_t проведет 2 секунды, после чего вновь вернется в st_normal и будет готов обрабатывать новые сообщения.\r\nВот как агент processor_t выглядит:\r\nТеперь мы можем определить агента requests_generator_t, у которого есть пачка запросов, которые нужно доставить до processor_t. Агент request_generator_t раз в 3 секунды отправляет всю пачку, а затем ждет подтверждения о доставке в виде delivery_receipt_t.\r\nКогда delivery_recept_t приходит, агент requests_generator_t выбрасывает доставленный запрос из пачки. Если пачка совсем опустела, то работа примера завершается. Если же еще что-то осталось, то оставшаяся пачка будет отослана заново когда наступит следующее время перепосылки.\r\nИтак, вот код агента request_generator_t. Он довольно объемный, но примитивный. Обратить внимание можно разве что на внутренности метода send_requests(), в котором отсылаются сообщения request_t, вложенные в специальный конверт.\r\nВот теперь у нас есть сообщения и есть агенты, которые с помощью этих сообщений должны общаться. Осталась самая малость — как-то заставить прилетать сообщения delivery_receipt_t при доставке request_t до processor_t.\r\nДелается это с помощью вот такого конверта:\r\nВ общем-то, здесь нет ничего сложного. Мы наследуемся от so_5::extra::enveloped_msg::just_envelope_t. Это вспомогательный тип конверта, который хранит вложенное в него сообщение и предоставляет базовую реализацию хуков\r\nhandler_found_hook() и transformation_hook(). Поэтому нам остается только сохранить внутри custom_envelope_t нужные нам атрибуты и отослать delivery_receipt_t внутри хука handler_found_hook().\r\nВот, собственно, и все. Если запустить данный пример, то получим следующее:\r\nВ качестве дополнения нужно сказать, что на практике такой простой custom_envelope_t для формирования отчетов о доставке вряд ли подойдет. Но если кому-то интересна эта тема, то ее можно обсудить в комментариях, а не увеличивать объем статьи.\r\nОтличный вопрос! На который у нас самих пока нет исчерпывающего ответа. Вероятно, возможности ограничиваются разве что фантазией пользователей. Ну а если для воплощения фантазий в SObjectizer-е чего-то не хватает, то об этом можно сказать нам. Мы всегда прислушиваемся. И, что немаловажно, временами даже делаем :)\r\nЕсли же говорить чуть более серьезно, то есть еще одна фича, которую хотелось бы временами иметь и которая даже планировалась для so_5_extra-1.2.0. Но которая, скорее всего, в релиз 1.2.0 уже не попадет.\r\nРечь идет о том, чтобы упростить интеграцию -ов и агентов.\r\nДело в том, что первоначально mchain-ы были добавлены в SObjectizer для того, чтобы упростить общение агентов с другими частями приложения, которые написаны без агентов. Например, есть главный поток приложения, на котором с помощью GUI идет взаимодействие с пользователем. И есть несколько агентов-worker-ов, которые выполняют фоновую «тяжелую» работу. Отослать сообщение агенту из главного потока не проблема: достаточно вызвать обычный send. А вот как передать информацию назад?\r\nДля этого и были добавлены mchain-ы.\r\nНо со временем выяснилось, что mchain-ы могут играть гораздо большую роль. Можно, в принципе, делать многопоточные приложения на SObjectizer-е вообще без агентов, только на mchain-ах (подробнее ). А еще можно использовать mchain-ы как средство балансировки нагрузки на агентов. Как механизм решения проблемы producer-consumer.\r\nПроблема producer-consumer заключается в том, что если producer генерирует сообщения быстрее, чем их может обрабатывать consumer, то нас ждут неприятности. Очереди сообщений будут расти, со временем может деградировать производительность или вообще произойдет вылет приложения из-за исчерпания памяти.\r\nОбычное решение, которое мы предлагали использовать в этом случае — это использовать . Так же можно использовать и  (либо как основной механизм защиты, либо как дополнение к collector-performer). Но написание collector-performer требует дополнительной работы от программиста.\r\nА вот mchain-ы могли бы использоваться для этих целей с минимальными усилиями со стороны разработчика. Так, producer бы помещал очередное сообщение в mchain, а consumer бы забирал сообщения из этого mchain.\r\nНо проблема в том, что когда consumer — это агент, то агенту не очень удобно работать с mchain-ом посредством имеющихся функций receive() и select(). И вот это неудобство можно было бы попробовать устранить с помощью какого-то инструмента для интеграции агентов и mchain-ов.\r\nПри разработке такого инструмента нужно будет решить несколько задачек. Например, когда сообщение приходит в mchain, то в какой момент оно должно быть из mchain-а извлечено? Если consumer свободен и ничего не обрабатывает, то можно забрать сообщение из mchain-а сразу и отдать его агенту-consumer-у. Если consumer-у уже было отослано сообщение из mchain-а, он это сообщение еще не успел обработать, но в mchain уже приходит новое сообщение… Как быть в этом случае?\r\nЕсть предположение, что конверты могут помочь в этом случае. Так, когда мы берем первое сообщение из mchain-а и отсылаем его consumer-у, то мы оборачиваем это сообщение в специальный конверт. Когда конверт видит, что сообщение доставлено и обработано, он запрашивает следующее сообщение из mchain-а (если таковое есть).\r\nКонечно, здесь все не так просто. Но пока что выглядит вполне решаемо. И, надеюсь, подобный механизм появится в одной из следующих версий so_5_extra.\r\nНужно отметить, что у нас самих добавленные возможности вызывают двойственные чувства.\r\nС одной стороны, конверты уже позволили/позволяют сделать вещи, о которых ранее говорилось (а о чем-то просто мечталось). Например, это гарантированная отмена таймеров и ограничение на время доставки, отчеты о доставки, возможность отзыва ранее отосланного сообщения.\r\nС другой стороны, непонятно, к чему это приведет впоследствии. Ведь из любой возможности можно сделать проблему, если начать эту возможность эксплуатировать где нужно и где не нужно. Так может мы приоткрываем ящик Пандоры и сами еще не представляем, что нас ждет?\r\nОстается только набраться терпения и посмотреть, куда это все нас приведет.\r\nВместо заключения хочется рассказать о том, каким мы видим самое ближайшее (и не только) будущее SObjectizer-а. Если кого-то что-то в наших планах не устраивает, то можно высказаться и повлиять на то, как SObjectizer-5 будет развиваться.\r\nПервые бета-версии SObjectizer-5.5.23 и so_5_extra-1.2.0 уже зафиксированы и доступны для загрузки и экспериментов. К релизу нужно будет проделать еще много работы в области документации и примеров использования. Поэтому официальный релиз планируется в первой декаде ноября. Если получится раньше, сделаем раньше.\r\nРелиз SObjectizer-5.5.23, судя по всему, будет означать, что эволюция ветки 5.5 подходит к своему финалу. Самый . С тех пор SObjectizer-5 эволюционировал в рамках ветки 5.5 без каких-либо серьезных ломающих изменений между версиями. Это было непросто. Особенно с учетом того, что все это время нам приходилось оглядываться на компиляторы, в которых была далеко не идеальная поддержка C++11.\r\nСейчас мы уже не видим смысла оглядываться на совместимость внутри ветки 5.5 и, особенно, на старые C++ компиляторы. То, что можно было оправдать в 2014-ом, когда C++14 еще только готовились официально принять, а C++17 еще не было на горизонте, сейчас уже выглядит совсем по-другому.\r\nПлюс к тому, в самом SObjectizer-5.5 уже накопилось изрядное количество граблей и подпорок, которые появились из-за этой самой совместимости и которые затрудняют дальнейшее развитие SObjectizer-а.\r\nПоэтому мы в ближайшие месяцы собираемся действовать по следующему сценарию:\r\n1. Разработка следующей версии so_5_extra, в которую хочется добавить инструментарий для упрощения написания тестов для агентов. Будет ли это so_5_extra-1.3.0 (т.е. с ломающими изменениями относительно 1.2.0) или это будет so_5_extra-1.2.1 (т.е. без ломающих изменений) пока не понятно. Посмотрим, как пойдет. Понятно только, что следующая версия so_5_extra будет базироваться на SObjectizer-5.5.\r\n1a. Если для следующей версии so_5_extra потребуется сделать что-то дополнительное в SObjectizer-5.5, то будет выпущена следующая версия 5.5.24. Если же для so_5_extra не нужно будет вносить доработки в ядро SObjectizer-а, то версия 5.5.23 окажется последней значимой версией в рамках ветки 5.5. Мелкие bug-fix релизы будут выходить. Но само развитие ветки 5.5 прекращается на версии 5.5.23 или 5.5.24.\r\n2. Затем будет выпущена версия SObjectizer-5.6.0, которая откроет новую ветку. В ветке 5.6 мы вычистим код SObjectizer-а от всех накопившихся костылей и подпорок, а также от старого хлама, который давным давно помечен, как deprecated. Вероятно, какие-то вещи подвергнуться рефакторингу (например, может быть изменен abstract_message_box_t), но вряд ли кардинальному. Основные же принципы работы и характерные черты SObjectizer-5.5 в SObjectizer-5.6 останутся в том же виде.\r\nSObjectizer-5.6 будет требовать уже C++14 (хотя бы на уровне GCC-5.5). Компиляторы Visual C++ ниже VC++ 15 (который из Visual Studio 2017) поддерживаться не будут.\r\nВетка 5.6 рассматривается нами как стабильная ветка SObjectizer-а, которая будет актуальна до тех пор, пока не появится первая версия SObjectizer-5.7.\r\nРелиз версии 5.6.0 хотелось бы сделать в начале 2019-го года, ориентировочно в феврале.\r\n3. После стабилизации ветки 5.6 мы бы хотели начать работать над веткой 5.7, в которой можно было бы пересмотреть какие-то базовые принципы работы SObjectizer-а. Например, совсем отказаться от публичных диспетчеров, оставив только приватные. Переделать механизм коопераций и их взаимоотношений родитель-потомок, тем самым избавившись от узкого места при регистрации/дерегистрации коопераций. Убрать деление на message/signal. Оставить для отсылки сообщений только send/send_delayed/send_periodic, а методы deliver_message и schedule_timer упрятать «под капот». Модифицировать механизм диспетчеризации сообщений так, чтобы либо совсем убрать dynamic_cast-ы из этого процесса, либо свести их к самому минимуму.\r\nВ общем, тут есть где развернуться. При этом SObjectizer-5.7 уже будет требовать C++17, без оглядки на C++14.\r\nЕсли смотреть на вещи без розовых очков, то хорошо, если релиз 5.7.0 состоится в конце осени 2019. Т.е. основной рабочей версией SObjectizer-а на 2019-й будет ветка 5.6.\r\n4. Параллельно всему этому будет развиваться so_5_extra. Вероятно, вместе с SObjectizer-5.6 будет выпущена версия so_5_extra-2, которая на протяжении 2019-го года будет вбирать в себя новый функционал, но на базе SObjectizer-5.6.\r\nТаким образом мы сами видим для SObjectizer-5 поступательную эволюцию с постепенным пересмотром каких-то из базовых принципов работы SObjectizer-5. При этом мы постараемся делать это как можно более плавно, чтобы можно было с минимальными болевыми ощущениями переходить с одной версии на другую.\r\nОднако, если кто-то хотел бы от SObjectizer-а более кардинальных и значимых изменений, то . Если совсем коротко: можно переделать SObjectizer как угодно, вплоть до того, чтобы реализовать SObjectizer-6 для другого языка программирования. Но делать это полностью за свой счет, как это происходит с эволюцией SObjectizer-5, мы не будем.\r\nНа этом, пожалуй, все. В комментариях  получилось хорошее и конструктивное обсуждение. Нам было бы полезно, если бы подобное обсуждение случилось и в этот раз. Как всегда мы готовы ответить на любые вопросы, а на толковые, так и с удовольствием.\r\nА самым терпеливым читателям, добравшимся до этих строк большое спасибо за потраченное на прочтение статьи время.", "url": "https://habr.com/ru/post/426983/"},
{"title": "Как правильно и неправильно спать", "article_text": "Не так давно мимо нас пробегала неплохая статья об ужасном состоянии производительности современного ПО (, ). Эта статья напомнила мне об одном антипаттерне кода, который встречается весьма часто и в общем кое-как работает, но приводит к небольшим потерям производительности то тут, то там. Ну, знаете, мелочь, пофиксить которую руки никак не дойдут. Беда лишь в том, что десяток таких «мелочей», разбросанных в разных местах кода начинают приводить к проблемам типа «вроде у меня последний Intel Core i7, а прокрутка дёргается».Я говорю о неверном использовании функции  (регистр может отличаться в зависимости от языка программирования и платформы). Итак, что же такое Sleep? Документация отвечает на этот вопрос предельно просто: это пауза в выполнении текущего потока на указанное количество миллисекунд. Нельзя не отметить эстетическую красоту прототипа данной функции: \r\nВсего один параметр (предельно понятный), никаких кодов ошибок или исключений — работает всегда. Таких приятных и понятных функций очень мало!\r\nЧто же могло пойти не так? То, что программисты используют эту замечательную функцию не для того, для чего она предназначена.\r\nА предназначена она для программной симуляции какого-то внешнего, определённого чем-то реальным, процесса паузы. \r\nМы пишем приложение «часы», в котором раз в секунду нужно менять цифру на экране (или положение стрелки). Функция Sleep здесь подходит как нельзя лучше: нам реально нечего делать чётко определённый промежуток времени (ровно одну секунду). Почему бы и не поспать?\r\nМы пишем контроллер  хлебопечки. Алгоритм работы задаётся одной из программ и выглядит примерно так: \r\nЗдесь тоже всё чётко: мы работаем со временем, оно задано технологическим процессом. Использование Sleep — приемлемо.\r\nА теперь посмотрим на примеры неверного использования Sleep.\r\nКогда мне нужен какой-то пример некорректного кода на С++ — я иду в  кода текстового редактора Notepad++. Его код ужасен настолько, что любой антипаттерн там точно найдётся, я об этом даже  когда-то писал. Не подвёл меня ноутпадик++ и в этот раз! Давайте посмотрим, как в нём используется Sleep.\r\nПри старте Notepad++ проверяет, не запущен ли уже другой экземпляр его процесса и, если это так, ищет его окно и отправляет ему сообщение, а сам закрывается. Для детектирования другого своего процесса используется стандартный способ — глобальный именованный мьютекс. Но вот для поиска окон написан следующий код:\r\nПрограммист, писавший этот код, попытался найти окно уже запущенного Notepad++ и даже предусмотрел ситуацию, когда два процесса были запущены буквально одновременно, так что первый из них уже создал глобальный мьютекс, но ещё не создал окно редактора. В этом случае второй процесс будет ждать создания окна «5 раз по 100 мс». В итоге мы или не дождёмся вообще, или потеряем до 100 мс между моментом реального создания окна и выходом из Sleep.\r\nЭто и есть первый (и один из главных) антипаттернов использования Sleep. Мы ждём не наступление события, а «сколько-то миллисекунд, вдруг повезёт». Ждём столько, чтобы с одной стороны не очень раздражать пользователя, а с другой стороны — иметь шанс дождаться нужного нам события. Да, пользователь может не заметить паузы в 100 мс при старте приложения. Но если подобная практика «ждать сколько-нибудь от балды» будет принята и допустима в проекте — закончиться это может тем, что ждать мы будем на каждом шагу по самым мелочным причинам. Здесь 100 мс, там ещё 50 мс, а здесь вот 200 мс — и вот у нас программа уже «почему-то тормозит несколько секунд». \r\nКроме того, просто эстетически неприятно видеть код, работающий долго в то время, как он мог бы работать быстро. В данном конкретном случае можно было бы использовать функцию , подписавшись на событие HSHELL_WINDOWCREATED — и получить нотификацию о создании окна мгновенно. Да, код становиться чуть сложнее, но буквально на 3-4 строки. И мы выигрываем до 100 мс! А самое главное — мы больше не используем функции безусловного ожидания там, где ожидание не является безусловным.\r\nЯ не очень разбирался, чего конкретно и как долго ждёт этот код в Notepad++, но общий антипаттерн «запустить поток и подождать» я видел часто. Люди ждут разного: начала работы другого потока, получения из него каких-то данных, окончания его работы. Плохо здесь сразу два момента:\r\nЗдесь мы видим фоновый поток, который спит в ожидании каких-то событий. \r\nНужно признать, что здесь используется не Sleep, а , который более интеллектуален и может прерывать ожидание при некоторых событиях (типа завершения асинхронных операций). Но это нисколько не помогает! Дело в том, что цикл while (!m_bTerminate) имеет полное право работать бесконечно, игнорируя вызванный из другого потока метод RequestTermination(), сбрасывающий переменную m_bTerminate в true. О причинах и следствия этого я писал в . Для избегания этого следовало бы использовать что-то, гарантированно правильно работающее между потоками: atomic, event или что-то подобное.\r\nДа, формально SleepEx не виноват в проблеме использования обычной булевой переменной для синхронизации потоков, это отдельная ошибка другого класса. Но почему она стала возможной в этом коде? Потому, что сначала программист подумал «тут надо спать», а затем задумался как долго и по какому условию прекратить это делать. А в правильном сценарии у него даже и не должно было бы возникнуть первой мысли. В голове должно была бы возникнуть мысль «тут надо ожидать события» — и вот с этого момента мысль уже бы работала в сторону выбора правильного механизма синхронизации данных между потоками, который исключил бы как булевскую переменную, так и использование SleepEx.\r\nВ этом примере мы посмотрим на функцию backupDocument, которая выполняет роль «автосохранялки», полезной на случай непредвиденного падения редактора. По-умолчанию она спит 7 секунд, затем даёт команду сохранить изменения (если они были). \r\nИнтервал поддаётся изменению, но не в этом беда. Любой интервал будет одновременно слишком большим и слишком малым. Если мы набираем одну букву в минуту — нет никакого смысла спать всего 7 секунд. Если мы откуда-то копипастим 10 мегабайт текста — не нужно ждать после этого ещё 7 секунд, это достаточно большой объём, чтобы инициировать бекап немедленно (вдруг мы его откуда-то вырезали и там его не осталось, а редактор через секунду крешнется). \r\nТ.е. простым ожиданием мы здесь заменяем отсутствующий более интеллектуальный алгоритм.\r\nNotepad++ умеет «набирать текст» — т.е. эмулировать ввод текста человеком, делая паузы между вставкой букв. Вроде бы писалось это как «пасхальное яйцо», но можно придумать и какое-нибудь рабочее применение этой фиче ().\r\nБеда здесь в том, что в код вшито представление о каком-то «среднем человеке», делающем паузу 400-800 мс между каждой нажатой клавишей. Ок, может это «в среднем» и нормально. Но вы знаете, если используемая мною программа делает какие-то паузы в своей работы просто потому, что они кажутся ей красивыми и подходящими — это совсем не значит, что я разделяю её мнение. Мне хотелось бы иметь возможность настройки длительности данных пауз. И, если в случае Notepad++ это не очень критично, то в других программах мне иногда встречались настройки типа «обновлять данные: часто, нормально, редко», где «часто» не было для меня достаточно часто, а «редко» — не было достаточно редко. Да и «нормально» не было нормально. Подобный функционал должен давать пользователю возможность точно указать количество миллисекунд, который он хотел бы ждать до выполнения нужного действия. С обязательной возможностью ввести «0». Причём 0 в данном случае вообще не должен даже передаваться аргументом в функцию Sleep, а просто исключать её вызов (Sleep(0) на самом деле не возвращается мгновенно, а отдаёт оставшийся кусок выданного планировщиком временного слота другому потоку).\r\nС помощью Sleep можно и нужно выполнять ожидание тогда, когда это именно безусловно заданное ожидание в течение конкретного промежутка времени и есть какое-то логическое объяснение, почему он такой: «по техпроцессу», «время рассчитано вот по этой формуле», «столько ждать сказал заказчик». Ожидание каких-то событий или синхронизация потоков не должны реализовываться с использованием функции Sleep.", "url": "https://habr.com/ru/company/infopulse/blog/427843/"},
{"title": "Численная проверка abc-гипотезы (да, той самой)", "article_text": "Привет, Habr.\r\nНа  Habr было уже несколько статей про abc-гипотезу (например  и  годах). Сама история про теорему, которую сначала много лет не могут доказать, а потом столько же лет не могут проверить, безусловно заслуживает как минимум, художественного фильма. Но в тени этой чудесной истории, сама теорема рассматривается черезчур поверхностно, хотя она не менее интересна. Уже хотя бы тем, что abc-гипотеза — одна из немногих нерешенных проблем современной науки, постановку задачи которой сможет понять даже пятиклассник. Если же эта гипотеза действительно верна, то из нее легко следует доказательство других важных теорем, например доказательство .\r\nНе претендуя на лавры Мотидзуки, я  решил проверить с помощью компьютера, насколько выполняются обещанные в гипотезе равенства. Собственно, почему бы нет — современные процессоры ведь не только для того чтобы в игры играть — почему бы не использовать компьютер по своему основному (compute — вычислять) предназначению…\r\nКому интересно что получилось, прошу под кат.\r\nНачнем с начала. О чем собственно, теорема? Как гласит  (формулировка в английской версии немного более понятна), для взаимно-простых (не имеющих общих делителей) чисел a, b и с, таких что a+b=c, для любого ε>0 существует  троек a+b=c, таких что: \r\nФункция rad называется , и обозначает произведение простых множителей числа. Например, rad(16) = rad(2*2*2*2) = 2, rad(17) = 17 (17 простое число), rad(18) = rad(2*3*3) = 2*3 = 6, rad(1000000) = rad(2^6 ⋅ 5^6) = 2*5 = 10.\r\nСобственно, суть теоремы в том, что количество таких троек довольно мало. Например, если взять наугад ε=0.2 и равенство 100+27=127: rad(100) = rad(2*2*5*5) = 10, rad(27)=rad(3*3*3)=3, rad(127) = 127, rad(a*b*c) = rad(a)*rad(b)*rad(с) = 3810, 3810^1.2 явно больше 127, неравенство не выполняется. Но бывают и исключения, например для равенства 49 + 576 = 625 условие теоремы выполняется (желающие могут проверить самостоятельно).\r\nСледующий ключевой для нас момент — этих равенств, согласно теореме, ограниченное число. Т.е. это значит, что их все можно просто попытаться перебрать на компьютере. В итоге, это дает нам  вполне интересную задачу по программированию. \r\nИтак, приступим.\r\nПервая версия была написана на Python, и хотя этот язык слишком медленный для подобных расчетов, писать код на нем легко и просто, что удобно для прототипирования.: раскладываем число на простые множители, затем убираем повторы, преобразуя массив в множество. Затем просто получаем произведение всех элементов.: раскладываем числа на множители, и просто проверяем пересечение множеств.: используем уже созданные функции, тут все просто.\r\nЖелающие могут поэкспериментировать самостоятельно, скопировав вышеприведенный код в любой онлайн-редактор языка Python. Разумеется, код работает ожидаемо медленно, и перебор всех троек хотя бы до миллиона был бы слишком долгим. Ниже под спойлером есть оптимизированная версия, рекомендуется использовать ее.\r\nОкончательная версия была переписана на С++ с использованием многопоточности и некоторой оптимизации (работать на Си с пересечением множеств было бы слишком хардкорно, хотя вероятно и быстрее). Исходный код под спойлером, его можно скомпилировать в бесплатном компиляторе g++, код работает под Windows, OSX и даже на Raspberry Pi.\r\nДля тех кому лень устанавливать компилятор С++, приведена слегка оптимизированная Python-версия, запустить которую можно в любом онлайн редакторе (я использовал ).\r\nТроек a,b,c действительно очень мало. \r\nНекоторые результаты приведены ниже:: 1 «тройка», время выполнения <0.001c\r\n1 + 8 = 9: 2 «тройки», время выполнения <0.001c\r\n1 + 8 = 9\r\n1 + 80 = 81: 8 «троек», время выполнения <0.01c\r\n1 + 8 = 9\r\n1 + 80 = 81\r\n1 + 242 = 243\r\n1 + 288 = 289\r\n1 + 512 = 513\r\n3 + 125 = 128\r\n13 + 243 = 256\r\n49 + 576 = 625: 23 «тройки», время выполнения 2с: 53 «тройки», время выполнения 50c\r\nПри  имеем всего лишь 102 «тройки», полный список приведен под спойлером.\r\nУвы, программа работает все равно медленно, результатов для N=10000000 я так и не дождался, время вычисления составляет больше часа (возможно я где-то ошибся с оптимизацией алгоритма, и можно сделать лучше).\r\nЕще интереснее посмотреть результаты графически:\r\nВ принципе, вполне очевидно, что зависимость количества возможных троек от N растет заметно медленнее самого N, и вполне вероятно, что результат будет сходиться к какому-то конкретному числу для каждого ε. Кстати, при увеличении ε число «троек» заметно сокращается, например при ε=0.4 имеем всего 2 равенства при N<100000 (1 + 4374 = 4375 и 343 + 59049 = 59392). Так что в целом, похоже что теорема действительно выполняется (ну и наверное ее уже проверяли на компьютерах помощнее, и возможно, все это уже давно посчитано).\r\nЖелающие могут поэкспериментировать самостоятельно, если у кого будут результаты для чисел 10000000 и выше, я с удовольствием добавлю их к статье. Разумеется, было бы интересно «досчитать» до того момента, когда множество «троек» совсем перестанет расти, но это может занять реально долгое время, скорость расчета похоже зависит от N как N*N (а может и N^3), и процесс весьма долгий. Но тем не менее, удивительное рядом, и желающие вполне могут присоединиться к поиску.\r\nПравка: как подсказали в комментариях, в Википедии  уже есть — в диапазоне N до 10^18 количество «троек» все же растет, так что «конец» множества пока не найден. Тем интереснее — интрига пока сохраняется.", "url": "https://habr.com/ru/post/427091/"},
{"title": "Реализация алгоритма k-means (k-средних) на примере работы с пикселями", "article_text": "Всем привет! Недавно нужно было написать код для реализации сегментации изображения с помощью метода k – средних (англ. k-means). Ну, первым делом Google в помощь. Нашел много информации, как и с математической точки зрения (всякие там сложные математические каракули, хрен поймёшь, что там написано), так и некоторые программные реализации, которые есть в английском интернете. Эти коды конечно прекрасны – спору нет, но саму суть идеи сложно поймать. Как – то оно там все сложно, запутано, да и пока сам, ручками, не пропишешь код, ничего не поймешь. В этой статье хочу показать простую, не производительную, но, надеюсь, понятную реализацию этого чудесного алгоритма. Ладно, погнали!\r\nИтак, что такое кластеризация с точки зрения нашего восприятия? Приведу пример, допустим, есть милое изображение с цветочками с дачи твоей бабушки.\r\nВопрос следующий: определить, сколько на данном фото участков, залитых приблизительно одним цветом. Ну это совсем не сложно: белые лепестки – раз, желтые центры – два (я не биолог, как они именуются, не знаю), зелень – три. Эти участки и называются кластерами. Кластер -объединение данных, имеющих общие признаки (цвет, положение и т.д.). Процесс определения и помещения каждой составляющей каких-либо данных в такие кластеры — участки и называется кластеризацией.\r\nЕсть много алгоритмов кластеризации, но самый простой из них — k – средних, о котором дальше и пойдет речь. K-средних – простой и эффективный алгоритм, который легко реализовать программным методом. Данные, которые мы будем распределять по кластерам — пиксели. Как известно, цветной пиксель имеет три составляющих — red, green и blue. Наложение этих составляющих и создает палитру существующих цветов.\r\nВ памяти компьютера каждая составляющая цвета характеризуется числом от 0 до 255. То есть комбинируя различные значения красного, зеленого и синего, получаем палитру цветов на экране.\r\nНа примере пикселей мы и реализуем наш алгоритм. K-средних – итерационный алгоритм, то есть он даст правильный результат, после энного количества повторов некоторых математических вычислений.\r\nРеализовывать данный проект я буду на С++. Первый файл – «k_means.h», в нем я определил основные типы данных, константы, и основной класс для работы — «K_means».\r\nДля характеристики каждого пикселя создадим структуру, которая состоит из трех составляющих пикселя, для которых я выбрал тип double для более точных расчетов, а также определил некоторые константы для работы программы:\r\nСам класс K_means:\r\nПробежимся по составляющим класса: \r\nvectorpixcel — вектор для пикселей;\r\nq_klaster – количество кластеров;\r\nk_pixcel – количество пикселей;\r\nvectorcentr – вектор для центров кластеризации, количество элементов в нем определяется q_klaster;\r\nidentify_centers() – метод для случайного выбора начальных центров среди входных пикселей;\r\ncompute() и compute_s() встроенные методы для расчета расстояния между пикселями и пересчета центров соответственно;\r\nтри конструктора: первый по умолчанию, второй — для инициализации пикселей из массива, третий — для инициализации пикселей из текстового файла (в моей реализации сначала файл случайно заполняется данными, и потом с этого файла считываются пиксели для работы программы, почему не напрямую в вектор – просто так нужно в моем случае);\r\nclustering(std::ostream & os) – метод кластеризации;\r\nметод и перегрузка оператора вывода для публикации результатов.\r\nРеализация методов:\r\nЭто метод для выбора начальных центров кластеризации и добавления их в вектор центров. Осуществляется проверка на повтор центров и замена их в этих случаях.\r\nРеализация конструктора для инициализации пикселей из массива. \r\nВ этот конструктор мы передаем объект ввода для возможности ввода данных как из файла, так и из консоли.Основной метод кластеризации.\r\nВывод начальных данных.\r\nЭтот пример спланирован наперед, пиксели выбраны специально для демонстрации. Программе достаточно двух итераций, чтобы сгруппировать данные в три кластера. Посмотрев на центры двух последних итераций, можно заметить, что они практически остались на месте.\r\nИнтереснее случаи при рандомной генерации пикселей. Сгенерировав 50 точек, которые нужно поделить на 10 кластеров, я получил 5 итераций. Сгенерировав 50 точек, которые нужно поделить на 3 кластера, я получил все 100 максимально допустимых итераций. Можно заметить, что чем больше кластеров, тем легче программе найти наиболее схожие пиксели и объединить их в меньшие группы, и наоборот — если кластеров мало, а точек много, часто алгоритм завершается только от превышения максимально допустимого количества итераций, так как некоторые пиксели постоянно прыгают из одного кластера в другой. Тем не менее, основная масса все равно определяются в свои кластеры окончательно. \r\nНу а теперь давайте проверим результат кластеризации. Взяв результат некоторых кластеров из примера 50 точек на 10 кластеров, я вбил результат этих данных в Illustrator и вот что получилось:\r\nВидно, что в каждом кластере преобладают какие-либо оттенки цвета, и тут нужно понимать, что пиксели были выбраны случайно, аналогом такого изображения в реальной жизни является какая-то картина, на которую случайно набрызгали всех красок и выделить участки схожих цветов сложно. \r\nДопустим, у нас есть такое фото. Остров мы можем определить, как один кластер, но при увеличении мы видим, что он состоит из разных оттенков зеленого.\r\nА это 8 кластер, но в уменьшенном варианте, результат аналогичен:\r\nПолную версию программы можно посмотреть на моем .", "url": "https://habr.com/ru/post/427761/"},
{"title": "Разработка интерфейсных классов на С++", "article_text": "Интерфейсным классом называется класс, не имеющий данных и состоящий в основном из чисто виртуальных функций. Такое решение позволяет полностью отделить реализацию от интерфейса — клиент использует интерфейсный класс, — в другом месте создается производный класс, в котором переопределяются чисто виртуальные функции и определяется функция-фабрика. Детали реализации полностью скрыты от клиента. Таким образом реализуется истинная инкапсуляция, невозможная при использовании обычного класса. Про интерфейсные классы можно почитать у Скотта Мейерса [Meyers2]. Интерфейсные классы также называют классами-протоколами.Использование интерфейсных классов позволяет ослабить зависимости между разными частями проекта, что упрощает командную разработку, снижается время компиляции/сборки. Интерфейсные классы делают более простой реализацию гибких, динамических решений, когда модули подгружаются выборочно во время исполнения. Использование интерфейсных классов в качестве интерфейса (API) библиотек (SDK) упрощает решение проблем двоичной совместимости.Интерфейсные классы используются достаточно широко, с их помощью реализуют интерфейс (API) библиотек (SDK), интерфейс подключаемых модулей (plugin’ов) и многое другое. Многие паттерны Банды Четырех [GoF] естественным образом реализуются с помощью интерфейсных классов. К интерфейсным классам можно отнести COM-интерфейсы. Но, к сожалению, при реализации решений на основе интерфейсныx классов часто допускаются ошибки. Попробуем навести ясность в этом вопросе.В этом разделе кратко описывается ряд особенностей C++, которые надо знать, чтобы полностью понимать решения, предлагаемые для интерфейсных классов.Если программист не определил функции-члены класса из следующего списка — конструктор по умолчанию, копирующий конструктор, оператор копирующего присваивания, деструктор, — то компилятор может сделать это за него. С++11 добавил к этому списку перемещающий конструктор и оператор перемещающего присваивания. Эти функции-члены называются специальные функции-члены. Они генерируются, только если они используются, и выполняются дополнительные условия, специфичные для каждой функции. Обратим внимание, на то, что это использование может оказаться достаточно скрытым (например, при реализации наследования). Если требуемая функция не может быть сгенерирована, выдается ошибка. (За исключением перемещающих операций, они заменяются на копирующие.) Генерируемые компилятором функции-члены являются открытыми и встраиваемыми.Специальные функции-члены не наследуются, если в производном классе требуется специальная функция-член, то компилятор всегда будет пытаться ее генерировать, наличие определенной программистом соответствующей функции-члена в базовом классе на это не влияет.Программист может запретить генерацию специальных функций-членов, в С++11 надо применить при объявлении конструкцию , в С++98 объявить соответствующую функцию-член закрытой и не определять. При наследовании классов, запрет генерации специальной функции-члена, сделанный в базовом классе, распространяется на все производные классы.Если программиста устраивает функции-члены, генерируемые компилятором, то в С++11 он может обозначить это явно, а не просто опустив объявление. Для этого при объявлении надо использовать конструкцию , код при этом лучше читается и появляется дополнительные возможности, связанные с управлением уровнем доступа.Подробности о специальных функциях-членах можно найти в [Meyers3].Создание и удаление объектов с помощью операторов  — это типичная операция «два в одном». При вызове  сначала выделяется память для объекта. Если выделение прошло успешно, то вызывается конструктор. Если конструктор выбрасывает исключение, то выделенная память освобождается. При вызове оператора  все происходит в обратном порядке: сначала вызывается деструктор, потом освобождается память. Деструктор не должен выбрасывать исключений.Если оператор  используется для создания массива объектов, то сначала выделяется память для всего массива. Если выделение прошло успешно, то вызывается конструктор по умолчанию для каждого элемента массива начиная с нулевого. Если какой-нибудь конструктор выбрасывает исключение, то для всех созданных элементов массива вызывается деструктор в порядке, обратном вызову конструктора, затем выделенная память освобождается. Для удаления массива надо вызвать оператор  (называется оператор  для массивов), при этом для всех элементов массива вызывается деструктор в порядке, обратном вызову конструктора, затем выделенная память освобождается.Внимание! Необходимо вызывать правильную форму оператора  в зависимости от того, удаляется одиночный объект или массив. Это правило надо соблюдать неукоснительно, иначе можно получить неопределенное поведение, то есть может случиться все, что угодно: утечки памяти, аварийное завершение и т.д. Подробнее см. [Meyers2].Стандартные функции выделения памяти при невозможности удовлетворить запрос выбрасывают исключение типа .Любую форму оператора  безопасно применять к нулевому указателю.В приведенном выше описании необходимо сделать одно уточнение. Для так называемых тривиальных типов (встроенные типы, структуры в стиле С), конструктор может не вызываться, а деструктор в любом случае ничего не делает. См. также раздел 1.6.Когда оператор  применяется к указателю на класс, деструктор этого класса должен быть доступен в точке вызова . (Есть некоторое исключение из этого правила, рассмотренное в разделе 1.6.) Таким образом, делая деструктор защищенным или закрытым, программист запрещает использование оператора  там, где деструктор недоступен. Напомним, что если в классе не определен деструктор, компилятор это сделает самостоятельно, и этот деструктор будет открытым (см. раздел 1.1).Если оператор  создал объект, то вызов оператора  для его удаления должен быть в том же модуле. Образно говоря, «положи туда, где взял». Это правило хорошо известно, см., например [Sutter/Alexandrescu]. При нарушении этого правила может произойти «нестыковка» функций выделения и освобождения памяти, что, как правило, приводит к аварийному завершению программы.Если проектируется полиморфная иерархия классов, экземпляры которых удаляются с помощью оператора , то в базовом классе должен быть открытый виртуальный деструктор, это гарантирует вызов деструктора фактического типа объекта при применении оператора  к указателю на базовый класс. При нарушении этого правила может произойти вызов деструктора базового класса, из-за чего возможна утечка ресурсов.Определенные проблемы может создать «всеядность» оператора , его можно применить к указателю типа  или к указателю на класс, который имеет неполное (упреждающее) объявление. В этом случае ошибки не происходит, просто вызов деструктора пропускается, вызывается только функция освобождения памяти. Рассмотрим пример:Этот код компилируется, даже если в точке вызова  не доступно полное объявление класса . Правда, при компиляции (Visual Studio) выдается предупреждение:Если есть реализация  и , то код компонуется, если  возвращает указатель на объект, созданный оператором , то вызов  успешно выполняется, деструктор при этом не вызывается. Понятно, что это может привести к утечке ресурсов, так что еще раз о необходимости внимательно относится к предупреждениям.Ситуация эта не надумана, она легко может возникнуть при использовании классов типа интеллектуального указателя или классов-дескрипторов. Скотт Мейерс разбирается с этой проблемой в [Meyers3].Концепция интерфейсных классов базируется на таких понятиях С++ как чисто виртуальные функции и абстрактные классы.Виртуальная функция, объявленная с использованием конструкции , называется чисто виртуальной.В отличии от обычной виртуальной функции, чисто виртуальную функцию можно не определять (за исключением деструктора, см. раздел 2.3), но она должна быть переопределена в одном из производных классов.Чисто виртуальные функции могут быть определены. Герб Саттер предлагает несколько полезных применений для этой возможности [Shutter].Абстрактным классом называется класс, имеющий хотя бы одну чисто виртуальную функцию. Абстрактным будет также класс, производный от абстрактного класса и не переопределяющий хотя бы одну чисто виртуальную функцию. Стандарт С++ запрещает создавать экземпляры абстрактного класса, можно создавать только экземпляры производных не абстрактных классов. Таким образом, абстрактный класс создается, чтобы использоваться в качестве базового класса. Соответственно, если в абстрактном классе определяется конструктор, то его не имеет смысла делать открытым, он должен быть защищенным.В ряде случаев чисто виртуальным целесообразно сделать деструктор. Но такое решение имеет две особенности.Пример использования чисто виртуального деструктора можно найти в разделе 4.4.Интерфейсным классом называется абстрактный класс, не имеющий данных и состоящий в основном из чисто виртуальных функций. Такой класс может иметь обычные виртуальные функции (не чисто виртуальные), например деструктор. Также могут быть статические функции-члены, например функции-фабрики.Реализацией интерфейсного класса будем называть производный класс, в котором переопределены чисто виртуальные функции. Реализаций одного и того же интерфейсного класса может быть несколько, причем возможны две схемы: горизонтальная, когда несколько разных классов наследуют один и тот же интерфейсный класс, и вертикальная, когда интерфейсный класс является корнем полиморфной иерархии. Конечно, могут быть и гибриды.Ключевым моментом концепции интерфейсных классов является полное отделение интерфейса от реализации — клиент работает только с интерфейсным классом, реализация ему не доступна.Недоступность класса реализации вызывает определенные проблемы при создании объектов. Клиент должен создать экземпляр класса реализации и получить указатель на интерфейсный класс, через который и будет осуществляться доступ к объекту. Так как класс реализации не доступен, то использовать конструктор нельзя, поэтому используется функция-фабрика, определяемая на стороне реализации. Эта функция обычно создает объект с помощью оператора  и возвращает указатель на созданный объект, приведенный к указателю на интерфейсный класс. Функция-фабрика может быть статическим членом интерфейсного класса, но это не обязательно, она, например, может быть членом специального класса-фабрики (который, в свою очередь, сам может быть интерфейсным) или свободной функцией. Функция-фабрика может возвращать не сырой указатель на интерфейсный класс, а интеллектуальный. Этот вариант рассмотрен в разделах 3.3.4 и 4.3.2.Удаление объекта является чрезвычайно ответственной операцией. При ошибке возникает либо утечка памяти, либо двойное удаление, которое обычно приводит к аварийному завершению программы. Ниже этот вопрос рассматривается максимально подробно, причем много внимания уделяется предупреждению ошибочных действий клиента.Существуют четыре основных варианта:Для этого в интерфейсном классе необходимо иметь открытый виртуальный деструктор. В этом случае оператор , вызванный для указателя на интерфейсный класс на стороне клиента обеспечивает вызов деструктора класса-реализации. Этот вариант может работать, но удачным его признать трудно. Мы получаем вызовы операторов  и  по разные стороны «барьера»,  на стороне реализации,  на стороне клиента. А если реализация интерфейсного класса сделана в отдельном модуле (что достаточно обычное дело), то получаем нарушение правила из раздела 1.4.Более прогрессивным является другой вариант: интерфейсный класс должен иметь специальную виртуальную функцию, которая и удаляет объект. Такая функция, в конце концов, сводится к вызову , но это происходит уже на стороне реализации. Называться такая функция может по-разному, например , но используются и другие варианты: , , , , , etc. Кроме соблюдения правила из раздела 1.4, этот вариант имеет несколько дополнительных преимуществ.В этом варианте попытка удаления объекта с помощью оператора  может компилироваться и даже выполняться, но это является ошибкой. Для ее предотвращения в интерфейсном классе достаточно иметь пустой или чисто виртуальный защищенный деструктор (см. раздел 1.3). Отметим, что использование оператора  может оказаться достаточно сильно замаскированным, например, стандартные интеллектуальные указатели для удаления объекта по умолчанию используют оператор  и соответствующий код глубоко «зарыт» в их реализации. Защищенный деструктор позволяет обнаружить все такие попытки на этапе компиляции.Этот вариант может привлечь определенной симметрией процедур создания и удаления объекта, но реально он никаких преимуществ по сравнению с предыдущим вариантом не имеет, а вот дополнительных проблем появляется много. Этот вариант не рекомендуется к использованию и в дальнейшем не рассматривается.В этом случае функция-фабрика возвращает не сырой указатель на интерфейсный класс, а соответствующий интеллектуальный указатель. Этот интеллектуальный указатель создается на стороне реализации и инкапсулирует объект-удалитель, который автоматически удаляет объект реализации, когда интеллектуальный указатель (или последняя его копия) выходит из области видимости на стороне клиента. В этом случае специальная виртуальная функция для удаления объекта реализации может не потребоваться, но защищенный деструктор по-прежнему нужен, необходимо предотвратить ошибочное использование оператора . (Правда, надо отметить, что вероятность такой ошибки заметно снижается.) Более подробно этот вариант рассмотрен в разделе 4.3.2.В ряде случаев клиент может получать указатель на интерфейсный класс, но не владеть им. Управления временем жизни объекта реализации находится полностью на стороне реализации. Например, объект может быть статическим объектом-синглтоном (такое решение характерно для фабрик). Другой пример связан с двунаправленным взаимодействием, см. раздел 3.7. Удалять такой объект клиент не должен, но защищенный деструктор для такого интерфейсного класса нужен, необходимо предотвратить ошибочное использование оператора .Для интерфейсного класса создание копии объекта реализации с помощью копирующего конструктора невозможно, поэтому если требуется копирование, то в классе должна быть виртуальная функция, создающая копию объекта реализации и возвращающая указатель на интерфейсный класс. Такую функцию часто называют виртуальным конструктором, и традиционное имя для нее  или .Использование оператора копирующего присваивания не запрещено, но нельзя признать удачной идеей. Оператор копирующего присваивания всегда является парным, он должен идти в паре с копирующим конструктором. Оператор, генерируемый компилятором по умолчанию, бессмыслен, он ничего не делает. Теоретически можно объявить оператор присваивания чисто виртуальным с последующим переопределением, но виртуальное присваивание является не рекомендуемой практикой, подробности можно найти в [Meyers1]. К тому же присваивание выглядит весьма неестественно: доступ к объектам класса реализации обычно осуществляется через указатель на интерфейсный класс, поэтому присваивание будет выглядеть так:Оператор присваивания лучше всего запретить, а при необходимости подобной семантики иметь в интерфейсном классе соответствующую виртуальную функцию.Запретить присваивание можно двумя способами.Часто конструктор интерфейсного класса не объявляется. В этом случае компилятор генерирует конструктор по умолчанию, необходимый для реализации наследования (см. раздел 1.1). Этот конструктор открытый, хотя достаточно, чтобы он был защищенным. Если в интерфейсном классе копирующий конструктор объявлен удаленным (), то генерация компилятором конструктора по умолчанию подавляется, и необходимо явно объявить такой конструктор. Естественно его сделать защищенным с определением по умолчанию (). В принципе, объявление такого защищенного конструктора можно делать всегда. Пример находится в разделе 4.4.Интерфейсные классы удобно использовать для организации двунаправленного взаимодействия. Если некоторый модуль доступен через интерфейсные классы, то клиент также может создать реализации некоторых интерфейсных классов и передать указатели на них в модуль. Через эти указатели модуль может получать сервисы от клиента а также передавать клиенту данные или нотификации.Так как доступ к объектам класса реализации обычно осуществляется через указатель, то для управления их временем жизни естественно воспользоваться интеллектуальными указателями. Но следует иметь в виду, что если используется второй вариант удаления объектов, то стандартным интеллектуальным указателем необходимо передать пользовательский удалитель (тип) или экземпляр этого типа. Если этого не сделать, то для удаления объекта интеллектуальный указатель будет использовать оператор , и код просто не будет компилироваться (благодаря защищенному деструктору). Стандартные интеллектуальные указатели (включая использование пользовательских удалителей) подробно рассмотрены в [Josuttis], [Meyers3]. Пример использования пользовательского удалителя можно найти в разделе 4.3.1.Если интерфейсный класс поддерживает счетчик ссылок, то целесообразно использовать не стандартные интеллектуальные указатели, а специально написанный для такого случая, это сделать достаточно легко.Следует с осторожностью объявлять функции-члены интерфейсных классов как const. Одним из важных достоинств интерфейсных классов является возможность максимально полного отделения интерфейса от реализации, но ограничения, связанные с константностью функции-члена, могут создать проблемы при разработке класса реализации.COM-интерфейсы являются примером интерфейсных классов, но следует иметь в виду, что COM — это независимый от языка программирования стандарт, и COM-интерфейсы можно реализовывать на разных языках, например на C, где нет ни деструкторов, ни защищенных членов. Разработка COM-интерфейсов на C++ должна вестись в соответствии с правилами, определяемыми технологией COM.Достаточно часто интерфейсные классы используются в качестве интерфейса (API) для целых библиотек (SDK). В этом случае целесообразно следовать следующей схеме. Библиотека имеет доступную функцию-фабрику, которая возвращает указатель на интерфейсный класс-фабрику, с помощью которого и создаются экземпляры классов реализации других интерфейсных классов. В этом случае для библиотек, поддерживающих явную спецификацию экспорта (Windows DLL), требуется всего одна точка экспорта: вышеупомянутая функция-фабрика. Весь остальной интерфейс библиотеки становится доступным через таблицы виртуальных функций. Именно такая схема позволяет максимально просто реализовывать гибкие, динамические решения, когда модули подгружаются выборочно во время исполнения. Модуль загружается с помощью  или ее аналогом на других платформах, далее получается адрес функции-фабрики, и после этого библиотека становится полностью доступной.Так как интерфейсный класс редко бывает один, то обычно целесообразно создать базовый класс.Вот демонстрационный интерфейсный класс.Отметим, что защищенный деструктор должен быть как в базовом классе, так и в интерфейсном классе. В базовом классе он нужен, потому что в некоторых сценариях клиент может использовать указатель на . В интерфейсном классе он нужен, потому что при его отсутствии компилятор сгенерирует открытый деструктор по умолчанию (см. раздел 1.3). Запрет присваивания достаточно сделать в базовом классе, он будет распространяться на все производные классы.В классе реализации деструктор является защищенным, конструктор, а также наследование от интерфейсного класса являются закрытыми, а функция-фабрика объявлена другом, это обеспечивает максимальную инкапсуляцию процедуры создания и удаления объекта.При создании интеллектуального указателя на стороне клиента необходимо использовать пользовательский удалитель. Класс-удалитель очень простой (он может быть вложен в ):Для  класс-удалитель является шаблонным параметром:Отметим, что благодаря тому, что класс-удалитель не содержит данных, размер  равен размеру сырого указателя.Вот шаблон функции-фабрики:Вот шаблон преобразования из сырого указателя в интеллектуальный:Экземпляры  можно инициализировать экземплярами , поэтому специальные функции, возвращающие  определять не нужно. Вот пример создания объектов типа .А этот ошибочный код благодаря защищенному деструктору не компилируется (конструктор должен принимать второй аргумент — объект-удалитель):Также нельзя использовать шаблон , он не поддерживает пользовательские удалители (соответствующий код не будет компилироваться).Описанная схема имеет недостаток: через интеллектуальный указатель можно вызвать виртуальную функцию удаления объекта реализации, что приведет к двойному удалению. Эту проблему можно решить так: сделать виртуальную функцию удаления защищенной, а класс-удалитель другом. Пример находится в разделе 4.4.Интеллектуальный указатель можно создавать на стороне реализации. В этом случае клиент получает его в качестве возвращаемого значения функциии-фабрики. Если использовать  и в его конструктор передать указатель на класс реализации, который имеет открытый деструктор, то пользовательский удалитель не нужен (и не требуется специальная виртуальная функция для удаления объекта реализации). В этом случае конструктор  (а это шаблон) создает объект-удалитель по умолчанию, который базируется на типе аргумента и при удалении применяет оператор  к указателю на объект реализации. Для  объект-удалитель входит в состав экземпляра интеллектуального указателя (точнее его управляющего блока) и тип объекта-удалителя не влияет на тип интеллектуального указателя. В этом варианте предыдущий пример можно переписать так.Для функции-фабрики более оптимальным является вариант с использованием шаблона :В описанном сценарии нельзя использовать , так как у него несколько иная стратегия удаления, класс-удалитель является шаблонным параметром, то есть является составной частью типа интеллектуального указателя.В отличие от C# или Java в C++ нет специального понятия «интерфейс», необходимое поведение моделируется с помощью виртуальных функций. Это дает дополнительную гибкость при реализации интерфейсного класса. Рассмотрим еще один вариант реализации .Чисто виртуальный деструктор нужно определить,  не чисто виртуальная функция, поэтому ее также нужно определить.Остальные интерфейсные классы наследуются от . Теперь при реализации интерфейсного класса не требуется переопределять , она определена в базовом классе и благодаря виртуальному деструктору обеспечивает вызов деструктора класса реализации. Класс-удалитель также естественно сделать вложенным в .  объявлена защищенной, класс-удалитель другом. Это запрещает непосредственный вызов  на стороне клиента и тем самым снижает вероятность ошибок, связанных с удалением объекта. Рассмотренный вариант ориентирован на использование интеллектуальных указателей, описанное в разделе 4.3.1.Если модуль, доступный через интерфейсные классы, проектируется как модуль, использующий исключения для сообщения об ошибках, то можно предложить следующий вариант реализации класса исключения.В заголовочном файле, доступном клиенту, объявляется интерфейсный класс  и обычный класс .При возникновении исключительной ситуации модуль выбрасывает исключение типа , клиент перехватывает это исключение и получает информацию через доступный указатель на . При необходимости клиент может пробросить исключение дальше, путем вызова оператора , или сохранить исключение. Первый конструктор класса  используется только в точке выброса исключения, его экспортировать из модуля не надо. Остальные функции-члены являются встраиваемыми и доступны как модулю, так и клиенту.Реализовать  можно, например, следующим образом.Класс реализации :Определение конструктора :Обратим внимание на то, что при программировании в смешанных решениях — .NET — родные модули, — такое исключение корректно проходит границу между родным и управляемым модулем, если он написан на C++/CLI. Таким образом, это исключение может быть выброшено в родном модуле, а перехвачено в управляемом классе, написанном на C++/CLI.Шаблон интерфейсного класса-коллекции может выглядеть следующим образом:С такой коллекцией уже можно достаточно комфортно работать, но при желании указатель на такой шаблонный класс можно обернуть в шаблон класса-контейнера, который предоставляет интерфейс в стиле контейнеров стандартной библиотеки.Такой контейнер реализовать совсем не сложно. Он владеет коллекцией, то есть выполняет ее освобождение в деструкторе. Возможно, это контейнер не полностью удовлетворяет требованиям, предъявляемым к стандартным контейнерам, но это не особенно нужно, главное он имеет функции-члены  и , которые возвращают итератор. А вот если итератор определен в соответствии со стандартом итератора (см. [Josuttis]), то с этим контейнером можно использовать диапазонный цикл  и стандартные алгоритмы. Определение итератора в соответствии с правилами стандартной библиотеки является достаточно объемным и поэтому здесь не приводится. Определения шаблонов классов контейнера и итератора полностью находится в заголовочных файлах и, следовательно, никаких функций дополнительно экспортировать не надо.Интерфейсные классы являются достаточно низкоуровневыми средствами программирования. Для более комфортной работы их желательно обернуть в классы-обертки, обеспечивающие автоматическое управление временем жизни объектов. Также обычно желательно иметь стандартные решения типа исключений и контейнеров. Выше было показано, как это можно сделать для программирования в среде С++. Но интерфейсные классы могут служить функциональной основой для реализации решений и на других платформах, таких как .NET, Java или Pyton. На этих платформах используются другие механизмы управления временем жизни объектов и другие стандартные интерфейсы. В этом случае надо создавать обертку, используя технологию, обеспечивающую интеграцию с целевой платформой и учитывающую особенности платформы. Например для .NET Framework такая обертка пишется на C++/CLI и она будет отличаться от предложенной выше обертки для C++. Пример можно посмотреть .Объект реализации интерфейсного класса создается функцией-фабрикой, которая возвращает указатель или интеллектуальный указатель на интерфейсный класс.Для удаления объекта реализации интерфейсного класса существуют три варианта.В первом варианте интерфейсный класс должен иметь открытый виртуальный деструктор.Во втором варианте интерфейсный класс должен иметь защищенный деструктор, который предохраняет от ошибочного использования оператора . Если в этом варианте для управления временем жизни объектов реализации интерфейсного класса используются стандартные интеллектуальные указатели, то им необходимо передать пользовательский удалитель.В третьем варианте функция-фабрика возвращает интеллектуальный указатель, который создается на стороне реализации и инкапсулирует процедуру удаления объекта реализации. В этом случае специальная виртуальная функция для удаления объекта реализации может не потребоваться, но защищенный деструктор нужен, необходимо предотвратить ошибочное использование оператора .Семантика копирования для объектов реализации интерфейсного класса реализуется с помощью специальных виртуальных функций.Интерфейсные классы позволяют упростить компоновку модулей, почти весь интерфейс модуля становится доступным через таблицы виртуальных функций, поэтому не сложно реализовывать гибкие, динамические решения, когда модули подгружаются выборочно во время исполнения.", "url": "https://habr.com/ru/post/427281/"}
]